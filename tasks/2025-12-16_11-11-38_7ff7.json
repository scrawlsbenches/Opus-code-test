{
  "version": 1,
  "session_id": "7ff7",
  "started_at": "2025-12-16T11:11:38.253282",
  "saved_at": "2025-12-16T11:23:16.323980",
  "tasks": [
    {
      "id": "T-20251216-111138-7ff7-001",
      "title": "Add error logging to ML session capture hook instead of silent suppression",
      "status": "pending",
      "priority": "low",
      "category": "maintenance",
      "description": "The ml-session-capture-hook.sh script at line 65 silently swallows all errors with '2>/dev/null || true'. While intentional to not block session end, this makes debugging difficult. Consider logging errors to ~/.ml-capture.log or similar.",
      "depends_on": [],
      "effort": "medium",
      "created_at": "2025-12-16T11:11:38.253714",
      "updated_at": null,
      "completed_at": null,
      "context": {},
      "retrospective": null
    },
    {
      "id": "T-20251216-111143-7ff7-002",
      "title": "Document ML training milestone thresholds derivation",
      "status": "pending",
      "priority": "low",
      "category": "docs",
      "description": "The MILESTONES dict in ml_data_collector.py (lines 82-86) contains magic numbers for training thresholds (500 commits, 100 sessions, etc). Add comments explaining how these thresholds were derived or link to research/documentation.",
      "depends_on": [],
      "effort": "medium",
      "created_at": "2025-12-16T11:11:43.009096",
      "updated_at": null,
      "completed_at": null,
      "context": {},
      "retrospective": null
    },
    {
      "id": "T-20251216-111146-7ff7-003",
      "title": "Make CSV export truncation limit configurable",
      "status": "pending",
      "priority": "low",
      "category": "enhancement",
      "description": "The CSV export in ml_data_collector.py (lines 1507-1510) truncates input/output fields to 1000 characters. This arbitrary limit should be configurable via command-line argument (e.g., --max-field-length) to allow users to adjust based on their needs.",
      "depends_on": [],
      "effort": "medium",
      "created_at": "2025-12-16T11:11:46.965042",
      "updated_at": null,
      "completed_at": null,
      "context": {},
      "retrospective": null
    },
    {
      "id": "T-20251216-111152-7ff7-004",
      "title": "Refactor session_logger.py to import from ml_data_collector instead of duplicating",
      "status": "pending",
      "priority": "low",
      "category": "refactor",
      "description": "The .claude/hooks/session_logger.py duplicates get_current_session() and start_session() logic from ml_data_collector.py. Refactor to import these functions from the main module to reduce code duplication and ensure consistency.",
      "depends_on": [],
      "effort": "medium",
      "created_at": "2025-12-16T11:11:52.061126",
      "updated_at": null,
      "completed_at": null,
      "context": {},
      "retrospective": null
    },
    {
      "id": "T-20251216-111935-7ff7-005",
      "title": "Improve ML file prediction by filtering out unrelated task management files",
      "status": "pending",
      "priority": "medium",
      "category": "enhancement",
      "description": "The ML file prediction model ranks task management files (task_utils.py, SKILL.md) highly when the query contains 'task' even when the query is about unrelated code tasks like 'Fix bug in query expansion'. Consider adding stop-word filtering or context-aware scoring.",
      "depends_on": [],
      "effort": "medium",
      "created_at": "2025-12-16T11:19:35.622304",
      "updated_at": null,
      "completed_at": null,
      "context": {},
      "retrospective": null
    },
    {
      "id": "T-20251216-111939-7ff7-006",
      "title": "Retrain ML model after analysis.py refactoring to improve predictions",
      "status": "pending",
      "priority": "low",
      "category": "maintenance",
      "description": "The analysis.py was recently refactored into cortical/analysis/ package with submodules (clustering.py, pagerank.py, etc). The model should be retrained with recent commits to learn these new file patterns. Run: python scripts/ml_file_prediction.py train",
      "depends_on": [],
      "effort": "medium",
      "created_at": "2025-12-16T11:19:39.941213",
      "updated_at": null,
      "completed_at": null,
      "context": {},
      "retrospective": null
    },
    {
      "id": "T-20251216-112131-7ff7-007",
      "title": "Investigate test file prediction accuracy in ML model",
      "status": "pending",
      "priority": "medium",
      "category": "investigation",
      "description": "The ML file prediction model often predicts the wrong test files. For example, 'Add tests for tokenizer module' ranked tests/unit/test_validation.py and tests/test_mcp_server.py above tests/test_tokenizer.py. Investigate: (1) How test file co-occurrence is learned, (2) Whether test file naming conventions are being captured, (3) If module-to-test-file mapping could be added as a feature.",
      "depends_on": [],
      "effort": "medium",
      "created_at": "2025-12-16T11:21:31.144820",
      "updated_at": null,
      "completed_at": null,
      "context": {},
      "retrospective": null
    },
    {
      "id": "T-20251216-112135-7ff7-008",
      "title": "Add stop-word filtering to ML file prediction queries",
      "status": "pending",
      "priority": "medium",
      "category": "enhancement",
      "description": "Common words like 'add', 'fix', 'update', 'implement' appear in COMMIT_TYPE_PATTERNS but also pollute keyword matching. The word 'task' triggers task_utils.py even for unrelated queries. Investigate: (1) Adding a stop-word list for prediction queries, (2) Weighting commit type matches differently from keyword matches, (3) Context-aware filtering based on query structure.",
      "depends_on": [],
      "effort": "medium",
      "created_at": "2025-12-16T11:21:35.983365",
      "updated_at": null,
      "completed_at": null,
      "context": {},
      "retrospective": null
    },
    {
      "id": "T-20251216-112153-7ff7-009",
      "title": "Add file path migration awareness to ML predictions",
      "status": "pending",
      "priority": "medium",
      "category": "enhancement",
      "description": "FILE_PATH_MIGRATIONS in ml_file_prediction.py maps old paths to new (e.g., cortical/processor.py -> cortical/processor/*.py). However, predictions for refactored modules don't work well. Investigate: (1) Whether migrations are being applied during prediction, (2) If recent commits post-refactor are weighted higher, (3) Adding recency weighting to file predictions.",
      "depends_on": [],
      "effort": "medium",
      "created_at": "2025-12-16T11:21:53.481607",
      "updated_at": null,
      "completed_at": null,
      "context": {},
      "retrospective": null
    },
    {
      "id": "T-20251216-112158-7ff7-010",
      "title": "Implement confidence scoring with actionable thresholds",
      "status": "pending",
      "priority": "medium",
      "category": "enhancement",
      "description": "The model shows warnings for low confidence but thresholds are arbitrary. Investigate: (1) Analyzing score distributions across good/bad predictions, (2) Setting data-driven thresholds (e.g., P90 of incorrect predictions), (3) Adding 'high confidence' vs 'explore these' tiers in output, (4) Suggesting when to provide seed files.",
      "depends_on": [],
      "effort": "medium",
      "created_at": "2025-12-16T11:21:58.016222",
      "updated_at": null,
      "completed_at": null,
      "context": {},
      "retrospective": null
    },
    {
      "id": "T-20251216-112202-7ff7-011",
      "title": "Add semantic similarity to ML file predictions",
      "status": "pending",
      "priority": "low",
      "category": "research",
      "description": "Current model uses keyword matching and co-occurrence. Could improve with: (1) Using the CorticalTextProcessor to expand query terms semantically, (2) Building file embeddings from docstrings/comments, (3) Matching query intent to file purposes from .ai_meta files. This would be dog-fooding our own IR system.",
      "depends_on": [],
      "effort": "medium",
      "created_at": "2025-12-16T11:22:02.156479",
      "updated_at": null,
      "completed_at": null,
      "context": {},
      "retrospective": null
    },
    {
      "id": "T-20251216-112220-7ff7-012",
      "title": "Audit ML data collector for data quality issues",
      "status": "pending",
      "priority": "medium",
      "category": "investigation",
      "description": "Review ml_data_collector.py for potential data quality issues: (1) Check if chat entries have balanced query/response lengths, (2) Verify commit hunks capture meaningful context (not just +/- lines), (3) Ensure session linking is working (commits linked to chats), (4) Check for duplicate or corrupted entries, (5) Validate schema compliance across all stored data.",
      "depends_on": [],
      "effort": "medium",
      "created_at": "2025-12-16T11:22:20.207566",
      "updated_at": null,
      "completed_at": null,
      "context": {},
      "retrospective": null
    },
    {
      "id": "T-20251216-112224-7ff7-013",
      "title": "Investigate hook reliability and error recovery",
      "status": "pending",
      "priority": "medium",
      "category": "investigation",
      "description": "The ml-session-capture-hook.sh silently suppresses errors. Investigate: (1) What errors are being suppressed (run manually with stderr), (2) Whether the hook fails silently on malformed transcripts, (3) If partial captures are possible (some exchanges saved, others lost), (4) Adding optional verbose mode for debugging, (5) Error recovery strategies.",
      "depends_on": [],
      "effort": "medium",
      "created_at": "2025-12-16T11:22:24.941220",
      "updated_at": null,
      "completed_at": null,
      "context": {},
      "retrospective": null
    },
    {
      "id": "T-20251216-112231-7ff7-014",
      "title": "Profile ML data collector performance on large datasets",
      "status": "pending",
      "priority": "low",
      "category": "performance",
      "description": "As ML data grows, investigate potential bottlenecks: (1) Profile count_data() with many files, (2) Check if glob patterns are efficient, (3) Measure export_data() memory usage with 10k+ records, (4) Test atomic_write_json() under concurrent access, (5) Benchmark quality-report generation time.",
      "depends_on": [],
      "effort": "medium",
      "created_at": "2025-12-16T11:22:31.321559",
      "updated_at": null,
      "completed_at": null,
      "context": {},
      "retrospective": null
    },
    {
      "id": "T-20251216-112249-7ff7-015",
      "title": "Review analysis package refactoring for API consistency",
      "status": "pending",
      "priority": "medium",
      "category": "code-review",
      "description": "The analysis.py was split into cortical/analysis/ package with 8 modules. Review: (1) Check all public functions are re-exported in __init__.py, (2) Verify import paths in processor/compute.py still work, (3) Ensure backward compatibility for external users, (4) Check if any functions were accidentally omitted, (5) Update CLAUDE.md architecture section if needed.",
      "depends_on": [],
      "effort": "medium",
      "created_at": "2025-12-16T11:22:49.362759",
      "updated_at": null,
      "completed_at": null,
      "context": {},
      "retrospective": null
    },
    {
      "id": "T-20251216-112253-7ff7-016",
      "title": "Consolidate session management code between ml_data_collector and session_logger",
      "status": "pending",
      "priority": "low",
      "category": "refactor",
      "description": "session_logger.py duplicates get_current_session() and start_session() from ml_data_collector.py. Tasks: (1) Move shared session functions to a common module, (2) Have both scripts import from the shared module, (3) Ensure backward compatibility for existing hooks, (4) Add tests for the shared module, (5) Update documentation.",
      "depends_on": [],
      "effort": "medium",
      "created_at": "2025-12-16T11:22:53.092758",
      "updated_at": null,
      "completed_at": null,
      "context": {},
      "retrospective": null
    },
    {
      "id": "T-20251216-112257-7ff7-017",
      "title": "Add integration tests for ML data collection pipeline",
      "status": "pending",
      "priority": "medium",
      "category": "testing",
      "description": "The ML data collection system lacks end-to-end tests. Add tests for: (1) Full transcript -> chat entries pipeline, (2) Commit hook -> commit data pipeline, (3) Session start -> exchanges -> session end flow, (4) Export to all formats (JSONL, CSV, HuggingFace), (5) Backfill command with mock git history.",
      "depends_on": [],
      "effort": "medium",
      "created_at": "2025-12-16T11:22:57.783651",
      "updated_at": null,
      "completed_at": null,
      "context": {},
      "retrospective": null
    },
    {
      "id": "T-20251216-112312-7ff7-018",
      "title": "Create ML model evaluation dashboard",
      "status": "pending",
      "priority": "low",
      "category": "enhancement",
      "description": "Add a dashboard/report for ongoing model evaluation: (1) Track MRR/Recall over time as model is retrained, (2) Show prediction accuracy by commit type (feat vs fix vs docs), (3) Identify consistently mispredicted file patterns, (4) Compare model versions side-by-side, (5) Export metrics for external analysis.",
      "depends_on": [],
      "effort": "medium",
      "created_at": "2025-12-16T11:23:12.170410",
      "updated_at": null,
      "completed_at": null,
      "context": {},
      "retrospective": null
    },
    {
      "id": "T-20251216-112316-7ff7-019",
      "title": "Document ML training data requirements and best practices",
      "status": "pending",
      "priority": "low",
      "category": "docs",
      "description": "Create documentation covering: (1) Minimum commits needed for reliable predictions (currently 339), (2) How to interpret confidence scores, (3) When to retrain the model (after refactoring, new modules), (4) How file co-occurrence learning works, (5) Troubleshooting poor predictions.",
      "depends_on": [],
      "effort": "medium",
      "created_at": "2025-12-16T11:23:16.323874",
      "updated_at": null,
      "completed_at": null,
      "context": {},
      "retrospective": null
    }
  ]
}