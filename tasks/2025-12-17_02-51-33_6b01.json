{
  "version": 1,
  "session_id": "6b01",
  "started_at": "2025-12-17T02:51:33.834930",
  "saved_at": "2025-12-17T02:53:25.283183",
  "tasks": [
    {
      "id": "T-20251217-025133-6b01-001",
      "title": "Replace broad except Exception blocks with specific exception handling",
      "status": "pending",
      "priority": "high",
      "category": "bugfix",
      "description": "Found multiple 'except Exception:' blocks in wal.py, cli_wrapper.py, state_storage.py, mcp_server.py, and ml_experiments modules that could hide bugs and make debugging difficult. Replace these with specific exception types that are actually expected.",
      "depends_on": [],
      "effort": "medium",
      "created_at": "2025-12-17T02:51:33.835462",
      "updated_at": null,
      "completed_at": null,
      "context": {},
      "retrospective": null
    },
    {
      "id": "T-20251217-025138-6b01-002",
      "title": "Fix MetricsCollector thread-safety documentation",
      "status": "pending",
      "priority": "medium",
      "category": "docs",
      "description": "The MetricsCollector class comment says 'Thread-safe for single-threaded use' which is contradictory and confusing. Should clarify that thread safety is NOT guaranteed and external locking is required for multi-threaded use.",
      "depends_on": [],
      "effort": "medium",
      "created_at": "2025-12-17T02:51:38.298085",
      "updated_at": null,
      "completed_at": null,
      "context": {},
      "retrospective": null
    },
    {
      "id": "T-20251217-025153-6b01-003",
      "title": "Implement LRU eviction for query expansion cache",
      "status": "pending",
      "priority": "high",
      "category": "feature",
      "description": "The _query_expansion_cache has _query_cache_max_size=100 defined but there's no actual LRU eviction logic. The cache can grow unbounded. Implement proper LRU cache behavior using collections.OrderedDict or functools.lru_cache.",
      "depends_on": [],
      "effort": "medium",
      "created_at": "2025-12-17T02:51:53.060012",
      "updated_at": null,
      "completed_at": null,
      "context": {},
      "retrospective": null
    },
    {
      "id": "T-20251217-025157-6b01-004",
      "title": "Add input validation for graph_boosted_search weight parameters",
      "status": "pending",
      "priority": "medium",
      "category": "bugfix",
      "description": "The graph_boosted_search function accepts pagerank_weight and proximity_weight parameters but doesn't validate that their sum is <= 1.0. This could lead to unexpected scoring behavior where the base score is over-weighted or under-weighted.",
      "depends_on": [],
      "effort": "medium",
      "created_at": "2025-12-17T02:51:57.601737",
      "updated_at": null,
      "completed_at": null,
      "context": {},
      "retrospective": null
    },
    {
      "id": "T-20251217-025201-6b01-005",
      "title": "Bound MetricsCollector timing history to prevent memory growth",
      "status": "pending",
      "priority": "high",
      "category": "bugfix",
      "description": "MetricsCollector.operations stores all timings in an unbounded list (op_data['timings']). For long-running processes, this can cause memory growth. Should implement circular buffer or rolling window for timing history.",
      "depends_on": [],
      "effort": "medium",
      "created_at": "2025-12-17T02:52:01.729330",
      "updated_at": null,
      "completed_at": null,
      "context": {},
      "retrospective": null
    },
    {
      "id": "T-20251217-025215-6b01-006",
      "title": "Extract common document name boost logic from search functions",
      "status": "pending",
      "priority": "low",
      "category": "refactor",
      "description": "find_documents_for_query and fast_find_documents have nearly identical document name boosting code (~30 lines each). Extract this into a shared helper function to reduce code duplication and simplify maintenance.",
      "depends_on": [],
      "effort": "medium",
      "created_at": "2025-12-17T02:52:15.027619",
      "updated_at": null,
      "completed_at": null,
      "context": {},
      "retrospective": null
    },
    {
      "id": "T-20251217-025219-6b01-007",
      "title": "Factor out common PageRank iteration logic",
      "status": "pending",
      "priority": "low",
      "category": "refactor",
      "description": "compute_pagerank, compute_semantic_pagerank, and compute_hierarchical_pagerank all contain similar iteration loops (70+ lines each). Consider extracting the core iteration logic into a shared helper to reduce code duplication.",
      "depends_on": [],
      "effort": "medium",
      "created_at": "2025-12-17T02:52:19.074954",
      "updated_at": null,
      "completed_at": null,
      "context": {},
      "retrospective": null
    },
    {
      "id": "T-20251217-025222-6b01-008",
      "title": "Consider making JSON the default persistence format over pickle",
      "status": "pending",
      "priority": "medium",
      "category": "security",
      "description": "Pickle format is deprecated in the codebase due to security concerns (arbitrary code execution risk) with deprecation warnings. Consider making JSON/StateLoader the default format to improve security posture. Currently pickle remains the default despite deprecation.",
      "depends_on": [],
      "effort": "medium",
      "created_at": "2025-12-17T02:52:22.784767",
      "updated_at": null,
      "completed_at": null,
      "context": {},
      "retrospective": null
    },
    {
      "id": "T-20251217-025238-6b01-009",
      "title": "Add configurable thresholds to replace hard-coded magic numbers",
      "status": "pending",
      "priority": "low",
      "category": "feature",
      "description": "Various functions have hard-coded thresholds (e.g., max_bigrams_per_term=100, max_bigrams_per_doc=500, candidate_multiplier=3). Consider making these configurable via CorticalConfig or function parameters for better tunability.",
      "depends_on": [],
      "effort": "medium",
      "created_at": "2025-12-17T02:52:38.483580",
      "updated_at": null,
      "completed_at": null,
      "context": {},
      "retrospective": null
    },
    {
      "id": "T-20251217-025242-6b01-010",
      "title": "Add integration tests for checkpoint resume functionality",
      "status": "pending",
      "priority": "medium",
      "category": "test",
      "description": "The compute_all checkpoint/resume feature (_save_checkpoint, _load_checkpoint_progress, resume_from_checkpoint) is implemented but could use more comprehensive integration tests to verify the full checkpoint-resume workflow survives crashes properly.",
      "depends_on": [],
      "effort": "medium",
      "created_at": "2025-12-17T02:52:42.907200",
      "updated_at": null,
      "completed_at": null,
      "context": {},
      "retrospective": null
    },
    {
      "id": "T-20251217-025247-6b01-011",
      "title": "Add type annotations for return types in to_dict methods",
      "status": "pending",
      "priority": "low",
      "category": "docs",
      "description": "Several to_dict() methods (in Minicolumn, HierarchicalLayer, CorticalConfig) return Dict but could have more specific type hints like Dict[str, Any] or TypedDict for better IDE support and documentation.",
      "depends_on": [],
      "effort": "medium",
      "created_at": "2025-12-17T02:52:47.659523",
      "updated_at": null,
      "completed_at": null,
      "context": {},
      "retrospective": null
    },
    {
      "id": "T-20251217-025300-6b01-012",
      "title": "Add docstrings to private methods in processor module",
      "status": "pending",
      "priority": "low",
      "category": "docs",
      "description": "Some private methods in processor/*.py modules (_apply_score_adjustments, _boost_overlapping_docs, etc.) lack comprehensive docstrings. Adding documentation would improve maintainability.",
      "depends_on": [],
      "effort": "medium",
      "created_at": "2025-12-17T02:53:00.861321",
      "updated_at": null,
      "completed_at": null,
      "context": {},
      "retrospective": null
    },
    {
      "id": "T-20251217-025305-6b01-013",
      "title": "Consider async support for large corpus processing",
      "status": "pending",
      "priority": "low",
      "category": "feature",
      "description": "For processing very large corpora, async/await support could improve throughput. Functions like add_documents_batch and compute_all could benefit from async patterns for parallel document processing.",
      "depends_on": [],
      "effort": "medium",
      "created_at": "2025-12-17T02:53:05.028714",
      "updated_at": null,
      "completed_at": null,
      "context": {},
      "retrospective": null
    },
    {
      "id": "T-20251217-025310-6b01-014",
      "title": "Add logging level configuration guidance",
      "status": "pending",
      "priority": "low",
      "category": "docs",
      "description": "Some info-level log messages (e.g., in compute_all, save_processor) might be better as debug-level for production use. Add documentation about recommended logging configuration for different environments.",
      "depends_on": [],
      "effort": "medium",
      "created_at": "2025-12-17T02:53:10.051261",
      "updated_at": null,
      "completed_at": null,
      "context": {},
      "retrospective": null
    },
    {
      "id": "T-20251217-025321-6b01-015",
      "title": "Add validation for division by zero in scoring calculations",
      "status": "pending",
      "priority": "medium",
      "category": "bugfix",
      "description": "Several scoring calculations in analysis modules use division operations (e.g., normalized_score = score / max_score). Add explicit checks for division by zero to prevent runtime errors when max_score is 0.",
      "depends_on": [],
      "effort": "medium",
      "created_at": "2025-12-17T02:53:21.701901",
      "updated_at": null,
      "completed_at": null,
      "context": {},
      "retrospective": null
    },
    {
      "id": "T-20251217-025325-6b01-016",
      "title": "Add performance benchmarks for common operations",
      "status": "pending",
      "priority": "medium",
      "category": "test",
      "description": "Add automated benchmark tests that track performance of key operations (compute_all, find_documents_for_query, process_document) to detect performance regressions. Could use pytest-benchmark or a simple timing framework.",
      "depends_on": [],
      "effort": "medium",
      "created_at": "2025-12-17T02:53:25.283102",
      "updated_at": null,
      "completed_at": null,
      "context": {},
      "retrospective": null
    }
  ]
}