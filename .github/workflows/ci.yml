name: CI - Test Suite

# =============================================================================
# CI TEST ARCHITECTURE - READ BEFORE MODIFYING
# =============================================================================
#
# CRITICAL: Pytest runs unittest-based tests natively!
# DO NOT run both pytest and unittest on the same test files.
# This doubles CI time and provides no benefit.
#
# ‚ùå WRONG (runs tests twice):
#    coverage run -m pytest tests/
#    coverage run --append -m unittest discover -s tests
#
# ‚úÖ CORRECT (pytest handles both):
#    coverage run -m pytest tests/
#
# PARALLEL ARCHITECTURE (optimized for speed):
#
#   validate-task-list   smoke-tests      showcase
#        (< 5s)           (< 30s)         (parallel)
#          ‚îÇ                 ‚îÇ                ‚îÇ
#          ‚îÇ                 ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
#          ‚îÇ                 ‚îÇ                ‚îÇ                 ‚îÇ
#          ‚ñº                 ‚ñº                ‚ñº                 ‚ñº
#    (continues)  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
#                 ‚îÇ unit-tests ‚îÄ‚îÄ‚îÄ‚îÄ‚îê       ‚îÇ      ‚îÇ regression-tests ‚îÇ
#                 ‚îÇ integration    ‚îÇ (cov) ‚îÇ      ‚îÇ behavioral-tests ‚îÇ
#                 ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îÇ performance-tests‚îÇ
#                         ‚îÇ                       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
#                         ‚ñº                           (no coverage)
#                  coverage-report
#                (combines coverage
#                 from unit + integration
#                 WITHOUT re-running tests)
#
# Each stage runs specific test files to avoid duplication.
# coverage-report ONLY combines coverage data - it does NOT run tests again.
# =============================================================================

on:
  push:
  pull_request:
    branches: [ main ]
  workflow_dispatch:  # Allow manual triggering

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  # ==========================================================================
  # Stage 0: Task List Validation (< 5s)
  # Quick check for stale/inconsistent task list - runs in parallel with smoke
  # ==========================================================================
  validate-task-list:
    name: "üìã Validate Task List"
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4

    - name: Set up Python 3.11
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'

    - name: Validate TASK_LIST.md
      run: |
        echo "=== Validating Task List ==="
        python scripts/validate_task_list.py
        echo "‚úÖ Task list validation passed"

    - name: Report Pending Tasks
      if: always()
      run: |
        echo "=== Pending Tasks Report ==="
        python scripts/ci_task_report.py --github
      env:
        GITHUB_STEP_SUMMARY: ${{ github.step_summary }}

  # ==========================================================================
  # Stage 1: Smoke Tests (< 30s)
  # Quick sanity check - if this fails, something is fundamentally broken
  # ==========================================================================
  smoke-tests:
    name: "üí® Smoke Tests"
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4

    - name: Set up Python 3.11
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'

    - name: Install test dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -e ".[dev]"

    - name: Run smoke tests
      run: |
        echo "=== Running Smoke Tests ==="
        python -m pytest tests/smoke/ -v --tb=short
        echo "‚úÖ Smoke tests passed"

  # ==========================================================================
  # Stage 2: Unit Tests with Coverage (< 2 min)
  # Fast, isolated tests for individual components
  # Runs in PARALLEL with integration-tests after smoke-tests pass
  # ==========================================================================
  unit-tests:
    name: "üß™ Unit Tests"
    runs-on: ubuntu-latest
    needs: smoke-tests
    steps:
    - uses: actions/checkout@v4

    - name: Set up Python 3.11
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'

    - name: Install test dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -e ".[dev]"

    - name: Run unit tests with coverage
      run: |
        echo "=== Running Unit Tests ==="
        # Run unit tests - pytest handles both pytest AND unittest style tests
        # Using a single pytest call is faster than multiple unittest discovers
        # Note: Legacy tests removed 2025-12-13 - now covered by tests/unit/
        coverage run --source=cortical -m pytest \
          tests/unit/ \
          -v --tb=short

        coverage report --include="cortical/*"

    - name: Upload unit test coverage data
      uses: actions/upload-artifact@v4
      with:
        name: coverage-unit
        path: .coverage
        # Rename to avoid collision when combining
        include-hidden-files: true

  # ==========================================================================
  # Stage 3: Integration Tests (< 3 min)
  # Tests for component interactions
  # Runs in PARALLEL with unit-tests after smoke-tests pass
  # ==========================================================================
  integration-tests:
    name: "üîó Integration Tests"
    runs-on: ubuntu-latest
    needs: smoke-tests  # Changed: runs parallel with unit-tests
    steps:
    - uses: actions/checkout@v4

    - name: Set up Python 3.11
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'

    - name: Install test dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -e ".[dev]"

    - name: Run integration tests with coverage
      run: |
        echo "=== Running Integration Tests ==="
        # Run integration tests - single pytest call is faster than multiple unittest discovers
        # Includes tests/integration/ plus remaining legacy tests that provide unique coverage
        # Note: 3 legacy tests removed 2025-12-13 (test_behavioral.py, test_intent_query.py,
        #       test_query_optimization.py) - now covered by unit tests
        coverage run --source=cortical -m pytest \
          tests/integration/ \
          tests/test_incremental_indexing.py \
          tests/test_edge_cases.py \
          tests/test_coverage_gaps.py \
          tests/test_analyze_louvain_resolution.py \
          tests/test_evaluate_cluster.py \
          tests/test_cli_wrapper.py \
          tests/test_search_codebase.py \
          tests/test_ask_codebase.py \
          tests/test_generate_ai_metadata.py \
          tests/test_showcase.py \
          -v --tb=short

        coverage report --include="cortical/*"

    - name: Upload integration test coverage data
      uses: actions/upload-artifact@v4
      with:
        name: coverage-integration
        path: .coverage
        include-hidden-files: true

  # ==========================================================================
  # Stage 4: Regression Tests (< 1 min)
  # Tests for specific bugs that were fixed
  # Runs in PARALLEL with unit/integration after smoke-tests pass
  # ==========================================================================
  regression-tests:
    name: "üîí Regression Tests"
    runs-on: ubuntu-latest
    needs: smoke-tests  # Changed: runs parallel, only needs smoke
    steps:
    - uses: actions/checkout@v4

    - name: Set up Python 3.11
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'

    - name: Install test dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -e ".[dev]"

    - name: Run regression tests
      run: |
        echo "=== Running Regression Tests ==="
        python -m pytest tests/regression/ -v --tb=short
        echo "‚úÖ All regressions still fixed"

  # ==========================================================================
  # Stage 5: Behavioral Tests (< 2 min)
  # Tests for user-facing quality and relevance
  # Runs in PARALLEL with unit/integration after smoke-tests pass
  # ==========================================================================
  behavioral-tests:
    name: "üéØ Behavioral Tests"
    runs-on: ubuntu-latest
    needs: smoke-tests  # Changed: runs parallel, only needs smoke
    steps:
    - uses: actions/checkout@v4

    - name: Set up Python 3.11
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'

    - name: Install test dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -e ".[dev]"

    - name: Run behavioral tests
      run: |
        echo "=== Running Behavioral Tests ==="
        # Note: tests/test_behavioral.py removed 2025-12-13 - superseded by tests/behavioral/
        python -m pytest tests/behavioral/ -v --tb=short
        echo "‚úÖ Behavioral quality verified"

  # ==========================================================================
  # Stage 6: Performance Tests (< 1 min, no coverage)
  # Timing-based tests to catch performance regressions
  # Runs in PARALLEL with unit/integration after smoke-tests pass
  # ==========================================================================
  performance-tests:
    name: "‚è±Ô∏è Performance Tests"
    runs-on: ubuntu-latest
    needs: smoke-tests  # Changed: runs parallel, only needs smoke
    steps:
    - uses: actions/checkout@v4

    - name: Set up Python 3.11
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'

    - name: Install test dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -e ".[dev]"

    - name: Run performance tests
      run: |
        echo "=== Running Performance Tests (no coverage) ==="
        python -m pytest tests/performance/ -v --tb=short -s
        echo "‚úÖ Performance within thresholds"

  # ==========================================================================
  # Stage 7: Full Coverage Report
  # Combines coverage from unit + integration tests WITHOUT re-running tests
  # ==========================================================================
  coverage-report:
    name: "üìä Coverage Report"
    runs-on: ubuntu-latest
    needs: [unit-tests, integration-tests]
    steps:
    - uses: actions/checkout@v4

    - name: Set up Python 3.11
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'

    - name: Install coverage
      run: |
        python -m pip install --upgrade pip
        pip install coverage

    - name: Download unit coverage
      uses: actions/download-artifact@v4
      with:
        name: coverage-unit
        path: coverage-unit

    - name: Download integration coverage
      uses: actions/download-artifact@v4
      with:
        name: coverage-integration
        path: coverage-integration

    - name: Combine coverage data and generate report
      run: |
        echo "=== Combining Coverage Data ==="
        # ‚ö†Ô∏è  IMPORTANT: This job ONLY combines coverage - NO test runs!
        #
        # Tests were already run in unit-tests and integration-tests stages.
        # Running tests again here would double CI time.
        #
        # We use 'coverage combine' to merge the .coverage files from
        # the parallel test jobs.

        # Move coverage files to current directory with unique names
        mv coverage-unit/.coverage .coverage.unit
        mv coverage-integration/.coverage .coverage.integration

        # Combine coverage data from both jobs
        coverage combine .coverage.unit .coverage.integration

        # Generate reports
        echo "=== Coverage Report ==="
        coverage report -m --include="cortical/*"
        coverage xml -o coverage.xml

        # Check threshold (fail if below 89%)
        coverage report --fail-under=89 --include="cortical/*"
        echo "‚úÖ Coverage threshold met"

    - name: Upload final coverage report
      uses: actions/upload-artifact@v4
      with:
        name: coverage-report
        path: coverage.xml

  # ==========================================================================
  # Showcase (runs in parallel with all other jobs)
  # Runs the full showcase demo - independent of test results
  # ==========================================================================
  showcase:
    name: "üé≠ Showcase Demo"
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4

    - name: Set up Python 3.11
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'

    - name: Run showcase
      run: |
        echo "=== Running Showcase Demo ==="
        python showcase.py

  # ==========================================================================
  # Security Scanning (runs in parallel with all other jobs)
  # Static analysis and dependency scanning for security vulnerabilities
  # ==========================================================================
  security-scan:
    name: "üîê Security Scan"
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4

    - name: Set up Python 3.11
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'

    - name: Install security tools
      run: |
        python -m pip install --upgrade pip
        pip install bandit pip-audit detect-secrets

    - name: Run Bandit (SAST)
      run: |
        echo "=== Running Bandit Static Analysis ==="
        # -ll = only show medium and higher severity issues
        # -r = recursive
        # Skip B101 (assert) as we use asserts for invariants in non-production code
        bandit -r cortical/ -ll -s B101 -f txt || true
        echo "‚úÖ Bandit scan complete"

    - name: Run pip-audit (Dependency Scanning)
      run: |
        echo "=== Running pip-audit Dependency Check ==="
        pip install -e ".[dev]"
        pip-audit --desc || echo "‚ö†Ô∏è Review dependency vulnerabilities above"

    - name: Run detect-secrets (Secret Scanning)
      run: |
        echo "=== Running detect-secrets ==="
        # Scan for accidentally committed secrets
        detect-secrets scan --all-files --exclude-files '\.git/.*' --exclude-files '.*\.pkl' --exclude-files '.*\.json' > .secrets-baseline.json || true
        # Check if any high-entropy secrets were found (excluding test fixtures)
        python -c "
import json
with open('.secrets-baseline.json') as f:
    data = json.load(f)
    results = data.get('results', {})
    real_secrets = {k: v for k, v in results.items() if not k.startswith('tests/')}
    if real_secrets:
        print('‚ö†Ô∏è Potential secrets found in:')
        for file in real_secrets:
            print(f'  - {file}')
        print('Please review and ensure no real secrets are committed.')
    else:
        print('‚úÖ No secrets detected in source files')
"
