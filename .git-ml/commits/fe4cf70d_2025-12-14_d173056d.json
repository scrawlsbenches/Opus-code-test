{
  "hash": "fe4cf70d2f3220920dd7e09e52876a00663066a1",
  "message": "Merge remote-tracking branch 'origin/main' into claude/replace-pkl-git-friendly-01DD3ra3P5hj9NK57johJff5",
  "author": "Claude",
  "timestamp": "2025-12-14 00:20:12 +0000",
  "branch": "claude/multi-index-design-DvifZ",
  "files_changed": [
    ".claude/skills/task-manager/SKILL.md",
    ".claude/workflows/bugfix.yaml",
    ".claude/workflows/feature.yaml",
    ".claude/workflows/refactor.yaml",
    ".github/workflows/ci.yml",
    ".gitignore",
    "docs/merge-friendly-tasks.md",
    "docs/task-management-dogfooding.md",
    "docs/workflow-templates.md",
    "scripts/ci_task_create.py",
    "scripts/ci_task_report.py",
    "scripts/consolidate_tasks.py",
    "scripts/new_task.py",
    "scripts/task_utils.py",
    "scripts/workflow.py",
    "tasks/2025-12-13_22-32-34_e233.json",
    "tasks/2025-12-13_22-33-34_2d89.json",
    "tasks/2025-12-13_22-42-20_6ac7.json",
    "tasks/2025-12-13_22-50-18_cdd1.json",
    "tasks/2025-12-13_23-54-58_1a1d.json",
    "tests/integration/test_task_integration.py",
    "tests/integration/test_workflow_integration.py",
    "tests/unit/test_task_utils.py",
    "tests/unit/test_workflow.py"
  ],
  "insertions": 5393,
  "deletions": 0,
  "hunks": [
    {
      "file": ".claude/skills/task-manager/SKILL.md",
      "function": null,
      "start_line": 0,
      "lines_added": [
        "---",
        "name: task-manager",
        "description: Manage tasks with merge-friendly IDs for parallel agent workflows. Use when creating, updating, or querying tasks during development. Prevents conflicts when multiple agents run in parallel.",
        "allowed-tools: Read, Bash, Write",
        "---",
        "# Task Manager Skill",
        "",
        "This skill enables **merge-friendly task management** for parallel agent workflows. It uses timestamp+session IDs that can't conflict when multiple agents work simultaneously.",
        "",
        "## Key Capabilities",
        "",
        "- **Conflict-free task creation**: Each agent writes to its own session file",
        "- **Unique task IDs**: `T-YYYYMMDD-HHMMSS-XXXX` format",
        "- **Session tracking**: All tasks from one session share a suffix",
        "- **Consolidation**: Merge task files like `git gc`",
        "- **TASK_LIST.md compatible**: Can generate markdown summaries",
        "",
        "## When to Use",
        "",
        "- Starting a new piece of work that needs tracking",
        "- Creating tasks from parallel agent workflows",
        "- Consolidating tasks after multi-agent runs",
        "- Querying task status across sessions",
        "",
        "## Quick Start",
        "",
        "### Create Tasks",
        "",
        "```python",
        "# In Python",
        "from scripts.task_utils import TaskSession",
        "",
        "session = TaskSession()",
        "task = session.create_task(",
        "    title=\"Implement feature X\",",
        "    priority=\"high\",",
        "    category=\"arch\",",
        "    description=\"Add new capability to processor\"",
        ")",
        "print(f\"Created: {task.id}\")  # T-20251213-143052-a1b2",
        "session.save()  # â†’ tasks/2025-12-13_14-30-52_a1b2.json",
        "```",
        "",
        "### Generate Task ID (CLI)",
        "",
        "```bash",
        "# Full format",
        "python scripts/task_utils.py generate",
        "# Output: T-20251213-143052-a1b2",
        "",
        "# Short format",
        "python scripts/task_utils.py generate --short",
        "# Output: T-a1b2c3d4",
        "```",
        "",
        "### List All Tasks",
        "",
        "```bash",
        "python scripts/task_utils.py list",
        "python scripts/task_utils.py list --status pending",
        "```",
        "",
        "### Consolidate Tasks",
        "",
        "```bash",
        "# See summary",
        "python scripts/consolidate_tasks.py --summary",
        "",
        "# Consolidate and deduplicate",
        "python scripts/consolidate_tasks.py --update --auto-merge",
        "",
        "# Archive old session files",
        "python scripts/consolidate_tasks.py --update --archive",
        "```",
        "",
        "## Task Structure",
        "",
        "```json",
        "{",
        "  \"id\": \"T-20251213-143052-a1b2\",",
        "  \"title\": \"Implement feature X\",",
        "  \"status\": \"pending\",",
        "  \"priority\": \"high\",",
        "  \"category\": \"arch\",",
        "  \"description\": \"...\",",
        "  \"depends_on\": [\"T-20251213-143000-c3d4\"],",
        "  \"effort\": \"medium\",",
        "  \"context\": {",
        "    \"files\": [\"cortical/processor.py\"],",
        "    \"methods\": [\"compute_all()\"]",
        "  }",
        "}",
        "```",
        "",
        "## Integration with TASK_LIST.md",
        "",
        "The new system can coexist with the legacy `TASK_LIST.md`:",
        "- Legacy tasks keep `#123` format",
        "- New parallel work uses `T-...` format",
        "- Both can be referenced and tracked",
        "",
        "## Tips",
        "",
        "1. **Create session at workflow start** - all tasks share session suffix",
        "2. **Save before commit** - persist tasks to disk",
        "3. **Consolidate weekly** - merge sessions, resolve duplicates",
        "4. **Use context field** - add file/method references for quick navigation"
      ],
      "lines_removed": [],
      "context_before": [],
      "context_after": [],
      "change_type": "add"
    },
    {
      "file": ".claude/workflows/bugfix.yaml",
      "function": null,
      "start_line": 0,
      "lines_added": [
        "# Workflow: Bug Fix",
        "# Creates a standard set of tasks for fixing bugs",
        "",
        "name: \"Bug Fix\"",
        "description: \"Investigation -> Fix -> Test -> Document\"",
        "category: \"bugfix\"",
        "",
        "# Variables that will be prompted or provided",
        "variables:",
        "  - name: bug_title",
        "    description: \"Brief description of the bug\"",
        "    required: true",
        "  - name: priority",
        "    description: \"Bug priority\"",
        "    default: \"high\"",
        "    choices: [\"high\", \"medium\", \"low\"]",
        "  - name: affected_file",
        "    description: \"Primary file affected (optional)\"",
        "    required: false",
        "",
        "tasks:",
        "  - id: investigate",
        "    title: \"Investigate: {bug_title}\"",
        "    category: \"research\"",
        "    priority: \"{priority}\"",
        "    effort: \"small\"",
        "    description: |",
        "      Investigate the root cause of: {bug_title}",
        "",
        "      Steps:",
        "      1. Reproduce the issue",
        "      2. Identify the root cause",
        "      3. Document findings in task notes",
        "",
        "  - id: fix",
        "    title: \"Fix: {bug_title}\"",
        "    category: \"bugfix\"",
        "    priority: \"{priority}\"",
        "    effort: \"medium\"",
        "    depends_on: [investigate]",
        "    description: |",
        "      Implement the fix for: {bug_title}",
        "",
        "      Checklist:",
        "      - [ ] Fix implemented",
        "      - [ ] Code follows existing patterns",
        "      - [ ] No new warnings introduced",
        "",
        "  - id: test",
        "    title: \"Add regression test for: {bug_title}\"",
        "    category: \"test\"",
        "    priority: \"high\"",
        "    effort: \"small\"",
        "    depends_on: [fix]",
        "    description: |",
        "      Add test(s) to prevent regression.",
        "",
        "      Requirements:",
        "      - Test should fail without the fix",
        "      - Test should pass with the fix",
        "      - Test covers edge cases",
        "",
        "  - id: document",
        "    title: \"Document fix for: {bug_title}\"",
        "    category: \"docs\"",
        "    priority: \"low\"",
        "    effort: \"small\"",
        "    depends_on: [fix]",
        "    description: |",
        "      Update any relevant documentation.",
        "",
        "      Consider:",
        "      - CHANGELOG entry",
        "      - Code comments if complex",
        "      - Update troubleshooting docs if user-facing"
      ],
      "lines_removed": [],
      "context_before": [],
      "context_after": [],
      "change_type": "add"
    },
    {
      "file": ".claude/workflows/feature.yaml",
      "function": null,
      "start_line": 0,
      "lines_added": [
        "# Workflow: Feature Implementation",
        "# Creates tasks for implementing a new feature",
        "",
        "name: \"Feature\"",
        "description: \"Design -> Implement -> Test -> Review\"",
        "category: \"feature\"",
        "",
        "variables:",
        "  - name: feature_name",
        "    description: \"Name of the feature\"",
        "    required: true",
        "  - name: priority",
        "    description: \"Feature priority\"",
        "    default: \"medium\"",
        "    choices: [\"high\", \"medium\", \"low\"]",
        "  - name: effort",
        "    description: \"Overall effort estimate\"",
        "    default: \"large\"",
        "    choices: [\"small\", \"medium\", \"large\"]",
        "",
        "tasks:",
        "  - id: design",
        "    title: \"Design: {feature_name}\"",
        "    category: \"arch\"",
        "    priority: \"{priority}\"",
        "    effort: \"medium\"",
        "    description: |",
        "      Design the API and architecture for: {feature_name}",
        "",
        "      Deliverables:",
        "      - API design (function signatures, data structures)",
        "      - Integration points with existing code",
        "      - Edge cases to handle",
        "",
        "  - id: implement",
        "    title: \"Implement: {feature_name}\"",
        "    category: \"feature\"",
        "    priority: \"{priority}\"",
        "    effort: \"{effort}\"",
        "    depends_on: [design]",
        "    description: |",
        "      Implement the core functionality for: {feature_name}",
        "",
        "      Checklist:",
        "      - [ ] Core logic implemented",
        "      - [ ] Error handling added",
        "      - [ ] Follows existing code patterns",
        "",
        "  - id: unit_tests",
        "    title: \"Unit tests for: {feature_name}\"",
        "    category: \"test\"",
        "    priority: \"high\"",
        "    effort: \"medium\"",
        "    depends_on: [implement]",
        "    description: |",
        "      Write comprehensive unit tests.",
        "",
        "      Coverage requirements:",
        "      - Happy path scenarios",
        "      - Edge cases",
        "      - Error conditions",
        "      - Target: 90%+ coverage for new code",
        "",
        "  - id: integration_tests",
        "    title: \"Integration tests for: {feature_name}\"",
        "    category: \"test\"",
        "    priority: \"high\"",
        "    effort: \"medium\"",
        "    depends_on: [implement]",
        "    description: |",
        "      Write integration tests verifying feature works with existing system.",
        "",
        "      Test scenarios:",
        "      - End-to-end workflows",
        "      - Interaction with other components",
        "      - Performance characteristics",
        "",
        "  - id: documentation",
        "    title: \"Documentation for: {feature_name}\"",
        "    category: \"docs\"",
        "    priority: \"medium\"",
        "    effort: \"small\"",
        "    depends_on: [unit_tests, integration_tests]",
        "    description: |",
        "      Document the new feature.",
        "",
        "      Include:",
        "      - Usage examples",
        "      - API reference updates",
        "      - CLAUDE.md updates if applicable"
      ],
      "lines_removed": [],
      "context_before": [],
      "context_after": [],
      "change_type": "add"
    },
    {
      "file": ".claude/workflows/refactor.yaml",
      "function": null,
      "start_line": 0,
      "lines_added": [
        "# Workflow: Refactoring",
        "# Creates tasks for safe refactoring",
        "",
        "name: \"Refactor\"",
        "description: \"Analyze -> Refactor -> Verify -> Cleanup\"",
        "category: \"refactor\"",
        "",
        "variables:",
        "  - name: refactor_target",
        "    description: \"What is being refactored (module, function, pattern)\"",
        "    required: true",
        "  - name: priority",
        "    description: \"Refactor priority\"",
        "    default: \"medium\"",
        "    choices: [\"high\", \"medium\", \"low\"]",
        "",
        "tasks:",
        "  - id: analyze",
        "    title: \"Analyze before refactor: {refactor_target}\"",
        "    category: \"research\"",
        "    priority: \"{priority}\"",
        "    effort: \"small\"",
        "    description: |",
        "      Understand current state before refactoring.",
        "",
        "      Document:",
        "      - Current behavior and edge cases",
        "      - All callers/dependencies",
        "      - Test coverage baseline",
        "",
        "  - id: refactor",
        "    title: \"Refactor: {refactor_target}\"",
        "    category: \"refactor\"",
        "    priority: \"{priority}\"",
        "    effort: \"medium\"",
        "    depends_on: [analyze]",
        "    description: |",
        "      Perform the refactoring.",
        "",
        "      Guidelines:",
        "      - Make small, incremental changes",
        "      - Run tests after each change",
        "      - Keep commits atomic",
        "",
        "  - id: verify",
        "    title: \"Verify refactor: {refactor_target}\"",
        "    category: \"test\"",
        "    priority: \"high\"",
        "    effort: \"small\"",
        "    depends_on: [refactor]",
        "    description: |",
        "      Verify refactoring didn't break anything.",
        "",
        "      Checklist:",
        "      - [ ] All existing tests pass",
        "      - [ ] Coverage didn't decrease",
        "      - [ ] No new warnings",
        "      - [ ] Performance not degraded",
        "",
        "  - id: cleanup",
        "    title: \"Cleanup after refactor: {refactor_target}\"",
        "    category: \"codequal\"",
        "    priority: \"low\"",
        "    effort: \"small\"",
        "    depends_on: [verify]",
        "    description: |",
        "      Final cleanup tasks.",
        "",
        "      Consider:",
        "      - Remove dead code",
        "      - Update comments",
        "      - Remove temporary scaffolding"
      ],
      "lines_removed": [],
      "context_before": [],
      "context_after": [],
      "change_type": "add"
    },
    {
      "file": "workflows/ci.yml b/.github/workflows/ci.yml",
      "function": "jobs:",
      "start_line": 63,
      "lines_added": [
        "    - name: Report Pending Tasks",
        "      if: always()",
        "      run: |",
        "        echo \"=== Pending Tasks Report ===\"",
        "        python scripts/ci_task_report.py --github",
        "      env:",
        "        GITHUB_STEP_SUMMARY: ${{ github.step_summary }}",
        ""
      ],
      "lines_removed": [],
      "context_before": [
        "      uses: actions/setup-python@v5",
        "      with:",
        "        python-version: '3.11'",
        "",
        "    - name: Validate TASK_LIST.md",
        "      run: |",
        "        echo \"=== Validating Task List ===\"",
        "        python scripts/validate_task_list.py",
        "        echo \"âœ… Task list validation passed\"",
        ""
      ],
      "context_after": [
        "  # ==========================================================================",
        "  # Stage 1: Smoke Tests (< 30s)",
        "  # Quick sanity check - if this fails, something is fundamentally broken",
        "  # ==========================================================================",
        "  smoke-tests:",
        "    name: \"ðŸ’¨ Smoke Tests\"",
        "    runs-on: ubuntu-latest",
        "    steps:",
        "    - uses: actions/checkout@v4",
        ""
      ],
      "change_type": "add"
    },
    {
      "file": ".gitignore",
      "function": "CodeCoverage/",
      "start_line": 79,
      "lines_added": [
        "tasks/.current_session.json"
      ],
      "lines_removed": [],
      "context_before": [
        "[Tt]est[Rr]esult*/",
        "[Bb]uild[Ll]og.*",
        "",
        "# NUnit",
        "*.VisualState.xml",
        "TestResult.xml",
        "nunit-*.xml",
        "# Indexer progress files",
        ".index_progress.json",
        ".index_incremental_progress.json"
      ],
      "context_after": [],
      "change_type": "add"
    },
    {
      "file": "docs/merge-friendly-tasks.md",
      "function": null,
      "start_line": 0,
      "lines_added": [
        "# Merge-Friendly Task Management",
        "",
        "This document describes the merge-friendly task ID system for parallel agent workflows.",
        "",
        "## The Problem",
        "",
        "When multiple Claude agents run in parallel on the same repository:",
        "- Both might create task `#239` (next sequential ID)",
        "- Both modify `TASK_LIST.md` simultaneously",
        "- Git merge conflicts are guaranteed",
        "",
        "## The Solution",
        "",
        "Use **timestamp-based, session-scoped task IDs** that can't collide:",
        "",
        "```",
        "T-20251213-143052-a1b2",
        "â”‚ â”‚        â”‚      â”‚",
        "â”‚ â”‚        â”‚      â””â”€â”€ 4-char session suffix (unique per agent session)",
        "â”‚ â”‚        â””â”€â”€ Time created (HHMMSS)",
        "â”‚ â””â”€â”€ Date created (YYYYMMDD)",
        "â””â”€â”€ Task prefix",
        "```",
        "",
        "Combined with **per-session task files**:",
        "",
        "```",
        "tasks/",
        "â”œâ”€â”€ 2025-12-13_14-30-52_a1b2.json    # Agent A's session",
        "â”œâ”€â”€ 2025-12-13_14-31-05_c3d4.json    # Agent B's session",
        "â””â”€â”€ ...",
        "```",
        "",
        "## How It Works",
        "",
        "### 1. Each Agent Creates Its Own Session",
        "",
        "```python",
        "from scripts.task_utils import TaskSession",
        "",
        "# Start a session (gets unique suffix like \"a1b2\")",
        "session = TaskSession()",
        "",
        "# Create tasks (all get same suffix)",
        "task1 = session.create_task(",
        "    title=\"Implement feature X\",",
        "    priority=\"high\",",
        "    category=\"arch\",",
        "    description=\"...\",",
        "    effort=\"medium\"",
        ")",
        "",
        "task2 = session.create_task(",
        "    title=\"Add tests for feature X\",",
        "    priority=\"medium\",",
        "    category=\"test\",",
        "    depends_on=[task1.id]",
        ")",
        "",
        "# Save to tasks/2025-12-13_14-30-52_a1b2.json",
        "session.save()",
        "```",
        "",
        "### 2. No Merge Conflicts",
        "",
        "Each agent writes to a **unique filename**:",
        "- Agent A: `tasks/2025-12-13_14-30-52_a1b2.json`",
        "- Agent B: `tasks/2025-12-13_14-31-05_c3d4.json`",
        "",
        "Files never conflict because:",
        "1. Timestamps are different (even by milliseconds)",
        "2. Session IDs are randomly generated",
        "3. Each agent only writes to its own file",
        "",
        "### 3. Consolidation (Like `git gc`)",
        "",
        "Periodically consolidate task files:",
        "",
        "```bash",
        "# Show summary of all tasks",
        "python scripts/consolidate_tasks.py --summary",
        "",
        "# Auto-merge duplicates and consolidate",
        "python scripts/consolidate_tasks.py --update --auto-merge",
        "",
        "# Archive old session files after consolidation",
        "python scripts/consolidate_tasks.py --update --archive",
        "```",
        "",
        "## Task ID Formats",
        "",
        "### Full Format (Default)",
        "```",
        "T-20251213-143052-a1b2",
        "```",
        "- Sortable by creation time",
        "- Self-documenting (when it was created)",
        "- Session-traceable (which agent created it)",
        "",
        "### Short Format",
        "```",
        "T-a1b2c3d4",
        "```",
        "- More compact (8 hex chars)",
        "- Still practically unique",
        "- Good for quick references",
        "",
        "```python",
        "from scripts.task_utils import generate_short_task_id",
        "task_id = generate_short_task_id()  # T-a1b2c3d4",
        "```",
        "",
        "## CLI Commands",
        "",
        "### Generate Task ID",
        "```bash",
        "# Full format",
        "python scripts/task_utils.py generate",
        "# Output: T-20251213-143052-a1b2",
        "",
        "# Short format",
        "python scripts/task_utils.py generate --short",
        "# Output: T-a1b2c3d4",
        "```",
        "",
        "### List All Tasks",
        "```bash",
        "# List all tasks",
        "python scripts/task_utils.py list",
        "",
        "# Filter by status",
        "python scripts/task_utils.py list --status pending",
        "```",
        "",
        "### Consolidate Tasks",
        "```bash",
        "# Dry run (see what would happen)",
        "python scripts/consolidate_tasks.py --dry-run",
        "",
        "# Consolidate with summary",
        "python scripts/consolidate_tasks.py --update",
        "",
        "# Auto-merge duplicates",
        "python scripts/consolidate_tasks.py --update --auto-merge",
        "```",
        "",
        "## Comparison with Legacy System",
        "",
        "| Aspect | Legacy (`#133`) | New (`T-a1b2c3d4`) |",
        "|--------|-----------------|---------------------|",
        "| Collision risk | High (parallel agents) | ~Zero |",
        "| Human readable | Very easy | Moderate |",
        "| Git-friendly | Conflicts guaranteed | No conflicts |",
        "| Sorting | Natural numeric | Chronological |",
        "| Traceability | None | Session + timestamp |",
        "",
        "## Best Practices",
        "",
        "### For Parallel Agents",
        "",
        "1. **Always create a session** at the start of your work",
        "2. **Save the session** before your work is committed",
        "3. **Reference tasks by full ID** in commits and comments",
        "",
        "### For Consolidation",
        "",
        "1. **Run consolidation weekly** (or after parallel agent runs)",
        "2. **Use `--auto-merge`** to deduplicate similar tasks",
        "3. **Archive old files** to keep the directory clean",
        "",
        "### For Migration",
        "",
        "The new system can coexist with legacy `TASK_LIST.md`:",
        "- Legacy tasks keep their `#123` format",
        "- New tasks use `T-...` format",
        "- Both can be referenced and tracked",
        "",
        "## Architecture",
        "",
        "```",
        "tasks/",
        "â”œâ”€â”€ 2025-12-13_14-30-52_a1b2.json    # Agent sessions (append-only)",
        "â”œâ”€â”€ 2025-12-13_14-31-05_c3d4.json",
        "â”œâ”€â”€ consolidated_2025-12-13.json     # Periodic consolidation",
        "â””â”€â”€ archive/                          # Archived old files",
        "    â””â”€â”€ ...",
        "",
        "TASK_LIST.md                          # Optional: human-readable summary",
        "```",
        "",
        "This mirrors the `chunk_index.py` architecture for corpus indexing.",
        "",
        "## Task File Format",
        "",
        "```json",
        "{",
        "  \"version\": 1,",
        "  \"session_id\": \"a1b2\",",
        "  \"started_at\": \"2025-12-13T14:30:52\",",
        "  \"saved_at\": \"2025-12-13T14:35:00\",",
        "  \"tasks\": [",
        "    {",
        "      \"id\": \"T-20251213-143052-a1b2\",",
        "      \"title\": \"Implement feature X\",",
        "      \"status\": \"pending\",",
        "      \"priority\": \"high\",",
        "      \"category\": \"arch\",",
        "      \"description\": \"Detailed description...\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"medium\",",
        "      \"created_at\": \"2025-12-13T14:30:52\",",
        "      \"updated_at\": null,",
        "      \"completed_at\": null,",
        "      \"context\": {",
        "        \"files\": [\"cortical/processor.py\"],",
        "        \"methods\": [\"compute_all()\"]",
        "      }",
        "    }",
        "  ]",
        "}",
        "```",
        "",
        "## Future Enhancements",
        "",
        "1. **Real-time sync**: Watch for file changes and auto-consolidate",
        "2. **Web UI**: Visual task board from consolidated data",
        "3. **GitHub Issues sync**: Two-way sync with GitHub Issues",
        "4. **Task dependencies**: Topological sorting for execution order",
        "",
        "---",
        "",
        "*This system follows the same principles as `cortical/chunk_index.py` - append-only, git-friendly, merge-conflict-free.*"
      ],
      "lines_removed": [],
      "context_before": [],
      "context_after": [],
      "change_type": "add"
    },
    {
      "file": "docs/task-management-dogfooding.md",
      "function": null,
      "start_line": 0,
      "lines_added": [
        "# Task Management Dog-Fooding Guide",
        "",
        "This guide explains how to use the task management system to track its own development - eating our own dog food.",
        "",
        "## Overview",
        "",
        "The task management system is designed for parallel Claude agent workflows. We use it to:",
        "1. Track our own development tasks",
        "2. Coordinate between multiple agent sessions",
        "3. Ensure nothing falls through the cracks",
        "",
        "## Quick Reference",
        "",
        "```bash",
        "# List all tasks",
        "python scripts/new_task.py --list",
        "",
        "# Create a task",
        "python scripts/new_task.py \"Fix bug X\" --priority high --category bugfix",
        "",
        "# Complete a task",
        "python scripts/new_task.py --complete T-XXXXX",
        "",
        "# View task summary",
        "python scripts/new_task.py --summary",
        "",
        "# Use workflow templates",
        "python scripts/workflow.py run bugfix --bug_title \"Description\"",
        "",
        "# CI-friendly report",
        "python scripts/ci_task_report.py --github",
        "```",
        "",
        "## Dog-Fooding Workflow",
        "",
        "### 1. Start of Session",
        "",
        "At the beginning of each development session:",
        "",
        "```bash",
        "# Check pending tasks",
        "python scripts/new_task.py --list",
        "",
        "# Identify high-priority items",
        "python scripts/ci_task_report.py --quiet",
        "# Output: Tasks: 5 pending (ðŸ”´2 ðŸŸ¡3 ðŸŸ¢0)",
        "```",
        "",
        "**Key questions:**",
        "- Are there high-priority tasks I should address first?",
        "- Are there tasks from previous sessions that are stale?",
        "- What was I working on last time?",
        "",
        "### 2. Creating Tasks",
        "",
        "When you discover work to do:",
        "",
        "```bash",
        "# Quick task",
        "python scripts/new_task.py \"Investigate slow search\" --priority high",
        "",
        "# With workflow template (creates linked tasks)",
        "python scripts/workflow.py run bugfix --bug_title \"Search returns wrong results\"",
        "",
        "# Dry run first to preview",
        "python scripts/workflow.py run feature --feature_name \"New feature\" --dry-run",
        "```",
        "",
        "**Best practices:**",
        "- Create tasks immediately when you discover them",
        "- Use workflow templates for standard patterns",
        "- Set priority based on impact, not urgency",
        "- Include category for filtering",
        "",
        "### 3. Working on Tasks",
        "",
        "When starting work:",
        "",
        "```bash",
        "# Check what's pending",
        "python scripts/new_task.py --list --status pending",
        "",
        "# Pick a task and start working",
        "# (The system doesn't track \"in_progress\" automatically - you manage it)",
        "```",
        "",
        "### 4. Completing Tasks",
        "",
        "After finishing work:",
        "",
        "```bash",
        "# Mark task as done",
        "python scripts/new_task.py --complete T-20251213-143052-a1b2-001",
        "",
        "# Verify completion",
        "python scripts/new_task.py --list --status completed",
        "```",
        "",
        "**When to mark complete:**",
        "- Code is written and tested",
        "- Changes are committed",
        "- Related documentation updated",
        "- No blocking issues remain",
        "",
        "### 5. End of Session",
        "",
        "Before ending your session:",
        "",
        "```bash",
        "# Verify no orphaned tasks",
        "python scripts/new_task.py --list",
        "",
        "# Create continuation tasks for unfinished work",
        "python scripts/new_task.py \"Continue: Feature X implementation\" --description \"Left off at...\"",
        "",
        "# Commit task files",
        "git add tasks/*.json",
        "git commit -m \"Update task status\"",
        "git push",
        "```",
        "",
        "## Session Continuity",
        "",
        "The system maintains session state across CLI invocations:",
        "",
        "```",
        "tasks/",
        "â”œâ”€â”€ .current_session.json       # Current session metadata",
        "â”œâ”€â”€ 2025-12-13_14-30-52_a1b2.json  # Session 1 tasks",
        "â””â”€â”€ 2025-12-13_16-00-00_b2c3.json  # Session 2 tasks",
        "```",
        "",
        "### Starting a New Session",
        "",
        "```bash",
        "# Start fresh session (clears .current_session.json)",
        "python scripts/new_task.py --new-session",
        "",
        "# Tasks in new session get new IDs",
        "python scripts/new_task.py \"First task in new session\"",
        "# Creates: T-20251213-160000-c3d4-001",
        "```",
        "",
        "### Resuming Previous Session",
        "",
        "Sessions persist until you explicitly start a new one. Task IDs continue incrementing.",
        "",
        "## Parallel Agent Workflows",
        "",
        "### Multiple Agents Working Simultaneously",
        "",
        "Each agent creates tasks with unique session IDs:",
        "",
        "```",
        "Agent A: T-20251213-143052-a1b2-001, T-20251213-143052-a1b2-002",
        "Agent B: T-20251213-143055-c3d4-001, T-20251213-143055-c3d4-002",
        "```",
        "",
        "**No merge conflicts:** Different session IDs mean different filenames.",
        "",
        "### Consolidating Work",
        "",
        "After parallel work completes:",
        "",
        "```bash",
        "# View all tasks from all sessions",
        "python scripts/new_task.py --list",
        "",
        "# Generate consolidated report",
        "python scripts/consolidate_tasks.py --output CONSOLIDATED.md",
        "```",
        "",
        "## CI Integration",
        "",
        "The CI pipeline automatically shows pending tasks:",
        "",
        "```yaml",
        "# In .github/workflows/ci.yml",
        "- name: Report Pending Tasks",
        "  run: python scripts/ci_task_report.py --github",
        "```",
        "",
        "### CI Output Formats",
        "",
        "```bash",
        "# GitHub Actions (markdown tables)",
        "python scripts/ci_task_report.py --github",
        "",
        "# Console (readable)",
        "python scripts/ci_task_report.py",
        "",
        "# Minimal (one-liner)",
        "python scripts/ci_task_report.py --quiet",
        "",
        "# Fail if high-priority tasks exist",
        "python scripts/ci_task_report.py --fail-on-high",
        "```",
        "",
        "## Workflow Templates",
        "",
        "Pre-defined task chains for common patterns:",
        "",
        "| Workflow | Tasks | Use When |",
        "|----------|-------|----------|",
        "| `bugfix` | investigate â†’ fix â†’ test â†’ document | Fixing bugs |",
        "| `feature` | design â†’ implement â†’ unit_tests â†’ integration_tests â†’ docs | Adding features |",
        "| `refactor` | analyze â†’ plan â†’ execute â†’ verify | Restructuring code |",
        "",
        "### Creating Custom Workflows",
        "",
        "```yaml",
        "# .claude/workflows/my_workflow.yaml",
        "name: \"My Workflow\"",
        "description: \"Custom task chain\"",
        "variables:",
        "  - name: target",
        "    required: true",
        "tasks:",
        "  - id: step1",
        "    title: \"First: {target}\"",
        "  - id: step2",
        "    title: \"Second: {target}\"",
        "    depends_on: [step1]",
        "```",
        "",
        "## Testing the Task System",
        "",
        "When making changes to the task system itself:",
        "",
        "### 1. Run Unit Tests",
        "",
        "```bash",
        "python -m pytest tests/unit/test_task_utils.py tests/unit/test_workflow.py -v",
        "```",
        "",
        "### 2. Run Integration Tests",
        "",
        "```bash",
        "python -m pytest tests/integration/test_task_integration.py tests/integration/test_workflow_integration.py -v",
        "```",
        "",
        "### 3. Manual Dog-Fooding",
        "",
        "```bash",
        "# Create a test task",
        "python scripts/new_task.py \"Test task\" --priority low",
        "",
        "# Verify it appears",
        "python scripts/new_task.py --list",
        "",
        "# Complete it",
        "python scripts/new_task.py --complete T-XXXXX",
        "",
        "# Verify completion",
        "python scripts/new_task.py --list --status completed",
        "",
        "# Clean up (optional)",
        "# Delete the session file from tasks/",
        "```",
        "",
        "## Common Patterns",
        "",
        "### Bug Discovery During Feature Work",
        "",
        "```bash",
        "# You're working on feature X, discover bug Y",
        "python scripts/new_task.py \"Bug: Y found during X\" --priority high --category bugfix",
        "# Continue with feature X, bug Y is tracked",
        "```",
        "",
        "### Splitting Large Tasks",
        "",
        "```bash",
        "# Original task too big",
        "python scripts/workflow.py run feature --feature_name \"Large Feature\"",
        "# Creates 5 linked tasks automatically",
        "",
        "# Or manually create subtasks",
        "python scripts/new_task.py \"Part 1: Setup\" --priority high",
        "python scripts/new_task.py \"Part 2: Core logic\" --priority high",
        "python scripts/new_task.py \"Part 3: Tests\" --priority high",
        "```",
        "",
        "### Handling Blocked Tasks",
        "",
        "If a task is blocked:",
        "1. Don't mark it complete",
        "2. Create a new task for the blocker",
        "3. Add description noting the block",
        "",
        "```bash",
        "python scripts/new_task.py \"Blocked: Need API access for X\" --priority high",
        "```",
        "",
        "## Metrics and Reporting",
        "",
        "Track progress over time:",
        "",
        "```bash",
        "# Summary counts",
        "python scripts/new_task.py --summary",
        "",
        "# Output:",
        "# pending: 5",
        "# in_progress: 0",
        "# completed: 12",
        "# deferred: 1",
        "",
        "# CI report with priority breakdown",
        "python scripts/ci_task_report.py",
        "```",
        "",
        "## Files and Locations",
        "",
        "| Path | Purpose |",
        "|------|---------|",
        "| `tasks/*.json` | Task session files |",
        "| `tasks/.current_session.json` | Active session state |",
        "| `.claude/workflows/*.yaml` | Workflow templates |",
        "| `.claude/skills/task-manager/` | Claude Code skill definition |",
        "| `scripts/task_utils.py` | Core task utilities |",
        "| `scripts/new_task.py` | CLI for task management |",
        "| `scripts/workflow.py` | Workflow template engine |",
        "| `scripts/ci_task_report.py` | CI-friendly task reporter |",
        "| `scripts/consolidate_tasks.py` | Task consolidation |",
        "",
        "## Troubleshooting",
        "",
        "### Tasks Not Showing Up",
        "",
        "```bash",
        "# Check tasks directory exists",
        "ls -la tasks/",
        "",
        "# Check for valid JSON",
        "cat tasks/*.json | python -m json.tool",
        "```",
        "",
        "### Duplicate Task IDs",
        "",
        "This shouldn't happen due to timestamp + session + counter format. If it does:",
        "",
        "```bash",
        "# Check session file",
        "cat tasks/.current_session.json",
        "",
        "# Start new session",
        "python scripts/new_task.py --new-session",
        "```",
        "",
        "### CI Report Empty",
        "",
        "```bash",
        "# Ensure tasks directory exists",
        "mkdir -p tasks",
        "",
        "# Check if any tasks exist",
        "python scripts/task_utils.py list --dir tasks",
        "```",
        "",
        "---",
        "",
        "*Remember: We build this system for ourselves. If something is painful, fix it and add a task for improving it.*"
      ],
      "lines_removed": [],
      "context_before": [],
      "context_after": [],
      "change_type": "add"
    },
    {
      "file": "docs/workflow-templates.md",
      "function": null,
      "start_line": 0,
      "lines_added": [
        "# Workflow Templates",
        "",
        "Workflow templates enable creating multiple linked tasks from a single command. This is useful for standardizing common development patterns like bug fixes, features, and refactors.",
        "",
        "## Quick Start",
        "",
        "```bash",
        "# List available workflows",
        "python scripts/workflow.py list",
        "",
        "# Run the bugfix workflow",
        "python scripts/workflow.py run bugfix --bug_title \"Login fails with special characters\"",
        "",
        "# Dry run (see tasks without creating)",
        "python scripts/workflow.py run feature --feature_name \"Dark mode\" --dry-run",
        "```",
        "",
        "## Available Workflows",
        "",
        "### Bug Fix (`bugfix`)",
        "",
        "Creates 4 tasks with dependencies:",
        "",
        "```",
        "investigate â†’ fix â†’ test",
        "                 â†’ document",
        "```",
        "",
        "**Variables:**",
        "| Variable | Required | Default | Description |",
        "|----------|----------|---------|-------------|",
        "| `bug_title` | Yes | - | Brief description of the bug |",
        "| `priority` | No | high | Bug priority (high/medium/low) |",
        "| `affected_file` | No | - | Primary file affected |",
        "",
        "**Example:**",
        "```bash",
        "python scripts/workflow.py run bugfix \\",
        "    --bug_title \"Search returns stale results\" \\",
        "    --priority high",
        "```",
        "",
        "### Feature (`feature`)",
        "",
        "Creates 5 tasks with dependencies:",
        "",
        "```",
        "design â†’ implement â†’ unit_tests â†’ documentation",
        "                  â†’ integration_tests â†—",
        "```",
        "",
        "**Variables:**",
        "| Variable | Required | Default | Description |",
        "|----------|----------|---------|-------------|",
        "| `feature_name` | Yes | - | Name of the feature |",
        "| `priority` | No | medium | Feature priority |",
        "| `effort` | No | large | Overall effort (small/medium/large) |",
        "",
        "**Example:**",
        "```bash",
        "python scripts/workflow.py run feature \\",
        "    --feature_name \"Semantic search\" \\",
        "    --priority high \\",
        "    --effort large",
        "```",
        "",
        "### Refactor (`refactor`)",
        "",
        "Creates 4 tasks with dependencies:",
        "",
        "```",
        "analyze â†’ plan â†’ execute â†’ verify",
        "```",
        "",
        "**Variables:**",
        "| Variable | Required | Default | Description |",
        "|----------|----------|---------|-------------|",
        "| `refactor_target` | Yes | - | What to refactor |",
        "| `priority` | No | medium | Refactor priority |",
        "| `scope` | No | module | Scope (function/module/system) |",
        "",
        "**Example:**",
        "```bash",
        "python scripts/workflow.py run refactor \\",
        "    --refactor_target \"Query expansion logic\" \\",
        "    --scope module",
        "```",
        "",
        "## Creating Custom Workflows",
        "",
        "Workflows are YAML files in `.claude/workflows/`. Here's the structure:",
        "",
        "```yaml",
        "# .claude/workflows/my_workflow.yaml",
        "name: \"My Workflow\"",
        "description: \"Brief description of what this workflow does\"",
        "category: \"general\"",
        "",
        "variables:",
        "  - name: task_name",
        "    description: \"The name of the task\"",
        "    required: true",
        "  - name: priority",
        "    description: \"Task priority\"",
        "    default: \"medium\"",
        "    choices: [\"high\", \"medium\", \"low\"]",
        "",
        "tasks:",
        "  - id: first_task",
        "    title: \"First: {task_name}\"",
        "    category: \"planning\"",
        "    priority: \"{priority}\"",
        "    effort: \"small\"",
        "    description: |",
        "      Description with {task_name} substitution.",
        "",
        "  - id: second_task",
        "    title: \"Second: {task_name}\"",
        "    depends_on: [first_task]",
        "    description: |",
        "      This task depends on first_task completing.",
        "```",
        "",
        "### Variable Types",
        "",
        "| Field | Required | Description |",
        "|-------|----------|-------------|",
        "| `name` | Yes | Variable name (used in `{name}` placeholders) |",
        "| `description` | No | Help text shown to users |",
        "| `required` | No | If true, must be provided (default: true) |",
        "| `default` | No | Default value if not provided |",
        "| `choices` | No | List of valid values |",
        "",
        "### Task Fields",
        "",
        "| Field | Required | Default | Description |",
        "|-------|----------|---------|-------------|",
        "| `id` | Yes | - | Unique ID within workflow (used for depends_on) |",
        "| `title` | Yes | - | Task title (supports `{variable}` substitution) |",
        "| `category` | No | general | Task category |",
        "| `priority` | No | medium | Task priority (supports substitution) |",
        "| `effort` | No | medium | Effort estimate (supports substitution) |",
        "| `description` | No | \"\" | Detailed description |",
        "| `depends_on` | No | [] | List of task IDs this depends on |",
        "",
        "## API Usage",
        "",
        "You can also use workflows programmatically:",
        "",
        "```python",
        "from scripts.workflow import Workflow, run_workflow",
        "",
        "# Load a workflow",
        "workflow = Workflow.load(Path(\".claude/workflows/bugfix.yaml\"))",
        "",
        "# Run with variables",
        "variables = {\"bug_title\": \"Login bug\", \"priority\": \"high\"}",
        "tasks = run_workflow(workflow, variables, tasks_dir=\"tasks\", dry_run=False)",
        "",
        "# Access created tasks",
        "for task in tasks:",
        "    print(f\"{task.id}: {task.title}\")",
        "```",
        "",
        "## Task Output",
        "",
        "Tasks are saved as JSON files in the `tasks/` directory:",
        "",
        "```",
        "tasks/",
        "â”œâ”€â”€ 2025-12-13_14-30-52_a1b2.json  # Session file with tasks",
        "â””â”€â”€ 2025-12-13_15-00-00_c3d4.json  # Another session",
        "```",
        "",
        "Each session file contains:",
        "```json",
        "{",
        "  \"version\": 1,",
        "  \"session_id\": \"a1b2\",",
        "  \"started_at\": \"2025-12-13T14:30:52\",",
        "  \"saved_at\": \"2025-12-13T14:30:53\",",
        "  \"tasks\": [",
        "    {",
        "      \"id\": \"T-20251213-143052-a1b2-001\",",
        "      \"title\": \"Investigate: Login bug\",",
        "      \"status\": \"pending\",",
        "      \"priority\": \"high\",",
        "      \"depends_on\": []",
        "    },",
        "    {",
        "      \"id\": \"T-20251213-143052-a1b2-002\",",
        "      \"title\": \"Fix: Login bug\",",
        "      \"depends_on\": [\"T-20251213-143052-a1b2-001\"]",
        "    }",
        "  ]",
        "}",
        "```",
        "",
        "## Best Practices",
        "",
        "1. **Use dry-run first**: Always preview with `--dry-run` before creating tasks",
        "2. **Keep workflows focused**: Each workflow should handle one type of work",
        "3. **Use dependencies**: Link tasks to show the correct order",
        "4. **Descriptive titles**: Include the variable in titles for context",
        "5. **Add descriptions**: Include checklists and acceptance criteria",
        "",
        "## Integration with CI",
        "",
        "The CI pipeline shows pending tasks using `scripts/ci_task_report.py`:",
        "",
        "```bash",
        "# GitHub Actions format",
        "python scripts/ci_task_report.py --github",
        "",
        "# Console format",
        "python scripts/ci_task_report.py",
        "",
        "# Fail if high-priority tasks exist",
        "python scripts/ci_task_report.py --fail-on-high",
        "```"
      ],
      "lines_removed": [],
      "context_before": [],
      "context_after": [],
      "change_type": "add"
    },
    {
      "file": "scripts/ci_task_create.py",
      "function": null,
      "start_line": 0,
      "lines_added": [
        "#!/usr/bin/env python3",
        "\"\"\"",
        "Auto-create tasks from CI test failures.",
        "",
        "This script parses test output and creates tasks for failures automatically.",
        "Designed to be run in CI after test failures to ensure nothing is forgotten.",
        "",
        "Usage:",
        "    # From pytest output file",
        "    python scripts/ci_task_create.py --pytest output.txt",
        "",
        "    # From pytest-json-report",
        "    python scripts/ci_task_create.py --pytest-json report.json",
        "",
        "    # Pipe from pytest directly",
        "    pytest tests/ 2>&1 | python scripts/ci_task_create.py --pytest -",
        "",
        "    # Dry run (show tasks without creating)",
        "    pytest tests/ 2>&1 | python scripts/ci_task_create.py --pytest - --dry-run",
        "",
        "Examples:",
        "    # In CI workflow",
        "    - name: Run tests",
        "      run: pytest tests/ -v 2>&1 | tee test_output.txt || true",
        "",
        "    - name: Create tasks for failures",
        "      if: failure()",
        "      run: python scripts/ci_task_create.py --pytest test_output.txt",
        "\"\"\"",
        "",
        "import argparse",
        "import json",
        "import re",
        "import sys",
        "from pathlib import Path",
        "from typing import List, Tuple",
        "",
        "# Add scripts to path",
        "sys.path.insert(0, str(Path(__file__).parent))",
        "",
        "from task_utils import TaskSession, DEFAULT_TASKS_DIR",
        "",
        "",
        "def parse_pytest_output(content: str) -> List[Tuple[str, str, str]]:",
        "    \"\"\"",
        "    Parse pytest output to extract test failures.",
        "",
        "    Returns:",
        "        List of (test_name, file_path, error_message) tuples",
        "    \"\"\"",
        "    failures = []",
        "",
        "    # Pattern for FAILED lines: FAILED tests/test_foo.py::TestClass::test_name",
        "    failed_pattern = re.compile(r'FAILED\\s+([^\\s:]+)::(\\S+)')",
        "",
        "    # Pattern for error details in short format",
        "    error_pattern = re.compile(",
        "        r'([^\\s]+\\.py):(\\d+):\\s+(\\w+(?:Error|Exception|Failed|Failure).*?)(?=\\n[^\\s]|\\Z)',",
        "        re.MULTILINE | re.DOTALL",
        "    )",
        "",
        "    # Pattern for assertion errors",
        "    assert_pattern = re.compile(",
        "        r'>\\s+assert\\s+(.+?)\\nE\\s+(.+)',",
        "        re.MULTILINE",
        "    )",
        "",
        "    # Find all FAILED lines",
        "    for match in failed_pattern.finditer(content):",
        "        file_path = match.group(1)",
        "        test_name = match.group(2)",
        "",
        "        # Try to extract error message",
        "        error_msg = \"Test failed\"",
        "",
        "        # Look for AssertionError nearby",
        "        test_section_start = match.start()",
        "        test_section_end = content.find('FAILED', test_section_start + 1)",
        "        if test_section_end == -1:",
        "            test_section_end = len(content)",
        "",
        "        test_section = content[test_section_start:test_section_end]",
        "",
        "        # Look for assertion details",
        "        assert_match = assert_pattern.search(test_section)",
        "        if assert_match:",
        "            error_msg = f\"Assertion: {assert_match.group(2).strip()}\"",
        "        else:",
        "            # Look for any error",
        "            error_match = error_pattern.search(test_section)",
        "            if error_match:",
        "                error_msg = error_match.group(3).strip()[:100]",
        "",
        "        failures.append((test_name, file_path, error_msg))",
        "",
        "    return failures",
        "",
        "",
        "def parse_pytest_json(content: str) -> List[Tuple[str, str, str]]:",
        "    \"\"\"",
        "    Parse pytest-json-report output.",
        "",
        "    Returns:",
        "        List of (test_name, file_path, error_message) tuples",
        "    \"\"\"",
        "    failures = []",
        "",
        "    try:",
        "        data = json.loads(content)",
        "    except json.JSONDecodeError:",
        "        return failures",
        "",
        "    tests = data.get('tests', [])",
        "    for test in tests:",
        "        if test.get('outcome') == 'failed':",
        "            nodeid = test.get('nodeid', '')",
        "            parts = nodeid.split('::')",
        "",
        "            file_path = parts[0] if parts else 'unknown'",
        "            test_name = parts[-1] if parts else nodeid",
        "",
        "            # Extract error message from call phase",
        "            call = test.get('call', {})",
        "            longrepr = call.get('longrepr', '')",
        "            if isinstance(longrepr, str):",
        "                # Get first meaningful line",
        "                error_msg = longrepr.split('\\n')[0][:100]",
        "            else:",
        "                error_msg = \"Test failed\"",
        "",
        "            failures.append((test_name, file_path, error_msg))",
        "",
        "    return failures",
        "",
        "",
        "def create_tasks_for_failures(",
        "    failures: List[Tuple[str, str, str]],",
        "    tasks_dir: str = DEFAULT_TASKS_DIR,",
        "    dry_run: bool = False,",
        "    ci_run_id: str = None",
        ") -> List[str]:",
        "    \"\"\"",
        "    Create tasks for test failures.",
        "",
        "    Args:",
        "        failures: List of (test_name, file_path, error_message) tuples",
        "        tasks_dir: Directory to save tasks",
        "        dry_run: If True, print tasks without creating",
        "        ci_run_id: Optional CI run identifier for context",
        "",
        "    Returns:",
        "        List of created task IDs",
        "    \"\"\"",
        "    if not failures:",
        "        print(\"No test failures found.\")",
        "        return []",
        "",
        "    session = TaskSession()",
        "    created_ids = []",
        "",
        "    for test_name, file_path, error_msg in failures:",
        "        # Create descriptive title",
        "        title = f\"Fix failing test: {test_name}\"",
        "",
        "        # Create detailed description",
        "        description = f\"\"\"Test failure detected in CI.",
        "",
        "**Test:** {test_name}",
        "**File:** {file_path}",
        "**Error:** {error_msg}",
        "",
        "**Steps to fix:**",
        "1. Run the test locally to reproduce",
        "2. Investigate the failure",
        "3. Implement the fix",
        "4. Verify the test passes",
        "5. Ensure no regressions",
        "\"\"\"",
        "",
        "        if ci_run_id:",
        "            description += f\"\\n**CI Run:** {ci_run_id}\\n\"",
        "",
        "        context = {",
        "            \"source\": \"ci_auto_create\",",
        "            \"test_file\": file_path,",
        "            \"test_name\": test_name,",
        "            \"error\": error_msg[:200]",
        "        }",
        "",
        "        if ci_run_id:",
        "            context[\"ci_run_id\"] = ci_run_id",
        "",
        "        task = session.create_task(",
        "            title=title,",
        "            priority=\"high\",",
        "            category=\"test\",",
        "            description=description,",
        "            effort=\"small\",",
        "            context=context",
        "        )",
        "        created_ids.append(task.id)",
        "",
        "        if dry_run:",
        "            print(f\"[DRY RUN] Would create: {task.id}\")",
        "            print(f\"  Title: {title}\")",
        "            print(f\"  File: {file_path}\")",
        "            print(f\"  Error: {error_msg[:60]}...\")",
        "            print()",
        "",
        "    if not dry_run and created_ids:",
        "        filepath = session.save(tasks_dir)",
        "        print(f\"\\nâœ… Created {len(created_ids)} tasks for test failures\")",
        "        print(f\"Saved to: {filepath}\")",
        "        print(\"\\nCreated tasks:\")",
        "        for task_id in created_ids:",
        "            print(f\"  {task_id}\")",
        "",
        "    return created_ids",
        "",
        "",
        "def main():",
        "    parser = argparse.ArgumentParser(",
        "        description=\"Auto-create tasks from CI test failures\",",
        "        formatter_class=argparse.RawDescriptionHelpFormatter,",
        "        epilog=__doc__",
        "    )",
        "",
        "    parser.add_argument(",
        "        \"--pytest\", metavar=\"FILE\",",
        "        help=\"Parse pytest output file (use '-' for stdin)\"",
        "    )",
        "    parser.add_argument(",
        "        \"--pytest-json\", metavar=\"FILE\",",
        "        help=\"Parse pytest-json-report output file\"",
        "    )",
        "    parser.add_argument(",
        "        \"--dry-run\", action=\"store_true\",",
        "        help=\"Show tasks without creating\"",
        "    )",
        "    parser.add_argument(",
        "        \"--tasks-dir\", default=DEFAULT_TASKS_DIR,",
        "        help=f\"Tasks directory (default: {DEFAULT_TASKS_DIR})\"",
        "    )",
        "    parser.add_argument(",
        "        \"--ci-run-id\",",
        "        help=\"CI run identifier for context\"",
        "    )",
        "",
        "    args = parser.parse_args()",
        "",
        "    failures = []",
        "",
        "    if args.pytest:",
        "        if args.pytest == '-':",
        "            content = sys.stdin.read()",
        "        else:",
        "            with open(args.pytest) as f:",
        "                content = f.read()",
        "        failures = parse_pytest_output(content)",
        "",
        "    elif args.pytest_json:",
        "        with open(args.pytest_json) as f:",
        "            content = f.read()",
        "        failures = parse_pytest_json(content)",
        "",
        "    else:",
        "        parser.print_help()",
        "        print(\"\\nError: Must specify --pytest or --pytest-json\")",
        "        sys.exit(1)",
        "",
        "    if failures:",
        "        print(f\"Found {len(failures)} test failure(s)\\n\")",
        "",
        "    create_tasks_for_failures(",
        "        failures,",
        "        tasks_dir=args.tasks_dir,",
        "        dry_run=args.dry_run,",
        "        ci_run_id=args.ci_run_id",
        "    )",
        "",
        "",
        "if __name__ == \"__main__\":",
        "    main()"
      ],
      "lines_removed": [],
      "context_before": [],
      "context_after": [],
      "change_type": "add"
    },
    {
      "file": "scripts/ci_task_report.py",
      "function": null,
      "start_line": 0,
      "lines_added": [
        "#!/usr/bin/env python3",
        "\"\"\"",
        "CI Task Reporter - Intelligent pending task output for CI pipelines.",
        "",
        "This script outputs pending tasks in a CI-friendly format, suitable for:",
        "- GitHub Actions job summaries",
        "- Console output during CI runs",
        "- Slack/Discord notifications",
        "",
        "Features:",
        "- Groups by priority (high items first)",
        "- Shows estimated effort",
        "- Provides actionable summary",
        "- Exits with non-zero code if high-priority tasks exist (optional)",
        "",
        "Usage:",
        "    # Standard output",
        "    python scripts/ci_task_report.py",
        "",
        "    # GitHub Actions markdown format (writes to $GITHUB_STEP_SUMMARY)",
        "    python scripts/ci_task_report.py --github",
        "",
        "    # Fail CI if high-priority tasks pending",
        "    python scripts/ci_task_report.py --fail-on-high",
        "",
        "    # Quiet mode (summary only)",
        "    python scripts/ci_task_report.py --quiet",
        "\"\"\"",
        "",
        "import argparse",
        "import os",
        "import sys",
        "from pathlib import Path",
        "from typing import Dict, List",
        "",
        "# Add scripts to path",
        "sys.path.insert(0, str(Path(__file__).parent))",
        "",
        "from task_utils import load_all_tasks, Task, DEFAULT_TASKS_DIR",
        "",
        "",
        "def get_pending_tasks(tasks_dir: str = DEFAULT_TASKS_DIR) -> List[Task]:",
        "    \"\"\"Load only pending and in_progress tasks.\"\"\"",
        "    all_tasks = load_all_tasks(tasks_dir)",
        "    return [t for t in all_tasks if t.status in (\"pending\", \"in_progress\")]",
        "",
        "",
        "def group_by_priority(tasks: List[Task]) -> Dict[str, List[Task]]:",
        "    \"\"\"Group tasks by priority.\"\"\"",
        "    grouped = {\"high\": [], \"medium\": [], \"low\": []}",
        "    for task in tasks:",
        "        priority = task.priority if task.priority in grouped else \"medium\"",
        "        grouped[priority].append(task)",
        "    return grouped",
        "",
        "",
        "def format_console_report(tasks: List[Task]) -> str:",
        "    \"\"\"Format tasks for console output.\"\"\"",
        "    if not tasks:",
        "        return \"âœ… No pending tasks!\\n\"",
        "",
        "    grouped = group_by_priority(tasks)",
        "    lines = []",
        "",
        "    # Summary header",
        "    total = len(tasks)",
        "    high_count = len(grouped[\"high\"])",
        "    in_progress = sum(1 for t in tasks if t.status == \"in_progress\")",
        "",
        "    lines.append(\"=\" * 60)",
        "    lines.append(f\"ðŸ“‹ PENDING TASKS: {total} total ({high_count} high priority)\")",
        "    if in_progress:",
        "        lines.append(f\"   ðŸ”„ {in_progress} currently in progress\")",
        "    lines.append(\"=\" * 60)",
        "",
        "    # Priority sections",
        "    priority_config = [",
        "        (\"high\", \"ðŸ”´ HIGH PRIORITY\", \"These need attention!\"),",
        "        (\"medium\", \"ðŸŸ¡ MEDIUM PRIORITY\", \"\"),",
        "        (\"low\", \"ðŸŸ¢ LOW PRIORITY\", \"\"),",
        "    ]",
        "",
        "    for priority, header, note in priority_config:",
        "        if not grouped[priority]:",
        "            continue",
        "        lines.append(\"\")",
        "        lines.append(f\"{header}\" + (f\" - {note}\" if note else \"\"))",
        "        lines.append(\"-\" * 40)",
        "",
        "        for task in grouped[priority]:",
        "            status_marker = \"ðŸ”„\" if task.status == \"in_progress\" else \"  \"",
        "            effort_marker = {\"small\": \"S\", \"medium\": \"M\", \"large\": \"L\"}.get(task.effort, \"?\")",
        "            lines.append(f\"  {status_marker} [{effort_marker}] {task.id}\")",
        "            lines.append(f\"       {task.title}\")",
        "",
        "    lines.append(\"\")",
        "    lines.append(\"=\" * 60)",
        "",
        "    # Actionable summary",
        "    if high_count > 0:",
        "        lines.append(\"âš ï¸  HIGH PRIORITY TASKS REQUIRE ATTENTION\")",
        "",
        "    return \"\\n\".join(lines)",
        "",
        "",
        "def format_github_markdown(tasks: List[Task]) -> str:",
        "    \"\"\"Format tasks as GitHub-flavored markdown for job summary.\"\"\"",
        "    if not tasks:",
        "        return \"## âœ… No Pending Tasks\\n\\nAll tasks have been completed!\\n\"",
        "",
        "    grouped = group_by_priority(tasks)",
        "    lines = []",
        "",
        "    # Summary header",
        "    total = len(tasks)",
        "    high_count = len(grouped[\"high\"])",
        "    in_progress = sum(1 for t in tasks if t.status == \"in_progress\")",
        "",
        "    lines.append(\"## ðŸ“‹ Pending Tasks Summary\")",
        "    lines.append(\"\")",
        "    lines.append(f\"| Metric | Count |\")",
        "    lines.append(\"|--------|-------|\")",
        "    lines.append(f\"| Total Pending | **{total}** |\")",
        "    lines.append(f\"| ðŸ”´ High Priority | {high_count} |\")",
        "    lines.append(f\"| ðŸŸ¡ Medium Priority | {len(grouped['medium'])} |\")",
        "    lines.append(f\"| ðŸŸ¢ Low Priority | {len(grouped['low'])} |\")",
        "    lines.append(f\"| ðŸ”„ In Progress | {in_progress} |\")",
        "    lines.append(\"\")",
        "",
        "    # High priority callout",
        "    if high_count > 0:",
        "        lines.append(\"> âš ï¸ **Attention:** There are high-priority tasks that need attention!\")",
        "        lines.append(\"\")",
        "",
        "    # Task tables by priority",
        "    priority_config = [",
        "        (\"high\", \"### ðŸ”´ High Priority\"),",
        "        (\"medium\", \"### ðŸŸ¡ Medium Priority\"),",
        "        (\"low\", \"### ðŸŸ¢ Low Priority\"),",
        "    ]",
        "",
        "    for priority, header in priority_config:",
        "        if not grouped[priority]:",
        "            continue",
        "",
        "        lines.append(header)",
        "        lines.append(\"\")",
        "        lines.append(\"| Status | ID | Title | Effort | Category |\")",
        "        lines.append(\"|--------|----|----|--------|----------|\")",
        "",
        "        for task in grouped[priority]:",
        "            status = \"ðŸ”„\" if task.status == \"in_progress\" else \"ðŸ“‹\"",
        "            effort = {\"small\": \"S\", \"medium\": \"M\", \"large\": \"L\"}.get(task.effort, \"?\")",
        "            # Escape pipe characters in title",
        "            title = task.title.replace(\"|\", \"\\\\|\")",
        "            lines.append(f\"| {status} | `{task.id}` | {title} | {effort} | {task.category} |\")",
        "",
        "        lines.append(\"\")",
        "",
        "    # Quick commands",
        "    lines.append(\"<details>\")",
        "    lines.append(\"<summary>ðŸ“Œ Quick Commands</summary>\")",
        "    lines.append(\"\")",
        "    lines.append(\"```bash\")",
        "    lines.append(\"# List all tasks\")",
        "    lines.append(\"python scripts/new_task.py --list\")",
        "    lines.append(\"\")",
        "    lines.append(\"# Complete a task\")",
        "    lines.append(\"python scripts/new_task.py --complete T-XXXXX\")",
        "    lines.append(\"\")",
        "    lines.append(\"# Create new task\")",
        "    lines.append('python scripts/new_task.py \"Task title\" --priority high')",
        "    lines.append(\"```\")",
        "    lines.append(\"</details>\")",
        "",
        "    return \"\\n\".join(lines)",
        "",
        "",
        "def format_quiet_report(tasks: List[Task]) -> str:",
        "    \"\"\"Minimal one-line summary.\"\"\"",
        "    if not tasks:",
        "        return \"Tasks: 0 pending\"",
        "",
        "    grouped = group_by_priority(tasks)",
        "    return (",
        "        f\"Tasks: {len(tasks)} pending \"",
        "        f\"(ðŸ”´{len(grouped['high'])} ðŸŸ¡{len(grouped['medium'])} ðŸŸ¢{len(grouped['low'])})\"",
        "    )",
        "",
        "",
        "def main():",
        "    parser = argparse.ArgumentParser(",
        "        description=\"CI Task Reporter - Output pending tasks for CI pipelines\",",
        "        formatter_class=argparse.RawDescriptionHelpFormatter,",
        "        epilog=__doc__",
        "    )",
        "",
        "    parser.add_argument(",
        "        \"--github\", action=\"store_true\",",
        "        help=\"Output GitHub-flavored markdown (writes to GITHUB_STEP_SUMMARY if available)\"",
        "    )",
        "    parser.add_argument(",
        "        \"--fail-on-high\", action=\"store_true\",",
        "        help=\"Exit with code 1 if high-priority tasks exist\"",
        "    )",
        "    parser.add_argument(",
        "        \"--quiet\", \"-q\", action=\"store_true\",",
        "        help=\"Minimal output (summary line only)\"",
        "    )",
        "    parser.add_argument(",
        "        \"--dir\", default=DEFAULT_TASKS_DIR,",
        "        help=f\"Tasks directory (default: {DEFAULT_TASKS_DIR})\"",
        "    )",
        "    parser.add_argument(",
        "        \"--output\", \"-o\",",
        "        help=\"Write report to file instead of stdout\"",
        "    )",
        "",
        "    args = parser.parse_args()",
        "",
        "    # Load pending tasks",
        "    tasks = get_pending_tasks(args.dir)",
        "",
        "    # Format report",
        "    if args.quiet:",
        "        report = format_quiet_report(tasks)",
        "    elif args.github:",
        "        report = format_github_markdown(tasks)",
        "    else:",
        "        report = format_console_report(tasks)",
        "",
        "    # Output report",
        "    if args.output:",
        "        with open(args.output, \"w\") as f:",
        "            f.write(report)",
        "        print(f\"Report written to: {args.output}\")",
        "    else:",
        "        print(report)",
        "",
        "    # GitHub Actions: Write to step summary if available",
        "    if args.github and \"GITHUB_STEP_SUMMARY\" in os.environ:",
        "        summary_file = os.environ[\"GITHUB_STEP_SUMMARY\"]",
        "        with open(summary_file, \"a\") as f:",
        "            f.write(report + \"\\n\")",
        "",
        "    # Exit code logic",
        "    if args.fail_on_high:",
        "        grouped = group_by_priority(tasks)",
        "        if grouped[\"high\"]:",
        "            print(f\"\\nâŒ Failing: {len(grouped['high'])} high-priority tasks pending\")",
        "            sys.exit(1)",
        "",
        "",
        "if __name__ == \"__main__\":",
        "    main()"
      ],
      "lines_removed": [],
      "context_before": [],
      "context_after": [],
      "change_type": "add"
    },
    {
      "file": "scripts/consolidate_tasks.py",
      "function": null,
      "start_line": 0,
      "lines_added": [
        "#!/usr/bin/env python3",
        "\"\"\"",
        "Consolidate task files from parallel agent sessions.",
        "",
        "This script merges task files created by parallel agents into a unified",
        "view, resolving any conflicts and generating an updated TASK_LIST.md.",
        "",
        "Similar to `git gc` for chunk files, this consolidates distributed task",
        "state into a coherent whole.",
        "",
        "Usage:",
        "    # Show what would be consolidated (dry run)",
        "    python scripts/consolidate_tasks.py --dry-run",
        "",
        "    # Consolidate and update TASK_LIST.md",
        "    python scripts/consolidate_tasks.py --update",
        "",
        "    # Just generate a summary without modifying anything",
        "    python scripts/consolidate_tasks.py --summary",
        "",
        "    # Consolidate tasks from a specific directory",
        "    python scripts/consolidate_tasks.py --dir tasks/ --update",
        "",
        "Architecture:",
        "    tasks/",
        "    â”œâ”€â”€ 2025-12-13_14-30-52_a1b2.json    # Agent A's session",
        "    â”œâ”€â”€ 2025-12-13_14-31-05_c3d4.json    # Agent B's session",
        "    â””â”€â”€ ...",
        "",
        "    After consolidation:",
        "    â”œâ”€â”€ consolidated_2025-12-13_15-00-00.json  # Merged state",
        "    â””â”€â”€ (old files can be archived or removed)",
        "\"\"\"",
        "",
        "import argparse",
        "import json",
        "import os",
        "import shutil",
        "from collections import defaultdict",
        "from datetime import datetime",
        "from pathlib import Path",
        "from typing import Dict, List, Optional, Tuple, Any",
        "",
        "from task_utils import (",
        "    Task, TaskSession, load_all_tasks, consolidate_tasks,",
        "    DEFAULT_TASKS_DIR, generate_session_id",
        ")",
        "",
        "",
        "def find_conflicts(tasks: List[Task]) -> Dict[str, List[Task]]:",
        "    \"\"\"",
        "    Find tasks that might be duplicates or conflicts.",
        "",
        "    Returns dict of potential duplicate groups (same title, different IDs).",
        "    \"\"\"",
        "    by_title = defaultdict(list)",
        "    for task in tasks:",
        "        # Normalize title for comparison",
        "        normalized = task.title.lower().strip()",
        "        by_title[normalized].append(task)",
        "",
        "    # Return only groups with potential conflicts",
        "    return {title: tasks for title, tasks in by_title.items() if len(tasks) > 1}",
        "",
        "",
        "def merge_duplicate_tasks(tasks: List[Task]) -> Task:",
        "    \"\"\"",
        "    Merge potentially duplicate tasks into one.",
        "",
        "    Strategy:",
        "    - Keep the earliest creation time",
        "    - Use the most complete description",
        "    - Prefer higher priority",
        "    - Prefer \"in_progress\" or \"completed\" status over \"pending\"",
        "    \"\"\"",
        "    if len(tasks) == 1:",
        "        return tasks[0]",
        "",
        "    # Sort by creation time (keep earliest ID)",
        "    sorted_tasks = sorted(tasks, key=lambda t: t.created_at)",
        "    merged = Task(",
        "        id=sorted_tasks[0].id,",
        "        title=sorted_tasks[0].title,",
        "        created_at=sorted_tasks[0].created_at",
        "    )",
        "",
        "    # Merge fields from all tasks",
        "    priority_order = {\"high\": 0, \"medium\": 1, \"low\": 2}",
        "    status_order = {\"completed\": 0, \"in_progress\": 1, \"pending\": 2, \"deferred\": 3}",
        "",
        "    best_priority = min(tasks, key=lambda t: priority_order.get(t.priority, 1))",
        "    best_status = min(tasks, key=lambda t: status_order.get(t.status, 2))",
        "",
        "    merged.priority = best_priority.priority",
        "    merged.status = best_status.status",
        "    merged.category = sorted_tasks[0].category",
        "",
        "    # Use longest description",
        "    merged.description = max(tasks, key=lambda t: len(t.description)).description",
        "",
        "    # Merge dependencies",
        "    all_deps = set()",
        "    for task in tasks:",
        "        all_deps.update(task.depends_on)",
        "    merged.depends_on = list(all_deps)",
        "",
        "    # Merge context",
        "    merged.context = {}",
        "    for task in tasks:",
        "        merged.context.update(task.context)",
        "",
        "    # Track completion",
        "    completed = [t for t in tasks if t.completed_at]",
        "    if completed:",
        "        merged.completed_at = min(t.completed_at for t in completed)",
        "",
        "    return merged",
        "",
        "",
        "def consolidate_and_dedupe(",
        "    tasks_dir: str = DEFAULT_TASKS_DIR,",
        "    auto_merge: bool = False",
        ") -> Tuple[List[Task], Dict[str, List[Task]]]:",
        "    \"\"\"",
        "    Load all tasks and identify/resolve duplicates.",
        "",
        "    Args:",
        "        tasks_dir: Directory containing task session files",
        "        auto_merge: If True, automatically merge duplicates",
        "",
        "    Returns:",
        "        Tuple of (final task list, conflicts dict)",
        "    \"\"\"",
        "    all_tasks = load_all_tasks(tasks_dir)",
        "    conflicts = find_conflicts(all_tasks)",
        "",
        "    if not auto_merge or not conflicts:",
        "        return all_tasks, conflicts",
        "",
        "    # Auto-merge duplicates",
        "    merged_ids = set()",
        "    final_tasks = []",
        "",
        "    for title, conflict_group in conflicts.items():",
        "        merged = merge_duplicate_tasks(conflict_group)",
        "        final_tasks.append(merged)",
        "        merged_ids.update(t.id for t in conflict_group)",
        "",
        "    # Add non-conflicting tasks",
        "    for task in all_tasks:",
        "        if task.id not in merged_ids:",
        "            final_tasks.append(task)",
        "",
        "    return final_tasks, conflicts",
        "",
        "",
        "def generate_markdown_section(",
        "    tasks: List[Task],",
        "    status_filter: str,",
        "    priority_filter: Optional[str] = None",
        ") -> List[str]:",
        "    \"\"\"Generate markdown table rows for tasks matching filters.\"\"\"",
        "    filtered = [t for t in tasks if t.status == status_filter]",
        "    if priority_filter:",
        "        filtered = [t for t in filtered if t.priority == priority_filter]",
        "",
        "    if not filtered:",
        "        return []",
        "",
        "    # Sort by priority then creation time",
        "    priority_order = {\"high\": 0, \"medium\": 1, \"low\": 2}",
        "    filtered.sort(key=lambda t: (priority_order.get(t.priority, 1), t.created_at))",
        "",
        "    lines = []",
        "    for task in filtered:",
        "        deps = \", \".join(task.depends_on) if task.depends_on else \"-\"",
        "        lines.append(",
        "            f\"| {task.id} | {task.title} | {task.category} | {deps} | {task.effort} |\"",
        "        )",
        "",
        "    return lines",
        "",
        "",
        "def write_consolidated_file(",
        "    tasks: List[Task],",
        "    output_dir: str,",
        "    session_id: Optional[str] = None",
        ") -> Path:",
        "    \"\"\"Write consolidated tasks to a single JSON file.\"\"\"",
        "    dir_path = Path(output_dir)",
        "    dir_path.mkdir(parents=True, exist_ok=True)",
        "",
        "    sid = session_id or generate_session_id()",
        "    timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")",
        "    filename = f\"consolidated_{timestamp}_{sid}.json\"",
        "",
        "    filepath = dir_path / filename",
        "",
        "    data = {",
        "        \"version\": 1,",
        "        \"type\": \"consolidated\",",
        "        \"session_id\": sid,",
        "        \"created_at\": datetime.now().isoformat(),",
        "        \"task_count\": len(tasks),",
        "        \"tasks\": [t.to_dict() for t in tasks]",
        "    }",
        "",
        "    # Atomic write: temp file then rename",
        "    temp_filepath = filepath.with_suffix('.json.tmp')",
        "    try:",
        "        with open(temp_filepath, 'w') as f:",
        "            json.dump(data, f, indent=2)",
        "            f.flush()",
        "            os.fsync(f.fileno())",
        "        temp_filepath.rename(filepath)",
        "    except Exception:",
        "        if temp_filepath.exists():",
        "            temp_filepath.unlink()",
        "        raise",
        "",
        "    return filepath",
        "",
        "",
        "def _validate_archive_path(tasks_dir: Path, archive_path: Path) -> None:",
        "    \"\"\"",
        "    Validate that archive_path is within or under tasks_dir.",
        "",
        "    Raises:",
        "        ValueError: If archive_path escapes tasks_dir boundary",
        "    \"\"\"",
        "    # Resolve to absolute paths for comparison",
        "    tasks_resolved = tasks_dir.resolve()",
        "    archive_resolved = archive_path.resolve()",
        "",
        "    # Check that archive is within tasks directory",
        "    try:",
        "        archive_resolved.relative_to(tasks_resolved)",
        "    except ValueError:",
        "        raise ValueError(",
        "            f\"Archive path '{archive_path}' must be within tasks directory '{tasks_dir}'. \"",
        "            f\"Path traversal is not allowed for security reasons.\"",
        "        )",
        "",
        "",
        "def archive_old_session_files(",
        "    tasks_dir: str,",
        "    archive_dir: Optional[str] = None,",
        "    keep_consolidated: bool = True",
        ") -> List[Path]:",
        "    \"\"\"",
        "    Move old session files to archive after consolidation.",
        "",
        "    Args:",
        "        tasks_dir: Directory containing task files",
        "        archive_dir: Where to move old files (default: tasks/archive/).",
        "                     Must be within tasks_dir for security.",
        "        keep_consolidated: Don't archive consolidated_*.json files",
        "",
        "    Returns:",
        "        List of archived file paths",
        "",
        "    Raises:",
        "        ValueError: If archive_dir attempts path traversal outside tasks_dir",
        "    \"\"\"",
        "    dir_path = Path(tasks_dir)",
        "",
        "    # Default to subdirectory, validate if custom path provided",
        "    if archive_dir is None:",
        "        archive_path = dir_path / \"archive\"",
        "    else:",
        "        archive_path = Path(archive_dir)",
        "        # Security: validate path stays within tasks directory",
        "        _validate_archive_path(dir_path, archive_path)",
        "",
        "    archive_path.mkdir(parents=True, exist_ok=True)",
        "",
        "    archived = []",
        "    for filepath in dir_path.glob(\"*.json\"):",
        "        if keep_consolidated and filepath.name.startswith(\"consolidated_\"):",
        "            continue",
        "",
        "        dest = archive_path / filepath.name",
        "        shutil.move(str(filepath), str(dest))",
        "        archived.append(dest)",
        "",
        "    return archived",
        "",
        "",
        "def print_summary(tasks: List[Task], conflicts: Dict[str, List[Task]]) -> None:",
        "    \"\"\"Print a summary of task state.\"\"\"",
        "    by_status = defaultdict(list)",
        "    for task in tasks:",
        "        by_status[task.status].append(task)",
        "",
        "    print(\"\\n=== Task Summary ===\\n\")",
        "    print(f\"Total tasks: {len(tasks)}\")",
        "    print(f\"  In Progress: {len(by_status['in_progress'])}\")",
        "    print(f\"  Pending:     {len(by_status['pending'])}\")",
        "    print(f\"  Completed:   {len(by_status['completed'])}\")",
        "    print(f\"  Deferred:    {len(by_status['deferred'])}\")",
        "",
        "    if conflicts:",
        "        print(f\"\\nâš ï¸  Found {len(conflicts)} potential duplicate groups:\")",
        "        for title, group in conflicts.items():",
        "            print(f\"  - \\\"{title[:50]}...\\\" ({len(group)} tasks)\")",
        "            for task in group:",
        "                print(f\"      {task.id} [{task.status}]\")",
        "",
        "",
        "def main():",
        "    parser = argparse.ArgumentParser(",
        "        description=\"Consolidate task files from parallel agent sessions\"",
        "    )",
        "    parser.add_argument(",
        "        \"--dir\", default=DEFAULT_TASKS_DIR,",
        "        help=\"Tasks directory (default: tasks/)\"",
        "    )",
        "    parser.add_argument(",
        "        \"--dry-run\", action=\"store_true\",",
        "        help=\"Show what would be done without making changes\"",
        "    )",
        "    parser.add_argument(",
        "        \"--summary\", action=\"store_true\",",
        "        help=\"Show summary only\"",
        "    )",
        "    parser.add_argument(",
        "        \"--update\", action=\"store_true\",",
        "        help=\"Write consolidated file and archive old files\"",
        "    )",
        "    parser.add_argument(",
        "        \"--auto-merge\", action=\"store_true\",",
        "        help=\"Automatically merge duplicate tasks\"",
        "    )",
        "    parser.add_argument(",
        "        \"--output\", help=\"Output file for consolidated JSON\"",
        "    )",
        "    parser.add_argument(",
        "        \"--archive\", action=\"store_true\",",
        "        help=\"Archive old session files after consolidation\"",
        "    )",
        "",
        "    args = parser.parse_args()",
        "",
        "    # Check if tasks directory exists",
        "    if not Path(args.dir).exists():",
        "        print(f\"Tasks directory '{args.dir}' does not exist.\")",
        "        print(\"No tasks to consolidate. Use task_utils.py to create tasks first.\")",
        "        return",
        "",
        "    # Load and analyze tasks",
        "    tasks, conflicts = consolidate_and_dedupe(args.dir, args.auto_merge)",
        "",
        "    if not tasks:",
        "        print(\"No tasks found.\")",
        "        return",
        "",
        "    # Always show summary",
        "    print_summary(tasks, conflicts)",
        "",
        "    if args.summary or args.dry_run:",
        "        if args.dry_run and args.update:",
        "            print(\"\\n[Dry run] Would consolidate to:\")",
        "            print(f\"  {args.dir}/consolidated_TIMESTAMP_XXXX.json\")",
        "            if args.archive:",
        "                print(f\"  Would archive {len(list(Path(args.dir).glob('*.json')))} files\")",
        "        return",
        "",
        "    if args.update:",
        "        # Write consolidated file",
        "        output_path = write_consolidated_file(tasks, args.dir)",
        "        print(f\"\\nâœ… Consolidated to: {output_path}\")",
        "",
        "        if args.archive:",
        "            archived = archive_old_session_files(args.dir)",
        "            print(f\"ðŸ“¦ Archived {len(archived)} session files\")",
        "",
        "    if conflicts and not args.auto_merge:",
        "        print(\"\\nðŸ’¡ Tip: Use --auto-merge to automatically resolve duplicates\")",
        "",
        "",
        "if __name__ == \"__main__\":",
        "    main()"
      ],
      "lines_removed": [],
      "context_before": [],
      "context_after": [],
      "change_type": "add"
    },
    {
      "file": "scripts/new_task.py",
      "function": null,
      "start_line": 0,
      "lines_added": [
        "#!/usr/bin/env python3",
        "\"\"\"",
        "Quick task creation from command line.",
        "",
        "Usage:",
        "    # Create a task (interactive prompts)",
        "    python scripts/new_task.py",
        "",
        "    # Create with title only",
        "    python scripts/new_task.py \"Fix the login bug\"",
        "",
        "    # Create with options",
        "    python scripts/new_task.py \"Fix login bug\" --priority high --category bugfix",
        "",
        "    # Show current session tasks",
        "    python scripts/new_task.py --list",
        "",
        "    # Complete a task",
        "    python scripts/new_task.py --complete T-20251213-123456-a1b2-01",
        "",
        "Examples:",
        "    $ python scripts/new_task.py \"Add dark mode\" --priority medium --category feature",
        "    Created: T-20251213-143052-a1b2-01 - Add dark mode",
        "    Saved to: tasks/2025-12-13_14-30-52_a1b2.json",
        "\"\"\"",
        "",
        "import argparse",
        "import json",
        "import os",
        "import sys",
        "from pathlib import Path",
        "",
        "# Add scripts to path",
        "sys.path.insert(0, str(Path(__file__).parent))",
        "",
        "from task_utils import (",
        "    TaskSession,",
        "    Task,",
        "    load_all_tasks,",
        "    consolidate_tasks,",
        "    get_task_by_id,",
        "    DEFAULT_TASKS_DIR,",
        ")",
        "",
        "",
        "# Session file to persist between calls",
        "SESSION_FILE = Path(DEFAULT_TASKS_DIR) / \".current_session.json\"",
        "",
        "",
        "def get_or_create_session() -> TaskSession:",
        "    \"\"\"Get existing session or create new one.\"\"\"",
        "    if SESSION_FILE.exists():",
        "        try:",
        "            with open(SESSION_FILE) as f:",
        "                data = json.load(f)",
        "            session = TaskSession(",
        "                session_id=data[\"session_id\"],",
        "                started_at=data[\"started_at\"]",
        "            )",
        "            session._task_counter = data.get(\"task_counter\", 0)",
        "            # Load existing tasks",
        "            if Path(DEFAULT_TASKS_DIR).exists():",
        "                for filepath in Path(DEFAULT_TASKS_DIR).glob(f\"*_{data['session_id']}.json\"):",
        "                    loaded = TaskSession.load(filepath)",
        "                    session.tasks = loaded.tasks",
        "                    break",
        "            return session",
        "        except (json.JSONDecodeError, KeyError):",
        "            pass",
        "",
        "    # Create new session",
        "    session = TaskSession()",
        "    save_session_state(session)",
        "    return session",
        "",
        "",
        "def save_session_state(session: TaskSession) -> None:",
        "    \"\"\"Save session state for persistence.\"\"\"",
        "    Path(DEFAULT_TASKS_DIR).mkdir(parents=True, exist_ok=True)",
        "    with open(SESSION_FILE, \"w\") as f:",
        "        json.dump({",
        "            \"session_id\": session.session_id,",
        "            \"started_at\": session.started_at,",
        "            \"task_counter\": session._task_counter",
        "        }, f)",
        "",
        "",
        "def create_task(",
        "    title: str,",
        "    priority: str = \"medium\",",
        "    category: str = \"general\",",
        "    description: str = \"\",",
        "    effort: str = \"medium\"",
        ") -> Task:",
        "    \"\"\"Create a task in the current session.\"\"\"",
        "    session = get_or_create_session()",
        "",
        "    task = session.create_task(",
        "        title=title,",
        "        priority=priority,",
        "        category=category,",
        "        description=description,",
        "        effort=effort",
        "    )",
        "",
        "    filepath = session.save()",
        "    save_session_state(session)",
        "",
        "    return task, filepath",
        "",
        "",
        "def list_tasks(status_filter: str = None) -> None:",
        "    \"\"\"List all tasks.\"\"\"",
        "    tasks = load_all_tasks()",
        "",
        "    if status_filter:",
        "        tasks = [t for t in tasks if t.status == status_filter]",
        "",
        "    if not tasks:",
        "        print(\"No tasks found.\")",
        "        return",
        "",
        "    # Group by status",
        "    by_status = {}",
        "    for task in tasks:",
        "        by_status.setdefault(task.status, []).append(task)",
        "",
        "    status_emoji = {",
        "        \"in_progress\": \"ðŸ”„\",",
        "        \"pending\": \"ðŸ“‹\",",
        "        \"completed\": \"âœ…\",",
        "        \"deferred\": \"â¸ï¸\"",
        "    }",
        "",
        "    for status in [\"in_progress\", \"pending\", \"completed\", \"deferred\"]:",
        "        if status not in by_status:",
        "            continue",
        "        print(f\"\\n{status_emoji.get(status, 'â€¢')} {status.upper()}\")",
        "        for task in by_status[status]:",
        "            priority_marker = {\"high\": \"ðŸ”´\", \"medium\": \"ðŸŸ¡\", \"low\": \"ðŸŸ¢\"}.get(task.priority, \"\")",
        "            print(f\"  {priority_marker} {task.id}: {task.title}\")",
        "",
        "",
        "def complete_task(task_id: str) -> bool:",
        "    \"\"\"Mark a task as completed.\"\"\"",
        "    # Find the task",
        "    task = get_task_by_id(task_id)",
        "    if not task:",
        "        print(f\"Task not found: {task_id}\")",
        "        return False",
        "",
        "    # Load the session file containing this task",
        "    for filepath in Path(DEFAULT_TASKS_DIR).glob(\"*.json\"):",
        "        if filepath.name.startswith(\".\"):",
        "            continue",
        "        try:",
        "            session = TaskSession.load(filepath)",
        "            for t in session.tasks:",
        "                if t.id == task_id:",
        "                    t.mark_complete()",
        "                    session.save(DEFAULT_TASKS_DIR)",
        "                    print(f\"âœ… Completed: {task_id} - {t.title}\")",
        "                    return True",
        "        except:",
        "            continue",
        "",
        "    print(f\"Could not update task: {task_id}\")",
        "    return False",
        "",
        "",
        "def new_session() -> None:",
        "    \"\"\"Start a new session.\"\"\"",
        "    if SESSION_FILE.exists():",
        "        SESSION_FILE.unlink()",
        "    session = get_or_create_session()",
        "    print(f\"Started new session: {session.session_id}\")",
        "",
        "",
        "def main():",
        "    parser = argparse.ArgumentParser(",
        "        description=\"Quick task creation for parallel agent workflows\",",
        "        formatter_class=argparse.RawDescriptionHelpFormatter,",
        "        epilog=__doc__",
        "    )",
        "",
        "    parser.add_argument(\"title\", nargs=\"?\", help=\"Task title\")",
        "    parser.add_argument(\"-p\", \"--priority\", choices=[\"high\", \"medium\", \"low\"],",
        "                        default=\"medium\", help=\"Task priority\")",
        "    parser.add_argument(\"-c\", \"--category\", default=\"general\", help=\"Task category\")",
        "    parser.add_argument(\"-d\", \"--description\", default=\"\", help=\"Task description\")",
        "    parser.add_argument(\"-e\", \"--effort\", choices=[\"small\", \"medium\", \"large\"],",
        "                        default=\"medium\", help=\"Effort estimate\")",
        "    parser.add_argument(\"-l\", \"--list\", action=\"store_true\", help=\"List all tasks\")",
        "    parser.add_argument(\"-s\", \"--status\", help=\"Filter by status when listing\")",
        "    parser.add_argument(\"--complete\", metavar=\"TASK_ID\", help=\"Mark task as completed\")",
        "    parser.add_argument(\"--new-session\", action=\"store_true\", help=\"Start a new session\")",
        "    parser.add_argument(\"--summary\", action=\"store_true\", help=\"Show task summary\")",
        "",
        "    args = parser.parse_args()",
        "",
        "    # Ensure tasks directory exists",
        "    Path(DEFAULT_TASKS_DIR).mkdir(parents=True, exist_ok=True)",
        "",
        "    if args.new_session:",
        "        new_session()",
        "    elif args.list:",
        "        list_tasks(args.status)",
        "    elif args.complete:",
        "        complete_task(args.complete)",
        "    elif args.summary:",
        "        grouped = consolidate_tasks()",
        "        print(\"\\n=== Task Summary ===\")",
        "        for status, tasks in grouped.items():",
        "            if tasks:",
        "                print(f\"{status}: {len(tasks)}\")",
        "    elif args.title:",
        "        task, filepath = create_task(",
        "            title=args.title,",
        "            priority=args.priority,",
        "            category=args.category,",
        "            description=args.description,",
        "            effort=args.effort",
        "        )",
        "        print(f\"Created: {task.id} - {task.title}\")",
        "        print(f\"Saved to: {filepath}\")",
        "    else:",
        "        # Interactive mode",
        "        print(\"Create a new task (Ctrl+C to cancel)\")",
        "        title = input(\"Title: \").strip()",
        "        if not title:",
        "            print(\"Title is required\")",
        "            return",
        "",
        "        priority = input(\"Priority [high/medium/low] (medium): \").strip() or \"medium\"",
        "        category = input(\"Category (general): \").strip() or \"general\"",
        "        description = input(\"Description (optional): \").strip()",
        "",
        "        task, filepath = create_task(",
        "            title=title,",
        "            priority=priority,",
        "            category=category,",
        "            description=description",
        "        )",
        "        print(f\"\\nCreated: {task.id} - {task.title}\")",
        "        print(f\"Saved to: {filepath}\")",
        "",
        "",
        "if __name__ == \"__main__\":",
        "    main()"
      ],
      "lines_removed": [],
      "context_before": [],
      "context_after": [],
      "change_type": "add"
    },
    {
      "file": "scripts/task_utils.py",
      "function": null,
      "start_line": 0,
      "lines_added": [
        "#!/usr/bin/env python3",
        "\"\"\"",
        "Merge-friendly task ID management utilities.",
        "",
        "This module provides utilities for generating unique task IDs that won't",
        "conflict when multiple agents work in parallel. Follows the same pattern",
        "as cortical/chunk_index.py for append-only, git-friendly storage.",
        "",
        "Task ID Format:",
        "    Standalone: T-YYYYMMDD-HHMMSS-XXXX",
        "    Session:    T-YYYYMMDD-HHMMSS-XXXX-NN",
        "",
        "    Where:",
        "    - T = Task prefix",
        "    - YYYYMMDD = Date created",
        "    - HHMMSS = Time created",
        "    - XXXX = 4-char random suffix (from session UUID)",
        "    - NN = Task number within session (01, 02, etc.)",
        "",
        "Example:",
        "    T-20251213-143052-a1b2       # Standalone",
        "    T-20251213-143052-a1b2-01    # Session task 1",
        "    T-20251213-143052-a1b2-02    # Session task 2",
        "",
        "Usage:",
        "    from scripts.task_utils import generate_task_id, TaskSession",
        "",
        "    # Simple ID generation (standalone)",
        "    task_id = generate_task_id()  # T-20251213-143052-a1b2",
        "",
        "    # Session-based (guaranteed unique within session)",
        "    session = TaskSession()",
        "    task1 = session.new_task_id()  # T-20251213-143052-a1b2-01",
        "    task2 = session.new_task_id()  # T-20251213-143052-a1b2-02",
        "\"\"\"",
        "",
        "import json",
        "import os",
        "import uuid",
        "from dataclasses import dataclass, field, asdict",
        "from datetime import datetime",
        "from pathlib import Path",
        "from typing import Dict, List, Optional, Any",
        "",
        "",
        "# Directory for per-session task files",
        "DEFAULT_TASKS_DIR = \"tasks\"",
        "",
        "",
        "def generate_session_id() -> str:",
        "    \"\"\"Generate a short session ID (4 hex chars).\"\"\"",
        "    return uuid.uuid4().hex[:4]",
        "",
        "",
        "def generate_task_id(session_id: Optional[str] = None) -> str:",
        "    \"\"\"",
        "    Generate a unique, merge-friendly task ID.",
        "",
        "    Args:",
        "        session_id: Optional session suffix. If None, generates random suffix.",
        "",
        "    Returns:",
        "        Task ID in format T-YYYYMMDD-HHMMSS-XXXX",
        "",
        "    Example:",
        "        >>> generate_task_id()",
        "        'T-20251213-143052-a1b2'",
        "        >>> generate_task_id(\"test\")",
        "        'T-20251213-143052-test'",
        "    \"\"\"",
        "    now = datetime.now()",
        "    date_str = now.strftime(\"%Y%m%d\")",
        "    time_str = now.strftime(\"%H%M%S\")",
        "    suffix = session_id or generate_session_id()",
        "    return f\"T-{date_str}-{time_str}-{suffix}\"",
        "",
        "",
        "def generate_short_task_id() -> str:",
        "    \"\"\"",
        "    Generate a shorter unique task ID (8 hex chars).",
        "",
        "    Returns:",
        "        Task ID in format T-XXXXXXXX",
        "",
        "    Example:",
        "        >>> generate_short_task_id()",
        "        'T-a1b2c3d4'",
        "    \"\"\"",
        "    return f\"T-{uuid.uuid4().hex[:8]}\"",
        "",
        "",
        "@dataclass",
        "class Task:",
        "    \"\"\"A single task with merge-friendly ID.\"\"\"",
        "    id: str",
        "    title: str",
        "    status: str = \"pending\"  # pending, in_progress, completed, deferred",
        "    priority: str = \"medium\"  # high, medium, low",
        "    category: str = \"general\"",
        "    description: str = \"\"",
        "    depends_on: List[str] = field(default_factory=list)",
        "    effort: str = \"medium\"  # small, medium, large",
        "    created_at: str = field(default_factory=lambda: datetime.now().isoformat())",
        "    updated_at: Optional[str] = None",
        "    completed_at: Optional[str] = None",
        "    context: Dict[str, Any] = field(default_factory=dict)",
        "",
        "    def to_dict(self) -> Dict[str, Any]:",
        "        \"\"\"Convert to dictionary for serialization.\"\"\"",
        "        return asdict(self)",
        "",
        "    @classmethod",
        "    def from_dict(cls, d: Dict[str, Any]) -> 'Task':",
        "        \"\"\"Create Task from dictionary.\"\"\"",
        "        return cls(**d)",
        "",
        "    def mark_complete(self) -> None:",
        "        \"\"\"Mark task as completed.\"\"\"",
        "        self.status = \"completed\"",
        "        self.completed_at = datetime.now().isoformat()",
        "        self.updated_at = self.completed_at",
        "",
        "    def mark_in_progress(self) -> None:",
        "        \"\"\"Mark task as in progress.\"\"\"",
        "        self.status = \"in_progress\"",
        "        self.updated_at = datetime.now().isoformat()",
        "",
        "",
        "@dataclass",
        "class TaskSession:",
        "    \"\"\"",
        "    A session for creating tasks with consistent session suffix.",
        "",
        "    All tasks created in a session share the same suffix, making it",
        "    easy to identify which tasks were created together.",
        "",
        "    Example:",
        "        session = TaskSession()",
        "        task1 = session.create_task(\"Implement feature X\")",
        "        task2 = session.create_task(\"Add tests for feature X\")",
        "        session.save()  # Writes to tasks/2025-12-13_14-30-52_a1b2.json",
        "    \"\"\"",
        "    session_id: str = field(default_factory=generate_session_id)",
        "    tasks: List[Task] = field(default_factory=list)",
        "    started_at: str = field(default_factory=lambda: datetime.now().isoformat())",
        "    tasks_dir: str = DEFAULT_TASKS_DIR",
        "    _task_counter: int = field(default=0, repr=False)",
        "",
        "    def new_task_id(self) -> str:",
        "        \"\"\"Generate a new task ID with this session's suffix and counter.",
        "",
        "        The counter ensures unique IDs even when multiple tasks are created",
        "        within the same second.",
        "        \"\"\"",
        "        self._task_counter += 1",
        "        now = datetime.now()",
        "        date_str = now.strftime(\"%Y%m%d\")",
        "        time_str = now.strftime(\"%H%M%S\")",
        "        # Format: T-YYYYMMDD-HHMMSS-SSSS-NNN where NNN is task number (supports 999 tasks)",
        "        return f\"T-{date_str}-{time_str}-{self.session_id}-{self._task_counter:03d}\"",
        "",
        "    def create_task(",
        "        self,",
        "        title: str,",
        "        priority: str = \"medium\",",
        "        category: str = \"general\",",
        "        description: str = \"\",",
        "        depends_on: Optional[List[str]] = None,",
        "        effort: str = \"medium\",",
        "        context: Optional[Dict[str, Any]] = None",
        "    ) -> Task:",
        "        \"\"\"",
        "        Create a new task in this session.",
        "",
        "        Args:",
        "            title: Task title/summary",
        "            priority: high, medium, low",
        "            category: Task category (arch, devex, codequal, etc.)",
        "            description: Detailed description",
        "            depends_on: List of task IDs this depends on",
        "            effort: small, medium, large",
        "            context: Quick context dict (files, methods, etc.)",
        "",
        "        Returns:",
        "            The created Task object",
        "        \"\"\"",
        "        task = Task(",
        "            id=self.new_task_id(),",
        "            title=title,",
        "            priority=priority,",
        "            category=category,",
        "            description=description,",
        "            depends_on=depends_on or [],",
        "            effort=effort,",
        "            context=context or {}",
        "        )",
        "        self.tasks.append(task)",
        "        return task",
        "",
        "    def get_filename(self) -> str:",
        "        \"\"\"Get the session filename.\"\"\"",
        "        dt = datetime.fromisoformat(self.started_at)",
        "        timestamp = dt.strftime(\"%Y-%m-%d_%H-%M-%S\")",
        "        return f\"{timestamp}_{self.session_id}.json\"",
        "",
        "    def save(self, tasks_dir: Optional[str] = None) -> Path:",
        "        \"\"\"",
        "        Save session tasks to a JSON file atomically.",
        "",
        "        Uses write-to-temp-then-rename pattern to prevent data loss",
        "        if the process crashes during write.",
        "",
        "        Args:",
        "            tasks_dir: Directory for task files (default: tasks/)",
        "",
        "        Returns:",
        "            Path to the saved file",
        "",
        "        Raises:",
        "            OSError: If write or rename fails",
        "        \"\"\"",
        "        dir_path = Path(tasks_dir or self.tasks_dir)",
        "        dir_path.mkdir(parents=True, exist_ok=True)",
        "",
        "        filepath = dir_path / self.get_filename()",
        "        temp_filepath = filepath.with_suffix('.json.tmp')",
        "",
        "        data = {",
        "            \"version\": 1,",
        "            \"session_id\": self.session_id,",
        "            \"started_at\": self.started_at,",
        "            \"saved_at\": datetime.now().isoformat(),",
        "            \"tasks\": [t.to_dict() for t in self.tasks]",
        "        }",
        "",
        "        try:",
        "            # Write to temp file first",
        "            with open(temp_filepath, 'w') as f:",
        "                json.dump(data, f, indent=2)",
        "                f.flush()",
        "                os.fsync(f.fileno())  # Ensure data is on disk",
        "",
        "            # Atomic rename (on POSIX systems)",
        "            temp_filepath.rename(filepath)",
        "        except Exception:",
        "            # Clean up temp file on failure",
        "            if temp_filepath.exists():",
        "                temp_filepath.unlink()",
        "            raise",
        "",
        "        return filepath",
        "",
        "    @classmethod",
        "    def load(cls, filepath: Path) -> 'TaskSession':",
        "        \"\"\"Load a session from file.\"\"\"",
        "        with open(filepath) as f:",
        "            data = json.load(f)",
        "",
        "        session = cls(",
        "            session_id=data['session_id'],",
        "            started_at=data['started_at']",
        "        )",
        "        session.tasks = [Task.from_dict(t) for t in data['tasks']]",
        "        return session",
        "",
        "",
        "def load_all_tasks(tasks_dir: str = DEFAULT_TASKS_DIR) -> List[Task]:",
        "    \"\"\"",
        "    Load all tasks from all session files.",
        "",
        "    Args:",
        "        tasks_dir: Directory containing task session files",
        "",
        "    Returns:",
        "        List of all tasks, sorted by creation time",
        "    \"\"\"",
        "    dir_path = Path(tasks_dir)",
        "    if not dir_path.exists():",
        "        return []",
        "",
        "    all_tasks = []",
        "    for filepath in sorted(dir_path.glob(\"*.json\")):",
        "        try:",
        "            session = TaskSession.load(filepath)",
        "            all_tasks.extend(session.tasks)",
        "        except (json.JSONDecodeError, KeyError) as e:",
        "            print(f\"Warning: Could not load {filepath}: {e}\")",
        "",
        "    # Sort by creation time",
        "    all_tasks.sort(key=lambda t: t.created_at)",
        "    return all_tasks",
        "",
        "",
        "def get_task_by_id(task_id: str, tasks_dir: str = DEFAULT_TASKS_DIR) -> Optional[Task]:",
        "    \"\"\"Find a task by its ID across all session files.\"\"\"",
        "    for task in load_all_tasks(tasks_dir):",
        "        if task.id == task_id:",
        "            return task",
        "    return None",
        "",
        "",
        "def consolidate_tasks(",
        "    tasks_dir: str = DEFAULT_TASKS_DIR,",
        "    output_file: Optional[str] = None",
        ") -> Dict[str, List[Task]]:",
        "    \"\"\"",
        "    Consolidate all tasks from session files into a summary.",
        "",
        "    Args:",
        "        tasks_dir: Directory containing task session files",
        "        output_file: Optional path to write consolidated markdown",
        "",
        "    Returns:",
        "        Dict of tasks grouped by status",
        "    \"\"\"",
        "    all_tasks = load_all_tasks(tasks_dir)",
        "",
        "    # Group by status",
        "    grouped = {",
        "        \"in_progress\": [],",
        "        \"pending\": [],",
        "        \"completed\": [],",
        "        \"deferred\": []",
        "    }",
        "",
        "    for task in all_tasks:",
        "        status = task.status if task.status in grouped else \"pending\"",
        "        grouped[status].append(task)",
        "",
        "    # Sort within groups by priority",
        "    priority_order = {\"high\": 0, \"medium\": 1, \"low\": 2}",
        "    for status in grouped:",
        "        grouped[status].sort(key=lambda t: priority_order.get(t.priority, 1))",
        "",
        "    if output_file:",
        "        _write_consolidated_markdown(grouped, output_file)",
        "",
        "    return grouped",
        "",
        "",
        "def _write_consolidated_markdown(",
        "    grouped: Dict[str, List[Task]],",
        "    output_file: str",
        ") -> None:",
        "    \"\"\"Write consolidated tasks to markdown file.\"\"\"",
        "    lines = [",
        "        \"# Consolidated Task List\",",
        "        \"\",",
        "        f\"**Generated:** {datetime.now().isoformat()}\",",
        "        \"\",",
        "        \"---\",",
        "        \"\"",
        "    ]",
        "",
        "    status_headers = {",
        "        \"in_progress\": \"## ðŸ”„ In Progress\",",
        "        \"pending\": \"## ðŸ“‹ Pending\",",
        "        \"completed\": \"## âœ… Completed\",",
        "        \"deferred\": \"## â¸ï¸ Deferred\"",
        "    }",
        "",
        "    for status, tasks in grouped.items():",
        "        if not tasks:",
        "            continue",
        "",
        "        lines.append(status_headers.get(status, f\"## {status.title()}\"))",
        "        lines.append(\"\")",
        "        lines.append(\"| ID | Title | Priority | Category | Effort |\")",
        "        lines.append(\"|---|------|----------|----------|--------|\")",
        "",
        "        for task in tasks:",
        "            lines.append(",
        "                f\"| {task.id} | {task.title} | {task.priority} | \"",
        "                f\"{task.category} | {task.effort} |\"",
        "            )",
        "        lines.append(\"\")",
        "",
        "    with open(output_file, 'w') as f:",
        "        f.write('\\n'.join(lines))",
        "",
        "",
        "# CLI interface",
        "if __name__ == \"__main__\":",
        "    import argparse",
        "",
        "    parser = argparse.ArgumentParser(",
        "        description=\"Merge-friendly task management utilities\"",
        "    )",
        "    subparsers = parser.add_subparsers(dest=\"command\", help=\"Commands\")",
        "",
        "    # generate command",
        "    gen_parser = subparsers.add_parser(\"generate\", help=\"Generate a task ID\")",
        "    gen_parser.add_argument(\"--short\", action=\"store_true\", help=\"Short format (T-XXXXXXXX)\")",
        "",
        "    # consolidate command",
        "    cons_parser = subparsers.add_parser(\"consolidate\", help=\"Consolidate task files\")",
        "    cons_parser.add_argument(\"--dir\", default=DEFAULT_TASKS_DIR, help=\"Tasks directory\")",
        "    cons_parser.add_argument(\"--output\", help=\"Output markdown file\")",
        "",
        "    # list command",
        "    list_parser = subparsers.add_parser(\"list\", help=\"List all tasks\")",
        "    list_parser.add_argument(\"--dir\", default=DEFAULT_TASKS_DIR, help=\"Tasks directory\")",
        "    list_parser.add_argument(\"--status\", help=\"Filter by status\")",
        "",
        "    args = parser.parse_args()",
        "",
        "    if args.command == \"generate\":",
        "        if args.short:",
        "            print(generate_short_task_id())",
        "        else:",
        "            print(generate_task_id())",
        "",
        "    elif args.command == \"consolidate\":",
        "        grouped = consolidate_tasks(args.dir, args.output)",
        "        for status, tasks in grouped.items():",
        "            print(f\"{status}: {len(tasks)} tasks\")",
        "        if args.output:",
        "            print(f\"\\nWritten to {args.output}\")",
        "",
        "    elif args.command == \"list\":",
        "        tasks = load_all_tasks(args.dir)",
        "        if args.status:",
        "            tasks = [t for t in tasks if t.status == args.status]",
        "",
        "        for task in tasks:",
        "            print(f\"[{task.status}] {task.id}: {task.title}\")",
        "",
        "    else:",
        "        parser.print_help()"
      ],
      "lines_removed": [],
      "context_before": [],
      "context_after": [],
      "change_type": "add"
    },
    {
      "file": "scripts/workflow.py",
      "function": null,
      "start_line": 0,
      "lines_added": [
        "#!/usr/bin/env python3",
        "\"\"\"",
        "Workflow template engine for task creation.",
        "",
        "Spawns multiple linked tasks from YAML workflow templates.",
        "",
        "Usage:",
        "    # List available workflows",
        "    python scripts/workflow.py list",
        "",
        "    # Run a workflow",
        "    python scripts/workflow.py run bugfix --bug_title \"Login crashes on special chars\"",
        "",
        "    # Run with all options",
        "    python scripts/workflow.py run feature \\\\",
        "        --feature_name \"Dark mode\" \\\\",
        "        --priority high \\\\",
        "        --effort large",
        "",
        "    # Dry run (show tasks without creating)",
        "    python scripts/workflow.py run bugfix --bug_title \"Test\" --dry-run",
        "\"\"\"",
        "",
        "import argparse",
        "import sys",
        "from dataclasses import dataclass",
        "from pathlib import Path",
        "from typing import Any, Dict, List, Optional",
        "",
        "# Try to import yaml, fall back to basic parsing if not available",
        "try:",
        "    import yaml",
        "    HAS_YAML = True",
        "except ImportError:",
        "    HAS_YAML = False",
        "",
        "# Add scripts to path",
        "sys.path.insert(0, str(Path(__file__).parent))",
        "",
        "from task_utils import TaskSession, Task",
        "",
        "",
        "# Default workflows directory",
        "WORKFLOWS_DIR = Path(__file__).parent.parent / \".claude\" / \"workflows\"",
        "",
        "",
        "@dataclass",
        "class WorkflowVariable:",
        "    \"\"\"A variable in a workflow template.\"\"\"",
        "    name: str",
        "    description: str",
        "    required: bool = True",
        "    default: Optional[str] = None",
        "    choices: Optional[List[str]] = None",
        "",
        "",
        "@dataclass",
        "class WorkflowTask:",
        "    \"\"\"A task template in a workflow.\"\"\"",
        "    id: str",
        "    title: str",
        "    category: str = \"general\"",
        "    priority: str = \"medium\"",
        "    effort: str = \"medium\"",
        "    description: str = \"\"",
        "    depends_on: List[str] = None",
        "",
        "    def __post_init__(self):",
        "        if self.depends_on is None:",
        "            self.depends_on = []",
        "",
        "",
        "@dataclass",
        "class Workflow:",
        "    \"\"\"A workflow template that creates multiple tasks.\"\"\"",
        "    name: str",
        "    description: str",
        "    category: str",
        "    variables: List[WorkflowVariable]",
        "    tasks: List[WorkflowTask]",
        "",
        "    @classmethod",
        "    def from_dict(cls, data: Dict[str, Any]) -> 'Workflow':",
        "        \"\"\"Create workflow from parsed YAML dict.\"\"\"",
        "        variables = [",
        "            WorkflowVariable(",
        "                name=v['name'],",
        "                description=v.get('description', ''),",
        "                required=v.get('required', True),",
        "                default=v.get('default'),",
        "                choices=v.get('choices')",
        "            )",
        "            for v in data.get('variables', [])",
        "        ]",
        "",
        "        tasks = [",
        "            WorkflowTask(",
        "                id=t['id'],",
        "                title=t['title'],",
        "                category=t.get('category', 'general'),",
        "                priority=t.get('priority', 'medium'),",
        "                effort=t.get('effort', 'medium'),",
        "                description=t.get('description', ''),",
        "                depends_on=t.get('depends_on', [])",
        "            )",
        "            for t in data.get('tasks', [])",
        "        ]",
        "",
        "        return cls(",
        "            name=data['name'],",
        "            description=data.get('description', ''),",
        "            category=data.get('category', 'general'),",
        "            variables=variables,",
        "            tasks=tasks",
        "        )",
        "",
        "    @classmethod",
        "    def load(cls, filepath: Path) -> 'Workflow':",
        "        \"\"\"Load workflow from YAML file.\"\"\"",
        "        if not HAS_YAML:",
        "            raise ImportError(",
        "                \"PyYAML is required for workflow templates. \"",
        "                \"Install with: pip install pyyaml\"",
        "            )",
        "",
        "        with open(filepath) as f:",
        "            data = yaml.safe_load(f)",
        "",
        "        return cls.from_dict(data)",
        "",
        "",
        "def list_workflows(workflows_dir: Path = WORKFLOWS_DIR) -> List[Workflow]:",
        "    \"\"\"List all available workflow templates.\"\"\"",
        "    workflows = []",
        "",
        "    if not workflows_dir.exists():",
        "        return workflows",
        "",
        "    for filepath in sorted(workflows_dir.glob(\"*.yaml\")):",
        "        try:",
        "            workflow = Workflow.load(filepath)",
        "            workflows.append(workflow)",
        "        except Exception as e:",
        "            print(f\"Warning: Could not load {filepath}: {e}\")",
        "",
        "    return workflows",
        "",
        "",
        "def substitute_variables(text: str, variables: Dict[str, str]) -> str:",
        "    \"\"\"Substitute {variable} placeholders in text.\"\"\"",
        "    result = text",
        "    for name, value in variables.items():",
        "        result = result.replace(f\"{{{name}}}\", value)",
        "    return result",
        "",
        "",
        "def run_workflow(",
        "    workflow: Workflow,",
        "    variables: Dict[str, str],",
        "    tasks_dir: str = \"tasks\",",
        "    dry_run: bool = False",
        ") -> List[Task]:",
        "    \"\"\"",
        "    Execute a workflow template, creating all tasks.",
        "",
        "    Args:",
        "        workflow: The workflow to execute",
        "        variables: Variable values to substitute",
        "        tasks_dir: Directory to save tasks",
        "        dry_run: If True, show tasks but don't create",
        "",
        "    Returns:",
        "        List of created Task objects",
        "    \"\"\"",
        "    # Validate required variables",
        "    for var in workflow.variables:",
        "        if var.required and var.name not in variables:",
        "            if var.default:",
        "                variables[var.name] = var.default",
        "            else:",
        "                raise ValueError(f\"Missing required variable: {var.name}\")",
        "",
        "        # Validate choices",
        "        if var.choices and var.name in variables:",
        "            if variables[var.name] not in var.choices:",
        "                raise ValueError(",
        "                    f\"Invalid value for {var.name}: {variables[var.name]}. \"",
        "                    f\"Must be one of: {var.choices}\"",
        "                )",
        "",
        "    # Create session",
        "    session = TaskSession()",
        "",
        "    # Map workflow task IDs to actual task IDs",
        "    id_mapping: Dict[str, str] = {}",
        "",
        "    # Create tasks in order",
        "    created_tasks = []",
        "    for wf_task in workflow.tasks:",
        "        # Substitute variables",
        "        title = substitute_variables(wf_task.title, variables)",
        "        description = substitute_variables(wf_task.description, variables)",
        "        priority = substitute_variables(wf_task.priority, variables)",
        "        effort = substitute_variables(wf_task.effort, variables)",
        "",
        "        # Resolve dependencies to actual task IDs",
        "        depends_on = [",
        "            id_mapping[dep_id]",
        "            for dep_id in wf_task.depends_on",
        "            if dep_id in id_mapping",
        "        ]",
        "",
        "        # Create task",
        "        task = session.create_task(",
        "            title=title,",
        "            category=wf_task.category,",
        "            priority=priority,",
        "            effort=effort,",
        "            description=description,",
        "            depends_on=depends_on",
        "        )",
        "",
        "        id_mapping[wf_task.id] = task.id",
        "        created_tasks.append(task)",
        "",
        "    if dry_run:",
        "        print(f\"\\n[Dry Run] Would create {len(created_tasks)} tasks:\\n\")",
        "        for task in created_tasks:",
        "            deps = f\" (depends on: {len(task.depends_on)})\" if task.depends_on else \"\"",
        "            print(f\"  [{task.priority.upper()}] {task.title}{deps}\")",
        "            if task.description:",
        "                # Show first line of description",
        "                first_line = task.description.strip().split('\\n')[0]",
        "                print(f\"           {first_line[:60]}...\")",
        "        return created_tasks",
        "",
        "    # Save",
        "    filepath = session.save(tasks_dir)",
        "    print(f\"\\nCreated {len(created_tasks)} tasks from '{workflow.name}' workflow\")",
        "    print(f\"Saved to: {filepath}\\n\")",
        "",
        "    for task in created_tasks:",
        "        deps = f\" (depends on: {len(task.depends_on)})\" if task.depends_on else \"\"",
        "        print(f\"  {task.id}: {task.title}{deps}\")",
        "",
        "    return created_tasks",
        "",
        "",
        "def main():",
        "    parser = argparse.ArgumentParser(",
        "        description=\"Workflow template engine for task creation\",",
        "        formatter_class=argparse.RawDescriptionHelpFormatter,",
        "        epilog=__doc__",
        "    )",
        "",
        "    subparsers = parser.add_subparsers(dest=\"command\", help=\"Commands\")",
        "",
        "    # List command",
        "    list_parser = subparsers.add_parser(\"list\", help=\"List available workflows\")",
        "    list_parser.add_argument(",
        "        \"--dir\", default=str(WORKFLOWS_DIR),",
        "        help=\"Workflows directory\"",
        "    )",
        "",
        "    # Run command",
        "    run_parser = subparsers.add_parser(\"run\", help=\"Run a workflow\")",
        "    run_parser.add_argument(\"workflow\", help=\"Workflow name (e.g., 'bugfix', 'feature')\")",
        "    run_parser.add_argument(\"--dry-run\", action=\"store_true\", help=\"Show tasks without creating\")",
        "    run_parser.add_argument(\"--tasks-dir\", default=\"tasks\", help=\"Tasks directory\")",
        "",
        "    # Parse known args first to get workflow name",
        "    args, remaining = parser.parse_known_args()",
        "",
        "    if args.command == \"list\":",
        "        workflows = list_workflows(Path(args.dir))",
        "        if not workflows:",
        "            print(\"No workflows found.\")",
        "            print(f\"Add .yaml files to: {args.dir}\")",
        "            return",
        "",
        "        print(\"\\nAvailable Workflows:\\n\")",
        "        for wf in workflows:",
        "            print(f\"  {wf.name.lower().replace(' ', '_')}\")",
        "            print(f\"    {wf.description}\")",
        "            print(f\"    Tasks: {len(wf.tasks)}\")",
        "            if wf.variables:",
        "                var_names = [v.name for v in wf.variables]",
        "                print(f\"    Variables: {', '.join(var_names)}\")",
        "            print()",
        "",
        "    elif args.command == \"run\":",
        "        # Find workflow file",
        "        workflow_name = args.workflow.lower().replace(' ', '_')",
        "        workflow_path = WORKFLOWS_DIR / f\"{workflow_name}.yaml\"",
        "",
        "        if not workflow_path.exists():",
        "            print(f\"Workflow not found: {workflow_name}\")",
        "            print(f\"Available: {', '.join(p.stem for p in WORKFLOWS_DIR.glob('*.yaml'))}\")",
        "            return",
        "",
        "        workflow = Workflow.load(workflow_path)",
        "",
        "        # Add workflow-specific arguments dynamically",
        "        for var in workflow.variables:",
        "            arg_name = f\"--{var.name}\"",
        "            help_text = var.description",
        "            if var.default:",
        "                help_text += f\" (default: {var.default})\"",
        "            if var.choices:",
        "                help_text += f\" (choices: {', '.join(var.choices)})\"",
        "",
        "            run_parser.add_argument(",
        "                arg_name,",
        "                default=var.default,",
        "                required=var.required and not var.default,",
        "                help=help_text",
        "            )",
        "",
        "        # Re-parse with dynamic arguments",
        "        args = parser.parse_args()",
        "",
        "        # Collect variables",
        "        variables = {}",
        "        for var in workflow.variables:",
        "            value = getattr(args, var.name, None)",
        "            if value:",
        "                variables[var.name] = value",
        "",
        "        # Run workflow",
        "        try:",
        "            run_workflow(",
        "                workflow,",
        "                variables,",
        "                tasks_dir=args.tasks_dir,",
        "                dry_run=args.dry_run",
        "            )",
        "        except ValueError as e:",
        "            print(f\"Error: {e}\")",
        "            return",
        "",
        "    else:",
        "        parser.print_help()",
        "",
        "",
        "if __name__ == \"__main__\":",
        "    main()"
      ],
      "lines_removed": [],
      "context_before": [],
      "context_after": [],
      "change_type": "add"
    },
    {
      "file": "tasks/2025-12-13_22-32-34_e233.json",
      "function": null,
      "start_line": 0,
      "lines_added": [
        "{",
        "  \"version\": 1,",
        "  \"session_id\": \"e233\",",
        "  \"started_at\": \"2025-12-13T22:32:34.072421\",",
        "  \"saved_at\": \"2025-12-13T23:48:47.611980\",",
        "  \"tasks\": [",
        "    {",
        "      \"id\": \"T-20251213-223234-e233-01\",",
        "      \"title\": \"Document dog-fooding workflow\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"high\",",
        "      \"category\": \"docs\",",
        "      \"description\": \"Create a practical guide for using the task system in daily work\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"small\",",
        "      \"created_at\": \"2025-12-13T22:32:34.072535\",",
        "      \"updated_at\": \"2025-12-13T23:48:47.611790\",",
        "      \"completed_at\": \"2025-12-13T23:48:47.611790\",",
        "      \"context\": {",
        "        \"files\": [",
        "          \"docs/merge-friendly-tasks.md\"",
        "        ]",
        "      }",
        "    },",
        "    {",
        "      \"id\": \"T-20251213-223234-e233-02\",",
        "      \"title\": \"Add convenience script for quick task creation\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"devex\",",
        "      \"description\": \"One-liner to create task from command line\",",
        "      \"depends_on\": [",
        "        \"T-20251213-223234-e233-01\"",
        "      ],",
        "      \"effort\": \"small\",",
        "      \"created_at\": \"2025-12-13T22:32:34.072592\",",
        "      \"updated_at\": \"2025-12-13T22:33:26.107132\",",
        "      \"completed_at\": \"2025-12-13T22:33:26.107132\",",
        "      \"context\": {}",
        "    },",
        "    {",
        "      \"id\": \"T-20251213-223234-e233-03\",",
        "      \"title\": \"Test task recovery from crash scenario\",",
        "      \"status\": \"pending\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"test\",",
        "      \"description\": \"Verify tasks persist correctly if agent crashes mid-work\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"medium\",",
        "      \"created_at\": \"2025-12-13T22:32:34.072623\",",
        "      \"updated_at\": null,",
        "      \"completed_at\": null,",
        "      \"context\": {}",
        "    }",
        "  ]",
        "}"
      ],
      "lines_removed": [],
      "context_before": [],
      "context_after": [],
      "change_type": "add"
    },
    {
      "file": "tasks/2025-12-13_22-33-34_2d89.json",
      "function": null,
      "start_line": 0,
      "lines_added": [
        "{",
        "  \"version\": 1,",
        "  \"session_id\": \"2d89\",",
        "  \"started_at\": \"2025-12-13T22:33:34.431014\",",
        "  \"saved_at\": \"2025-12-13T23:54:54.911673\",",
        "  \"tasks\": [",
        "    {",
        "      \"id\": \"T-20251213-223334-2d89-01\",",
        "      \"title\": \"Investigate performance bottleneck in search\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"high\",",
        "      \"category\": \"perf\",",
        "      \"description\": \"\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"medium\",",
        "      \"created_at\": \"2025-12-13T22:33:34.431621\",",
        "      \"updated_at\": \"2025-12-13T23:54:54.911470\",",
        "      \"completed_at\": \"2025-12-13T23:54:54.911470\",",
        "      \"context\": {}",
        "    },",
        "    {",
        "      \"id\": \"T-20251213-232522-2d89-002\",",
        "      \"title\": \"Update CI to output pending tasks intelligently\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"automation\",",
        "      \"description\": \"Add a CI step that shows pending tasks in a smart way: grouped by priority, showing blockers first, with context about what's ready to work on next. Could integrate with the workflow system to show task chains and dependencies.\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"medium\",",
        "      \"created_at\": \"2025-12-13T23:25:22.253447\",",
        "      \"updated_at\": \"2025-12-13T23:34:11.766071\",",
        "      \"completed_at\": \"2025-12-13T23:34:11.766071\",",
        "      \"context\": {}",
        "    }",
        "  ]",
        "}"
      ],
      "lines_removed": [],
      "context_before": [],
      "context_after": [],
      "change_type": "add"
    },
    {
      "file": "tasks/2025-12-13_22-42-20_6ac7.json",
      "function": null,
      "start_line": 0,
      "lines_added": [
        "{",
        "  \"version\": 1,",
        "  \"session_id\": \"6ac7\",",
        "  \"started_at\": \"2025-12-13T22:42:20.986896\",",
        "  \"saved_at\": \"2025-12-13T23:48:47.726752\",",
        "  \"tasks\": [",
        "    {",
        "      \"id\": \"T-20251213-224220-6ac7-01\",",
        "      \"title\": \"Fix non-atomic file writes (data loss risk)\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"high\",",
        "      \"category\": \"bugfix\",",
        "      \"description\": \"TaskSession.save() should write to .tmp then atomic rename\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"small\",",
        "      \"created_at\": \"2025-12-13T22:42:20.986937\",",
        "      \"updated_at\": \"2025-12-13T22:48:20.519513\",",
        "      \"completed_at\": \"2025-12-13T22:48:20.519513\",",
        "      \"context\": {",
        "        \"files\": [",
        "          \"scripts/task_utils.py\"",
        "        ],",
        "        \"line\": 229",
        "      }",
        "    },",
        "    {",
        "      \"id\": \"T-20251213-224220-6ac7-02\",",
        "      \"title\": \"Fix path traversal vulnerability in archive\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"high\",",
        "      \"category\": \"security\",",
        "      \"description\": \"archive_old_session_files() must validate paths stay within tasks/\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"small\",",
        "      \"created_at\": \"2025-12-13T22:42:20.986947\",",
        "      \"updated_at\": \"2025-12-13T22:48:20.628391\",",
        "      \"completed_at\": \"2025-12-13T22:48:20.628391\",",
        "      \"context\": {",
        "        \"files\": [",
        "          \"scripts/consolidate_tasks.py\"",
        "        ],",
        "        \"line\": 214",
        "      }",
        "    },",
        "    {",
        "      \"id\": \"T-20251213-224220-6ac7-03\",",
        "      \"title\": \"Fix task counter overflow at 100 tasks\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"high\",",
        "      \"category\": \"bugfix\",",
        "      \"description\": \"Expand counter format from 02d to 03d or use base36\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"small\",",
        "      \"created_at\": \"2025-12-13T22:42:20.986955\",",
        "      \"updated_at\": \"2025-12-13T22:48:20.763992\",",
        "      \"completed_at\": \"2025-12-13T22:48:20.763992\",",
        "      \"context\": {",
        "        \"files\": [",
        "          \"scripts/task_utils.py\"",
        "        ],",
        "        \"line\": 156",
        "      }",
        "    },",
        "    {",
        "      \"id\": \"T-20251213-224220-6ac7-04\",",
        "      \"title\": \"Add workflow templates (bugfix, feature, refactor)\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"feature\",",
        "      \"description\": \"YAML templates in .claude/workflows/ that spawn task chains\",",
        "      \"depends_on\": [",
        "        \"T-20251213-224220-6ac7-01\",",
        "        \"T-20251213-224220-6ac7-02\",",
        "        \"T-20251213-224220-6ac7-03\"",
        "      ],",
        "      \"effort\": \"medium\",",
        "      \"created_at\": \"2025-12-13T22:42:20.986963\",",
        "      \"updated_at\": \"2025-12-13T22:50:36.977578\",",
        "      \"completed_at\": \"2025-12-13T22:50:36.977578\",",
        "      \"context\": {}",
        "    },",
        "    {",
        "      \"id\": \"T-20251213-224220-6ac7-05\",",
        "      \"title\": \"Add auto-task creation from CI test failures\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"automation\",",
        "      \"description\": \"Parse pytest failures, create bugfix tasks automatically\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"medium\",",
        "      \"created_at\": \"2025-12-13T22:42:20.986976\",",
        "      \"updated_at\": \"2025-12-13T23:48:47.726631\",",
        "      \"completed_at\": \"2025-12-13T23:48:47.726631\",",
        "      \"context\": {",
        "        \"files\": [",
        "          \".github/workflows/ci.yml\",",
        "          \"scripts/create_tasks_from_ci.py\"",
        "        ]",
        "      }",
        "    },",
        "    {",
        "      \"id\": \"T-20251213-224220-6ac7-06\",",
        "      \"title\": \"Add task retrospective metadata capture\",",
        "      \"status\": \"pending\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"feature\",",
        "      \"description\": \"Track files_touched, duration, tests_written for learning\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"large\",",
        "      \"created_at\": \"2025-12-13T22:42:20.986983\",",
        "      \"updated_at\": null,",
        "      \"completed_at\": null,",
        "      \"context\": {}",
        "    }",
        "  ]",
        "}"
      ],
      "lines_removed": [],
      "context_before": [],
      "context_after": [],
      "change_type": "add"
    },
    {
      "file": "tasks/2025-12-13_22-50-18_cdd1.json",
      "function": null,
      "start_line": 0,
      "lines_added": [
        "{",
        "  \"version\": 1,",
        "  \"session_id\": \"cdd1\",",
        "  \"started_at\": \"2025-12-13T22:50:18.707702\",",
        "  \"saved_at\": \"2025-12-13T23:46:07.936790\",",
        "  \"tasks\": [",
        "    {",
        "      \"id\": \"T-20251213-225018-cdd1-001\",",
        "      \"title\": \"Design: Workflow templates\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"arch\",",
        "      \"description\": \"Design the API and architecture for: Workflow templates\\n\\nDeliverables:\\n- API design (function signatures, data structures)\\n- Integration points with existing code\\n- Edge cases to handle\\n\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"medium\",",
        "      \"created_at\": \"2025-12-13T22:50:18.707760\",",
        "      \"updated_at\": \"2025-12-13T22:50:37.089387\",",
        "      \"completed_at\": \"2025-12-13T22:50:37.089387\",",
        "      \"context\": {}",
        "    },",
        "    {",
        "      \"id\": \"T-20251213-225018-cdd1-002\",",
        "      \"title\": \"Implement: Workflow templates\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"feature\",",
        "      \"description\": \"Implement the core functionality for: Workflow templates\\n\\nChecklist:\\n- [ ] Core logic implemented\\n- [ ] Error handling added\\n- [ ] Follows existing code patterns\\n\",",
        "      \"depends_on\": [",
        "        \"T-20251213-225018-cdd1-001\"",
        "      ],",
        "      \"effort\": \"medium\",",
        "      \"created_at\": \"2025-12-13T22:50:18.707774\",",
        "      \"updated_at\": \"2025-12-13T22:50:37.198821\",",
        "      \"completed_at\": \"2025-12-13T22:50:37.198821\",",
        "      \"context\": {}",
        "    },",
        "    {",
        "      \"id\": \"T-20251213-225018-cdd1-003\",",
        "      \"title\": \"Unit tests for: Workflow templates\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"high\",",
        "      \"category\": \"test\",",
        "      \"description\": \"Write comprehensive unit tests.\\n\\nCoverage requirements:\\n- Happy path scenarios\\n- Edge cases\\n- Error conditions\\n- Target: 90%+ coverage for new code\\n\",",
        "      \"depends_on\": [",
        "        \"T-20251213-225018-cdd1-002\"",
        "      ],",
        "      \"effort\": \"medium\",",
        "      \"created_at\": \"2025-12-13T22:50:18.707790\",",
        "      \"updated_at\": \"2025-12-13T23:46:07.707667\",",
        "      \"completed_at\": \"2025-12-13T23:46:07.707667\",",
        "      \"context\": {}",
        "    },",
        "    {",
        "      \"id\": \"T-20251213-225018-cdd1-004\",",
        "      \"title\": \"Integration tests for: Workflow templates\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"high\",",
        "      \"category\": \"test\",",
        "      \"description\": \"Write integration tests verifying feature works with existing system.\\n\\nTest scenarios:\\n- End-to-end workflows\\n- Interaction with other components\\n- Performance characteristics\\n\",",
        "      \"depends_on\": [",
        "        \"T-20251213-225018-cdd1-002\"",
        "      ],",
        "      \"effort\": \"medium\",",
        "      \"created_at\": \"2025-12-13T22:50:18.707805\",",
        "      \"updated_at\": \"2025-12-13T23:46:07.832328\",",
        "      \"completed_at\": \"2025-12-13T23:46:07.832328\",",
        "      \"context\": {}",
        "    },",
        "    {",
        "      \"id\": \"T-20251213-225018-cdd1-005\",",
        "      \"title\": \"Documentation for: Workflow templates\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"docs\",",
        "      \"description\": \"Document the new feature.\\n\\nInclude:\\n- Usage examples\\n- API reference updates\\n- CLAUDE.md updates if applicable\\n\",",
        "      \"depends_on\": [",
        "        \"T-20251213-225018-cdd1-003\",",
        "        \"T-20251213-225018-cdd1-004\"",
        "      ],",
        "      \"effort\": \"small\",",
        "      \"created_at\": \"2025-12-13T22:50:18.707823\",",
        "      \"updated_at\": \"2025-12-13T23:46:07.936682\",",
        "      \"completed_at\": \"2025-12-13T23:46:07.936682\",",
        "      \"context\": {}",
        "    }",
        "  ]",
        "}"
      ],
      "lines_removed": [],
      "context_before": [],
      "context_after": [],
      "change_type": "add"
    },
    {
      "file": "tasks/2025-12-13_23-54-58_1a1d.json",
      "function": null,
      "start_line": 0,
      "lines_added": [
        "{",
        "  \"version\": 1,",
        "  \"session_id\": \"1a1d\",",
        "  \"started_at\": \"2025-12-13T23:54:58.530536\",",
        "  \"saved_at\": \"2025-12-13T23:54:58.531057\",",
        "  \"tasks\": [",
        "    {",
        "      \"id\": \"T-20251213-235458-1a1d-001\",",
        "      \"title\": \"Optimize doc_name_boost: cache tokenized document names\",",
        "      \"status\": \"pending\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"perf\",",
        "      \"description\": \"Performance bottleneck identified: doc_name_boost re-tokenizes all document names on every search.\\n\\nRoot cause: Lines 70-103 in query/search.py tokenize every doc_id on every query.\\nImpact: 70% of search time on 2000-doc corpus (3.95ms overhead).\\n\\nRecommendation: Cache tokenized doc names in Minicolumn during process_document().\\nExpected benefit: 3-4x faster searches on large corpora.\\nEffort estimate: 2-4 hours.\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"medium\",",
        "      \"created_at\": \"2025-12-13T23:54:58.530954\",",
        "      \"updated_at\": null,",
        "      \"completed_at\": null,",
        "      \"context\": {}",
        "    }",
        "  ]",
        "}"
      ],
      "lines_removed": [],
      "context_before": [],
      "context_after": [],
      "change_type": "add"
    },
    {
      "file": "tests/integration/test_task_integration.py",
      "function": null,
      "start_line": 0,
      "lines_added": [
        "\"\"\"",
        "Integration tests for merge-friendly task utilities.",
        "",
        "These tests verify that the task system works correctly in realistic",
        "multi-agent scenarios where multiple sessions create tasks concurrently.",
        "",
        "Run with: pytest tests/integration/test_task_integration.py -v",
        "\"\"\"",
        "",
        "import json",
        "import os",
        "import shutil",
        "import sys",
        "import tempfile",
        "import threading",
        "import time",
        "import unittest",
        "from concurrent.futures import ThreadPoolExecutor, as_completed",
        "from pathlib import Path",
        "",
        "# Add scripts to path",
        "sys.path.insert(0, str(Path(__file__).parent.parent.parent / \"scripts\"))",
        "",
        "from task_utils import (",
        "    TaskSession,",
        "    Task,",
        "    load_all_tasks,",
        "    consolidate_tasks,",
        "    generate_task_id,",
        "    generate_short_task_id,",
        ")",
        "from consolidate_tasks import (",
        "    consolidate_and_dedupe,",
        "    find_conflicts,",
        "    merge_duplicate_tasks,",
        "    write_consolidated_file,",
        "    archive_old_session_files,",
        ")",
        "",
        "",
        "class TestMultiSessionConcurrency(unittest.TestCase):",
        "    \"\"\"Test that multiple sessions don't conflict when run concurrently.\"\"\"",
        "",
        "    def setUp(self):",
        "        \"\"\"Create temporary directory for task files.\"\"\"",
        "        self.temp_dir = tempfile.mkdtemp()",
        "",
        "    def tearDown(self):",
        "        \"\"\"Clean up temporary directory.\"\"\"",
        "        shutil.rmtree(self.temp_dir)",
        "",
        "    def test_parallel_sessions_create_unique_files(self):",
        "        \"\"\"Multiple sessions running in parallel should create unique files.\"\"\"",
        "        num_sessions = 10",
        "        sessions_created = []",
        "",
        "        def create_session_with_tasks():",
        "            session = TaskSession()",
        "            session.create_task(title=f\"Task from session {session.session_id}\")",
        "            filepath = session.save(self.temp_dir)",
        "            return str(filepath)",
        "",
        "        # Run sessions in parallel",
        "        with ThreadPoolExecutor(max_workers=num_sessions) as executor:",
        "            futures = [executor.submit(create_session_with_tasks) for _ in range(num_sessions)]",
        "            for future in as_completed(futures):",
        "                sessions_created.append(future.result())",
        "",
        "        # All files should be unique",
        "        self.assertEqual(len(set(sessions_created)), num_sessions)",
        "",
        "        # All files should exist",
        "        for filepath in sessions_created:",
        "            self.assertTrue(Path(filepath).exists())",
        "",
        "    def test_parallel_task_id_generation_high_uniqueness(self):",
        "        \"\"\"Task IDs generated in parallel should be mostly unique.",
        "",
        "        Note: Same-second generation may cause collisions (timestamp-based).",
        "        We verify >95% uniqueness which is sufficient for real-world use",
        "        where agents run for longer durations.",
        "        \"\"\"",
        "        num_ids = 1000",
        "        generated_ids = []",
        "",
        "        def generate_ids():",
        "            return [generate_task_id() for _ in range(100)]",
        "",
        "        with ThreadPoolExecutor(max_workers=10) as executor:",
        "            futures = [executor.submit(generate_ids) for _ in range(10)]",
        "            for future in as_completed(futures):",
        "                generated_ids.extend(future.result())",
        "",
        "        # At least 95% should be unique (same-second collisions expected)",
        "        unique_count = len(set(generated_ids))",
        "        uniqueness_ratio = unique_count / num_ids",
        "        self.assertGreater(uniqueness_ratio, 0.95,",
        "            f\"Only {uniqueness_ratio*100:.1f}% unique IDs\")",
        "",
        "    def test_concurrent_session_saves_no_corruption(self):",
        "        \"\"\"Concurrent saves should not corrupt files.\"\"\"",
        "        sessions = [TaskSession() for _ in range(5)]",
        "",
        "        # Add tasks to each session",
        "        for i, session in enumerate(sessions):",
        "            for j in range(10):",
        "                session.create_task(title=f\"Session {i} Task {j}\")",
        "",
        "        # Save all concurrently",
        "        def save_session(session):",
        "            return session.save(self.temp_dir)",
        "",
        "        with ThreadPoolExecutor(max_workers=5) as executor:",
        "            futures = [executor.submit(save_session, s) for s in sessions]",
        "            filepaths = [f.result() for f in as_completed(futures)]",
        "",
        "        # Verify all files are valid JSON",
        "        for filepath in filepaths:",
        "            with open(filepath) as f:",
        "                data = json.load(f)",
        "                self.assertIn(\"tasks\", data)",
        "                self.assertEqual(len(data[\"tasks\"]), 10)",
        "",
        "",
        "class TestConsolidationIntegration(unittest.TestCase):",
        "    \"\"\"Test task consolidation across multiple session files.\"\"\"",
        "",
        "    def setUp(self):",
        "        \"\"\"Create temporary directory with multiple session files.\"\"\"",
        "        self.temp_dir = tempfile.mkdtemp()",
        "",
        "    def tearDown(self):",
        "        \"\"\"Clean up temporary directory.\"\"\"",
        "        shutil.rmtree(self.temp_dir)",
        "",
        "    def test_consolidate_preserves_all_tasks(self):",
        "        \"\"\"Consolidation should preserve all tasks from all sessions.\"\"\"",
        "        total_tasks = 0",
        "",
        "        # Create multiple sessions with varying task counts",
        "        for i in range(5):",
        "            session = TaskSession()",
        "            task_count = (i + 1) * 3  # 3, 6, 9, 12, 15 tasks",
        "            for j in range(task_count):",
        "                session.create_task(title=f\"Session {i} Task {j}\")",
        "            total_tasks += task_count",
        "            session.save(self.temp_dir)",
        "",
        "        # Load all tasks",
        "        all_tasks = load_all_tasks(self.temp_dir)",
        "        self.assertEqual(len(all_tasks), total_tasks)",
        "",
        "    def test_consolidate_detects_duplicates(self):",
        "        \"\"\"Consolidation should detect tasks with same title as potential duplicates.\"\"\"",
        "        # Create two sessions with same task title",
        "        session1 = TaskSession()",
        "        session1.create_task(title=\"Fix authentication bug\")",
        "        session1.save(self.temp_dir)",
        "",
        "        session2 = TaskSession()",
        "        session2.create_task(title=\"Fix authentication bug\")  # Duplicate!",
        "        session2.save(self.temp_dir)",
        "",
        "        # Load and check for conflicts",
        "        all_tasks = load_all_tasks(self.temp_dir)",
        "        conflicts = find_conflicts(all_tasks)",
        "",
        "        self.assertEqual(len(conflicts), 1)",
        "        self.assertIn(\"fix authentication bug\", conflicts)",
        "        self.assertEqual(len(conflicts[\"fix authentication bug\"]), 2)",
        "",
        "    def test_auto_merge_resolves_duplicates(self):",
        "        \"\"\"Auto-merge should combine duplicate tasks intelligently.\"\"\"",
        "        # Create two sessions with same task, different metadata",
        "        session1 = TaskSession()",
        "        task1 = session1.create_task(",
        "            title=\"Fix authentication bug\",",
        "            priority=\"low\",",
        "            description=\"Short description\"",
        "        )",
        "        session1.save(self.temp_dir)",
        "",
        "        # Wait a bit to ensure different timestamp",
        "        time.sleep(0.01)",
        "",
        "        session2 = TaskSession()",
        "        task2 = session2.create_task(",
        "            title=\"Fix authentication bug\",",
        "            priority=\"high\",  # Higher priority",
        "            description=\"Much longer and more detailed description of the bug\"",
        "        )",
        "        task2.mark_in_progress()  # More advanced status",
        "        session2.save(self.temp_dir)",
        "",
        "        # Consolidate with auto-merge",
        "        tasks, conflicts = consolidate_and_dedupe(self.temp_dir, auto_merge=True)",
        "",
        "        # Should have merged to one task",
        "        auth_tasks = [t for t in tasks if \"authentication\" in t.title.lower()]",
        "        self.assertEqual(len(auth_tasks), 1)",
        "",
        "        merged = auth_tasks[0]",
        "        # Should keep higher priority",
        "        self.assertEqual(merged.priority, \"high\")",
        "        # Should keep more advanced status",
        "        self.assertEqual(merged.status, \"in_progress\")",
        "        # Should keep longer description",
        "        self.assertIn(\"longer\", merged.description)",
        "",
        "    def test_consolidated_file_is_valid(self):",
        "        \"\"\"Written consolidated file should be valid and loadable.\"\"\"",
        "        # Create some sessions",
        "        for i in range(3):",
        "            session = TaskSession()",
        "            session.create_task(title=f\"Task {i}\")",
        "            session.save(self.temp_dir)",
        "",
        "        all_tasks = load_all_tasks(self.temp_dir)",
        "",
        "        # Write consolidated file",
        "        consolidated_path = write_consolidated_file(all_tasks, self.temp_dir)",
        "",
        "        # Verify it's valid JSON",
        "        with open(consolidated_path) as f:",
        "            data = json.load(f)",
        "",
        "        self.assertEqual(data[\"type\"], \"consolidated\")",
        "        self.assertEqual(data[\"task_count\"], 3)",
        "        self.assertEqual(len(data[\"tasks\"]), 3)",
        "",
        "    def test_archive_moves_files_correctly(self):",
        "        \"\"\"Archiving should move session files but keep consolidated.\"\"\"",
        "        # Create sessions",
        "        session_files = []",
        "        for i in range(3):",
        "            session = TaskSession()",
        "            session.create_task(title=f\"Task {i}\")",
        "            path = session.save(self.temp_dir)",
        "            session_files.append(path)",
        "",
        "        # Write consolidated file",
        "        all_tasks = load_all_tasks(self.temp_dir)",
        "        consolidated_path = write_consolidated_file(all_tasks, self.temp_dir)",
        "",
        "        # Archive old files",
        "        archived = archive_old_session_files(self.temp_dir)",
        "",
        "        # Session files should be moved",
        "        self.assertEqual(len(archived), 3)",
        "        for path in session_files:",
        "            self.assertFalse(path.exists())",
        "",
        "        # Consolidated file should remain",
        "        self.assertTrue(consolidated_path.exists())",
        "",
        "        # Archive directory should exist",
        "        archive_dir = Path(self.temp_dir) / \"archive\"",
        "        self.assertTrue(archive_dir.exists())",
        "        self.assertEqual(len(list(archive_dir.glob(\"*.json\"))), 3)",
        "",
        "",
        "class TestTaskLifecycleIntegration(unittest.TestCase):",
        "    \"\"\"Test complete task lifecycle: create -> update -> complete -> consolidate.\"\"\"",
        "",
        "    def setUp(self):",
        "        \"\"\"Create temporary directory for task files.\"\"\"",
        "        self.temp_dir = tempfile.mkdtemp()",
        "",
        "    def tearDown(self):",
        "        \"\"\"Clean up temporary directory.\"\"\"",
        "        shutil.rmtree(self.temp_dir)",
        "",
        "    def test_full_task_lifecycle(self):",
        "        \"\"\"Test complete lifecycle of task management.\"\"\"",
        "        # 1. Create tasks in session",
        "        session = TaskSession()",
        "        task1 = session.create_task(",
        "            title=\"Implement feature\",",
        "            priority=\"high\",",
        "            category=\"feature\"",
        "        )",
        "        task2 = session.create_task(",
        "            title=\"Write tests\",",
        "            priority=\"medium\",",
        "            depends_on=[task1.id]",
        "        )",
        "",
        "        # 2. Update task status before saving",
        "        task1.mark_in_progress()",
        "        task1.mark_complete()",
        "        self.assertEqual(task1.status, \"completed\")",
        "        self.assertIsNotNone(task1.completed_at)",
        "",
        "        # 3. Save and verify persistence",
        "        session.save(self.temp_dir)",
        "",
        "        # 4. Load and verify",
        "        all_tasks = load_all_tasks(self.temp_dir)",
        "        self.assertEqual(len(all_tasks), 2)",
        "",
        "        # 5. Consolidate and check grouping",
        "        grouped = consolidate_tasks(self.temp_dir)",
        "        self.assertEqual(len(grouped[\"pending\"]), 1)  # task2",
        "        self.assertEqual(len(grouped[\"completed\"]), 1)  # task1",
        "",
        "    def test_multi_agent_workflow_simulation(self):",
        "        \"\"\"Simulate a realistic multi-agent workflow.\"\"\"",
        "        # Agent A: Research phase",
        "        agent_a = TaskSession()",
        "        a1 = agent_a.create_task(",
        "            title=\"Research existing codebase\",",
        "            priority=\"high\",",
        "            category=\"research\"",
        "        )",
        "        a2 = agent_a.create_task(",
        "            title=\"Identify integration points\",",
        "            depends_on=[a1.id]",
        "        )",
        "        agent_a.save(self.temp_dir)",
        "",
        "        # Agent B: Implementation phase (concurrent)",
        "        agent_b = TaskSession()",
        "        b1 = agent_b.create_task(",
        "            title=\"Implement core feature\",",
        "            priority=\"high\",",
        "            category=\"implementation\"",
        "        )",
        "        b2 = agent_b.create_task(",
        "            title=\"Add unit tests\",",
        "            depends_on=[b1.id]",
        "        )",
        "        agent_b.save(self.temp_dir)",
        "",
        "        # Agent C: Documentation (concurrent)",
        "        agent_c = TaskSession()",
        "        c1 = agent_c.create_task(",
        "            title=\"Update documentation\",",
        "            priority=\"medium\",",
        "            category=\"docs\"",
        "        )",
        "        agent_c.save(self.temp_dir)",
        "",
        "        # Verify all tasks exist and are unique",
        "        all_tasks = load_all_tasks(self.temp_dir)",
        "        self.assertEqual(len(all_tasks), 5)",
        "",
        "        # All IDs should be unique",
        "        all_ids = [t.id for t in all_tasks]",
        "        self.assertEqual(len(set(all_ids)), 5)",
        "",
        "        # Dependencies should reference valid IDs",
        "        for task in all_tasks:",
        "            for dep_id in task.depends_on:",
        "                self.assertTrue(",
        "                    any(t.id == dep_id for t in all_tasks),",
        "                    f\"Dependency {dep_id} not found\"",
        "                )",
        "",
        "",
        "class TestFileSystemResilience(unittest.TestCase):",
        "    \"\"\"Test resilience to file system edge cases.\"\"\"",
        "",
        "    def setUp(self):",
        "        \"\"\"Create temporary directory for task files.\"\"\"",
        "        self.temp_dir = tempfile.mkdtemp()",
        "",
        "    def tearDown(self):",
        "        \"\"\"Clean up temporary directory.\"\"\"",
        "        shutil.rmtree(self.temp_dir)",
        "",
        "    def test_handles_missing_directory(self):",
        "        \"\"\"load_all_tasks should handle missing directory gracefully.\"\"\"",
        "        tasks = load_all_tasks(\"/nonexistent/path/that/does/not/exist\")",
        "        self.assertEqual(tasks, [])",
        "",
        "    def test_handles_empty_directory(self):",
        "        \"\"\"load_all_tasks should handle empty directory.\"\"\"",
        "        tasks = load_all_tasks(self.temp_dir)",
        "        self.assertEqual(tasks, [])",
        "",
        "    def test_handles_corrupt_file(self):",
        "        \"\"\"load_all_tasks should skip corrupt files.\"\"\"",
        "        # Create valid session",
        "        session = TaskSession()",
        "        session.create_task(title=\"Valid task\")",
        "        session.save(self.temp_dir)",
        "",
        "        # Create corrupt file",
        "        corrupt_path = Path(self.temp_dir) / \"2025-12-13_00-00-00_xxxx.json\"",
        "        with open(corrupt_path, \"w\") as f:",
        "            f.write(\"{ this is not valid json }\")",
        "",
        "        # Should load valid tasks and skip corrupt",
        "        tasks = load_all_tasks(self.temp_dir)",
        "        self.assertEqual(len(tasks), 1)",
        "",
        "    def test_creates_directory_on_save(self):",
        "        \"\"\"save() should create directory if it doesn't exist.\"\"\"",
        "        nested_dir = Path(self.temp_dir) / \"nested\" / \"deep\" / \"tasks\"",
        "        session = TaskSession()",
        "        session.create_task(title=\"Task\")",
        "        filepath = session.save(str(nested_dir))",
        "",
        "        self.assertTrue(filepath.exists())",
        "        self.assertTrue(nested_dir.exists())",
        "",
        "",
        "class TestSecurityAndRobustness(unittest.TestCase):",
        "    \"\"\"Test security fixes and robustness improvements.\"\"\"",
        "",
        "    def setUp(self):",
        "        \"\"\"Create temporary directory for task files.\"\"\"",
        "        self.temp_dir = tempfile.mkdtemp()",
        "",
        "    def tearDown(self):",
        "        \"\"\"Clean up temporary directory.\"\"\"",
        "        shutil.rmtree(self.temp_dir)",
        "",
        "    def test_path_traversal_rejected(self):",
        "        \"\"\"Archive should reject path traversal attempts.\"\"\"",
        "        # Create a session with tasks",
        "        session = TaskSession()",
        "        session.create_task(title=\"Task\")",
        "        session.save(self.temp_dir)",
        "",
        "        # Attempt path traversal with ..",
        "        evil_archive = str(Path(self.temp_dir) / \"..\" / \"evil_dir\")",
        "        with self.assertRaises(ValueError) as cm:",
        "            archive_old_session_files(self.temp_dir, archive_dir=evil_archive)",
        "        self.assertIn(\"path traversal\", str(cm.exception).lower())",
        "",
        "    def test_absolute_path_outside_tasks_rejected(self):",
        "        \"\"\"Archive should reject absolute paths outside tasks directory.\"\"\"",
        "        session = TaskSession()",
        "        session.create_task(title=\"Task\")",
        "        session.save(self.temp_dir)",
        "",
        "        # Attempt to use /tmp as archive (outside tasks_dir)",
        "        with self.assertRaises(ValueError) as cm:",
        "            archive_old_session_files(self.temp_dir, archive_dir=\"/tmp\")",
        "        self.assertIn(\"must be within\", str(cm.exception).lower())",
        "",
        "    def test_subdirectory_archive_allowed(self):",
        "        \"\"\"Archive within tasks directory should be allowed.\"\"\"",
        "        session = TaskSession()",
        "        session.create_task(title=\"Task\")",
        "        session.save(self.temp_dir)",
        "",
        "        # Subdirectory should work fine",
        "        sub_archive = str(Path(self.temp_dir) / \"deep\" / \"archive\")",
        "        archived = archive_old_session_files(self.temp_dir, archive_dir=sub_archive)",
        "        self.assertEqual(len(archived), 1)",
        "        self.assertTrue(Path(sub_archive).exists())",
        "",
        "    def test_counter_supports_100_plus_tasks(self):",
        "        \"\"\"Session should support 100+ tasks without format issues.\"\"\"",
        "        session = TaskSession()",
        "",
        "        # Create 150 tasks",
        "        for i in range(150):",
        "            task = session.create_task(title=f\"Task {i}\")",
        "",
        "        # All IDs should be unique and follow pattern",
        "        all_ids = [t.id for t in session.tasks]",
        "        self.assertEqual(len(set(all_ids)), 150)",
        "",
        "        # Check format consistency (3-digit counter)",
        "        for task in session.tasks:",
        "            parts = task.id.split(\"-\")",
        "            self.assertEqual(len(parts), 5)  # T-YYYYMMDD-HHMMSS-XXXX-NNN",
        "            counter = parts[-1]",
        "            self.assertEqual(len(counter), 3)  # Always 3 digits",
        "",
        "    def test_atomic_write_no_temp_file_left_on_success(self):",
        "        \"\"\"Successful save should not leave temp files.\"\"\"",
        "        session = TaskSession()",
        "        session.create_task(title=\"Task\")",
        "        filepath = session.save(self.temp_dir)",
        "",
        "        # Check no .tmp files exist",
        "        tmp_files = list(Path(self.temp_dir).glob(\"*.tmp\"))",
        "        self.assertEqual(len(tmp_files), 0)",
        "",
        "        # Main file should exist",
        "        self.assertTrue(filepath.exists())",
        "",
        "    def test_save_creates_valid_json(self):",
        "        \"\"\"Saved file should be valid JSON after atomic write.\"\"\"",
        "        session = TaskSession()",
        "        for i in range(10):",
        "            session.create_task(title=f\"Task {i}\")",
        "        filepath = session.save(self.temp_dir)",
        "",
        "        # Should load without error",
        "        with open(filepath) as f:",
        "            data = json.load(f)",
        "",
        "        self.assertEqual(len(data[\"tasks\"]), 10)",
        "        self.assertEqual(data[\"session_id\"], session.session_id)",
        "",
        "",
        "if __name__ == \"__main__\":",
        "    unittest.main()"
      ],
      "lines_removed": [],
      "context_before": [],
      "context_after": [],
      "change_type": "add"
    },
    {
      "file": "tests/integration/test_workflow_integration.py",
      "function": null,
      "start_line": 0,
      "lines_added": [
        "#!/usr/bin/env python3",
        "\"\"\"",
        "Integration tests for workflow template engine.",
        "",
        "These tests verify that the workflow system loads real templates,",
        "executes them correctly, and creates valid task files with proper",
        "dependency resolution.",
        "",
        "Run with: pytest tests/integration/test_workflow_integration.py -v",
        "\"\"\"",
        "",
        "import json",
        "import shutil",
        "import sys",
        "import tempfile",
        "import unittest",
        "from pathlib import Path",
        "",
        "# Add scripts to path",
        "sys.path.insert(0, str(Path(__file__).parent.parent.parent / \"scripts\"))",
        "",
        "from workflow import (",
        "    Workflow,",
        "    WorkflowVariable,",
        "    WorkflowTask,",
        "    list_workflows,",
        "    run_workflow,",
        "    substitute_variables,",
        "    WORKFLOWS_DIR,",
        ")",
        "from task_utils import Task, TaskSession, load_all_tasks",
        "",
        "",
        "class TestWorkflowLoading(unittest.TestCase):",
        "    \"\"\"Test loading real workflow templates from .claude/workflows/.\"\"\"",
        "",
        "    def test_load_bugfix_workflow(self):",
        "        \"\"\"Verify bugfix.yaml loads correctly.\"\"\"",
        "        workflow_path = WORKFLOWS_DIR / \"bugfix.yaml\"",
        "        self.assertTrue(workflow_path.exists(), \"bugfix.yaml should exist\")",
        "",
        "        workflow = Workflow.load(workflow_path)",
        "",
        "        self.assertEqual(workflow.name, \"Bug Fix\")",
        "        self.assertEqual(workflow.category, \"bugfix\")",
        "        self.assertEqual(len(workflow.tasks), 4, \"Bugfix workflow should have 4 tasks\")",
        "        self.assertGreater(len(workflow.variables), 0, \"Should have variables\")",
        "",
        "        # Verify task IDs",
        "        task_ids = [t.id for t in workflow.tasks]",
        "        self.assertIn(\"investigate\", task_ids)",
        "        self.assertIn(\"fix\", task_ids)",
        "        self.assertIn(\"test\", task_ids)",
        "        self.assertIn(\"document\", task_ids)",
        "",
        "        # Verify dependencies",
        "        fix_task = next(t for t in workflow.tasks if t.id == \"fix\")",
        "        self.assertIn(\"investigate\", fix_task.depends_on)",
        "",
        "    def test_load_feature_workflow(self):",
        "        \"\"\"Verify feature.yaml loads correctly.\"\"\"",
        "        workflow_path = WORKFLOWS_DIR / \"feature.yaml\"",
        "        self.assertTrue(workflow_path.exists(), \"feature.yaml should exist\")",
        "",
        "        workflow = Workflow.load(workflow_path)",
        "",
        "        self.assertEqual(workflow.name, \"Feature\")",
        "        self.assertEqual(workflow.category, \"feature\")",
        "        self.assertEqual(len(workflow.tasks), 5, \"Feature workflow should have 5 tasks\")",
        "",
        "        # Verify task IDs",
        "        task_ids = [t.id for t in workflow.tasks]",
        "        self.assertIn(\"design\", task_ids)",
        "        self.assertIn(\"implement\", task_ids)",
        "        self.assertIn(\"unit_tests\", task_ids)",
        "        self.assertIn(\"integration_tests\", task_ids)",
        "        self.assertIn(\"documentation\", task_ids)",
        "",
        "        # Verify complex dependencies",
        "        doc_task = next(t for t in workflow.tasks if t.id == \"documentation\")",
        "        self.assertIn(\"unit_tests\", doc_task.depends_on)",
        "        self.assertIn(\"integration_tests\", doc_task.depends_on)",
        "",
        "    def test_load_refactor_workflow(self):",
        "        \"\"\"Verify refactor.yaml loads correctly.\"\"\"",
        "        workflow_path = WORKFLOWS_DIR / \"refactor.yaml\"",
        "        self.assertTrue(workflow_path.exists(), \"refactor.yaml should exist\")",
        "",
        "        workflow = Workflow.load(workflow_path)",
        "",
        "        self.assertEqual(workflow.name, \"Refactor\")",
        "        self.assertEqual(workflow.category, \"refactor\")",
        "        self.assertEqual(len(workflow.tasks), 4, \"Refactor workflow should have 4 tasks\")",
        "",
        "        # Verify task IDs",
        "        task_ids = [t.id for t in workflow.tasks]",
        "        self.assertIn(\"analyze\", task_ids)",
        "        self.assertIn(\"refactor\", task_ids)",
        "        self.assertIn(\"verify\", task_ids)",
        "        self.assertIn(\"cleanup\", task_ids)",
        "",
        "    def test_list_workflows_returns_all(self):",
        "        \"\"\"Verify list_workflows finds all three templates.\"\"\"",
        "        workflows = list_workflows()",
        "",
        "        self.assertGreaterEqual(len(workflows), 3, \"Should find at least 3 workflows\")",
        "",
        "        workflow_names = [w.name for w in workflows]",
        "        self.assertIn(\"Bug Fix\", workflow_names)",
        "        self.assertIn(\"Feature\", workflow_names)",
        "        self.assertIn(\"Refactor\", workflow_names)",
        "",
        "    def test_workflow_variables_have_correct_types(self):",
        "        \"\"\"Verify workflow variables are parsed correctly.\"\"\"",
        "        workflow = Workflow.load(WORKFLOWS_DIR / \"bugfix.yaml\")",
        "",
        "        # Find bug_title variable",
        "        bug_title_var = next(v for v in workflow.variables if v.name == \"bug_title\")",
        "        self.assertTrue(bug_title_var.required)",
        "        self.assertIsNone(bug_title_var.default)",
        "",
        "        # Find priority variable with choices",
        "        priority_var = next(v for v in workflow.variables if v.name == \"priority\")",
        "        self.assertIsNotNone(priority_var.choices)",
        "        self.assertIn(\"high\", priority_var.choices)",
        "        self.assertIn(\"medium\", priority_var.choices)",
        "        self.assertIn(\"low\", priority_var.choices)",
        "",
        "",
        "class TestWorkflowExecution(unittest.TestCase):",
        "    \"\"\"Test end-to-end workflow execution with real file creation.\"\"\"",
        "",
        "    def setUp(self):",
        "        \"\"\"Create temporary directory for tasks.\"\"\"",
        "        self.temp_dir = tempfile.mkdtemp()",
        "",
        "    def tearDown(self):",
        "        \"\"\"Clean up temporary directory.\"\"\"",
        "        shutil.rmtree(self.temp_dir)",
        "",
        "    def test_bugfix_workflow_creates_four_tasks(self):",
        "        \"\"\"Verify bugfix workflow creates exactly 4 tasks.\"\"\"",
        "        workflow = Workflow.load(WORKFLOWS_DIR / \"bugfix.yaml\")",
        "        variables = {",
        "            \"bug_title\": \"Login crashes on special chars\",",
        "            \"priority\": \"high\"",
        "        }",
        "",
        "        tasks = run_workflow(workflow, variables, tasks_dir=self.temp_dir, dry_run=True)",
        "",
        "        self.assertEqual(len(tasks), 4, \"Bugfix workflow should create 4 tasks\")",
        "        self.assertIsInstance(tasks[0], Task)",
        "",
        "        # Verify titles contain substituted bug_title",
        "        for task in tasks:",
        "            self.assertIn(\"Login crashes on special chars\", task.title)",
        "",
        "    def test_bugfix_workflow_saves_to_json(self):",
        "        \"\"\"Verify workflow creates valid JSON file.\"\"\"",
        "        workflow = Workflow.load(WORKFLOWS_DIR / \"bugfix.yaml\")",
        "        variables = {",
        "            \"bug_title\": \"Null pointer in auth module\",",
        "            \"priority\": \"high\"",
        "        }",
        "",
        "        tasks = run_workflow(workflow, variables, tasks_dir=self.temp_dir, dry_run=False)",
        "",
        "        # Check that JSON file was created",
        "        json_files = list(Path(self.temp_dir).glob(\"*.json\"))",
        "        self.assertEqual(len(json_files), 1, \"Should create exactly one JSON file\")",
        "",
        "        # Verify JSON is valid",
        "        with open(json_files[0]) as f:",
        "            data = json.load(f)",
        "",
        "        self.assertEqual(data[\"version\"], 1)",
        "        self.assertIn(\"tasks\", data)",
        "        self.assertEqual(len(data[\"tasks\"]), 4)",
        "",
        "        # Verify tasks have correct structure",
        "        for task_data in data[\"tasks\"]:",
        "            self.assertIn(\"id\", task_data)",
        "            self.assertIn(\"title\", task_data)",
        "            self.assertIn(\"status\", task_data)",
        "            self.assertIn(\"depends_on\", task_data)",
        "",
        "    def test_feature_workflow_creates_five_tasks(self):",
        "        \"\"\"Verify feature workflow creates exactly 5 tasks.\"\"\"",
        "        workflow = Workflow.load(WORKFLOWS_DIR / \"feature.yaml\")",
        "        variables = {",
        "            \"feature_name\": \"Dark mode toggle\",",
        "            \"priority\": \"medium\",",
        "            \"effort\": \"large\"",
        "        }",
        "",
        "        tasks = run_workflow(workflow, variables, tasks_dir=self.temp_dir, dry_run=True)",
        "",
        "        self.assertEqual(len(tasks), 5, \"Feature workflow should create 5 tasks\")",
        "",
        "        # Verify task categories",
        "        categories = [t.category for t in tasks]",
        "        self.assertIn(\"arch\", categories)  # design task",
        "        self.assertIn(\"feature\", categories)  # implement task",
        "        self.assertIn(\"test\", categories)  # test tasks",
        "        self.assertIn(\"docs\", categories)  # documentation task",
        "",
        "    def test_refactor_workflow_creates_four_tasks(self):",
        "        \"\"\"Verify refactor workflow creates exactly 4 tasks.\"\"\"",
        "        workflow = Workflow.load(WORKFLOWS_DIR / \"refactor.yaml\")",
        "        variables = {",
        "            \"refactor_target\": \"query module split\",",
        "            \"priority\": \"medium\"",
        "        }",
        "",
        "        tasks = run_workflow(workflow, variables, tasks_dir=self.temp_dir, dry_run=True)",
        "",
        "        self.assertEqual(len(tasks), 4, \"Refactor workflow should create 4 tasks\")",
        "",
        "        # Verify titles",
        "        titles = [t.title for t in tasks]",
        "        self.assertTrue(any(\"Analyze\" in t for t in titles))",
        "        self.assertTrue(any(\"Refactor\" in t for t in titles))",
        "        self.assertTrue(any(\"Verify\" in t for t in titles))",
        "        self.assertTrue(any(\"Cleanup\" in t for t in titles))",
        "",
        "",
        "class TestDependencyResolution(unittest.TestCase):",
        "    \"\"\"Test that workflow dependencies are resolved to actual task IDs.\"\"\"",
        "",
        "    def setUp(self):",
        "        \"\"\"Create temporary directory for tasks.\"\"\"",
        "        self.temp_dir = tempfile.mkdtemp()",
        "",
        "    def tearDown(self):",
        "        \"\"\"Clean up temporary directory.\"\"\"",
        "        shutil.rmtree(self.temp_dir)",
        "",
        "    def test_bugfix_dependency_chain(self):",
        "        \"\"\"Verify bugfix workflow dependency chain is correct.\"\"\"",
        "        workflow = Workflow.load(WORKFLOWS_DIR / \"bugfix.yaml\")",
        "        variables = {\"bug_title\": \"Test bug\", \"priority\": \"high\"}",
        "",
        "        tasks = run_workflow(workflow, variables, tasks_dir=self.temp_dir, dry_run=True)",
        "",
        "        # Build task map by title pattern",
        "        investigate = next(t for t in tasks if \"Investigate\" in t.title)",
        "        fix = next(t for t in tasks if \"Fix:\" in t.title)",
        "        test = next(t for t in tasks if \"regression test\" in t.title)",
        "        document = next(t for t in tasks if \"Document\" in t.title)",
        "",
        "        # Verify dependencies use actual task IDs, not template IDs",
        "        self.assertEqual(len(investigate.depends_on), 0, \"Investigate has no dependencies\")",
        "        self.assertIn(investigate.id, fix.depends_on, \"Fix depends on investigate\")",
        "        self.assertIn(fix.id, test.depends_on, \"Test depends on fix\")",
        "        self.assertIn(fix.id, document.depends_on, \"Document depends on fix\")",
        "",
        "        # Verify IDs are not template IDs",
        "        self.assertNotIn(\"investigate\", fix.depends_on)",
        "        self.assertNotIn(\"fix\", test.depends_on)",
        "",
        "    def test_feature_complex_dependencies(self):",
        "        \"\"\"Verify feature workflow has correct dependency graph.\"\"\"",
        "        workflow = Workflow.load(WORKFLOWS_DIR / \"feature.yaml\")",
        "        variables = {",
        "            \"feature_name\": \"Test feature\",",
        "            \"priority\": \"medium\",",
        "            \"effort\": \"large\"",
        "        }",
        "",
        "        tasks = run_workflow(workflow, variables, tasks_dir=self.temp_dir, dry_run=True)",
        "",
        "        # Map tasks by title pattern",
        "        design = next(t for t in tasks if \"Design:\" in t.title)",
        "        implement = next(t for t in tasks if \"Implement:\" in t.title)",
        "        unit_tests = next(t for t in tasks if \"Unit tests\" in t.title)",
        "        integration_tests = next(t for t in tasks if \"Integration tests\" in t.title)",
        "        documentation = next(t for t in tasks if \"Documentation\" in t.title)",
        "",
        "        # Verify dependency chain",
        "        self.assertEqual(len(design.depends_on), 0, \"Design has no dependencies\")",
        "        self.assertIn(design.id, implement.depends_on, \"Implement depends on design\")",
        "        self.assertIn(implement.id, unit_tests.depends_on, \"Unit tests depend on implement\")",
        "        self.assertIn(implement.id, integration_tests.depends_on, \"Integration tests depend on implement\")",
        "",
        "        # Documentation depends on BOTH test tasks",
        "        self.assertIn(unit_tests.id, documentation.depends_on)",
        "        self.assertIn(integration_tests.id, documentation.depends_on)",
        "",
        "        # Verify no template IDs leak through",
        "        for task in tasks:",
        "            for dep_id in task.depends_on:",
        "                self.assertTrue(dep_id.startswith(\"T-\"), f\"Dependency {dep_id} should be a real task ID\")",
        "",
        "    def test_dependencies_point_to_existing_tasks(self):",
        "        \"\"\"Verify all dependency IDs reference actual tasks in the session.\"\"\"",
        "        workflow = Workflow.load(WORKFLOWS_DIR / \"feature.yaml\")",
        "        variables = {",
        "            \"feature_name\": \"Test\",",
        "            \"priority\": \"high\",",
        "            \"effort\": \"medium\"",
        "        }",
        "",
        "        tasks = run_workflow(workflow, variables, tasks_dir=self.temp_dir, dry_run=False)",
        "",
        "        # Load tasks from file",
        "        loaded_tasks = load_all_tasks(self.temp_dir)",
        "        task_ids = {t.id for t in loaded_tasks}",
        "",
        "        # Verify every dependency points to an existing task",
        "        for task in loaded_tasks:",
        "            for dep_id in task.depends_on:",
        "                self.assertIn(dep_id, task_ids, f\"Dependency {dep_id} should exist in task set\")",
        "",
        "",
        "class TestVariableSubstitution(unittest.TestCase):",
        "    \"\"\"Test variable substitution in task titles and descriptions.\"\"\"",
        "",
        "    def setUp(self):",
        "        \"\"\"Create temporary directory for tasks.\"\"\"",
        "        self.temp_dir = tempfile.mkdtemp()",
        "",
        "    def tearDown(self):",
        "        \"\"\"Clean up temporary directory.\"\"\"",
        "        shutil.rmtree(self.temp_dir)",
        "",
        "    def test_bug_title_appears_in_all_tasks(self):",
        "        \"\"\"Verify bug_title variable is substituted in all task titles.\"\"\"",
        "        workflow = Workflow.load(WORKFLOWS_DIR / \"bugfix.yaml\")",
        "        bug_title = \"Timeout in database connection\"",
        "        variables = {\"bug_title\": bug_title, \"priority\": \"high\"}",
        "",
        "        tasks = run_workflow(workflow, variables, tasks_dir=self.temp_dir, dry_run=True)",
        "",
        "        # All tasks should contain the bug title",
        "        for task in tasks:",
        "            self.assertIn(bug_title, task.title,",
        "                         f\"Task title '{task.title}' should contain '{bug_title}'\")",
        "",
        "    def test_description_substitution(self):",
        "        \"\"\"Verify variable substitution works in task descriptions.\"\"\"",
        "        workflow = Workflow.load(WORKFLOWS_DIR / \"bugfix.yaml\")",
        "        bug_title = \"Memory leak in cache\"",
        "        variables = {\"bug_title\": bug_title, \"priority\": \"high\"}",
        "",
        "        tasks = run_workflow(workflow, variables, tasks_dir=self.temp_dir, dry_run=True)",
        "",
        "        # At least one description should contain the bug title",
        "        descriptions = [t.description for t in tasks if t.description]",
        "        self.assertTrue(any(bug_title in desc for desc in descriptions),",
        "                       \"At least one description should contain bug_title\")",
        "",
        "    def test_priority_substitution(self):",
        "        \"\"\"Verify priority variable is substituted correctly.\"\"\"",
        "        workflow = Workflow.load(WORKFLOWS_DIR / \"bugfix.yaml\")",
        "        variables = {\"bug_title\": \"Test\", \"priority\": \"low\"}",
        "",
        "        tasks = run_workflow(workflow, variables, tasks_dir=self.temp_dir, dry_run=True)",
        "",
        "        # First task (investigate) should have priority from variable",
        "        investigate_task = tasks[0]",
        "        self.assertEqual(investigate_task.priority, \"low\")",
        "",
        "    def test_effort_substitution_in_feature_workflow(self):",
        "        \"\"\"Verify effort variable is substituted in feature workflow.\"\"\"",
        "        workflow = Workflow.load(WORKFLOWS_DIR / \"feature.yaml\")",
        "        variables = {",
        "            \"feature_name\": \"Test\",",
        "            \"priority\": \"high\",",
        "            \"effort\": \"small\"  # Override default",
        "        }",
        "",
        "        tasks = run_workflow(workflow, variables, tasks_dir=self.temp_dir, dry_run=True)",
        "",
        "        # Implementation task should have small effort",
        "        implement_task = next(t for t in tasks if \"Implement:\" in t.title)",
        "        self.assertEqual(implement_task.effort, \"small\")",
        "",
        "    def test_multiple_variable_substitution(self):",
        "        \"\"\"Verify multiple variables work together.\"\"\"",
        "        workflow = Workflow.load(WORKFLOWS_DIR / \"feature.yaml\")",
        "        variables = {",
        "            \"feature_name\": \"Semantic search\",",
        "            \"priority\": \"high\",",
        "            \"effort\": \"large\"",
        "        }",
        "",
        "        tasks = run_workflow(workflow, variables, tasks_dir=self.temp_dir, dry_run=True)",
        "",
        "        # Check design task has both substitutions",
        "        design_task = tasks[0]",
        "        self.assertIn(\"Semantic search\", design_task.title)",
        "        self.assertEqual(design_task.priority, \"high\")",
        "        self.assertEqual(design_task.effort, \"medium\")  # Design has hardcoded medium",
        "",
        "        # Check implementation task",
        "        impl_task = next(t for t in tasks if \"Implement:\" in t.title)",
        "        self.assertIn(\"Semantic search\", impl_task.title)",
        "        self.assertEqual(impl_task.priority, \"high\")",
        "        self.assertEqual(impl_task.effort, \"large\")",
        "",
        "    def test_substitute_variables_function(self):",
        "        \"\"\"Test the substitute_variables helper function directly.\"\"\"",
        "        text = \"Fix: {bug_title} (Priority: {priority})\"",
        "        variables = {\"bug_title\": \"Auth error\", \"priority\": \"high\"}",
        "",
        "        result = substitute_variables(text, variables)",
        "",
        "        self.assertEqual(result, \"Fix: Auth error (Priority: high)\")",
        "        self.assertNotIn(\"{\", result)",
        "        self.assertNotIn(\"}\", result)",
        "",
        "",
        "class TestWorkflowValidation(unittest.TestCase):",
        "    \"\"\"Test workflow variable validation and error handling.\"\"\"",
        "",
        "    def setUp(self):",
        "        \"\"\"Create temporary directory for tasks.\"\"\"",
        "        self.temp_dir = tempfile.mkdtemp()",
        "",
        "    def tearDown(self):",
        "        \"\"\"Clean up temporary directory.\"\"\"",
        "        shutil.rmtree(self.temp_dir)",
        "",
        "    def test_missing_required_variable_raises_error(self):",
        "        \"\"\"Verify missing required variable raises ValueError.\"\"\"",
        "        workflow = Workflow.load(WORKFLOWS_DIR / \"bugfix.yaml\")",
        "        variables = {\"priority\": \"high\"}  # Missing bug_title",
        "",
        "        with self.assertRaises(ValueError) as ctx:",
        "            run_workflow(workflow, variables, tasks_dir=self.temp_dir, dry_run=True)",
        "",
        "        self.assertIn(\"bug_title\", str(ctx.exception))",
        "",
        "    def test_invalid_choice_raises_error(self):",
        "        \"\"\"Verify invalid choice value raises ValueError.\"\"\"",
        "        workflow = Workflow.load(WORKFLOWS_DIR / \"bugfix.yaml\")",
        "        variables = {",
        "            \"bug_title\": \"Test\",",
        "            \"priority\": \"urgent\"  # Invalid - not in choices",
        "        }",
        "",
        "        with self.assertRaises(ValueError) as ctx:",
        "            run_workflow(workflow, variables, tasks_dir=self.temp_dir, dry_run=True)",
        "",
        "        self.assertIn(\"priority\", str(ctx.exception))",
        "        self.assertIn(\"urgent\", str(ctx.exception))",
        "",
        "    def test_default_value_used_when_missing(self):",
        "        \"\"\"Verify default values are used for missing optional variables.\"\"\"",
        "        workflow = Workflow.load(WORKFLOWS_DIR / \"bugfix.yaml\")",
        "        variables = {\"bug_title\": \"Test\"}  # Missing priority, should use default",
        "",
        "        tasks = run_workflow(workflow, variables, tasks_dir=self.temp_dir, dry_run=True)",
        "",
        "        # Should use default priority \"high\"",
        "        self.assertTrue(any(t.priority == \"high\" for t in tasks))",
        "",
        "",
        "class TestDryRunMode(unittest.TestCase):",
        "    \"\"\"Test dry run mode doesn't create files.\"\"\"",
        "",
        "    def setUp(self):",
        "        \"\"\"Create temporary directory for tasks.\"\"\"",
        "        self.temp_dir = tempfile.mkdtemp()",
        "",
        "    def tearDown(self):",
        "        \"\"\"Clean up temporary directory.\"\"\"",
        "        shutil.rmtree(self.temp_dir)",
        "",
        "    def test_dry_run_does_not_create_files(self):",
        "        \"\"\"Verify dry_run=True doesn't create JSON files.\"\"\"",
        "        workflow = Workflow.load(WORKFLOWS_DIR / \"bugfix.yaml\")",
        "        variables = {\"bug_title\": \"Test\", \"priority\": \"high\"}",
        "",
        "        tasks = run_workflow(workflow, variables, tasks_dir=self.temp_dir, dry_run=True)",
        "",
        "        # Should return tasks",
        "        self.assertEqual(len(tasks), 4)",
        "",
        "        # But should not create files",
        "        json_files = list(Path(self.temp_dir).glob(\"*.json\"))",
        "        self.assertEqual(len(json_files), 0, \"Dry run should not create files\")",
        "",
        "    def test_normal_run_creates_files(self):",
        "        \"\"\"Verify dry_run=False creates files.\"\"\"",
        "        workflow = Workflow.load(WORKFLOWS_DIR / \"bugfix.yaml\")",
        "        variables = {\"bug_title\": \"Test\", \"priority\": \"high\"}",
        "",
        "        tasks = run_workflow(workflow, variables, tasks_dir=self.temp_dir, dry_run=False)",
        "",
        "        # Should create exactly one JSON file",
        "        json_files = list(Path(self.temp_dir).glob(\"*.json\"))",
        "        self.assertEqual(len(json_files), 1, \"Should create one JSON file\")",
        "",
        "",
        "if __name__ == \"__main__\":",
        "    unittest.main()"
      ],
      "lines_removed": [],
      "context_before": [],
      "context_after": [],
      "change_type": "add"
    },
    {
      "file": "tests/unit/test_task_utils.py",
      "function": null,
      "start_line": 0,
      "lines_added": [
        "\"\"\"Unit tests for merge-friendly task ID utilities.\"\"\"",
        "",
        "import json",
        "import os",
        "import sys",
        "import tempfile",
        "import unittest",
        "from datetime import datetime",
        "from pathlib import Path",
        "",
        "# Add scripts to path",
        "sys.path.insert(0, str(Path(__file__).parent.parent.parent / \"scripts\"))",
        "",
        "from task_utils import (",
        "    generate_task_id,",
        "    generate_short_task_id,",
        "    generate_session_id,",
        "    Task,",
        "    TaskSession,",
        "    load_all_tasks,",
        "    get_task_by_id,",
        "    consolidate_tasks,",
        ")",
        "",
        "",
        "class TestTaskIdGeneration(unittest.TestCase):",
        "    \"\"\"Tests for task ID generation.\"\"\"",
        "",
        "    def test_generate_task_id_format(self):",
        "        \"\"\"Task ID should have correct format.\"\"\"",
        "        task_id = generate_task_id()",
        "        # Format: T-YYYYMMDD-HHMMSS-XXXX",
        "        self.assertTrue(task_id.startswith(\"T-\"))",
        "        parts = task_id.split(\"-\")",
        "        self.assertEqual(len(parts), 4)",
        "        self.assertEqual(len(parts[1]), 8)  # YYYYMMDD",
        "        self.assertEqual(len(parts[2]), 6)  # HHMMSS",
        "        self.assertEqual(len(parts[3]), 4)  # session suffix",
        "",
        "    def test_generate_task_id_with_session(self):",
        "        \"\"\"Task ID should use provided session suffix.\"\"\"",
        "        task_id = generate_task_id(\"test\")",
        "        self.assertTrue(task_id.endswith(\"-test\"))",
        "",
        "    def test_generate_short_task_id(self):",
        "        \"\"\"Short task ID should be 10 characters.\"\"\"",
        "        task_id = generate_short_task_id()",
        "        # Format: T-XXXXXXXX",
        "        self.assertTrue(task_id.startswith(\"T-\"))",
        "        self.assertEqual(len(task_id), 10)",
        "",
        "    def test_generate_session_id(self):",
        "        \"\"\"Session ID should be 4 hex characters.\"\"\"",
        "        session_id = generate_session_id()",
        "        self.assertEqual(len(session_id), 4)",
        "        # Should be valid hex",
        "        int(session_id, 16)",
        "",
        "    def test_unique_task_ids(self):",
        "        \"\"\"Generated task IDs should be unique.\"\"\"",
        "        ids = {generate_task_id() for _ in range(100)}",
        "        self.assertEqual(len(ids), 100)",
        "",
        "",
        "class TestTask(unittest.TestCase):",
        "    \"\"\"Tests for Task dataclass.\"\"\"",
        "",
        "    def test_task_creation(self):",
        "        \"\"\"Task should be created with required fields.\"\"\"",
        "        task = Task(id=\"T-test\", title=\"Test task\")",
        "        self.assertEqual(task.id, \"T-test\")",
        "        self.assertEqual(task.title, \"Test task\")",
        "        self.assertEqual(task.status, \"pending\")",
        "",
        "    def test_task_to_dict(self):",
        "        \"\"\"Task should serialize to dict.\"\"\"",
        "        task = Task(",
        "            id=\"T-test\",",
        "            title=\"Test task\",",
        "            priority=\"high\",",
        "            category=\"arch\"",
        "        )",
        "        d = task.to_dict()",
        "        self.assertEqual(d[\"id\"], \"T-test\")",
        "        self.assertEqual(d[\"title\"], \"Test task\")",
        "        self.assertEqual(d[\"priority\"], \"high\")",
        "",
        "    def test_task_from_dict(self):",
        "        \"\"\"Task should deserialize from dict.\"\"\"",
        "        d = {",
        "            \"id\": \"T-test\",",
        "            \"title\": \"Test task\",",
        "            \"status\": \"completed\",",
        "            \"priority\": \"low\",",
        "            \"category\": \"test\",",
        "            \"description\": \"\",",
        "            \"depends_on\": [],",
        "            \"effort\": \"small\",",
        "            \"created_at\": \"2025-12-13T00:00:00\",",
        "            \"updated_at\": None,",
        "            \"completed_at\": None,",
        "            \"context\": {}",
        "        }",
        "        task = Task.from_dict(d)",
        "        self.assertEqual(task.id, \"T-test\")",
        "        self.assertEqual(task.status, \"completed\")",
        "",
        "    def test_mark_complete(self):",
        "        \"\"\"mark_complete should update status and timestamp.\"\"\"",
        "        task = Task(id=\"T-test\", title=\"Test task\")",
        "        self.assertEqual(task.status, \"pending\")",
        "        self.assertIsNone(task.completed_at)",
        "",
        "        task.mark_complete()",
        "        self.assertEqual(task.status, \"completed\")",
        "        self.assertIsNotNone(task.completed_at)",
        "",
        "    def test_mark_in_progress(self):",
        "        \"\"\"mark_in_progress should update status and timestamp.\"\"\"",
        "        task = Task(id=\"T-test\", title=\"Test task\")",
        "        task.mark_in_progress()",
        "        self.assertEqual(task.status, \"in_progress\")",
        "        self.assertIsNotNone(task.updated_at)",
        "",
        "",
        "class TestTaskSession(unittest.TestCase):",
        "    \"\"\"Tests for TaskSession.\"\"\"",
        "",
        "    def setUp(self):",
        "        \"\"\"Create temporary directory for task files.\"\"\"",
        "        self.temp_dir = tempfile.mkdtemp()",
        "",
        "    def tearDown(self):",
        "        \"\"\"Clean up temporary directory.\"\"\"",
        "        import shutil",
        "        shutil.rmtree(self.temp_dir)",
        "",
        "    def test_session_id_consistency(self):",
        "        \"\"\"All tasks in session should share same session suffix.\"\"\"",
        "        session = TaskSession()",
        "        id1 = session.new_task_id()",
        "        id2 = session.new_task_id()",
        "",
        "        # Format: T-YYYYMMDD-HHMMSS-XXXX-NN",
        "        # Session suffix is second to last part",
        "        parts1 = id1.split(\"-\")",
        "        parts2 = id2.split(\"-\")",
        "",
        "        session_suffix1 = parts1[-2]",
        "        session_suffix2 = parts2[-2]",
        "",
        "        self.assertEqual(session_suffix1, session_suffix2)",
        "        self.assertEqual(session_suffix1, session.session_id)",
        "",
        "        # Task counters should be different (3-digit format)",
        "        counter1 = parts1[-1]",
        "        counter2 = parts2[-1]",
        "        self.assertNotEqual(counter1, counter2)",
        "        self.assertEqual(counter1, \"001\")",
        "        self.assertEqual(counter2, \"002\")",
        "",
        "    def test_create_task(self):",
        "        \"\"\"create_task should add task to session.\"\"\"",
        "        session = TaskSession()",
        "        task = session.create_task(",
        "            title=\"Test task\",",
        "            priority=\"high\"",
        "        )",
        "",
        "        self.assertEqual(len(session.tasks), 1)",
        "        self.assertEqual(task.title, \"Test task\")",
        "        self.assertEqual(task.priority, \"high\")",
        "",
        "    def test_save_and_load(self):",
        "        \"\"\"Session should save and load correctly.\"\"\"",
        "        session = TaskSession()",
        "        session.create_task(title=\"Task 1\")",
        "        session.create_task(title=\"Task 2\")",
        "",
        "        filepath = session.save(self.temp_dir)",
        "        self.assertTrue(filepath.exists())",
        "",
        "        loaded = TaskSession.load(filepath)",
        "        self.assertEqual(len(loaded.tasks), 2)",
        "        self.assertEqual(loaded.tasks[0].title, \"Task 1\")",
        "",
        "    def test_session_filename_format(self):",
        "        \"\"\"Session filename should have correct format.\"\"\"",
        "        session = TaskSession()",
        "        filename = session.get_filename()",
        "        # Format: YYYY-MM-DD_HH-MM-SS_XXXX.json",
        "        self.assertTrue(filename.endswith(\".json\"))",
        "        parts = filename[:-5].split(\"_\")  # Remove .json",
        "        self.assertEqual(len(parts), 3)",
        "",
        "",
        "class TestTaskLoading(unittest.TestCase):",
        "    \"\"\"Tests for loading tasks from multiple files.\"\"\"",
        "",
        "    def setUp(self):",
        "        \"\"\"Create temporary directory with task files.\"\"\"",
        "        self.temp_dir = tempfile.mkdtemp()",
        "",
        "        # Create two sessions",
        "        session1 = TaskSession()",
        "        session1.create_task(title=\"Session 1 Task 1\")",
        "        session1.create_task(title=\"Session 1 Task 2\")",
        "        session1.save(self.temp_dir)",
        "",
        "        session2 = TaskSession()",
        "        session2.create_task(title=\"Session 2 Task 1\")",
        "        session2.save(self.temp_dir)",
        "",
        "    def tearDown(self):",
        "        \"\"\"Clean up temporary directory.\"\"\"",
        "        import shutil",
        "        shutil.rmtree(self.temp_dir)",
        "",
        "    def test_load_all_tasks(self):",
        "        \"\"\"load_all_tasks should load from all session files.\"\"\"",
        "        tasks = load_all_tasks(self.temp_dir)",
        "        self.assertEqual(len(tasks), 3)",
        "",
        "    def test_load_empty_directory(self):",
        "        \"\"\"load_all_tasks should return empty list for missing directory.\"\"\"",
        "        tasks = load_all_tasks(\"/nonexistent\")",
        "        self.assertEqual(tasks, [])",
        "",
        "    def test_get_task_by_id(self):",
        "        \"\"\"get_task_by_id should find task across sessions.\"\"\"",
        "        tasks = load_all_tasks(self.temp_dir)",
        "        target_id = tasks[0].id",
        "",
        "        found = get_task_by_id(target_id, self.temp_dir)",
        "        self.assertIsNotNone(found)",
        "        self.assertEqual(found.id, target_id)",
        "",
        "    def test_get_task_by_id_not_found(self):",
        "        \"\"\"get_task_by_id should return None for missing ID.\"\"\"",
        "        found = get_task_by_id(\"T-nonexistent\", self.temp_dir)",
        "        self.assertIsNone(found)",
        "",
        "",
        "class TestConsolidation(unittest.TestCase):",
        "    \"\"\"Tests for task consolidation.\"\"\"",
        "",
        "    def setUp(self):",
        "        \"\"\"Create temporary directory with task files.\"\"\"",
        "        self.temp_dir = tempfile.mkdtemp()",
        "",
        "    def tearDown(self):",
        "        \"\"\"Clean up temporary directory.\"\"\"",
        "        import shutil",
        "        shutil.rmtree(self.temp_dir)",
        "",
        "    def test_consolidate_groups_by_status(self):",
        "        \"\"\"consolidate_tasks should group by status.\"\"\"",
        "        session = TaskSession()",
        "        task1 = session.create_task(title=\"Pending task\")",
        "        task2 = session.create_task(title=\"In progress task\")",
        "        task2.mark_in_progress()",
        "        task3 = session.create_task(title=\"Completed task\")",
        "        task3.mark_complete()",
        "        session.save(self.temp_dir)",
        "",
        "        grouped = consolidate_tasks(self.temp_dir)",
        "",
        "        self.assertEqual(len(grouped[\"pending\"]), 1)",
        "        self.assertEqual(len(grouped[\"in_progress\"]), 1)",
        "        self.assertEqual(len(grouped[\"completed\"]), 1)",
        "",
        "",
        "if __name__ == \"__main__\":",
        "    unittest.main()"
      ],
      "lines_removed": [],
      "context_before": [],
      "context_after": [],
      "change_type": "add"
    },
    {
      "file": "tests/unit/test_workflow.py",
      "function": null,
      "start_line": 0,
      "lines_added": [
        "#!/usr/bin/env python3",
        "\"\"\"Unit tests for workflow template engine.\"\"\"",
        "",
        "import sys",
        "import tempfile",
        "import unittest",
        "from pathlib import Path",
        "from unittest.mock import MagicMock, patch, call",
        "",
        "# Add scripts to path",
        "sys.path.insert(0, str(Path(__file__).parent.parent.parent / \"scripts\"))",
        "",
        "from workflow import (",
        "    WorkflowVariable,",
        "    WorkflowTask,",
        "    Workflow,",
        "    substitute_variables,",
        "    run_workflow,",
        ")",
        "",
        "",
        "class TestWorkflowVariable(unittest.TestCase):",
        "    \"\"\"Tests for WorkflowVariable dataclass.\"\"\"",
        "",
        "    def test_variable_with_defaults(self):",
        "        \"\"\"WorkflowVariable should use default values.\"\"\"",
        "        var = WorkflowVariable(",
        "            name=\"test_var\",",
        "            description=\"Test variable\"",
        "        )",
        "        self.assertEqual(var.name, \"test_var\")",
        "        self.assertEqual(var.description, \"Test variable\")",
        "        self.assertTrue(var.required)",
        "        self.assertIsNone(var.default)",
        "        self.assertIsNone(var.choices)",
        "",
        "    def test_variable_with_all_fields(self):",
        "        \"\"\"WorkflowVariable should accept all optional fields.\"\"\"",
        "        var = WorkflowVariable(",
        "            name=\"priority\",",
        "            description=\"Task priority\",",
        "            required=False,",
        "            default=\"medium\",",
        "            choices=[\"low\", \"medium\", \"high\"]",
        "        )",
        "        self.assertEqual(var.name, \"priority\")",
        "        self.assertEqual(var.description, \"Task priority\")",
        "        self.assertFalse(var.required)",
        "        self.assertEqual(var.default, \"medium\")",
        "        self.assertEqual(var.choices, [\"low\", \"medium\", \"high\"])",
        "",
        "    def test_variable_required_false(self):",
        "        \"\"\"WorkflowVariable should allow required=False.\"\"\"",
        "        var = WorkflowVariable(",
        "            name=\"optional\",",
        "            description=\"Optional field\",",
        "            required=False",
        "        )",
        "        self.assertFalse(var.required)",
        "",
        "    def test_variable_with_default_no_choices(self):",
        "        \"\"\"WorkflowVariable should allow default without choices.\"\"\"",
        "        var = WorkflowVariable(",
        "            name=\"effort\",",
        "            description=\"Effort estimate\",",
        "            default=\"medium\"",
        "        )",
        "        self.assertEqual(var.default, \"medium\")",
        "        self.assertIsNone(var.choices)",
        "",
        "",
        "class TestWorkflowTask(unittest.TestCase):",
        "    \"\"\"Tests for WorkflowTask dataclass.\"\"\"",
        "",
        "    def test_task_post_init_none_depends_on(self):",
        "        \"\"\"__post_init__ should initialize depends_on to empty list if None.\"\"\"",
        "        task = WorkflowTask(",
        "            id=\"task1\",",
        "            title=\"Test Task\",",
        "            depends_on=None",
        "        )",
        "        self.assertEqual(task.depends_on, [])",
        "",
        "    def test_task_post_init_preserves_depends_on(self):",
        "        \"\"\"__post_init__ should preserve non-None depends_on.\"\"\"",
        "        task = WorkflowTask(",
        "            id=\"task1\",",
        "            title=\"Test Task\",",
        "            depends_on=[\"task0\"]",
        "        )",
        "        self.assertEqual(task.depends_on, [\"task0\"])",
        "",
        "    def test_task_with_defaults(self):",
        "        \"\"\"WorkflowTask should use default values.\"\"\"",
        "        task = WorkflowTask(",
        "            id=\"task1\",",
        "            title=\"Test Task\"",
        "        )",
        "        self.assertEqual(task.id, \"task1\")",
        "        self.assertEqual(task.title, \"Test Task\")",
        "        self.assertEqual(task.category, \"general\")",
        "        self.assertEqual(task.priority, \"medium\")",
        "        self.assertEqual(task.effort, \"medium\")",
        "        self.assertEqual(task.description, \"\")",
        "        self.assertEqual(task.depends_on, [])",
        "",
        "    def test_task_with_all_fields(self):",
        "        \"\"\"WorkflowTask should accept all fields.\"\"\"",
        "        task = WorkflowTask(",
        "            id=\"task1\",",
        "            title=\"Test Task\",",
        "            category=\"bugfix\",",
        "            priority=\"high\",",
        "            effort=\"large\",",
        "            description=\"Detailed description\",",
        "            depends_on=[\"task0\", \"task2\"]",
        "        )",
        "        self.assertEqual(task.id, \"task1\")",
        "        self.assertEqual(task.title, \"Test Task\")",
        "        self.assertEqual(task.category, \"bugfix\")",
        "        self.assertEqual(task.priority, \"high\")",
        "        self.assertEqual(task.effort, \"large\")",
        "        self.assertEqual(task.description, \"Detailed description\")",
        "        self.assertEqual(task.depends_on, [\"task0\", \"task2\"])",
        "",
        "",
        "class TestWorkflowFromDict(unittest.TestCase):",
        "    \"\"\"Tests for Workflow.from_dict() parsing.\"\"\"",
        "",
        "    def test_minimal_workflow(self):",
        "        \"\"\"from_dict should parse workflow with minimal fields.\"\"\"",
        "        data = {",
        "            \"name\": \"Test Workflow\",",
        "            \"description\": \"A test workflow\",",
        "            \"category\": \"test\"",
        "        }",
        "        workflow = Workflow.from_dict(data)",
        "        self.assertEqual(workflow.name, \"Test Workflow\")",
        "        self.assertEqual(workflow.description, \"A test workflow\")",
        "        self.assertEqual(workflow.category, \"test\")",
        "        self.assertEqual(workflow.variables, [])",
        "        self.assertEqual(workflow.tasks, [])",
        "",
        "    def test_workflow_with_empty_variables(self):",
        "        \"\"\"from_dict should handle empty variables list.\"\"\"",
        "        data = {",
        "            \"name\": \"Test\",",
        "            \"variables\": []",
        "        }",
        "        workflow = Workflow.from_dict(data)",
        "        self.assertEqual(workflow.variables, [])",
        "",
        "    def test_workflow_with_empty_tasks(self):",
        "        \"\"\"from_dict should handle empty tasks list.\"\"\"",
        "        data = {",
        "            \"name\": \"Test\",",
        "            \"tasks\": []",
        "        }",
        "        workflow = Workflow.from_dict(data)",
        "        self.assertEqual(workflow.tasks, [])",
        "",
        "    def test_workflow_with_variables(self):",
        "        \"\"\"from_dict should parse variables with all optional fields.\"\"\"",
        "        data = {",
        "            \"name\": \"Test\",",
        "            \"variables\": [",
        "                {",
        "                    \"name\": \"bug_title\",",
        "                    \"description\": \"Bug title\",",
        "                    \"required\": True",
        "                },",
        "                {",
        "                    \"name\": \"priority\",",
        "                    \"description\": \"Priority level\",",
        "                    \"required\": False,",
        "                    \"default\": \"medium\",",
        "                    \"choices\": [\"low\", \"medium\", \"high\"]",
        "                }",
        "            ]",
        "        }",
        "        workflow = Workflow.from_dict(data)",
        "        self.assertEqual(len(workflow.variables), 2)",
        "",
        "        var1 = workflow.variables[0]",
        "        self.assertEqual(var1.name, \"bug_title\")",
        "        self.assertEqual(var1.description, \"Bug title\")",
        "        self.assertTrue(var1.required)",
        "        self.assertIsNone(var1.default)",
        "        self.assertIsNone(var1.choices)",
        "",
        "        var2 = workflow.variables[1]",
        "        self.assertEqual(var2.name, \"priority\")",
        "        self.assertEqual(var2.description, \"Priority level\")",
        "        self.assertFalse(var2.required)",
        "        self.assertEqual(var2.default, \"medium\")",
        "        self.assertEqual(var2.choices, [\"low\", \"medium\", \"high\"])",
        "",
        "    def test_workflow_with_tasks(self):",
        "        \"\"\"from_dict should parse tasks with all fields.\"\"\"",
        "        data = {",
        "            \"name\": \"Test\",",
        "            \"tasks\": [",
        "                {",
        "                    \"id\": \"task1\",",
        "                    \"title\": \"Fix {bug_title}\",",
        "                    \"category\": \"bugfix\",",
        "                    \"priority\": \"high\",",
        "                    \"effort\": \"small\",",
        "                    \"description\": \"Fix the bug\",",
        "                    \"depends_on\": []",
        "                },",
        "                {",
        "                    \"id\": \"task2\",",
        "                    \"title\": \"Test fix\",",
        "                    \"depends_on\": [\"task1\"]",
        "                }",
        "            ]",
        "        }",
        "        workflow = Workflow.from_dict(data)",
        "        self.assertEqual(len(workflow.tasks), 2)",
        "",
        "        task1 = workflow.tasks[0]",
        "        self.assertEqual(task1.id, \"task1\")",
        "        self.assertEqual(task1.title, \"Fix {bug_title}\")",
        "        self.assertEqual(task1.category, \"bugfix\")",
        "        self.assertEqual(task1.priority, \"high\")",
        "        self.assertEqual(task1.effort, \"small\")",
        "        self.assertEqual(task1.description, \"Fix the bug\")",
        "        self.assertEqual(task1.depends_on, [])",
        "",
        "        task2 = workflow.tasks[1]",
        "        self.assertEqual(task2.id, \"task2\")",
        "        self.assertEqual(task2.title, \"Test fix\")",
        "        self.assertEqual(task2.category, \"general\")  # default",
        "        self.assertEqual(task2.priority, \"medium\")  # default",
        "        self.assertEqual(task2.depends_on, [\"task1\"])",
        "",
        "    def test_workflow_default_category(self):",
        "        \"\"\"from_dict should use 'general' as default category.\"\"\"",
        "        data = {",
        "            \"name\": \"Test\"",
        "        }",
        "        workflow = Workflow.from_dict(data)",
        "        self.assertEqual(workflow.category, \"general\")",
        "",
        "    def test_workflow_default_description(self):",
        "        \"\"\"from_dict should use empty string as default description.\"\"\"",
        "        data = {",
        "            \"name\": \"Test\"",
        "        }",
        "        workflow = Workflow.from_dict(data)",
        "        self.assertEqual(workflow.description, \"\")",
        "",
        "",
        "class TestSubstituteVariables(unittest.TestCase):",
        "    \"\"\"Tests for substitute_variables() function.\"\"\"",
        "",
        "    def test_single_variable(self):",
        "        \"\"\"Should substitute single variable placeholder.\"\"\"",
        "        text = \"Fix {bug_title}\"",
        "        variables = {\"bug_title\": \"Login crash\"}",
        "        result = substitute_variables(text, variables)",
        "        self.assertEqual(result, \"Fix Login crash\")",
        "",
        "    def test_multiple_variables(self):",
        "        \"\"\"Should substitute multiple variable placeholders.\"\"\"",
        "        text = \"Fix {bug_title} with {priority} priority\"",
        "        variables = {",
        "            \"bug_title\": \"Login crash\",",
        "            \"priority\": \"high\"",
        "        }",
        "        result = substitute_variables(text, variables)",
        "        self.assertEqual(result, \"Fix Login crash with high priority\")",
        "",
        "    def test_variable_not_in_dict(self):",
        "        \"\"\"Should leave placeholder unchanged if variable not in dict.\"\"\"",
        "        text = \"Fix {bug_title} with {priority}\"",
        "        variables = {\"bug_title\": \"Login crash\"}",
        "        result = substitute_variables(text, variables)",
        "        self.assertEqual(result, \"Fix Login crash with {priority}\")",
        "",
        "    def test_empty_variables_dict(self):",
        "        \"\"\"Should return original text if variables dict is empty.\"\"\"",
        "        text = \"Fix {bug_title}\"",
        "        variables = {}",
        "        result = substitute_variables(text, variables)",
        "        self.assertEqual(result, \"Fix {bug_title}\")",
        "",
        "    def test_no_placeholders(self):",
        "        \"\"\"Should return original text if no placeholders.\"\"\"",
        "        text = \"Simple text without placeholders\"",
        "        variables = {\"bug_title\": \"Something\"}",
        "        result = substitute_variables(text, variables)",
        "        self.assertEqual(result, \"Simple text without placeholders\")",
        "",
        "    def test_multiple_occurrences(self):",
        "        \"\"\"Should substitute all occurrences of same variable.\"\"\"",
        "        text = \"{priority} bug: {bug_title} needs {priority} attention\"",
        "        variables = {",
        "            \"bug_title\": \"Login crash\",",
        "            \"priority\": \"high\"",
        "        }",
        "        result = substitute_variables(text, variables)",
        "        self.assertEqual(result, \"high bug: Login crash needs high attention\")",
        "",
        "    def test_nested_braces(self):",
        "        \"\"\"Should handle text with non-variable braces.\"\"\"",
        "        text = \"Code: function() { return {value}; }\"",
        "        variables = {\"value\": \"42\"}",
        "        result = substitute_variables(text, variables)",
        "        self.assertEqual(result, \"Code: function() { return 42; }\")",
        "",
        "",
        "class TestRunWorkflow(unittest.TestCase):",
        "    \"\"\"Tests for run_workflow() function.\"\"\"",
        "",
        "    def test_required_variable_missing_raises_error(self):",
        "        \"\"\"Should raise ValueError if required variable is missing.\"\"\"",
        "        workflow = Workflow(",
        "            name=\"Test\",",
        "            description=\"Test workflow\",",
        "            category=\"test\",",
        "            variables=[",
        "                WorkflowVariable(",
        "                    name=\"bug_title\",",
        "                    description=\"Bug title\",",
        "                    required=True",
        "                )",
        "            ],",
        "            tasks=[]",
        "        )",
        "        variables = {}",
        "",
        "        with self.assertRaises(ValueError) as cm:",
        "            run_workflow(workflow, variables, dry_run=True)",
        "",
        "        self.assertIn(\"Missing required variable: bug_title\", str(cm.exception))",
        "",
        "    def test_required_variable_with_default_uses_default(self):",
        "        \"\"\"Should use default value if required variable is missing but has default.\"\"\"",
        "        workflow = Workflow(",
        "            name=\"Test\",",
        "            description=\"Test workflow\",",
        "            category=\"test\",",
        "            variables=[",
        "                WorkflowVariable(",
        "                    name=\"priority\",",
        "                    description=\"Priority\",",
        "                    required=True,",
        "                    default=\"medium\"",
        "                )",
        "            ],",
        "            tasks=[",
        "                WorkflowTask(",
        "                    id=\"task1\",",
        "                    title=\"Task with {priority} priority\",",
        "                    priority=\"{priority}\"",
        "                )",
        "            ]",
        "        )",
        "        variables = {}",
        "",
        "        tasks = run_workflow(workflow, variables, dry_run=True)",
        "",
        "        self.assertEqual(len(tasks), 1)",
        "        self.assertEqual(tasks[0].title, \"Task with medium priority\")",
        "        self.assertEqual(tasks[0].priority, \"medium\")",
        "",
        "    def test_choice_validation_valid(self):",
        "        \"\"\"Should accept valid choice value.\"\"\"",
        "        workflow = Workflow(",
        "            name=\"Test\",",
        "            description=\"Test workflow\",",
        "            category=\"test\",",
        "            variables=[",
        "                WorkflowVariable(",
        "                    name=\"priority\",",
        "                    description=\"Priority\",",
        "                    choices=[\"low\", \"medium\", \"high\"]",
        "                )",
        "            ],",
        "            tasks=[",
        "                WorkflowTask(",
        "                    id=\"task1\",",
        "                    title=\"Task\"",
        "                )",
        "            ]",
        "        )",
        "        variables = {\"priority\": \"high\"}",
        "",
        "        # Should not raise",
        "        tasks = run_workflow(workflow, variables, dry_run=True)",
        "        self.assertEqual(len(tasks), 1)",
        "",
        "    def test_choice_validation_invalid_raises_error(self):",
        "        \"\"\"Should raise ValueError if choice value is invalid.\"\"\"",
        "        workflow = Workflow(",
        "            name=\"Test\",",
        "            description=\"Test workflow\",",
        "            category=\"test\",",
        "            variables=[",
        "                WorkflowVariable(",
        "                    name=\"priority\",",
        "                    description=\"Priority\",",
        "                    choices=[\"low\", \"medium\", \"high\"]",
        "                )",
        "            ],",
        "            tasks=[]",
        "        )",
        "        variables = {\"priority\": \"invalid\"}",
        "",
        "        with self.assertRaises(ValueError) as cm:",
        "            run_workflow(workflow, variables, dry_run=True)",
        "",
        "        self.assertIn(\"Invalid value for priority: invalid\", str(cm.exception))",
        "        self.assertIn(\"Must be one of:\", str(cm.exception))",
        "",
        "    @patch('workflow.TaskSession')",
        "    def test_dry_run_mode_no_save(self, mock_session_class):",
        "        \"\"\"Dry run should create tasks but not save them.\"\"\"",
        "        mock_session = MagicMock()",
        "        mock_session_class.return_value = mock_session",
        "",
        "        # Mock the task creation",
        "        mock_task = MagicMock()",
        "        mock_task.id = \"T-test-001\"",
        "        mock_task.title = \"Test Task\"",
        "        mock_task.priority = \"medium\"",
        "        mock_task.description = \"\"",
        "        mock_task.depends_on = []",
        "        mock_session.create_task.return_value = mock_task",
        "",
        "        workflow = Workflow(",
        "            name=\"Test\",",
        "            description=\"Test workflow\",",
        "            category=\"test\",",
        "            variables=[],",
        "            tasks=[",
        "                WorkflowTask(",
        "                    id=\"task1\",",
        "                    title=\"Test Task\"",
        "                )",
        "            ]",
        "        )",
        "        variables = {}",
        "",
        "        tasks = run_workflow(workflow, variables, dry_run=True)",
        "",
        "        self.assertEqual(len(tasks), 1)",
        "        # save() should NOT be called in dry run mode",
        "        mock_session.save.assert_not_called()",
        "",
        "    @patch('workflow.TaskSession')",
        "    def test_normal_mode_saves(self, mock_session_class):",
        "        \"\"\"Normal mode should create and save tasks.\"\"\"",
        "        mock_session = MagicMock()",
        "        mock_session_class.return_value = mock_session",
        "",
        "        # Mock the task creation",
        "        mock_task = MagicMock()",
        "        mock_task.id = \"T-test-001\"",
        "        mock_task.title = \"Test Task\"",
        "        mock_task.priority = \"medium\"",
        "        mock_task.description = \"\"",
        "        mock_task.depends_on = []",
        "        mock_session.create_task.return_value = mock_task",
        "        mock_session.save.return_value = Path(\"tasks/test.json\")",
        "",
        "        workflow = Workflow(",
        "            name=\"Test\",",
        "            description=\"Test workflow\",",
        "            category=\"test\",",
        "            variables=[],",
        "            tasks=[",
        "                WorkflowTask(",
        "                    id=\"task1\",",
        "                    title=\"Test Task\"",
        "                )",
        "            ]",
        "        )",
        "        variables = {}",
        "",
        "        tasks = run_workflow(workflow, variables, dry_run=False)",
        "",
        "        self.assertEqual(len(tasks), 1)",
        "        # save() SHOULD be called in normal mode",
        "        mock_session.save.assert_called_once_with(\"tasks\")",
        "",
        "    @patch('workflow.TaskSession')",
        "    def test_task_dependency_resolution(self, mock_session_class):",
        "        \"\"\"Should resolve workflow task IDs to actual task IDs.\"\"\"",
        "        mock_session = MagicMock()",
        "        mock_session_class.return_value = mock_session",
        "",
        "        # Mock task creation to return different IDs",
        "        mock_task1 = MagicMock()",
        "        mock_task1.id = \"T-actual-001\"",
        "        mock_task1.title = \"Task 1\"",
        "        mock_task1.priority = \"medium\"",
        "        mock_task1.description = \"\"",
        "        mock_task1.depends_on = []",
        "",
        "        mock_task2 = MagicMock()",
        "        mock_task2.id = \"T-actual-002\"",
        "        mock_task2.title = \"Task 2\"",
        "        mock_task2.priority = \"medium\"",
        "        mock_task2.description = \"\"",
        "        mock_task2.depends_on = [\"T-actual-001\"]",
        "",
        "        mock_session.create_task.side_effect = [mock_task1, mock_task2]",
        "",
        "        workflow = Workflow(",
        "            name=\"Test\",",
        "            description=\"Test workflow\",",
        "            category=\"test\",",
        "            variables=[],",
        "            tasks=[",
        "                WorkflowTask(",
        "                    id=\"wf_task1\",",
        "                    title=\"Task 1\"",
        "                ),",
        "                WorkflowTask(",
        "                    id=\"wf_task2\",",
        "                    title=\"Task 2\",",
        "                    depends_on=[\"wf_task1\"]",
        "                )",
        "            ]",
        "        )",
        "        variables = {}",
        "",
        "        tasks = run_workflow(workflow, variables, dry_run=True)",
        "",
        "        self.assertEqual(len(tasks), 2)",
        "        # Second task should have actual ID of first task in depends_on",
        "        second_call = mock_session.create_task.call_args_list[1]",
        "        self.assertEqual(second_call[1]['depends_on'], [\"T-actual-001\"])",
        "",
        "    @patch('workflow.TaskSession')",
        "    def test_variable_substitution_in_all_fields(self, mock_session_class):",
        "        \"\"\"Should substitute variables in title, description, priority, effort.\"\"\"",
        "        mock_session = MagicMock()",
        "        mock_session_class.return_value = mock_session",
        "",
        "        mock_task = MagicMock()",
        "        mock_task.id = \"T-test-001\"",
        "        mock_task.title = \"Fix Login crash\"",
        "        mock_task.priority = \"high\"",
        "        mock_task.effort = \"large\"",
        "        mock_task.description = \"Critical bug: Login crash\"",
        "        mock_task.depends_on = []",
        "        mock_session.create_task.return_value = mock_task",
        "",
        "        workflow = Workflow(",
        "            name=\"Test\",",
        "            description=\"Test workflow\",",
        "            category=\"test\",",
        "            variables=[",
        "                WorkflowVariable(name=\"bug_title\", description=\"Bug title\"),",
        "                WorkflowVariable(name=\"priority\", description=\"Priority\"),",
        "                WorkflowVariable(name=\"effort\", description=\"Effort\")",
        "            ],",
        "            tasks=[",
        "                WorkflowTask(",
        "                    id=\"task1\",",
        "                    title=\"Fix {bug_title}\",",
        "                    priority=\"{priority}\",",
        "                    effort=\"{effort}\",",
        "                    description=\"Critical bug: {bug_title}\"",
        "                )",
        "            ]",
        "        )",
        "        variables = {",
        "            \"bug_title\": \"Login crash\",",
        "            \"priority\": \"high\",",
        "            \"effort\": \"large\"",
        "        }",
        "",
        "        tasks = run_workflow(workflow, variables, dry_run=True)",
        "",
        "        # Verify substitution happened in create_task call",
        "        call_args = mock_session.create_task.call_args",
        "        self.assertEqual(call_args[1]['title'], \"Fix Login crash\")",
        "        self.assertEqual(call_args[1]['priority'], \"high\")",
        "        self.assertEqual(call_args[1]['effort'], \"large\")",
        "        self.assertEqual(call_args[1]['description'], \"Critical bug: Login crash\")",
        "",
        "    @patch('workflow.TaskSession')",
        "    def test_multiple_tasks_created(self, mock_session_class):",
        "        \"\"\"Should create all tasks in workflow.\"\"\"",
        "        mock_session = MagicMock()",
        "        mock_session_class.return_value = mock_session",
        "",
        "        mock_tasks = []",
        "        for i in range(3):",
        "            mock_task = MagicMock()",
        "            mock_task.id = f\"T-test-{i:03d}\"",
        "            mock_task.title = f\"Task {i+1}\"",
        "            mock_task.priority = \"medium\"",
        "            mock_task.description = \"\"",
        "            mock_task.depends_on = []",
        "            mock_tasks.append(mock_task)",
        "",
        "        mock_session.create_task.side_effect = mock_tasks",
        "",
        "        workflow = Workflow(",
        "            name=\"Test\",",
        "            description=\"Test workflow\",",
        "            category=\"test\",",
        "            variables=[],",
        "            tasks=[",
        "                WorkflowTask(id=\"task1\", title=\"Task 1\"),",
        "                WorkflowTask(id=\"task2\", title=\"Task 2\"),",
        "                WorkflowTask(id=\"task3\", title=\"Task 3\")",
        "            ]",
        "        )",
        "        variables = {}",
        "",
        "        tasks = run_workflow(workflow, variables, dry_run=True)",
        "",
        "        self.assertEqual(len(tasks), 3)",
        "        self.assertEqual(mock_session.create_task.call_count, 3)",
        "",
        "    @patch('workflow.TaskSession')",
        "    def test_custom_tasks_dir(self, mock_session_class):",
        "        \"\"\"Should use custom tasks directory when provided.\"\"\"",
        "        mock_session = MagicMock()",
        "        mock_session_class.return_value = mock_session",
        "",
        "        mock_task = MagicMock()",
        "        mock_task.id = \"T-test-001\"",
        "        mock_task.title = \"Test Task\"",
        "        mock_task.priority = \"medium\"",
        "        mock_task.description = \"\"",
        "        mock_task.depends_on = []",
        "        mock_session.create_task.return_value = mock_task",
        "        mock_session.save.return_value = Path(\"custom_dir/test.json\")",
        "",
        "        workflow = Workflow(",
        "            name=\"Test\",",
        "            description=\"Test workflow\",",
        "            category=\"test\",",
        "            variables=[],",
        "            tasks=[",
        "                WorkflowTask(id=\"task1\", title=\"Test Task\")",
        "            ]",
        "        )",
        "        variables = {}",
        "",
        "        tasks = run_workflow(workflow, variables, tasks_dir=\"custom_dir\", dry_run=False)",
        "",
        "        mock_session.save.assert_called_once_with(\"custom_dir\")",
        "",
        "    @patch('workflow.TaskSession')",
        "    def test_missing_dependency_ignored(self, mock_session_class):",
        "        \"\"\"Should ignore dependencies that haven't been created yet.\"\"\"",
        "        mock_session = MagicMock()",
        "        mock_session_class.return_value = mock_session",
        "",
        "        mock_task = MagicMock()",
        "        mock_task.id = \"T-test-001\"",
        "        mock_task.title = \"Task\"",
        "        mock_task.priority = \"medium\"",
        "        mock_task.description = \"\"",
        "        mock_task.depends_on = []",
        "        mock_session.create_task.return_value = mock_task",
        "",
        "        workflow = Workflow(",
        "            name=\"Test\",",
        "            description=\"Test workflow\",",
        "            category=\"test\",",
        "            variables=[],",
        "            tasks=[",
        "                WorkflowTask(",
        "                    id=\"task1\",",
        "                    title=\"Task\",",
        "                    depends_on=[\"nonexistent_task\"]",
        "                )",
        "            ]",
        "        )",
        "        variables = {}",
        "",
        "        tasks = run_workflow(workflow, variables, dry_run=True)",
        "",
        "        # Should create task with empty depends_on (missing dependency ignored)",
        "        call_args = mock_session.create_task.call_args",
        "        self.assertEqual(call_args[1]['depends_on'], [])",
        "",
        "",
        "if __name__ == \"__main__\":",
        "    unittest.main()"
      ],
      "lines_removed": [],
      "context_before": [],
      "context_after": [],
      "change_type": "add"
    }
  ],
  "hour_of_day": 0,
  "day_of_week": "Sunday",
  "seconds_since_last_commit": -134676,
  "is_merge": true,
  "is_initial": false,
  "parent_count": 2,
  "session_id": null,
  "related_chats": [],
  "ci_result": null,
  "reverted": false,
  "amended": false
}