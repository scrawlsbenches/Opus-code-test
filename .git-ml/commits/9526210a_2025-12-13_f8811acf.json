{
  "hash": "9526210a544611f6352035ad017748a959d0037e",
  "message": "Implement tasks #196, #186, #197: facade methods, warnings, CI validation",
  "author": "Claude",
  "timestamp": "2025-12-13 14:07:52 +0000",
  "branch": "claude/multi-index-design-DvifZ",
  "files_changed": [
    ".github/workflows/ci.yml",
    "TASK_LIST.md",
    "cortical/embeddings.py",
    "cortical/processor.py",
    "docs/quickstart.md",
    "tests/unit/test_embeddings.py",
    "tests/unit/test_processor_core.py"
  ],
  "insertions": 504,
  "deletions": 83,
  "hunks": [
    {
      "file": "workflows/ci.yml b/.github/workflows/ci.yml",
      "function": "name: CI - Test Suite",
      "start_line": 10,
      "lines_added": [
        "#   validate-task-list (< 5s)   smoke-tests (< 30s)",
        "#          â”‚                          â”‚",
        "#          â”‚                          â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”",
        "#          â”‚                          â”‚                                  â”‚",
        "#          â–¼                          â–¼                                  â–¼",
        "#    (continues)      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”",
        "#                     â”‚ unit-tests â”€â”€â”€â”€â”€â”                   â”‚    â”‚ regression-tests â”‚",
        "#                     â”‚ integration-tests â”‚ (with coverage) â”‚    â”‚ behavioral-tests â”‚",
        "#                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚ performance-testsâ”‚",
        "#                                â”‚                                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜",
        "#                                â–¼                                    (no coverage)",
        "#                         coverage-report",
        "#                       (combines coverage",
        "#                        from unit + integration",
        "#                        WITHOUT re-running tests)",
        "  # ==========================================================================",
        "  # Stage 0: Task List Validation (< 5s)",
        "  # Quick check for stale/inconsistent task list - runs in parallel with smoke",
        "  # ==========================================================================",
        "  validate-task-list:",
        "    name: \"ðŸ“‹ Validate Task List\"",
        "    runs-on: ubuntu-latest",
        "    steps:",
        "    - uses: actions/checkout@v4",
        "",
        "    - name: Set up Python 3.11",
        "      uses: actions/setup-python@v5",
        "      with:",
        "        python-version: '3.11'",
        "",
        "    - name: Validate TASK_LIST.md",
        "      run: |",
        "        echo \"=== Validating Task List ===\"",
        "        python scripts/validate_task_list.py",
        "        echo \"âœ… Task list validation passed\"",
        ""
      ],
      "lines_removed": [
        "#   smoke-tests (< 30s)",
        "#        â”‚",
        "#        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”",
        "#        â”‚                                              â”‚",
        "#        â–¼                                              â–¼",
        "#   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”",
        "#   â”‚ unit-tests â”€â”€â”€â”€â”€â”                   â”‚    â”‚ regression-tests â”‚",
        "#   â”‚ integration-tests â”‚ (with coverage) â”‚    â”‚ behavioral-tests â”‚",
        "#   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚ performance-testsâ”‚",
        "#              â”‚                                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜",
        "#              â–¼                                    (no coverage)",
        "#       coverage-report",
        "#     (combines coverage",
        "#      from unit + integration",
        "#      WITHOUT re-running tests)"
      ],
      "context_before": [
        "#",
        "# âŒ WRONG (runs tests twice):",
        "#    coverage run -m pytest tests/",
        "#    coverage run --append -m unittest discover -s tests",
        "#",
        "# âœ… CORRECT (pytest handles both):",
        "#    coverage run -m pytest tests/",
        "#",
        "# PARALLEL ARCHITECTURE (optimized for speed):",
        "#"
      ],
      "context_after": [
        "#",
        "# Each stage runs specific test files to avoid duplication.",
        "# coverage-report ONLY combines coverage data - it does NOT run tests again.",
        "# =============================================================================",
        "",
        "on:",
        "  push:",
        "  pull_request:",
        "    branches: [ main ]",
        "  workflow_dispatch:  # Allow manual triggering",
        "",
        "concurrency:",
        "  group: ${{ github.workflow }}-${{ github.ref }}",
        "  cancel-in-progress: true",
        "",
        "jobs:",
        "  # ==========================================================================",
        "  # Stage 1: Smoke Tests (< 30s)",
        "  # Quick sanity check - if this fails, something is fundamentally broken",
        "  # ==========================================================================",
        "  smoke-tests:",
        "    name: \"ðŸ’¨ Smoke Tests\"",
        "    runs-on: ubuntu-latest",
        "    steps:",
        "    - uses: actions/checkout@v4",
        ""
      ],
      "change_type": "modify"
    },
    {
      "file": "TASK_LIST.md",
      "function": null,
      "start_line": 1,
      "lines_added": [
        "**Pending Tasks:** 24",
        "**Completed Tasks:** 214 (see archive)"
      ],
      "lines_removed": [
        "**Pending Tasks:** 27",
        "**Completed Tasks:** 211 (see archive)"
      ],
      "context_before": [
        "# Task List: Cortical Text Processor",
        "",
        "Active backlog for the Cortical Text Processor project. Completed tasks are archived in [TASK_ARCHIVE.md](TASK_ARCHIVE.md).",
        "",
        "**Last Updated:** 2025-12-13"
      ],
      "context_after": [
        "",
        "**Legacy Test Cleanup:** 16 duplicated legacy tests removed, 13 remaining need investigation",
        "- See Tasks #198-205 for legacy test investigation",
        "",
        "**Unit Test Initiative:** âœ… COMPLETE - 85% coverage from unit tests (1,729 tests)",
        "- 19 modules at 90%+ coverage",
        "- See [Coverage Baseline](#unit-test-coverage-baseline) for per-module status",
        "",
        "---",
        ""
      ],
      "change_type": "modify"
    },
    {
      "file": "TASK_LIST.md",
      "function": "Active backlog for the Cortical Text Processor project. Completed tasks are arch",
      "start_line": 23,
      "lines_added": [],
      "lines_removed": [
        "| 186 | Add simplified facade methods (quick_search, rag_retrieve) | API | - | Small |"
      ],
      "context_before": [
        "",
        "| # | Task | Category | Depends | Effort |",
        "|---|------|----------|---------|--------|",
        "| 184 | Implement MCP Server for Claude Desktop integration | Integration | - | Large |",
        "| 192 | Deduplicate lateral_connections and typed_connections storage | Memory | - | Medium |",
        "",
        "### ðŸŸ¡ Medium (Do This Month)",
        "",
        "| # | Task | Category | Depends | Effort |",
        "|---|------|----------|---------|--------|"
      ],
      "context_after": [
        "| 133 | Implement WAL + snapshot persistence (fault-tolerant rebuild) | Arch | 132 | Large |",
        "| 134 | Implement protobuf serialization for corpus | Arch | 132 | Medium |",
        "| 135 | Implement chunked parallel processing for full-analysis | Arch | 132 | Large |",
        "| 95 | Split processor.py into modules | Arch | - | Large |",
        "| 99 | Add input validation to public methods | CodeQual | - | Medium |",
        "| 107 | Add Quick Context to tasks | TaskMgmt | - | Medium |",
        "| 198 | Investigate legacy test_coverage_gaps.py (91 tests) | Testing | - | Medium |",
        "| 199 | Investigate legacy test_cli_wrapper.py (96 tests) | Testing | - | Medium |",
        "| 200 | Investigate legacy test_edge_cases.py (53 tests) | Testing | - | Small |",
        "| 201 | Investigate legacy test_incremental_indexing.py (47 tests) | Testing | - | Small |"
      ],
      "change_type": "delete"
    },
    {
      "file": "TASK_LIST.md",
      "function": "Active backlog for the Cortical Text Processor project. Completed tasks are arch",
      "start_line": 60,
      "lines_added": [],
      "lines_removed": [
        "| 196 | Add runtime warning for spectral embeddings on large graphs | DevEx | - | Small |",
        "| 197 | Add task list validation to CI | TaskMgmt | - | Small |"
      ],
      "context_before": [
        "| 100 | Implement plugin/extension registry | Arch | - | Large |",
        "| 101 | Automate staleness tracking | Arch | - | Medium |",
        "| 106 | Add task dependency graph | TaskMgmt | - | Small |",
        "| 108 | Create task selection script | TaskMgmt | - | Medium |",
        "| 117 | Create debugging cookbook | AINav | - | Medium |",
        "| 118 | Add function complexity annotations | AINav | - | Small |",
        "| 140 | Analyze customer service cluster quality | Research | 127 | Small |",
        "| 129 | Test customer service retrieval quality | Testing | - | Small |",
        "| 130 | Expand customer service sample cluster | Samples | - | Medium |",
        "| 131 | Investigate cross-domain semantic bridges | Research | - | Medium |"
      ],
      "context_after": [
        "",
        "### â¸ï¸ Deferred",
        "",
        "| # | Task | Reason |",
        "|---|------|--------|",
        "| 110 | Add section markers to large files | Superseded by #119 (AI metadata generator) |",
        "| 111 | Add \"See Also\" cross-references | Superseded by #119 (AI metadata generator) |",
        "| 112 | Add docstring examples | Superseded by #119 (AI metadata generator) |",
        "| 7 | Document magic numbers in gaps.py | Low priority, functional as-is |",
        "| 42 | Add simple query language | Nice-to-have, not blocking |"
      ],
      "change_type": "delete"
    },
    {
      "file": "TASK_LIST.md",
      "function": "Active backlog for the Cortical Text Processor project. Completed tasks are arch",
      "start_line": 98,
      "lines_added": [
        "- #197 Task list validation in CI - Added validate-task-list job to workflow",
        "- #186 Simplified facade methods - quick_search(), rag_retrieve(), explore() (23 tests)",
        "- #196 Spectral embeddings warning - RuntimeWarning for large graphs (>5000 terms)"
      ],
      "lines_removed": [],
      "context_before": [
        "",
        "<!-- Note: Task #87 was completed 2025-12-13, moved to archive -->",
        "",
        "---",
        "",
        "## Recently Completed",
        "",
        "All completed tasks are now archived in [TASK_ARCHIVE.md](TASK_ARCHIVE.md).",
        "",
        "**Latest completions (2025-12-13):**"
      ],
      "context_after": [
        "- #193 Unify alpha validation - retrofit_embeddings() now accepts [0,1] consistently",
        "- #194 Layer validation - Added checks for invalid layer values (0-3) in persistence/layers",
        "- #195 Stopwords import - semantics.py now uses Tokenizer.DEFAULT_STOP_WORDS",
        "- #148 Performance test refactor - Moved to small synthetic corpus (25 docs)",
        "- #149 Performance test fix - Tests now use small_corpus.py fixtures",
        "- #182 Fluent API - FluentProcessor with method chaining (44 tests)",
        "- #183 Progress Feedback - ConsoleProgressReporter, callbacks (30 tests)",
        "- #185 Result Dataclasses - DocumentMatch, PassageMatch, QueryResult (56 tests)",
        "- #179 Fix definition search - line boundary fix in `find_definition_in_text()`",
        "- #180 Fix doc-type boosting - filename pattern + empty metadata fallback"
      ],
      "change_type": "add"
    },
    {
      "file": "TASK_LIST.md",
      "function": "All completed tasks are now archived in [TASK_ARCHIVE.md](TASK_ARCHIVE.md).",
      "start_line": 139,
      "lines_added": [],
      "lines_removed": [
        "### 186. Add Simplified Facade Methods",
        "",
        "**Meta:** `status:pending` `priority:medium` `category:api`",
        "**Files:** `cortical/processor.py`",
        "**Effort:** Small",
        "",
        "**Problem:** 80+ public methods; users don't know which to call for common tasks.",
        "",
        "**Solution:** Add purpose-focused facades:",
        "```python",
        "processor.quick_search(query)          # One-call document search",
        "processor.rag_retrieve(query, top_n=3) # Pre-configured for RAG",
        "processor.explore(query)               # With expansion visibility",
        "```",
        "",
        "**Acceptance:**",
        "- [ ] 3-4 facade methods added",
        "- [ ] Sensible defaults for each use case",
        "- [ ] Examples in quickstart.md",
        "",
        "",
        "### 196. Add runtime warning for spectral embeddings on large graphs",
        "",
        "**Meta:** `status:pending` `priority:low` `category:devex`",
        "**Files:** `cortical/embeddings.py`",
        "",
        "**Problem:**",
        "Spectral embeddings are O(nÂ²) but there's no runtime warning when called with large graphs. Users may wait unexpectedly.",
        "",
        "**Fix:** Add warning for large graphs:",
        "```python",
        "if n > 5000:",
        "    import warnings",
        "    warnings.warn(f\"Spectral embeddings with {n} terms will be slow (O(nÂ²))\")",
        "```",
        "",
        "",
        "### 197. Add Task List Validation to CI",
        "",
        "**Meta:** `status:pending` `priority:low` `category:taskmgmt`",
        "**Files:** `.github/workflows/ci.yml`, `scripts/validate_task_list.py`",
        "**Effort:** Small",
        "",
        "**Problem:** Task list staleness can accumulate unnoticed between reviews. Manual validation catches issues but isn't enforced.",
        "",
        "**Solution:** Add validation step to CI:",
        "```yaml",
        "- name: Validate task list",
        "  run: python scripts/validate_task_list.py",
        "```",
        "",
        "**Acceptance:**",
        "- [ ] CI runs `validate_task_list.py` on every PR",
        "- [ ] Fails build if stale tasks detected",
        "- [ ] Clear error messages guide resolution",
        "",
        ""
      ],
      "context_before": [
        "- `add_document(doc_id, content)` â†’ index document",
        "",
        "**Acceptance:**",
        "- [ ] Works in Claude Desktop",
        "- [ ] 5+ core tools implemented",
        "- [ ] Documentation for installation",
        "- [ ] Example MCP config file",
        "",
        "---",
        ""
      ],
      "context_after": [
        "### 192. Deduplicate lateral_connections and typed_connections storage",
        "",
        "**Meta:** `status:pending` `priority:high` `category:memory`",
        "**Files:** `cortical/minicolumn.py`",
        "",
        "**Problem:**",
        "Every typed connection is duplicated in `lateral_connections` for backward compatibility (`minicolumn.py:209-212`). For large graphs, this doubles memory for edge weights.",
        "",
        "**Options:**",
        "1. Deprecate `lateral_connections` in favor of `typed_connections`",
        "2. Make `lateral_connections` a property that derives from `typed_connections`",
        "3. Keep both but document the trade-off",
        "",
        "**Context from code review (2025-12-13):**",
        "- Found in comprehensive code review of core classes",
        "- Memory concern for large corpora with millions of edges",
        "",
        "---",
        "",
        "## Legacy Test Investigation Tasks",
        "",
        "These tasks were created during the test coverage review (2025-12-13). 16 duplicated legacy tests were removed, and 13 remaining tests need investigation to determine if they should be migrated to categorized test directories or kept as-is. Check git history for any previous migration work.",
        "",
        "### 198. Investigate test_coverage_gaps.py (91 tests)",
        "",
        "**Meta:** `status:pending` `priority:medium` `category:testing`",
        "**Files:** `tests/test_coverage_gaps.py`",
        "**Effort:** Medium",
        ""
      ],
      "change_type": "delete"
    },
    {
      "file": "TASK_LIST.md",
      "function": "These tasks were created during the test coverage review (2025-12-13). 16 duplic",
      "start_line": 362,
      "lines_added": [
        "| TaskMgmt | 3 | Task management system (#106, 107, 108) |",
        "| DevEx | 7 | Developer experience, scripts (#73-80) |"
      ],
      "lines_removed": [
        "| TaskMgmt | 4 | Task management system (#106, 107, 108, 197) |",
        "| DevEx | 8 | Developer experience, scripts (#73-80, 196) |",
        "| API | 1 | Simplified facades (#186) |"
      ],
      "context_before": [
        "",
        "---",
        "",
        "## Category Index",
        "",
        "| Category | Pending | Description |",
        "|----------|---------|-------------|",
        "| Arch | 5 | Architecture refactoring (#133, 134, 135, 95, 100, 101) |",
        "| CodeQual | 1 | Code quality improvements (#99) |",
        "| Testing | 9 | Test coverage and legacy investigation (#129, 198-205) |"
      ],
      "context_after": [
        "| AINav | 2 | AI assistant navigation (#117, 118) |",
        "| Research | 2 | Research and analysis (#140, 131) |",
        "| Samples | 1 | Sample document improvements (#130) |",
        "| Integration | 1 | MCP Server (#184) |",
        "| Memory | 1 | Optimization (#192) |",
        "",
        "*Updated 2025-12-13 - Unit test initiative COMPLETE (85% coverage, 1,729 tests)*",
        "",
        "---",
        "",
        "## Notes",
        "",
        "- **Effort estimates:** Small (<1 hour), Medium (1-4 hours), Large (1+ days)",
        "- **Dependencies:** Complete dependent tasks first",
        "- **Quick Context:** Key info to start task without searching"
      ],
      "change_type": "modify"
    },
    {
      "file": "cortical/embeddings.py",
      "function": "def _spectral_embeddings(",
      "start_line": 346,
      "lines_added": [
        "    import warnings",
        "",
        "    # Warn about slow computation on large graphs",
        "    if n > 5000:",
        "        warnings.warn(",
        "            f\"Spectral embeddings with {n} terms will be slow (O(nÂ²) complexity). \"",
        "            f\"Consider using max_terms parameter or 'fast'/'tfidf' method instead.\",",
        "            RuntimeWarning,",
        "            stacklevel=3  # Points to compute_graph_embeddings() caller",
        "        )",
        ""
      ],
      "lines_removed": [],
      "context_before": [
        "    dimensions: int,",
        "    sampled_terms: Optional[set] = None,",
        "    iterations: int = 50",
        ") -> Dict[str, List[float]]:",
        "    \"\"\"Compute embeddings using spectral methods (graph Laplacian).",
        "",
        "    Note: This is inherently O(dimensions Ã— iterations Ã— nÂ²) so it's slow for large graphs.",
        "    When sampled_terms is provided, only those terms get embeddings but the full graph",
        "    structure is still used for computation.",
        "    \"\"\""
      ],
      "context_after": [
        "    embeddings: Dict[str, List[float]] = {}",
        "",
        "    # If sampling, use only sampled terms for the graph",
        "    if sampled_terms is not None:",
        "        terms = [t for t in layer.minicolumns.keys() if t in sampled_terms]",
        "    else:",
        "        terms = list(layer.minicolumns.keys())",
        "",
        "    n = len(terms)",
        "    if n == 0:",
        "        return embeddings",
        "",
        "    term_to_idx = {t: i for i, t in enumerate(terms)}",
        "    adjacency: Dict[int, Dict[int, float]] = defaultdict(dict)",
        "    degrees = [0.0] * n",
        "",
        "    for term in terms:",
        "        col = layer.minicolumns[term]",
        "        i = term_to_idx[term]",
        "        for neighbor_id, weight in col.lateral_connections.items():",
        "            neighbor = layer.get_by_id(neighbor_id)",
        "            if neighbor and neighbor.content in term_to_idx:"
      ],
      "change_type": "add"
    },
    {
      "file": "cortical/processor.py",
      "function": "class CorticalTextProcessor:",
      "start_line": 1946,
      "lines_added": [
        "    # =========================================================================",
        "    # SIMPLIFIED FACADE METHODS",
        "    # =========================================================================",
        "    # These methods provide simple, one-call interfaces for common use cases.",
        "    # They use sensible defaults and simplified return types.",
        "",
        "    def quick_search(self, query: str, top_n: int = 5) -> List[str]:",
        "        \"\"\"",
        "        One-call document search with sensible defaults.",
        "",
        "        This is the simplest way to search. Returns just document IDs,",
        "        ranked by relevance.",
        "",
        "        Args:",
        "            query: Search query string",
        "            top_n: Number of results to return (default 5)",
        "",
        "        Returns:",
        "            List of document IDs ranked by relevance",
        "",
        "        Example:",
        "            >>> docs = processor.quick_search(\"pagerank algorithm\")",
        "            >>> for doc_id in docs:",
        "            ...     print(doc_id)",
        "        \"\"\"",
        "        results = self.find_documents_for_query(query, top_n=top_n)",
        "        return [doc_id for doc_id, _score in results]",
        "",
        "    def rag_retrieve(",
        "        self,",
        "        query: str,",
        "        top_n: int = 3,",
        "        max_chars_per_passage: int = 500",
        "    ) -> List[Dict[str, Any]]:",
        "        \"\"\"",
        "        Retrieve passages optimized for RAG (Retrieval-Augmented Generation).",
        "",
        "        Returns structured passage data ready for LLM context injection.",
        "        Each passage includes the text, source document, and position info.",
        "",
        "        Args:",
        "            query: Search query string",
        "            top_n: Number of passages to return (default 3)",
        "            max_chars_per_passage: Maximum characters per passage (default 500)",
        "",
        "        Returns:",
        "            List of passage dictionaries with keys:",
        "                - text: The passage text",
        "                - doc_id: Source document ID",
        "                - start: Start character position in document",
        "                - end: End character position in document",
        "                - score: Relevance score",
        "",
        "        Example:",
        "            >>> passages = processor.rag_retrieve(\"how does pagerank work\")",
        "            >>> for p in passages:",
        "            ...     print(f\"[{p['doc_id']}] {p['text'][:100]}...\")",
        "        \"\"\"",
        "        results = self.find_passages_for_query(",
        "            query,",
        "            top_n=top_n,",
        "            chunk_size=max_chars_per_passage",
        "        )",
        "        return [",
        "            {",
        "                'text': text,",
        "                'doc_id': doc_id,",
        "                'start': start,",
        "                'end': end,",
        "                'score': score",
        "            }",
        "            for text, doc_id, start, end, score in results",
        "        ]",
        "",
        "    def explore(self, query: str, top_n: int = 5) -> Dict[str, Any]:",
        "        \"\"\"",
        "        Search with query expansion visibility.",
        "",
        "        Like quick_search, but also shows how the query was expanded.",
        "        Useful for understanding why certain results were returned",
        "        and for debugging search quality.",
        "",
        "        Args:",
        "            query: Search query string",
        "            top_n: Number of results to return (default 5)",
        "",
        "        Returns:",
        "            Dictionary with:",
        "                - results: List of (doc_id, score) tuples",
        "                - expansion: Dict mapping expanded terms to weights",
        "                - original_terms: List of original query terms",
        "",
        "        Example:",
        "            >>> result = processor.explore(\"neural network\")",
        "            >>> print(\"Expanded to:\", list(result['expansion'].keys())[:5])",
        "            >>> print(\"Top result:\", result['results'][0][0])",
        "        \"\"\"",
        "        expansion = self.expand_query(query)",
        "        results = self.find_documents_for_query(query, top_n=top_n)",
        "        original_terms = list(self.tokenizer.tokenize(query))",
        "",
        "        return {",
        "            'results': results,",
        "            'expansion': expansion,",
        "            'original_terms': original_terms",
        "        }",
        ""
      ],
      "lines_removed": [],
      "context_before": [
        "        \"\"\"",
        "        return query_module.fast_find_documents(",
        "            query_text,",
        "            self.layers,",
        "            self.tokenizer,",
        "            top_n=top_n,",
        "            candidate_multiplier=candidate_multiplier,",
        "            use_code_concepts=use_code_concepts",
        "        )",
        ""
      ],
      "context_after": [
        "    def find_documents_with_boost(",
        "        self,",
        "        query_text: str,",
        "        top_n: int = 5,",
        "        auto_detect_intent: bool = True,",
        "        prefer_docs: bool = False,",
        "        custom_boosts: Optional[Dict[str, float]] = None,",
        "        use_expansion: bool = True,",
        "        use_semantic: bool = True",
        "    ) -> List[Tuple[str, float]]:"
      ],
      "change_type": "add"
    },
    {
      "file": "docs/quickstart.md",
      "function": "for doc_id, score in results:",
      "start_line": 38,
      "lines_added": [
        "## Simplified Facade Methods",
        "",
        "For common use cases, these simplified methods provide sensible defaults:",
        "",
        "### Quick Search (Just Doc IDs)",
        "",
        "```python",
        "# One-call search - returns just document IDs",
        "docs = processor.quick_search(\"neural learning\")",
        "print(docs)  # ['ai_intro', 'ml_basics']",
        "```",
        "",
        "### RAG Retrieve (For LLMs)",
        "",
        "```python",
        "# Get passages ready for LLM context injection",
        "passages = processor.rag_retrieve(\"how do neural networks work\", top_n=3)",
        "for p in passages:",
        "    print(f\"[{p['doc_id']}] {p['text'][:60]}... (score: {p['score']:.2f})\")",
        "```",
        "",
        "Each passage dict contains: `text`, `doc_id`, `start`, `end`, `score`.",
        "",
        "### Explore (With Query Expansion)",
        "",
        "```python",
        "# See how your query was expanded",
        "result = processor.explore(\"machine learning\")",
        "print(f\"Original: {result['original_terms']}\")",
        "print(f\"Expanded to: {list(result['expansion'].keys())[:5]}\")",
        "print(f\"Top result: {result['results'][0][0]}\")",
        "```",
        ""
      ],
      "lines_removed": [],
      "context_before": [
        "```",
        "",
        "**Output:**",
        "```",
        "ai_intro: 3.47",
        "ml_basics: 2.15",
        "```",
        "",
        "The processor found relevant documents and ranked them by semantic similarity.",
        ""
      ],
      "context_after": [
        "## Understanding the Results",
        "",
        "The Cortical Text Processor builds a graph of your documents:",
        "",
        "1. **Tokens** (Layer 0): Individual words like \"neural\", \"learning\", \"data\"",
        "2. **Bigrams** (Layer 1): Word pairs like \"neural networks\", \"machine learning\"",
        "3. **Concepts** (Layer 2): Clusters of related terms",
        "4. **Documents** (Layer 3): Your full documents",
        "",
        "When you search, the processor:"
      ],
      "change_type": "add"
    },
    {
      "file": "tests/unit/test_embeddings.py",
      "function": "class TestSpectralEmbeddings:",
      "start_line": 952,
      "lines_added": [
        "    def test_large_graph_warning(self):",
        "        \"\"\"Emits RuntimeWarning for graphs with >5000 terms.\"\"\"",
        "        import warnings",
        "        # Create layer with >5000 terms",
        "        cols = [",
        "            MockMinicolumn(content=f\"term{i}\")",
        "            for i in range(5001)",
        "        ]",
        "        layer = MockHierarchicalLayer(cols, level=0)",
        "",
        "        random.seed(42)",
        "        with warnings.catch_warnings(record=True) as w:",
        "            warnings.simplefilter(\"always\")",
        "            # Use iterations=1 and dimensions=1 for speed",
        "            _spectral_embeddings(layer, dimensions=1, iterations=1)",
        "",
        "            # Should have emitted a RuntimeWarning",
        "            assert len(w) >= 1",
        "            warning_messages = [str(warning.message) for warning in w]",
        "            assert any(\"5001 terms will be slow\" in msg for msg in warning_messages)",
        "            assert any(\"O(nÂ²)\" in msg for msg in warning_messages)",
        "",
        "    def test_small_graph_no_warning(self):",
        "        \"\"\"No warning for graphs with <=5000 terms.\"\"\"",
        "        import warnings",
        "        cols = [MockMinicolumn(content=f\"term{i}\") for i in range(100)]",
        "        layer = MockHierarchicalLayer(cols, level=0)",
        "",
        "        random.seed(42)",
        "        with warnings.catch_warnings(record=True) as w:",
        "            warnings.simplefilter(\"always\")",
        "            _spectral_embeddings(layer, dimensions=2, iterations=1)",
        "",
        "            # Should NOT have emitted a RuntimeWarning about large graphs",
        "            warning_messages = [str(warning.message) for warning in w]",
        "            assert not any(\"will be slow\" in msg for msg in warning_messages)",
        ""
      ],
      "lines_removed": [],
      "context_before": [
        "        ]",
        "        layer = MockHierarchicalLayer(cols, level=0)",
        "",
        "        random.seed(42)",
        "        embeddings = _spectral_embeddings(layer, dimensions=4)",
        "",
        "        # All nodes should get embeddings",
        "        for term in [\"a\", \"b\", \"c\", \"d\"]:",
        "            assert term in embeddings",
        ""
      ],
      "context_after": [
        "",
        "# =============================================================================",
        "# EMBEDDING SIMILARITY",
        "# =============================================================================",
        "",
        "",
        "class TestEmbeddingSimilarity:",
        "    \"\"\"Tests for embedding_similarity cosine similarity calculation.\"\"\"",
        "",
        "    def test_identical_vectors(self):"
      ],
      "change_type": "add"
    },
    {
      "file": "tests/unit/test_processor_core.py",
      "function": "class TestAdditionalCoverage(unittest.TestCase):",
      "start_line": 3237,
      "lines_added": [
        "# =============================================================================",
        "# SIMPLIFIED FACADE METHOD TESTS (Task #186)",
        "# =============================================================================",
        "",
        "",
        "class TestQuickSearch(unittest.TestCase):",
        "    \"\"\"Tests for quick_search() facade method.\"\"\"",
        "",
        "    def test_quick_search_returns_list_of_doc_ids(self):",
        "        \"\"\"quick_search returns list of document IDs.\"\"\"",
        "        processor = CorticalTextProcessor()",
        "        processor.process_document(\"doc1\", \"python programming language\")",
        "        processor.process_document(\"doc2\", \"java programming syntax\")",
        "        processor.compute_all()",
        "",
        "        results = processor.quick_search(\"programming\")",
        "",
        "        self.assertIsInstance(results, list)",
        "        for item in results:",
        "            self.assertIsInstance(item, str)",
        "            self.assertIn(item, [\"doc1\", \"doc2\"])",
        "",
        "    def test_quick_search_default_top_n(self):",
        "        \"\"\"quick_search returns up to 5 results by default.\"\"\"",
        "        processor = CorticalTextProcessor()",
        "        for i in range(10):",
        "            processor.process_document(f\"doc{i}\", f\"test content document {i}\")",
        "        processor.compute_all()",
        "",
        "        results = processor.quick_search(\"test\")",
        "",
        "        self.assertLessEqual(len(results), 5)",
        "",
        "    def test_quick_search_custom_top_n(self):",
        "        \"\"\"quick_search respects custom top_n parameter.\"\"\"",
        "        processor = CorticalTextProcessor()",
        "        for i in range(10):",
        "            processor.process_document(f\"doc{i}\", f\"common content {i}\")",
        "        processor.compute_all()",
        "",
        "        results = processor.quick_search(\"common\", top_n=3)",
        "",
        "        self.assertLessEqual(len(results), 3)",
        "",
        "    def test_quick_search_empty_corpus(self):",
        "        \"\"\"quick_search on empty corpus returns empty list.\"\"\"",
        "        processor = CorticalTextProcessor()",
        "",
        "        results = processor.quick_search(\"anything\")",
        "",
        "        self.assertEqual(results, [])",
        "",
        "    def test_quick_search_no_match(self):",
        "        \"\"\"quick_search with no matching terms returns empty list.\"\"\"",
        "        processor = CorticalTextProcessor()",
        "        processor.process_document(\"doc1\", \"python programming\")",
        "        processor.compute_all()",
        "",
        "        results = processor.quick_search(\"xyznonexistent123\")",
        "",
        "        self.assertEqual(results, [])",
        "",
        "",
        "class TestRagRetrieve(unittest.TestCase):",
        "    \"\"\"Tests for rag_retrieve() facade method.\"\"\"",
        "",
        "    def test_rag_retrieve_returns_list_of_dicts(self):",
        "        \"\"\"rag_retrieve returns list of passage dictionaries.\"\"\"",
        "        processor = CorticalTextProcessor()",
        "        processor.process_document(\"doc1\", \"Python is a programming language.\")",
        "        processor.compute_all()",
        "",
        "        results = processor.rag_retrieve(\"python\")",
        "",
        "        self.assertIsInstance(results, list)",
        "        for item in results:",
        "            self.assertIsInstance(item, dict)",
        "",
        "    def test_rag_retrieve_dict_structure(self):",
        "        \"\"\"rag_retrieve returns dicts with correct keys.\"\"\"",
        "        processor = CorticalTextProcessor()",
        "        processor.process_document(\"doc1\", \"Python is a programming language used for many tasks.\")",
        "        processor.compute_all()",
        "",
        "        results = processor.rag_retrieve(\"python\")",
        "",
        "        if results:  # May be empty if no match",
        "            item = results[0]",
        "            self.assertIn('text', item)",
        "            self.assertIn('doc_id', item)",
        "            self.assertIn('start', item)",
        "            self.assertIn('end', item)",
        "            self.assertIn('score', item)",
        "",
        "    def test_rag_retrieve_text_type(self):",
        "        \"\"\"rag_retrieve returns string text.\"\"\"",
        "        processor = CorticalTextProcessor()",
        "        processor.process_document(\"doc1\", \"Python is a programming language.\")",
        "        processor.compute_all()",
        "",
        "        results = processor.rag_retrieve(\"python\")",
        "",
        "        if results:",
        "            self.assertIsInstance(results[0]['text'], str)",
        "",
        "    def test_rag_retrieve_position_types(self):",
        "        \"\"\"rag_retrieve returns integer positions.\"\"\"",
        "        processor = CorticalTextProcessor()",
        "        processor.process_document(\"doc1\", \"Python is a programming language.\")",
        "        processor.compute_all()",
        "",
        "        results = processor.rag_retrieve(\"python\")",
        "",
        "        if results:",
        "            self.assertIsInstance(results[0]['start'], int)",
        "            self.assertIsInstance(results[0]['end'], int)",
        "",
        "    def test_rag_retrieve_default_top_n(self):",
        "        \"\"\"rag_retrieve returns up to 3 results by default.\"\"\"",
        "        processor = CorticalTextProcessor()",
        "        processor.process_document(\"doc1\", \"Test content. \" * 50)",
        "        processor.compute_all()",
        "",
        "        results = processor.rag_retrieve(\"test\")",
        "",
        "        self.assertLessEqual(len(results), 3)",
        "",
        "    def test_rag_retrieve_custom_top_n(self):",
        "        \"\"\"rag_retrieve respects custom top_n parameter.\"\"\"",
        "        processor = CorticalTextProcessor()",
        "        processor.process_document(\"doc1\", \"Test content. \" * 50)",
        "        processor.compute_all()",
        "",
        "        results = processor.rag_retrieve(\"test\", top_n=1)",
        "",
        "        self.assertLessEqual(len(results), 1)",
        "",
        "    def test_rag_retrieve_empty_corpus(self):",
        "        \"\"\"rag_retrieve on empty corpus returns empty list.\"\"\"",
        "        processor = CorticalTextProcessor()",
        "",
        "        results = processor.rag_retrieve(\"anything\")",
        "",
        "        self.assertEqual(results, [])",
        "",
        "    def test_rag_retrieve_max_chars_parameter(self):",
        "        \"\"\"rag_retrieve respects max_chars_per_passage parameter.\"\"\"",
        "        processor = CorticalTextProcessor()",
        "        processor.process_document(\"doc1\", \"Test content. \" * 100)",
        "        processor.compute_all()",
        "",
        "        results = processor.rag_retrieve(\"test\", max_chars_per_passage=200)",
        "",
        "        if results:",
        "            # Passage might be slightly longer due to chunk boundaries",
        "            self.assertLess(len(results[0]['text']), 300)",
        "",
        "",
        "class TestExplore(unittest.TestCase):",
        "    \"\"\"Tests for explore() facade method.\"\"\"",
        "",
        "    def test_explore_returns_dict(self):",
        "        \"\"\"explore returns a dictionary.\"\"\"",
        "        processor = CorticalTextProcessor()",
        "        processor.process_document(\"doc1\", \"python programming language\")",
        "        processor.compute_all()",
        "",
        "        result = processor.explore(\"python\")",
        "",
        "        self.assertIsInstance(result, dict)",
        "",
        "    def test_explore_has_results_key(self):",
        "        \"\"\"explore result contains 'results' key.\"\"\"",
        "        processor = CorticalTextProcessor()",
        "        processor.process_document(\"doc1\", \"python programming\")",
        "        processor.compute_all()",
        "",
        "        result = processor.explore(\"python\")",
        "",
        "        self.assertIn('results', result)",
        "        self.assertIsInstance(result['results'], list)",
        "",
        "    def test_explore_has_expansion_key(self):",
        "        \"\"\"explore result contains 'expansion' key.\"\"\"",
        "        processor = CorticalTextProcessor()",
        "        processor.process_document(\"doc1\", \"python programming\")",
        "        processor.compute_all()",
        "",
        "        result = processor.explore(\"python\")",
        "",
        "        self.assertIn('expansion', result)",
        "        self.assertIsInstance(result['expansion'], dict)",
        "",
        "    def test_explore_has_original_terms_key(self):",
        "        \"\"\"explore result contains 'original_terms' key.\"\"\"",
        "        processor = CorticalTextProcessor()",
        "        processor.process_document(\"doc1\", \"python programming\")",
        "        processor.compute_all()",
        "",
        "        result = processor.explore(\"python\")",
        "",
        "        self.assertIn('original_terms', result)",
        "        self.assertIsInstance(result['original_terms'], list)",
        "",
        "    def test_explore_results_format(self):",
        "        \"\"\"explore results are (doc_id, score) tuples.\"\"\"",
        "        processor = CorticalTextProcessor()",
        "        processor.process_document(\"doc1\", \"python programming\")",
        "        processor.compute_all()",
        "",
        "        result = processor.explore(\"python\")",
        "",
        "        if result['results']:",
        "            doc_id, score = result['results'][0]",
        "            self.assertIsInstance(doc_id, str)",
        "            self.assertIsInstance(score, (int, float))",
        "",
        "    def test_explore_expansion_contains_query_terms(self):",
        "        \"\"\"explore expansion includes original query terms.\"\"\"",
        "        processor = CorticalTextProcessor()",
        "        processor.process_document(\"doc1\", \"python programming language\")",
        "        processor.compute_all()",
        "",
        "        result = processor.explore(\"python programming\")",
        "",
        "        # Original terms should be in expansion with weight 1.0",
        "        self.assertIn('python', result['expansion'])",
        "",
        "    def test_explore_original_terms_from_query(self):",
        "        \"\"\"explore original_terms contains tokenized query.\"\"\"",
        "        processor = CorticalTextProcessor()",
        "        processor.process_document(\"doc1\", \"python programming\")",
        "        processor.compute_all()",
        "",
        "        result = processor.explore(\"python programming\")",
        "",
        "        self.assertIn('python', result['original_terms'])",
        "        self.assertIn('programming', result['original_terms'])",
        "",
        "    def test_explore_default_top_n(self):",
        "        \"\"\"explore returns up to 5 results by default.\"\"\"",
        "        processor = CorticalTextProcessor()",
        "        for i in range(10):",
        "            processor.process_document(f\"doc{i}\", f\"common term {i}\")",
        "        processor.compute_all()",
        "",
        "        result = processor.explore(\"common\")",
        "",
        "        self.assertLessEqual(len(result['results']), 5)",
        "",
        "    def test_explore_custom_top_n(self):",
        "        \"\"\"explore respects custom top_n parameter.\"\"\"",
        "        processor = CorticalTextProcessor()",
        "        for i in range(10):",
        "            processor.process_document(f\"doc{i}\", f\"common term {i}\")",
        "        processor.compute_all()",
        "",
        "        result = processor.explore(\"common\", top_n=2)",
        "",
        "        self.assertLessEqual(len(result['results']), 2)",
        "",
        "    def test_explore_empty_corpus(self):",
        "        \"\"\"explore on empty corpus returns valid structure.\"\"\"",
        "        processor = CorticalTextProcessor()",
        "",
        "        result = processor.explore(\"anything\")",
        "",
        "        self.assertIn('results', result)",
        "        self.assertIn('expansion', result)",
        "        self.assertIn('original_terms', result)",
        "        self.assertEqual(result['results'], [])",
        "",
        ""
      ],
      "lines_removed": [],
      "context_before": [
        "        processor = CorticalTextProcessor()",
        "        processor.process_document(\"doc1\", \"test code function\")",
        "",
        "        result1 = processor.expand_query_cached(\"test\", use_code_concepts=True)",
        "        result2 = processor.expand_query_cached(\"test\", use_code_concepts=False)",
        "",
        "        self.assertIsInstance(result1, dict)",
        "        self.assertIsInstance(result2, dict)",
        "",
        ""
      ],
      "context_after": [
        "if __name__ == '__main__':",
        "    unittest.main()"
      ],
      "change_type": "add"
    }
  ],
  "hour_of_day": 14,
  "day_of_week": "Saturday",
  "seconds_since_last_commit": -171416,
  "is_merge": false,
  "is_initial": false,
  "parent_count": 1,
  "session_id": null,
  "related_chats": [],
  "ci_result": null,
  "reverted": false,
  "amended": false
}