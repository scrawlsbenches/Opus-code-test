{
  "hash": "20f95ec3cf490e8df49959fe40e6f8f921f3b2e7",
  "message": "Complete tasks #116, #137, #139: Documentation and performance improvements",
  "author": "Claude",
  "timestamp": "2025-12-12 03:10:48 +0000",
  "branch": "claude/multi-index-design-DvifZ",
  "files_changed": [
    "CLAUDE.md",
    "TASK_LIST.md",
    "cortical/analysis.py",
    "cortical/minicolumn.py",
    "cortical/processor.py"
  ],
  "insertions": 104,
  "deletions": 9,
  "hunks": [
    {
      "file": "CLAUDE.md",
      "function": "processor.add_document_incremental(doc_id, text, recompute='none')",
      "start_line": 348,
      "lines_added": [
        "### Return Value Semantics",
        "",
        "Understanding what functions return in edge cases prevents bugs and confusion.",
        "",
        "#### Edge Case Returns",
        "",
        "| Scenario | Return Value | Example Functions |",
        "|----------|--------------|-------------------|",
        "| Empty corpus | `[]` (empty list) | `find_documents_for_query()`, `find_passages_for_query()` |",
        "| No matches | `[]` (empty list) | `find_documents_for_query()`, `expand_query()` returns `{}` |",
        "| Unknown doc_id | `{}` (empty dict) | `get_document_metadata()` |",
        "| Unknown term | `None` | `layer.get_minicolumn()`, `layer.get_by_id()` |",
        "| Invalid layer | `KeyError` raised | `get_layer()` |",
        "| Empty query | `ValueError` raised | `find_documents_for_query()` |",
        "| Invalid top_n | `ValueError` raised | `find_documents_for_query()` |",
        "",
        "#### Score Ranges",
        "",
        "| Score Type | Range | Notes |",
        "|------------|-------|-------|",
        "| Relevance score | Unbounded (0+) | Sum of TF-IDF Ã— expansion weights |",
        "| PageRank | 0.0-1.0 | Normalized probability distribution |",
        "| TF-IDF | Unbounded (0+) | Higher = more distinctive |",
        "| Connection weight | Unbounded (0+) | Co-occurrence count or semantic weight |",
        "| Similarity | 0.0-1.0 | Cosine similarity, Jaccard, etc. |",
        "| Confidence | 0.0-1.0 | Relation extraction confidence |",
        "",
        "#### Lookup Functions: None vs Exception",
        "",
        "**Return `None` for missing items:**",
        "```python",
        "col = layer.get_minicolumn(\"nonexistent\")  # Returns None",
        "col = layer.get_by_id(\"L0_nonexistent\")    # Returns None",
        "```",
        "",
        "**Raise exception for invalid structure:**",
        "```python",
        "layer = processor.get_layer(CorticalLayer.TOKENS)  # OK",
        "layer = processor.get_layer(999)  # Raises KeyError",
        "```",
        "",
        "#### Default Parameter Values",
        "",
        "Key defaults to know:",
        "",
        "| Parameter | Default | In Function |",
        "|-----------|---------|-------------|",
        "| `top_n` | `5` | `find_documents_for_query()` |",
        "| `top_n` | `5` | `find_passages_for_query()` |",
        "| `max_expansions` | `10` | `expand_query()` |",
        "| `damping` | `0.85` | `compute_pagerank()` |",
        "| `resolution` | `1.0` | `build_concept_clusters()` |",
        "| `chunk_size` | `200` | `find_passages_for_query()` |",
        "| `chunk_overlap` | `50` | `find_passages_for_query()` |",
        ""
      ],
      "lines_removed": [],
      "context_before": [
        "- **Before querying concepts** - check `COMP_CONCEPTS`",
        "",
        "#### Staleness After `load()`",
        "",
        "Loading a saved processor restores computation freshness state:",
        "```python",
        "processor = CorticalTextProcessor.load(\"corpus.pkl\")",
        "# Staleness state is preserved from when it was saved",
        "```",
        ""
      ],
      "context_after": [
        "---",
        "",
        "## Development Workflow",
        "",
        "### Before Writing Code",
        "",
        "1. **Read the relevant module** - understand existing patterns",
        "2. **Check TASK_LIST.md** - see if work is already planned/done",
        "3. **Run tests first** to establish baseline:",
        "   ```bash"
      ],
      "change_type": "add"
    },
    {
      "file": "TASK_LIST.md",
      "function": "Active backlog for the Cortical Text Processor project. Completed tasks are arch",
      "start_line": 17,
      "lines_added": [],
      "lines_removed": [
        "| 137 | Cap bigram connections to top-K per bigram | Perf | - | Small |",
        "| 139 | Batch bigram connection updates to reduce dict overhead | Perf | - | Small |",
        "| 116 | Document return value semantics | AINav | - | Medium |"
      ],
      "context_before": [
        "*All critical tasks completed!*",
        "",
        "### ðŸŸ  High (Do This Week)",
        "",
        "*All high priority tasks completed!*",
        "",
        "### ðŸŸ¡ Medium (Do This Month)",
        "",
        "| # | Task | Category | Depends | Effort |",
        "|---|------|----------|---------|--------|"
      ],
      "context_after": [
        "| 138 | Use sparse matrix multiplication for bigram connections | Perf | - | Medium |",
        "| 133 | Implement WAL + snapshot persistence (fault-tolerant rebuild) | Arch | 132 | Large |",
        "| 134 | Implement protobuf serialization for corpus | Arch | 132 | Medium |",
        "| 135 | Implement chunked parallel processing for full-analysis | Arch | 132 | Large |",
        "| 95 | Split processor.py into modules | Arch | 97 | Large |",
        "| 98 | Replace print() with logging | CodeQual | - | Medium |",
        "| 99 | Add input validation to public methods | CodeQual | - | Medium |",
        "| 102 | Add tests for edge cases | Testing | - | Medium |",
        "| 107 | Add Quick Context to tasks | TaskMgmt | - | Medium |",
        "| 115 | Create component interaction diagram | AINav | - | Medium |",
        "",
        "### ðŸŸ¢ Low (Backlog)",
        "",
        "| # | Task | Category | Depends | Effort |",
        "|---|------|----------|---------|--------|",
        "| 73 | Add \"Find Similar Code\" command | DevEx | - | Medium |",
        "| 74 | Add \"Explain This Code\" command | DevEx | - | Medium |",
        "| 75 | Add \"What Changed?\" semantic diff | DevEx | - | Large |",
        "| 76 | Add \"Suggest Related Files\" feature | DevEx | - | Medium |",
        "| 78 | Add code pattern detection | DevEx | - | Large |"
      ],
      "change_type": "delete"
    },
    {
      "file": "TASK_LIST.md",
      "function": "Active backlog for the Cortical Text Processor project. Completed tasks are arch",
      "start_line": 77,
      "lines_added": [
        "| 139 | Batch bigram connection updates to reduce dict overhead | 2025-12-12 | add_lateral_connections_batch() method in minicolumn.py |",
        "| 137 | Cap bigram connections to top-K per bigram | 2025-12-12 | max_connections_per_bigram parameter (default 50) in analysis.py |",
        "| 116 | Document return value semantics | 2025-12-12 | Edge cases, score ranges, None vs exceptions, default parameters |"
      ],
      "lines_removed": [],
      "context_before": [
        "| # | Task | Started | Notes |",
        "|---|------|---------|-------|",
        "| 87 | Add Python code samples and showcase | 2025-12-11 | samples/*.py created |",
        "",
        "---",
        "",
        "## Recently Completed (Last 7 Days)",
        "",
        "| # | Task | Completed | Notes |",
        "|---|------|-----------|-------|"
      ],
      "context_after": [
        "| 114 | Add type aliases for complex types | 2025-12-12 | cortical/types.py with 20+ aliases: DocumentScore, PassageResult, SemanticRelation, etc. |",
        "| 113 | Document staleness tracking system | 2025-12-12 | Comprehensive docs in CLAUDE.md: computation types, API, incremental updates |",
        "| 96 | Centralize duplicate constants | 2025-12-12 | cortical/constants.py with RELATION_WEIGHTS, DOC_TYPE_BOOSTS, query keywords |",
        "| 91 | Create docs/README.md index | 2025-12-12 | Navigation by audience, reading paths, categorized docs |",
        "| 92 | Add badges to README.md | 2025-12-12 | Python, License, Tests, Coverage, Zero Dependencies badges |",
        "| 93 | Update README with docs references | 2025-12-12 | Documentation section with table linking to docs/*.md |",
        "| 146 | Create behavioral tests for core user workflows | 2025-12-12 | 11 tests across 4 categories: Search, Performance, Quality, Robustness |",
        "| 145 | Improve graph embedding quality for common terms | 2025-12-12 | Added 'tfidf' method, IDF weighting to 'fast' method |",
        "| 143 | Investigate negative silhouette score in clustering | 2025-12-12 | Expected behavior: modularity â‰  silhouette (graph vs doc similarity) |",
        "| 142 | Investigate 74s compute_all() performance regression | 2025-12-12 | 5.2x speedup via fast embeddings + sampling (74s â†’ 14s) |"
      ],
      "change_type": "add"
    },
    {
      "file": "cortical/analysis.py",
      "function": "def compute_concept_connections(",
      "start_line": 1202,
      "lines_added": [
        "    max_bigrams_per_doc: int = 500,",
        "    max_connections_per_bigram: int = 50",
        "        max_connections_per_bigram: Maximum lateral connections per bigram minicolumn",
        "            to keep graph sparse and focused on strongest connections (default 50)",
        "        - skipped_max_connections: Number of connections skipped due to per-bigram limit",
        "            'skipped_large_docs': 0,",
        "            'skipped_max_connections': 0"
      ],
      "lines_removed": [
        "    max_bigrams_per_doc: int = 500",
        "            'skipped_large_docs': 0"
      ],
      "context_before": [
        "    }",
        "",
        "",
        "def compute_bigram_connections(",
        "    layers: Dict[CorticalLayer, HierarchicalLayer],",
        "    min_shared_docs: int = 1,",
        "    component_weight: float = 0.5,",
        "    chain_weight: float = 0.7,",
        "    cooccurrence_weight: float = 0.3,",
        "    max_bigrams_per_term: int = 100,"
      ],
      "context_after": [
        ") -> Dict[str, Any]:",
        "    \"\"\"",
        "    Build lateral connections between bigrams in Layer 1.",
        "",
        "    Bigrams are connected based on:",
        "    1. Shared component terms (\"neural_networks\" â†” \"neural_processing\")",
        "    2. Document co-occurrence (appear in same documents)",
        "    3. Chains (\"machine_learning\" â†” \"learning_algorithms\" where right=left)",
        "",
        "    Args:",
        "        layers: Dictionary of all layers",
        "        min_shared_docs: Minimum shared documents for co-occurrence connection",
        "        component_weight: Weight for shared component connections (default 0.5)",
        "        chain_weight: Weight for chain connections (default 0.7)",
        "        cooccurrence_weight: Weight for document co-occurrence (default 0.3)",
        "        max_bigrams_per_term: Skip terms appearing in more than this many bigrams",
        "            to avoid O(nÂ²) explosion from common terms like \"self\", \"return\" (default 100)",
        "        max_bigrams_per_doc: Skip documents with more than this many bigrams for",
        "            co-occurrence connections to avoid O(nÂ²) explosion (default 500)",
        "",
        "    Returns:",
        "        Statistics about connections created:",
        "        - connections_created: Total bidirectional connections",
        "        - component_connections: Connections from shared components",
        "        - chain_connections: Connections from chains",
        "        - cooccurrence_connections: Connections from document co-occurrence",
        "        - skipped_common_terms: Number of terms skipped due to max_bigrams_per_term",
        "        - skipped_large_docs: Number of docs skipped due to max_bigrams_per_doc",
        "    \"\"\"",
        "    layer1 = layers[CorticalLayer.BIGRAMS]",
        "",
        "    if layer1.column_count() == 0:",
        "        return {",
        "            'connections_created': 0,",
        "            'bigrams': 0,",
        "            'component_connections': 0,",
        "            'chain_connections': 0,",
        "            'cooccurrence_connections': 0,",
        "            'skipped_common_terms': 0,",
        "        }",
        "",
        "    bigrams = list(layer1.minicolumns.values())",
        "",
        "    # Build indexes for efficient lookup",
        "    # left_component_index: {\"neural\": [bigram1, bigram2, ...]}",
        "    # right_component_index: {\"networks\": [bigram1, bigram3, ...]}",
        "    # Note: Bigrams use space separators (e.g., \"neural networks\")",
        "    left_index: Dict[str, List[Minicolumn]] = defaultdict(list)",
        "    right_index: Dict[str, List[Minicolumn]] = defaultdict(list)"
      ],
      "change_type": "modify"
    },
    {
      "file": "cortical/analysis.py",
      "function": "def compute_bigram_connections(",
      "start_line": 1264,
      "lines_added": [
        "    skipped_max_connections = 0",
        "    # Track connection count per bigram to enforce max_connections_per_bigram",
        "    connection_counts: Dict[str, int] = defaultdict(int)",
        "",
        "        \"\"\"Add bidirectional connection if not already connected and under limit.\"\"\"",
        "        nonlocal component_connections, chain_connections, cooccurrence_connections, skipped_max_connections",
        "        # Check if either bigram has reached its connection limit",
        "        if (connection_counts[b1.id] >= max_connections_per_bigram or",
        "            connection_counts[b2.id] >= max_connections_per_bigram):",
        "            skipped_max_connections += 1",
        "            return False",
        "",
        "        connection_counts[b1.id] += 1",
        "        connection_counts[b2.id] += 1"
      ],
      "lines_removed": [
        "        \"\"\"Add bidirectional connection if not already connected.\"\"\"",
        "        nonlocal component_connections, chain_connections, cooccurrence_connections"
      ],
      "context_before": [
        "    for bigram in bigrams:",
        "        parts = bigram.content.split(' ')",
        "        if len(parts) == 2:",
        "            left_index[parts[0]].append(bigram)",
        "            right_index[parts[1]].append(bigram)",
        "",
        "    # Track connection types for statistics",
        "    component_connections = 0",
        "    chain_connections = 0",
        "    cooccurrence_connections = 0"
      ],
      "context_after": [
        "",
        "    # Track which pairs we've already connected (avoid duplicates)",
        "    connected_pairs: Set[Tuple[str, str]] = set()",
        "",
        "    def add_connection(b1: Minicolumn, b2: Minicolumn, weight: float, conn_type: str) -> bool:",
        "",
        "        pair = tuple(sorted([b1.id, b2.id]))",
        "        if pair in connected_pairs:",
        "            # Already connected, just strengthen the connection",
        "            b1.add_lateral_connection(b2.id, weight)",
        "            b2.add_lateral_connection(b1.id, weight)",
        "            return False",
        "",
        "        connected_pairs.add(pair)",
        "        b1.add_lateral_connection(b2.id, weight)",
        "        b2.add_lateral_connection(b1.id, weight)",
        "",
        "        if conn_type == 'component':",
        "            component_connections += 1",
        "        elif conn_type == 'chain':",
        "            chain_connections += 1",
        "        elif conn_type == 'cooccurrence':",
        "            cooccurrence_connections += 1",
        "",
        "        return True",
        ""
      ],
      "change_type": "modify"
    },
    {
      "file": "cortical/analysis.py",
      "function": "def compute_bigram_connections(",
      "start_line": 1374,
      "lines_added": [
        "        'skipped_large_docs': skipped_large_docs,",
        "        'skipped_max_connections': skipped_max_connections"
      ],
      "lines_removed": [
        "        'skipped_large_docs': skipped_large_docs"
      ],
      "context_before": [
        "                    weight = cooccurrence_weight * jaccard",
        "                    add_connection(b1, b2, weight, 'cooccurrence')",
        "",
        "    return {",
        "        'connections_created': len(connected_pairs),",
        "        'bigrams': len(bigrams),",
        "        'component_connections': component_connections,",
        "        'chain_connections': chain_connections,",
        "        'cooccurrence_connections': cooccurrence_connections,",
        "        'skipped_common_terms': skipped_common_terms,"
      ],
      "context_after": [
        "    }",
        "",
        "",
        "def compute_document_connections(",
        "    layers: Dict[CorticalLayer, HierarchicalLayer],",
        "    documents: Dict[str, str],",
        "    min_shared_terms: int = 3",
        ") -> None:",
        "    \"\"\"",
        "    Build lateral connections between documents."
      ],
      "change_type": "modify"
    },
    {
      "file": "cortical/minicolumn.py",
      "function": "class Minicolumn:",
      "start_line": 132,
      "lines_added": [
        "    def add_lateral_connections_batch(self, connections: Dict[str, float]) -> None:",
        "        \"\"\"",
        "        Add or strengthen multiple lateral connections at once.",
        "",
        "        More efficient than calling add_lateral_connection() in a loop",
        "        because it reduces function call overhead.",
        "",
        "        Args:",
        "            connections: Dictionary mapping target_id to weight to add",
        "        \"\"\"",
        "        lateral = self.lateral_connections",
        "        for target_id, weight in connections.items():",
        "            lateral[target_id] = lateral.get(target_id, 0) + weight",
        ""
      ],
      "lines_removed": [],
      "context_before": [
        "        wire together\").",
        "",
        "        Args:",
        "            target_id: ID of the target minicolumn",
        "            weight: Connection strength to add",
        "        \"\"\"",
        "        self.lateral_connections[target_id] = (",
        "            self.lateral_connections.get(target_id, 0) + weight",
        "        )",
        ""
      ],
      "context_after": [
        "    def add_typed_connection(",
        "        self,",
        "        target_id: str,",
        "        weight: float = 1.0,",
        "        relation_type: str = 'co_occurrence',",
        "        confidence: float = 1.0,",
        "        source: str = 'corpus'",
        "    ) -> None:",
        "        \"\"\"",
        "        Add or update a typed connection with metadata."
      ],
      "change_type": "add"
    },
    {
      "file": "cortical/processor.py",
      "function": "class CorticalTextProcessor:",
      "start_line": 904,
      "lines_added": [
        "        max_connections_per_bigram: int = 50,",
        "            max_connections_per_bigram: Maximum lateral connections per bigram minicolumn",
        "                to keep graph sparse and focused on strongest connections (default 50)",
        "            - skipped_max_connections: Number of connections skipped due to per-bigram limit",
        "            max_bigrams_per_doc=max_bigrams_per_doc,",
        "            max_connections_per_bigram=max_connections_per_bigram",
        "            skipped_conns = stats.get('skipped_max_connections', 0)",
        "            if skipped_conns:",
        "                skip_parts.append(f\"{skipped_conns} over-limit\")"
      ],
      "lines_removed": [
        "            max_bigrams_per_doc=max_bigrams_per_doc"
      ],
      "context_before": [
        "        if verbose: print(\"Computed document connections\")",
        "",
        "    def compute_bigram_connections(",
        "        self,",
        "        min_shared_docs: int = 1,",
        "        component_weight: float = 0.5,",
        "        chain_weight: float = 0.7,",
        "        cooccurrence_weight: float = 0.3,",
        "        max_bigrams_per_term: int = 100,",
        "        max_bigrams_per_doc: int = 500,"
      ],
      "context_after": [
        "        verbose: bool = True",
        "    ) -> Dict[str, Any]:",
        "        \"\"\"",
        "        Build lateral connections between bigrams based on shared components and co-occurrence.",
        "",
        "        Bigrams are connected when they:",
        "        - Share a component term (\"neural_networks\" â†” \"neural_processing\")",
        "        - Form chains (\"machine_learning\" â†” \"learning_algorithms\")",
        "        - Co-occur in the same documents",
        "",
        "        Args:",
        "            min_shared_docs: Minimum shared documents for co-occurrence connection",
        "            component_weight: Weight for shared component connections (default 0.5)",
        "            chain_weight: Weight for chain connections (default 0.7)",
        "            cooccurrence_weight: Weight for document co-occurrence (default 0.3)",
        "            max_bigrams_per_term: Skip terms appearing in more than this many bigrams",
        "                to avoid O(nÂ²) explosion from common terms like \"self\", \"return\" (default 100)",
        "            max_bigrams_per_doc: Skip documents with more than this many bigrams for",
        "                co-occurrence connections to avoid O(nÂ²) explosion (default 500)",
        "            verbose: Print progress messages",
        "",
        "        Returns:",
        "            Statistics about connections created:",
        "            - connections_created: Total bidirectional connections",
        "            - component_connections: Connections from shared components",
        "            - chain_connections: Connections from chains",
        "            - cooccurrence_connections: Connections from document co-occurrence",
        "            - skipped_common_terms: Number of terms skipped due to max_bigrams_per_term",
        "            - skipped_large_docs: Number of docs skipped due to max_bigrams_per_doc",
        "",
        "        Example:",
        "            >>> stats = processor.compute_bigram_connections()",
        "            >>> print(f\"Created {stats['connections_created']} bigram connections\")",
        "            >>> print(f\"  Component: {stats['component_connections']}\")",
        "            >>> print(f\"  Chain: {stats['chain_connections']}\")",
        "            >>> print(f\"  Co-occurrence: {stats['cooccurrence_connections']}\")",
        "        \"\"\"",
        "        stats = analysis.compute_bigram_connections(",
        "            self.layers,",
        "            min_shared_docs=min_shared_docs,",
        "            component_weight=component_weight,",
        "            chain_weight=chain_weight,",
        "            cooccurrence_weight=cooccurrence_weight,",
        "            max_bigrams_per_term=max_bigrams_per_term,",
        "        )",
        "        if verbose:",
        "            skipped_terms = stats.get('skipped_common_terms', 0)",
        "            skipped_docs = stats.get('skipped_large_docs', 0)",
        "            skip_parts = []",
        "            if skipped_terms:",
        "                skip_parts.append(f\"{skipped_terms} common terms\")",
        "            if skipped_docs:",
        "                skip_parts.append(f\"{skipped_docs} large docs\")",
        "            skip_msg = f\", skipped {', '.join(skip_parts)}\" if skip_parts else \"\"",
        "            print(f\"Created {stats['connections_created']} bigram connections \"",
        "                  f\"(component: {stats['component_connections']}, \"",
        "                  f\"chain: {stats['chain_connections']}, \"",
        "                  f\"cooccur: {stats['cooccurrence_connections']}{skip_msg})\")",
        "        return stats",
        "",
        "    def build_concept_clusters(",
        "        self,",
        "        min_cluster_size: Optional[int] = None,"
      ],
      "change_type": "modify"
    }
  ],
  "hour_of_day": 3,
  "day_of_week": "Friday",
  "seconds_since_last_commit": -297240,
  "is_merge": false,
  "is_initial": false,
  "parent_count": 1,
  "session_id": null,
  "related_chats": [],
  "ci_result": null,
  "reverted": false,
  "amended": false
}