{
  "hash": "1b7f6d571f565fc4979101cf03ccd8c9dfda610e",
  "message": "feat: Add commit-chat session linking for ML training",
  "author": "Claude",
  "timestamp": "2025-12-15 05:07:05 +0000",
  "branch": "claude/multi-index-design-DvifZ",
  "files_changed": [
    "scripts/ml_data_collector.py"
  ],
  "insertions": 234,
  "deletions": 6,
  "hunks": [
    {
      "file": "scripts/ml_data_collector.py",
      "function": "class SchemaValidationError(Exception):",
      "start_line": 44,
      "lines_added": [
        "CURRENT_SESSION_FILE = ML_DATA_DIR / \"current_session.json\""
      ],
      "lines_removed": [],
      "context_before": [
        "",
        "# ============================================================================",
        "# CONFIGURATION",
        "# ============================================================================",
        "",
        "ML_DATA_DIR = Path(\".git-ml\")",
        "COMMITS_DIR = ML_DATA_DIR / \"commits\"",
        "SESSIONS_DIR = ML_DATA_DIR / \"sessions\"",
        "CHATS_DIR = ML_DATA_DIR / \"chats\"",
        "ACTIONS_DIR = ML_DATA_DIR / \"actions\""
      ],
      "context_after": [
        "",
        "# Training milestones",
        "MILESTONES = {",
        "    \"file_prediction\": {\"commits\": 500, \"sessions\": 100, \"chats\": 200},",
        "    \"commit_messages\": {\"commits\": 2000, \"sessions\": 500, \"chats\": 1000},",
        "    \"code_suggestions\": {\"commits\": 5000, \"sessions\": 2000, \"chats\": 5000},",
        "}",
        "",
        "# Schema validation definitions",
        "COMMIT_SCHEMA = {"
      ],
      "change_type": "add"
    },
    {
      "file": "scripts/ml_data_collector.py",
      "function": "def validate_schema(data: dict, schema: dict, data_type: str) -> List[str]:",
      "start_line": 99,
      "lines_added": [
        "# ============================================================================",
        "# SESSION MANAGEMENT (for commit-chat linking)",
        "# ============================================================================",
        "",
        "def get_current_session() -> Optional[Dict]:",
        "    \"\"\"Get the current active session info.",
        "",
        "    Returns dict with 'id', 'started_at', 'chat_ids' or None if no session.",
        "    \"\"\"",
        "    if CURRENT_SESSION_FILE.exists():",
        "        try:",
        "            with open(CURRENT_SESSION_FILE, 'r', encoding='utf-8') as f:",
        "                return json.load(f)",
        "        except (json.JSONDecodeError, IOError):",
        "            return None",
        "    return None",
        "",
        "",
        "def start_session(session_id: Optional[str] = None) -> str:",
        "    \"\"\"Start a new session for commit-chat linking.",
        "",
        "    Args:",
        "        session_id: Optional session ID. Generated if not provided.",
        "",
        "    Returns:",
        "        The session ID.",
        "    \"\"\"",
        "    ensure_dirs()",
        "",
        "    session_id = session_id or generate_session_id()",
        "    session_data = {",
        "        'id': session_id,",
        "        'started_at': datetime.now().isoformat(),",
        "        'chat_ids': [],",
        "        'action_ids': [],",
        "    }",
        "",
        "    atomic_write_json(CURRENT_SESSION_FILE, session_data)",
        "    return session_id",
        "",
        "",
        "def get_or_create_session() -> str:",
        "    \"\"\"Get current session ID or create a new one.",
        "",
        "    Returns:",
        "        The current session ID.",
        "    \"\"\"",
        "    session = get_current_session()",
        "    if session:",
        "        return session['id']",
        "    return start_session()",
        "",
        "",
        "def add_chat_to_session(chat_id: str):",
        "    \"\"\"Record a chat ID in the current session for later commit linking.\"\"\"",
        "    session = get_current_session()",
        "    if not session:",
        "        # Auto-start session if needed",
        "        session = {",
        "            'id': generate_session_id(),",
        "            'started_at': datetime.now().isoformat(),",
        "            'chat_ids': [],",
        "            'action_ids': [],",
        "        }",
        "",
        "    if chat_id not in session['chat_ids']:",
        "        session['chat_ids'].append(chat_id)",
        "        ensure_dirs()",
        "        atomic_write_json(CURRENT_SESSION_FILE, session)",
        "",
        "",
        "def link_commit_to_session_chats(commit_hash: str) -> List[str]:",
        "    \"\"\"Link a commit to all chats from the current session.",
        "",
        "    Updates the chat entries to record that they resulted in this commit.",
        "    Also updates the commit's related_chats field.",
        "",
        "    Args:",
        "        commit_hash: The commit hash to link.",
        "",
        "    Returns:",
        "        List of chat IDs that were linked.",
        "    \"\"\"",
        "    session = get_current_session()",
        "    if not session or not session.get('chat_ids'):",
        "        return []",
        "",
        "    linked_chats = []",
        "",
        "    # Update each chat entry",
        "    for chat_id in session['chat_ids']:",
        "        chat_file = find_chat_file(chat_id)",
        "        if chat_file and chat_file.exists():",
        "            try:",
        "                with open(chat_file, 'r', encoding='utf-8') as f:",
        "                    chat_data = json.load(f)",
        "",
        "                # Mark chat as resulting in commit",
        "                chat_data['resulted_in_commit'] = True",
        "                chat_data['related_commit'] = commit_hash",
        "",
        "                atomic_write_json(chat_file, chat_data)",
        "                linked_chats.append(chat_id)",
        "            except (json.JSONDecodeError, IOError):",
        "                continue",
        "",
        "    return linked_chats",
        "",
        "",
        "def find_chat_file(chat_id: str) -> Optional[Path]:",
        "    \"\"\"Find the file path for a chat ID.\"\"\"",
        "    if not CHATS_DIR.exists():",
        "        return None",
        "",
        "    # Chat files are organized by date",
        "    for date_dir in CHATS_DIR.iterdir():",
        "        if date_dir.is_dir():",
        "            chat_file = date_dir / f\"{chat_id}.json\"",
        "            if chat_file.exists():",
        "                return chat_file",
        "",
        "    return None",
        "",
        "",
        "def end_session(summary: Optional[str] = None) -> Optional[Dict]:",
        "    \"\"\"End the current session and archive it.",
        "",
        "    Args:",
        "        summary: Optional summary of what was accomplished.",
        "",
        "    Returns:",
        "        The ended session data or None if no session.",
        "    \"\"\"",
        "    session = get_current_session()",
        "    if not session:",
        "        return None",
        "",
        "    session['ended_at'] = datetime.now().isoformat()",
        "    session['summary'] = summary",
        "",
        "    # Save to sessions archive",
        "    ensure_dirs()",
        "    SESSIONS_DIR.mkdir(parents=True, exist_ok=True)",
        "",
        "    archive_file = SESSIONS_DIR / f\"{session['started_at'][:10]}_{session['id']}.json\"",
        "    atomic_write_json(archive_file, session)",
        "",
        "    # Remove current session file",
        "    if CURRENT_SESSION_FILE.exists():",
        "        CURRENT_SESSION_FILE.unlink()",
        "",
        "    return session",
        "",
        ""
      ],
      "lines_removed": [],
      "context_before": [
        "    for field, expected in schema[\"types\"].items():",
        "        if field in data and data[field] is not None:",
        "            if isinstance(expected, tuple):",
        "                if not isinstance(data[field], expected):",
        "                    errors.append(f\"{data_type}: field '{field}' has wrong type\")",
        "            elif not isinstance(data[field], expected):",
        "                errors.append(f\"{data_type}: field '{field}' has type {type(data[field]).__name__}, expected {expected.__name__}\")",
        "    return errors",
        "",
        ""
      ],
      "context_after": [
        "# ============================================================================",
        "# DATA SCHEMAS",
        "# ============================================================================",
        "",
        "@dataclass",
        "class DiffHunk:",
        "    \"\"\"A single diff hunk from a commit.\"\"\"",
        "    file: str",
        "    function: Optional[str]  # Function/class containing the change",
        "    change_type: str  # add, modify, delete, rename"
      ],
      "change_type": "add"
    },
    {
      "file": "scripts/ml_data_collector.py",
      "function": "def atomic_write_json(filepath: Path, data: dict):",
      "start_line": 427,
      "lines_added": [
        "def save_commit_data(context: CommitContext, validate: bool = True, link_session: bool = True):",
        "    \"\"\"Save commit context to disk atomically with validation.",
        "",
        "    Args:",
        "        context: The commit context to save.",
        "        validate: Whether to validate against schema.",
        "        link_session: Whether to link with current session chats.",
        "    \"\"\"",
        "    # Link to current session if available",
        "    if link_session:",
        "        session = get_current_session()",
        "        if session:",
        "            context.session_id = session['id']",
        "            context.related_chats = session.get('chat_ids', [])",
        "",
        "    # Update chat entries to link back to this commit",
        "    if link_session and context.related_chats:",
        "        linked = link_commit_to_session_chats(context.hash)",
        "        if linked:",
        "            print(f\"Linked {len(linked)} chat(s) to commit {context.hash[:8]}\")",
        ""
      ],
      "lines_removed": [
        "def save_commit_data(context: CommitContext, validate: bool = True):",
        "    \"\"\"Save commit context to disk atomically with validation.\"\"\""
      ],
      "context_before": [
        "            json.dump(data, f, indent=2, ensure_ascii=False)",
        "        # Atomic rename (on POSIX systems)",
        "        os.replace(temp_path, filepath)",
        "    except Exception:",
        "        # Clean up temp file on failure",
        "        if os.path.exists(temp_path):",
        "            os.unlink(temp_path)",
        "        raise",
        "",
        ""
      ],
      "context_after": [
        "    ensure_dirs()",
        "",
        "    data = asdict(context)",
        "",
        "    # Validate before writing",
        "    if validate:",
        "        errors = validate_schema(data, COMMIT_SCHEMA, \"commit\")",
        "        if errors:",
        "            raise SchemaValidationError(f\"Commit validation failed: {errors}\")",
        "",
        "    # Use full hash + UUID suffix to prevent collisions",
        "    unique_id = uuid.uuid4().hex[:8]",
        "    filename = f\"{context.hash[:8]}_{context.timestamp[:10]}_{unique_id}.json\"",
        "    filepath = COMMITS_DIR / filename",
        "",
        "    atomic_write_json(filepath, data)",
        "    print(f\"Saved commit data to {filepath}\")",
        "",
        "",
        "def generate_chat_id() -> str:",
        "    \"\"\"Generate unique chat entry ID.\"\"\"",
        "    timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")",
        "    suffix = hashlib.sha256(str(datetime.now().timestamp()).encode()).hexdigest()[:6]",
        "    return f\"chat-{timestamp}-{suffix}\"",
        "",
        "",
        "def generate_session_id() -> str:",
        "    \"\"\"Generate unique session ID.\"\"\""
      ],
      "change_type": "modify"
    },
    {
      "file": "scripts/ml_data_collector.py",
      "function": "def save_chat_entry(entry: ChatEntry, validate: bool = True):",
      "start_line": 492,
      "lines_added": [
        "    \"\"\"Log a chat query/response pair.",
        "",
        "    If no session_id is provided, uses the current session (creating one if needed).",
        "    The chat is automatically registered with the session for commit linking.",
        "    \"\"\"",
        "    # Use current session or create one",
        "    if session_id is None:",
        "        session_id = get_or_create_session()",
        "        session_id=session_id,",
        "",
        "    # Register with session for commit linking",
        "    add_chat_to_session(entry.id)",
        ""
      ],
      "lines_removed": [
        "    \"\"\"Log a chat query/response pair.\"\"\"",
        "        session_id=session_id or generate_session_id(),"
      ],
      "context_before": [
        "",
        "def log_chat(",
        "    query: str,",
        "    response: str,",
        "    session_id: Optional[str] = None,",
        "    files_referenced: Optional[List[str]] = None,",
        "    files_modified: Optional[List[str]] = None,",
        "    tools_used: Optional[List[str]] = None,",
        "    user_feedback: Optional[str] = None,",
        ") -> ChatEntry:"
      ],
      "context_after": [
        "",
        "    entry = ChatEntry(",
        "        id=generate_chat_id(),",
        "        timestamp=datetime.now().isoformat(),",
        "        query=query,",
        "        response=response,",
        "        files_referenced=files_referenced or [],",
        "        files_modified=files_modified or [],",
        "        tools_used=tools_used or [],",
        "        user_feedback=user_feedback,",
        "        query_tokens=len(query.split()),  # Rough estimate",
        "        response_tokens=len(response.split()),",
        "    )",
        "",
        "    save_chat_entry(entry)",
        "    return entry",
        "",
        "",
        "def save_action(entry: ActionEntry, validate: bool = True):",
        "    \"\"\"Save an action entry to disk atomically with validation.\"\"\"",
        "    ensure_dirs()",
        "",
        "    data = asdict(entry)",
        "",
        "    # Validate before writing"
      ],
      "change_type": "modify"
    },
    {
      "file": "scripts/ml_data_collector.py",
      "function": "def main():",
      "start_line": 813,
      "lines_added": [
        "        # Backfill historical commits (no session linking for historical data)",
        "                # Disable session linking for historical backfill",
        "                save_commit_data(context, link_session=False)"
      ],
      "lines_removed": [
        "        # Backfill historical commits",
        "                save_commit_data(context)"
      ],
      "context_before": [
        "",
        "    command = sys.argv[1]",
        "",
        "    if command == \"commit\":",
        "        # Collect data for current or specified commit",
        "        commit_hash = sys.argv[2] if len(sys.argv) > 2 else None",
        "        context = collect_commit_data(commit_hash)",
        "        save_commit_data(context)",
        "",
        "    elif command == \"backfill\":"
      ],
      "context_after": [
        "        import argparse",
        "        parser = argparse.ArgumentParser()",
        "        parser.add_argument(\"-n\", \"--num\", type=int, default=100,",
        "                            help=\"Number of commits to backfill\")",
        "        args = parser.parse_args(sys.argv[2:])",
        "",
        "        hashes = run_git([\"log\", f\"-{args.num}\", \"--format=%H\"]).split(\"\\n\")",
        "        hashes = [h for h in hashes if h]",
        "        print(f\"Backfilling {len(hashes)} commits...\")",
        "",
        "        for i, h in enumerate(hashes):",
        "            try:",
        "                context = collect_commit_data(h)",
        "                if (i + 1) % 10 == 0:",
        "                    print(f\"  Progress: {i + 1}/{len(hashes)}\")",
        "            except Exception as e:",
        "                print(f\"  Error on {h[:8]}: {e}\")",
        "",
        "        print(f\"Backfill complete: {len(hashes)} commits\")",
        "",
        "    elif command == \"chat\":",
        "        # Log a chat entry",
        "        import argparse"
      ],
      "change_type": "modify"
    },
    {
      "file": "scripts/ml_data_collector.py",
      "function": "def main():",
      "start_line": 977,
      "lines_added": [
        "    elif command == \"session\":",
        "        # Session management for commit-chat linking",
        "        import argparse",
        "        parser = argparse.ArgumentParser()",
        "        parser.add_argument(\"action\", choices=[\"start\", \"end\", \"status\"],",
        "                            help=\"Session action\")",
        "        parser.add_argument(\"--summary\", help=\"Summary for end action\")",
        "        args = parser.parse_args(sys.argv[2:])",
        "",
        "        if args.action == \"start\":",
        "            session_id = start_session()",
        "            print(f\"Started session: {session_id}\")",
        "            print(\"Chats will be linked to commits made in this session.\")",
        "",
        "        elif args.action == \"end\":",
        "            session = end_session(args.summary)",
        "            if session:",
        "                print(f\"Ended session: {session['id']}\")",
        "                print(f\"  Chats logged: {len(session.get('chat_ids', []))}\")",
        "                print(f\"  Duration: {session.get('started_at', '?')} → {session.get('ended_at', '?')}\")",
        "            else:",
        "                print(\"No active session to end.\")",
        "",
        "        elif args.action == \"status\":",
        "            session = get_current_session()",
        "            if session:",
        "                print(\"\\n\" + \"=\" * 50)",
        "                print(\"CURRENT SESSION\")",
        "                print(\"=\" * 50)",
        "                print(f\"  ID:         {session['id']}\")",
        "                print(f\"  Started:    {session['started_at']}\")",
        "                print(f\"  Chats:      {len(session.get('chat_ids', []))}\")",
        "                if session.get('chat_ids'):",
        "                    print(\"  Chat IDs:\")",
        "                    for cid in session['chat_ids'][:5]:  # Show first 5",
        "                        print(f\"    - {cid}\")",
        "                    if len(session['chat_ids']) > 5:",
        "                        print(f\"    ... and {len(session['chat_ids']) - 5} more\")",
        "                print(\"=\" * 50 + \"\\n\")",
        "            else:",
        "                print(\"No active session. Use 'session start' to begin.\")",
        ""
      ],
      "lines_removed": [],
      "context_before": [
        "        # Summary",
        "        print(\"\\n\" + \"-\" * 60)",
        "        if all_errors:",
        "            print(f\"⚠️  Found {len(all_errors)} validation errors\")",
        "            if not args.verbose:",
        "                print(\"   Run with --verbose to see details\")",
        "        else:",
        "            print(\"✅ All data validated successfully!\")",
        "        print(\"=\" * 60 + \"\\n\")",
        ""
      ],
      "context_after": [
        "    else:",
        "        print(f\"Unknown command: {command}\")",
        "        print(__doc__)",
        "",
        "",
        "if __name__ == \"__main__\":",
        "    main()"
      ],
      "change_type": "add"
    }
  ],
  "hour_of_day": 5,
  "day_of_week": "Monday",
  "seconds_since_last_commit": -31063,
  "is_merge": false,
  "is_initial": false,
  "parent_count": 1,
  "session_id": null,
  "related_chats": [],
  "ci_result": null,
  "reverted": false,
  "amended": false
}