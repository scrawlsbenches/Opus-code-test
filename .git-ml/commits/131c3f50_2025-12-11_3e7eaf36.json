{
  "hash": "131c3f50f7e48275f4f0a3bdf526d83ded732817",
  "message": "Implement task #73: Add \"Find Similar Code\" command",
  "author": "Claude",
  "timestamp": "2025-12-11 02:07:03 +0000",
  "branch": "claude/multi-index-design-DvifZ",
  "files_changed": [
    "TASK_LIST.md",
    "scripts/search_codebase.py",
    "tests/test_search_codebase.py"
  ],
  "insertions": 434,
  "deletions": 12,
  "hunks": [
    {
      "file": "TASK_LIST.md",
      "function": "if is_code_query(query):  # Detect if searching for code patterns",
      "start_line": 2546,
      "lines_added": [
        "**Files:** `scripts/search_codebase.py`",
        "**Status:** [x] Completed",
        "**Solution Applied:**",
        "1. Added `find_similar_code()` function (~60 lines) implementing:",
        "   - Parses file:line references to extract target text from indexed documents",
        "   - Falls back to raw text comparison for direct code input",
        "   - Uses `get_fingerprint()` and `compare_fingerprints()` for similarity scoring",
        "   - Chunks documents and compares fingerprints against target",
        "   - Returns top-N similar passages with scores and shared terms",
        "2. Added `display_similar_results()` function for formatted output",
        "3. Added `--similar-to` / `-s` argument to CLI",
        "4. Added tests in `tests/test_search_codebase.py` (5 tests)",
        "",
        "**Usage:**",
        "# Find code similar to a file:line reference",
        "python scripts/search_codebase.py --similar-to cortical/processor.py:100",
        "",
        "# Find code similar to raw text",
        "python scripts/search_codebase.py -s \"def compute_score(items, weights)\"",
        "# With more results",
        "python scripts/search_codebase.py --similar-to processor.py:50 --top 10",
        "**Files Modified:**",
        "- `scripts/search_codebase.py` - Added `find_similar_code()`, `display_similar_results()`, CLI argument (~120 lines)",
        "- `tests/test_search_codebase.py` - New file with 23 tests for search functions"
      ],
      "lines_removed": [
        "**Files:** `scripts/search_codebase.py`, `cortical/processor.py`",
        "**Status:** [ ] Not Started",
        "**Solution:**",
        "Add `--similar-to` flag:",
        "# Find code similar to a specific function",
        "python scripts/search_codebase.py --similar-to \"cortical/processor.py:expand_query\"",
        "# Find code similar to clipboard/stdin",
        "echo \"def process(data): return data.strip()\" | python scripts/search_codebase.py --similar-to -",
        "**Implementation:**",
        "1. Extract fingerprint of target code",
        "2. Compare against all indexed passages",
        "3. Return passages with highest similarity scores"
      ],
      "context_before": [
        "else:",
        "    expanded = processor.expand_query(query)",
        "```",
        "",
        "**Impact:** \"get data\" would expand to include \"fetch\", \"load\", \"retrieve\", \"read\" variations.",
        "",
        "---",
        "",
        "### 73. Add \"Find Similar Code\" Command",
        ""
      ],
      "context_after": [
        "**Priority:** Medium",
        "",
        "**Problem:**",
        "No way to find code similar to a given snippet or function. Fingerprinting exists but isn't exposed.",
        "",
        "```bash",
        "",
        "```",
        "",
        "",
        "---",
        "",
        "## Creative Developer Experience Features",
        "",
        "### 74. Add \"Explain This Code\" Command",
        "",
        "**Files:** `scripts/explain_code.py` (new)",
        "**Status:** [ ] Not Started",
        "**Priority:** Medium"
      ],
      "change_type": "modify"
    },
    {
      "file": "scripts/search_codebase.py",
      "function": "def get_doc_type_label(doc_id: str) -> str:",
      "start_line": 43,
      "lines_added": [
        "def find_similar_code(",
        "    processor: CorticalTextProcessor,",
        "    target: str,",
        "    top_n: int = 5,",
        "    chunk_size: int = 400",
        ") -> list:",
        "    \"\"\"",
        "    Find code similar to a target reference or text.",
        "",
        "    Args:",
        "        processor: CorticalTextProcessor instance",
        "        target: Either a file:line reference (e.g., \"cortical/processor.py:100\")",
        "                or raw text to compare against",
        "        top_n: Number of similar results to return",
        "        chunk_size: Size of text chunks to compare",
        "",
        "    Returns:",
        "        List of result dicts with similarity scores",
        "    \"\"\"",
        "    # Determine if target is a file reference or raw text",
        "    if ':' in target and not target.startswith('http'):",
        "        # Parse file:line reference",
        "        parts = target.split(':')",
        "        file_path = parts[0]",
        "        try:",
        "            line_num = int(parts[1]) if len(parts) > 1 else 1",
        "        except ValueError:",
        "            line_num = 1",
        "",
        "        # Get content from indexed document",
        "        doc_content = processor.documents.get(file_path, '')",
        "        if not doc_content:",
        "            # Try without extension",
        "            for doc_id in processor.documents:",
        "                if doc_id.endswith(file_path) or file_path.endswith(doc_id):",
        "                    doc_content = processor.documents[doc_id]",
        "                    file_path = doc_id",
        "                    break",
        "",
        "        if not doc_content:",
        "            return []",
        "",
        "        # Extract passage around the line",
        "        lines = doc_content.split('\\n')",
        "        start_line = max(0, line_num - 1)",
        "        end_line = min(len(lines), start_line + 20)  # ~20 lines of context",
        "        target_text = '\\n'.join(lines[start_line:end_line])",
        "    else:",
        "        target_text = target",
        "",
        "    if not target_text.strip():",
        "        return []",
        "",
        "    # Get fingerprint of target",
        "    target_fp = processor.get_fingerprint(target_text, top_n=20)",
        "",
        "    # Compare against all documents",
        "    results = []",
        "    for doc_id, doc_content in processor.documents.items():",
        "        # Skip the source document if we're searching from a file reference",
        "        if ':' in target and doc_id in target:",
        "            continue",
        "",
        "        # Chunk the document and compare each chunk",
        "        for start in range(0, len(doc_content), chunk_size // 2):",
        "            end = min(start + chunk_size, len(doc_content))",
        "            chunk = doc_content[start:end]",
        "",
        "            if len(chunk.strip()) < 50:  # Skip very short chunks",
        "                continue",
        "",
        "            chunk_fp = processor.get_fingerprint(chunk, top_n=20)",
        "            comparison = processor.compare_fingerprints(target_fp, chunk_fp)",
        "",
        "            similarity = comparison.get('overall_similarity', 0)",
        "            if similarity > 0.1:  # Only include somewhat similar results",
        "                line_num = find_line_number(doc_content, start)",
        "                results.append({",
        "                    'file': doc_id,",
        "                    'line': line_num,",
        "                    'passage': chunk,",
        "                    'score': similarity,",
        "                    'reference': f\"{doc_id}:{line_num}\",",
        "                    'doc_type': get_doc_type_label(doc_id),",
        "                    'shared_terms': list(comparison.get('shared_terms', []))[:5]",
        "                })",
        "",
        "    # Sort by similarity and return top results",
        "    results.sort(key=lambda x: x['score'], reverse=True)",
        "    return results[:top_n]",
        "",
        "",
        "def display_similar_results(results: list, target: str, verbose: bool = False):",
        "    \"\"\"Display similar code results.\"\"\"",
        "    if not results:",
        "        print(f\"\\nNo similar code found for: {target}\")",
        "        return",
        "",
        "    print(f\"\\n{'─' * 60}\")",
        "    print(f\"Code similar to: {target}\")",
        "    print(f\"{'─' * 60}\\n\")",
        "",
        "    for i, result in enumerate(results, 1):",
        "        print(f\"[{i}] [{result['doc_type']}] {result['reference']}\")",
        "        print(f\"    Similarity: {result['score']:.1%}\")",
        "        if result.get('shared_terms'):",
        "            print(f\"    Shared: {', '.join(result['shared_terms'])}\")",
        "        print(\"─\" * 50)",
        "",
        "        if verbose:",
        "            print(format_passage(result['passage']))",
        "        else:",
        "            lines = result['passage'].split('\\n')[:5]",
        "            for line in lines:",
        "                if len(line) > 70:",
        "                    line = line[:67] + '...'",
        "                print(f\"  {line}\")",
        "            if len(result['passage'].split('\\n')) > 5:",
        "                print(f\"  ...\")",
        "        print()",
        "",
        ""
      ],
      "lines_removed": [],
      "context_before": [
        "    \"\"\"Get a display label for document type.\"\"\"",
        "    if doc_id.endswith('.md'):",
        "        if doc_id.startswith('docs/'):",
        "            return 'DOCS'",
        "        return 'DOC'",
        "    elif doc_id.startswith('tests/'):",
        "        return 'TEST'",
        "    return 'CODE'",
        "",
        ""
      ],
      "context_after": [
        "def search_codebase(",
        "    processor: CorticalTextProcessor,",
        "    query: str,",
        "    top_n: int = 5,",
        "    chunk_size: int = 400,",
        "    fast: bool = False,",
        "    prefer_docs: bool = False,",
        "    no_boost: bool = False",
        ") -> list:",
        "    \"\"\""
      ],
      "change_type": "add"
    },
    {
      "file": "scripts/search_codebase.py",
      "function": "def main():",
      "start_line": 242,
      "lines_added": [
        "  %(prog)s --similar-to cortical/processor.py:100  # Find similar code",
        "  %(prog)s -s \"def compute_pagerank\"      # Find code similar to text"
      ],
      "lines_removed": [],
      "context_before": [
        "    parser = argparse.ArgumentParser(",
        "        description='Search the indexed codebase',",
        "        epilog=\"\"\"",
        "Examples:",
        "  %(prog)s \"PageRank algorithm\"           # Search with auto-boost",
        "  %(prog)s \"what is PageRank\" --prefer-docs  # Always boost docs",
        "  %(prog)s \"compute pagerank\" --no-boost  # Disable boosting",
        "  %(prog)s \"architecture\" --fast          # Fast document-level search",
        "  %(prog)s \"fetch data\" --code            # Code-aware (also finds get/load/retrieve)",
        "  %(prog)s \"auth\" --code --expand         # Show programming synonyms"
      ],
      "context_after": [
        "        \"\"\"",
        "    )",
        "    parser.add_argument('query', nargs='?', help='Search query')",
        "    parser.add_argument('--corpus', '-c', default='corpus_dev.pkl',",
        "                        help='Corpus file path (default: corpus_dev.pkl)')",
        "    parser.add_argument('--top', '-n', type=int, default=5,",
        "                        help='Number of results (default: 5)')",
        "    parser.add_argument('--verbose', '-v', action='store_true',",
        "                        help='Show full passage text')",
        "    parser.add_argument('--expand', '-e', action='store_true',"
      ],
      "change_type": "add"
    },
    {
      "file": "scripts/search_codebase.py",
      "function": "Examples:",
      "start_line": 263,
      "lines_added": [
        "    parser.add_argument('--similar-to', '-s', metavar='TARGET',",
        "                        help='Find code similar to file:line reference or text')",
        "    elif args.similar_to:",
        "        # Find similar code mode",
        "        results = find_similar_code(",
        "            processor,",
        "            args.similar_to,",
        "            top_n=args.top",
        "        )",
        "        display_similar_results(results, args.similar_to, verbose=args.verbose)"
      ],
      "lines_removed": [],
      "context_before": [
        "    parser.add_argument('--interactive', '-i', action='store_true',",
        "                        help='Interactive search mode')",
        "    parser.add_argument('--fast', '-f', action='store_true',",
        "                        help='Fast search mode (document-level, ~2-3x faster)')",
        "    parser.add_argument('--prefer-docs', '-d', action='store_true',",
        "                        help='Always boost documentation files in results')",
        "    parser.add_argument('--no-boost', action='store_true',",
        "                        help='Disable document type boosting (raw TF-IDF)')",
        "    parser.add_argument('--code', action='store_true',",
        "                        help='Use code-aware query expansion (get→fetch/load/retrieve)')"
      ],
      "context_after": [
        "    args = parser.parse_args()",
        "",
        "    base_path = Path(__file__).parent.parent",
        "    corpus_path = base_path / args.corpus",
        "",
        "    # Check if corpus exists",
        "    if not corpus_path.exists():",
        "        print(f\"Error: Corpus file not found: {corpus_path}\")",
        "        print(\"Run 'python scripts/index_codebase.py' first to create it.\")",
        "        sys.exit(1)",
        "",
        "    # Load corpus",
        "    print(f\"Loading corpus from {corpus_path}...\")",
        "    processor = CorticalTextProcessor.load(str(corpus_path))",
        "    print(f\"Loaded {len(processor.documents)} documents\\n\")",
        "",
        "    if args.interactive:",
        "        interactive_mode(processor)",
        "    elif args.query:",
        "        if args.expand:",
        "            expand_query_display(processor, args.query, use_code=args.code)",
        "            print()",
        "",
        "        # Show query intent detection",
        "        is_conceptual = processor.is_conceptual_query(args.query)",
        "        if not args.no_boost:",
        "            intent_str = \"conceptual\" if is_conceptual else \"implementation\"",
        "            print(f\"(Query type: {intent_str})\")"
      ],
      "change_type": "add"
    },
    {
      "file": "tests/test_search_codebase.py",
      "function": null,
      "start_line": 0,
      "lines_added": [
        "\"\"\"",
        "Tests for scripts/search_codebase.py - search functions and utilities.",
        "\"\"\"",
        "",
        "import unittest",
        "import sys",
        "from pathlib import Path",
        "",
        "# Add parent and scripts directories to path",
        "sys.path.insert(0, str(Path(__file__).parent.parent))",
        "sys.path.insert(0, str(Path(__file__).parent.parent / 'scripts'))",
        "",
        "from cortical.processor import CorticalTextProcessor",
        "from search_codebase import (",
        "    find_line_number,",
        "    format_passage,",
        "    get_doc_type_label,",
        "    search_codebase,",
        "    find_similar_code",
        ")",
        "",
        "",
        "class TestUtilityFunctions(unittest.TestCase):",
        "    \"\"\"Tests for utility functions.\"\"\"",
        "",
        "    def test_find_line_number_start(self):",
        "        \"\"\"Test line number at start of document.\"\"\"",
        "        content = \"line1\\nline2\\nline3\"",
        "        self.assertEqual(find_line_number(content, 0), 1)",
        "",
        "    def test_find_line_number_second_line(self):",
        "        \"\"\"Test line number for second line.\"\"\"",
        "        content = \"line1\\nline2\\nline3\"",
        "        self.assertEqual(find_line_number(content, 6), 2)",
        "",
        "    def test_find_line_number_third_line(self):",
        "        \"\"\"Test line number for third line.\"\"\"",
        "        content = \"line1\\nline2\\nline3\"",
        "        self.assertEqual(find_line_number(content, 12), 3)",
        "",
        "    def test_format_passage_short(self):",
        "        \"\"\"Test formatting a short passage.\"\"\"",
        "        passage = \"Line 1\\nLine 2\\nLine 3\"",
        "        result = format_passage(passage)",
        "        self.assertIn(\"Line 1\", result)",
        "        self.assertIn(\"Line 2\", result)",
        "",
        "    def test_format_passage_truncates_long_lines(self):",
        "        \"\"\"Test that long lines are truncated.\"\"\"",
        "        long_line = \"x\" * 100",
        "        passage = long_line",
        "        result = format_passage(passage, max_width=50)",
        "        self.assertIn(\"...\", result)",
        "        self.assertLessEqual(len(result), 50)",
        "",
        "    def test_format_passage_limits_lines(self):",
        "        \"\"\"Test that many lines are limited.\"\"\"",
        "        passage = \"\\n\".join([f\"Line {i}\" for i in range(20)])",
        "        result = format_passage(passage)",
        "        self.assertIn(\"more lines\", result)",
        "",
        "    def test_get_doc_type_label_docs_markdown(self):",
        "        \"\"\"Test label for docs/ markdown files.\"\"\"",
        "        self.assertEqual(get_doc_type_label(\"docs/guide.md\"), \"DOCS\")",
        "",
        "    def test_get_doc_type_label_markdown(self):",
        "        \"\"\"Test label for other markdown files.\"\"\"",
        "        self.assertEqual(get_doc_type_label(\"README.md\"), \"DOC\")",
        "",
        "    def test_get_doc_type_label_test(self):",
        "        \"\"\"Test label for test files.\"\"\"",
        "        self.assertEqual(get_doc_type_label(\"tests/test_processor.py\"), \"TEST\")",
        "",
        "    def test_get_doc_type_label_code(self):",
        "        \"\"\"Test label for code files.\"\"\"",
        "        self.assertEqual(get_doc_type_label(\"cortical/processor.py\"), \"CODE\")",
        "",
        "",
        "class TestSearchCodebase(unittest.TestCase):",
        "    \"\"\"Tests for the search_codebase function.\"\"\"",
        "",
        "    @classmethod",
        "    def setUpClass(cls):",
        "        \"\"\"Set up processor with test documents.\"\"\"",
        "        cls.processor = CorticalTextProcessor()",
        "",
        "        # Add test documents",
        "        cls.processor.process_document(",
        "            \"processor.py\",",
        "            \"\"\"",
        "            The CorticalTextProcessor is the main API for text analysis.",
        "            It uses PageRank for term importance and TF-IDF for relevance.",
        "            Query expansion adds related terms to improve recall.",
        "            \"\"\"",
        "        )",
        "        cls.processor.process_document(",
        "            \"docs/guide.md\",",
        "            \"\"\"",
        "            # User Guide",
        "",
        "            This guide explains how PageRank works in the system.",
        "            PageRank measures the importance of terms based on connections.",
        "            \"\"\"",
        "        )",
        "        cls.processor.process_document(",
        "            \"tests/test_processor.py\",",
        "            \"\"\"",
        "            import unittest",
        "",
        "            class TestProcessor(unittest.TestCase):",
        "                def test_pagerank(self):",
        "                    processor = CorticalTextProcessor()",
        "                    processor.compute_all()",
        "            \"\"\"",
        "        )",
        "",
        "        cls.processor.compute_all()",
        "",
        "    def test_search_returns_results(self):",
        "        \"\"\"Test that search returns results.\"\"\"",
        "        results = search_codebase(self.processor, \"PageRank\", top_n=3)",
        "",
        "        self.assertIsInstance(results, list)",
        "        self.assertGreater(len(results), 0)",
        "",
        "    def test_search_result_structure(self):",
        "        \"\"\"Test result dict structure.\"\"\"",
        "        results = search_codebase(self.processor, \"PageRank\", top_n=1)",
        "",
        "        if results:",
        "            result = results[0]",
        "            self.assertIn('file', result)",
        "            self.assertIn('line', result)",
        "            self.assertIn('passage', result)",
        "            self.assertIn('score', result)",
        "            self.assertIn('reference', result)",
        "            self.assertIn('doc_type', result)",
        "",
        "    def test_search_fast_mode(self):",
        "        \"\"\"Test fast search mode.\"\"\"",
        "        results = search_codebase(",
        "            self.processor, \"PageRank\", top_n=3, fast=True",
        "        )",
        "",
        "        self.assertIsInstance(results, list)",
        "        # Fast mode always returns line 1",
        "        for result in results:",
        "            self.assertEqual(result['line'], 1)",
        "",
        "    def test_search_no_boost_mode(self):",
        "        \"\"\"Test search with boosting disabled.\"\"\"",
        "        results = search_codebase(",
        "            self.processor, \"PageRank\", top_n=3, no_boost=True",
        "        )",
        "",
        "        self.assertIsInstance(results, list)",
        "",
        "    def test_search_prefer_docs(self):",
        "        \"\"\"Test search with prefer_docs flag.\"\"\"",
        "        results = search_codebase(",
        "            self.processor, \"PageRank\", top_n=3, prefer_docs=True",
        "        )",
        "",
        "        self.assertIsInstance(results, list)",
        "",
        "    def test_search_empty_query(self):",
        "        \"\"\"Test search with empty query.\"\"\"",
        "        results = search_codebase(self.processor, \"\", top_n=3)",
        "        self.assertIsInstance(results, list)",
        "",
        "",
        "class TestFindSimilarCode(unittest.TestCase):",
        "    \"\"\"Tests for the find_similar_code function.\"\"\"",
        "",
        "    @classmethod",
        "    def setUpClass(cls):",
        "        \"\"\"Set up processor with test documents.\"\"\"",
        "        cls.processor = CorticalTextProcessor()",
        "",
        "        cls.processor.process_document(",
        "            \"module_a.py\",",
        "            \"\"\"",
        "            def calculate_score(items, weights):",
        "                total = 0",
        "                for item, weight in zip(items, weights):",
        "                    total += item * weight",
        "                return total / len(items) if items else 0",
        "            \"\"\"",
        "        )",
        "        cls.processor.process_document(",
        "            \"module_b.py\",",
        "            \"\"\"",
        "            def compute_weighted_average(values, factors):",
        "                result = 0",
        "                for value, factor in zip(values, factors):",
        "                    result += value * factor",
        "                return result / len(values) if values else 0",
        "            \"\"\"",
        "        )",
        "        cls.processor.process_document(",
        "            \"unrelated.py\",",
        "            \"\"\"",
        "            class UserAuthentication:",
        "                def verify_password(self, password, hash):",
        "                    return bcrypt.check(password, hash)",
        "            \"\"\"",
        "        )",
        "",
        "        cls.processor.compute_all()",
        "",
        "    def test_find_similar_with_text(self):",
        "        \"\"\"Test finding similar code with raw text.\"\"\"",
        "        target_code = \"def compute_score(data, weights): return sum()\"",
        "        results = find_similar_code(",
        "            self.processor, target_code, top_n=3",
        "        )",
        "",
        "        self.assertIsInstance(results, list)",
        "",
        "    def test_find_similar_result_structure(self):",
        "        \"\"\"Test that results have expected structure.\"\"\"",
        "        results = find_similar_code(",
        "            self.processor, \"def calculate total weighted\", top_n=1",
        "        )",
        "",
        "        if results:",
        "            result = results[0]",
        "            self.assertIn('file', result)",
        "            self.assertIn('line', result)",
        "            self.assertIn('passage', result)",
        "            self.assertIn('score', result)",
        "            self.assertIn('reference', result)",
        "            self.assertIn('doc_type', result)",
        "",
        "    def test_find_similar_with_file_reference(self):",
        "        \"\"\"Test finding similar code with file:line reference.\"\"\"",
        "        results = find_similar_code(",
        "            self.processor, \"module_a.py:1\", top_n=3",
        "        )",
        "",
        "        self.assertIsInstance(results, list)",
        "        # Should not include the source file itself",
        "        for result in results:",
        "            self.assertNotIn('module_a.py', result['reference'])",
        "",
        "    def test_find_similar_empty_text(self):",
        "        \"\"\"Test with empty target text.\"\"\"",
        "        results = find_similar_code(self.processor, \"\", top_n=3)",
        "        self.assertEqual(results, [])",
        "",
        "    def test_find_similar_nonexistent_file(self):",
        "        \"\"\"Test with nonexistent file reference.\"\"\"",
        "        results = find_similar_code(",
        "            self.processor, \"nonexistent.py:100\", top_n=3",
        "        )",
        "        self.assertEqual(results, [])",
        "",
        "",
        "class TestSearchCodebaseEmpty(unittest.TestCase):",
        "    \"\"\"Tests with empty processor.\"\"\"",
        "",
        "    def test_search_empty_processor(self):",
        "        \"\"\"Test search with empty processor.\"\"\"",
        "        processor = CorticalTextProcessor()",
        "        results = search_codebase(processor, \"anything\", top_n=3)",
        "        self.assertEqual(results, [])",
        "",
        "    def test_find_similar_empty_processor(self):",
        "        \"\"\"Test find_similar with empty processor.\"\"\"",
        "        processor = CorticalTextProcessor()",
        "        results = find_similar_code(processor, \"some code\", top_n=3)",
        "        self.assertEqual(results, [])",
        "",
        "",
        "if __name__ == '__main__':",
        "    unittest.main()"
      ],
      "lines_removed": [],
      "context_before": [],
      "context_after": [],
      "change_type": "add"
    }
  ],
  "hour_of_day": 2,
  "day_of_week": "Thursday",
  "seconds_since_last_commit": -387465,
  "is_merge": false,
  "is_initial": false,
  "parent_count": 1,
  "session_id": null,
  "related_chats": [],
  "ci_result": null,
  "reverted": false,
  "amended": false
}