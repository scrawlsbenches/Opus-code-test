{
  "hash": "2435c290aea5105e944ca6a2ccc62adb2616c872",
  "message": "Merge pull request #79 from scrawlsbenches/claude/security-features-refactor-GDSsX",
  "author": "scrawlsbenches",
  "timestamp": "2025-12-14 11:28:03 -0500",
  "branch": "claude/multi-index-design-DvifZ",
  "files_changed": [
    ".github/workflows/ci.yml",
    "CLAUDE.md",
    "tests/test_generate_ai_metadata.py"
  ],
  "insertions": 96,
  "deletions": 28,
  "hunks": [
    {
      "file": "workflows/ci.yml b/.github/workflows/ci.yml",
      "function": "name: CI - Test Suite",
      "start_line": 33,
      "lines_added": [
        "    branches:",
        "      - '**'  # Run on all branch pushes (explicit)"
      ],
      "lines_removed": [],
      "context_before": [
        "#                (combines coverage",
        "#                 from unit + integration",
        "#                 WITHOUT re-running tests)",
        "#",
        "# Each stage runs specific test files to avoid duplication.",
        "# coverage-report ONLY combines coverage data - it does NOT run tests again.",
        "# =============================================================================",
        "",
        "on:",
        "  push:"
      ],
      "context_after": [
        "  pull_request:",
        "    branches: [ main ]",
        "  workflow_dispatch:  # Allow manual triggering",
        "",
        "concurrency:",
        "  group: ${{ github.workflow }}-${{ github.ref }}",
        "  cancel-in-progress: true",
        "",
        "jobs:",
        "  # =========================================================================="
      ],
      "change_type": "add"
    },
    {
      "file": "workflows/ci.yml b/.github/workflows/ci.yml",
      "function": "jobs:",
      "start_line": 180,
      "lines_added": [
        "          tests/test_mcp_server.py \\"
      ],
      "lines_removed": [],
      "context_before": [
        "          tests/test_incremental_indexing.py \\",
        "          tests/test_edge_cases.py \\",
        "          tests/test_coverage_gaps.py \\",
        "          tests/test_analyze_louvain_resolution.py \\",
        "          tests/test_evaluate_cluster.py \\",
        "          tests/test_cli_wrapper.py \\",
        "          tests/test_search_codebase.py \\",
        "          tests/test_ask_codebase.py \\",
        "          tests/test_generate_ai_metadata.py \\",
        "          tests/test_showcase.py \\"
      ],
      "context_after": [
        "          -v --tb=short",
        "",
        "        coverage report --include=\"cortical/*\"",
        "",
        "    - name: Upload integration test coverage data",
        "      uses: actions/upload-artifact@v4",
        "      with:",
        "        name: coverage-integration",
        "        path: .coverage",
        "        include-hidden-files: true"
      ],
      "change_type": "add"
    },
    {
      "file": "workflows/ci.yml b/.github/workflows/ci.yml",
      "function": "jobs:",
      "start_line": 403,
      "lines_added": [
        "        python3 << 'PYTHON_SCRIPT'",
        "        import json",
        "        with open('.secrets-baseline.json') as f:",
        "            data = json.load(f)",
        "            results = data.get('results', {})",
        "            real_secrets = {k: v for k, v in results.items() if not k.startswith('tests/')}",
        "            if real_secrets:",
        "                print('⚠️ Potential secrets found in:')",
        "                for file in real_secrets:",
        "                    print(f'  - {file}')",
        "                print('Please review and ensure no real secrets are committed.')",
        "            else:",
        "                print('✅ No secrets detected in source files')",
        "        PYTHON_SCRIPT"
      ],
      "lines_removed": [
        "        python -c \"",
        "import json",
        "with open('.secrets-baseline.json') as f:",
        "    data = json.load(f)",
        "    results = data.get('results', {})",
        "    real_secrets = {k: v for k, v in results.items() if not k.startswith('tests/')}",
        "    if real_secrets:",
        "        print('⚠️ Potential secrets found in:')",
        "        for file in real_secrets:",
        "            print(f'  - {file}')",
        "        print('Please review and ensure no real secrets are committed.')",
        "    else:",
        "        print('✅ No secrets detected in source files')",
        "\""
      ],
      "context_before": [
        "        echo \"=== Running pip-audit Dependency Check ===\"",
        "        pip install -e \".[dev]\"",
        "        pip-audit --desc || echo \"⚠️ Review dependency vulnerabilities above\"",
        "",
        "    - name: Run detect-secrets (Secret Scanning)",
        "      run: |",
        "        echo \"=== Running detect-secrets ===\"",
        "        # Scan for accidentally committed secrets",
        "        detect-secrets scan --all-files --exclude-files '\\.git/.*' --exclude-files '.*\\.pkl' --exclude-files '.*\\.json' > .secrets-baseline.json || true",
        "        # Check if any high-entropy secrets were found (excluding test fixtures)"
      ],
      "context_after": [],
      "change_type": "modify"
    },
    {
      "file": "CLAUDE.md",
      "function": "class TestYourFeature(unittest.TestCase):",
      "start_line": 665,
      "lines_added": [
        "### Intentionally Skipped Tests",
        "",
        "Some tests are designed to skip under certain conditions. This is intentional, not a bug:",
        "",
        "| Test File | Skip Condition | Reason |",
        "|-----------|----------------|--------|",
        "| `tests/unit/test_protobuf_serialization.py` | `protobuf` not installed | Optional dependency for cross-language serialization |",
        "| `tests/test_evaluate_cluster.py` | `samples/` missing or < 5 files | Integration test requiring sample corpus |",
        "| `tests/unit/test_suggest_tasks.py` | `task_utils` not available | Optional task management feature |",
        "",
        "**Pattern for optional dependencies:**",
        "```python",
        "try:",
        "    from cortical.proto.serialization import to_proto, from_proto",
        "    PROTOBUF_AVAILABLE = True",
        "except ImportError:",
        "    PROTOBUF_AVAILABLE = False",
        "",
        "@unittest.skipIf(not PROTOBUF_AVAILABLE, \"protobuf package not installed\")",
        "class TestProtobufSerialization(unittest.TestCase):",
        "    ...",
        "```",
        "",
        "**Pattern for conditional resources:**",
        "```python",
        "def setUp(self):",
        "    if not os.path.exists(self.required_resource):",
        "        self.skipTest(\"Required resource not available\")",
        "```",
        ""
      ],
      "lines_removed": [],
      "context_before": [
        "| `fresh_processor` | function | Empty processor for isolated tests |",
        "| `small_corpus_docs` | function | Raw document dict |",
        "",
        "**Always test:**",
        "- Empty corpus case",
        "- Single document case",
        "- Multiple documents case",
        "- Edge cases specific to your feature",
        "- Add regression test if fixing a bug",
        ""
      ],
      "context_after": [
        "### CI/CD Best Practices",
        "",
        "**CRITICAL: Pytest runs unittest-based tests natively!**",
        "",
        "Never run both pytest and unittest on the same test files - this doubles CI time:",
        "",
        "```bash",
        "# ❌ WRONG - runs tests twice (doubles CI time from ~7min to ~15min+)",
        "coverage run -m pytest tests/",
        "coverage run --append -m unittest discover -s tests"
      ],
      "change_type": "add"
    },
    {
      "file": "tests/test_generate_ai_metadata.py",
      "function": "def test_func():",
      "start_line": 529,
      "lines_added": [
        "    def test_cortical_processor_package_metadata(self):",
        "        \"\"\"Test metadata generation for cortical/processor/ package modules.",
        "",
        "        Note: processor.py was refactored into processor/ package with mixins",
        "        as part of LEGACY-095. This test now checks the compute.py module",
        "        which contains the ComputeMixin class and compute_all method.",
        "        \"\"\"",
        "        # Test the compute module which has ComputeMixin and compute_all",
        "        compute_path = os.path.join(",
        "            '..', 'cortical', 'processor', 'compute.py'",
        "        if not os.path.exists(compute_path):",
        "            self.skipTest(\"processor/compute.py not found\")",
        "        analyzer = ModuleAnalyzer(compute_path)",
        "        # Should find the ComputeMixin class",
        "        self.assertIn('ComputeMixin', metadata['classes'])",
        "        # Should find compute_all method (may be listed as function or method)",
        "        self.assertTrue(",
        "            any('compute_all' in name for name in func_names),",
        "            f\"compute_all not found in functions: {func_names}\"",
        "        )",
        "        compute_all_keys = [k for k in func_names if 'compute_all' in k]",
        "        if compute_all_keys:",
        "            self.assertIn('complexity', metadata['functions'][compute_all_keys[0]])",
        "",
        "    def test_cortical_processor_documents_metadata(self):",
        "        \"\"\"Test metadata generation for processor/documents.py module.",
        "",
        "        This module contains DocumentsMixin with process_document method.",
        "        \"\"\"",
        "        documents_path = os.path.join(",
        "            os.path.dirname(__file__),",
        "            '..', 'cortical', 'processor', 'documents.py'",
        "        )",
        "",
        "        if not os.path.exists(documents_path):",
        "            self.skipTest(\"processor/documents.py not found\")",
        "",
        "        analyzer = ModuleAnalyzer(documents_path)",
        "        metadata = analyzer.generate_metadata()",
        "",
        "        # Should find the DocumentsMixin class",
        "        self.assertIn('DocumentsMixin', metadata['classes'])",
        "",
        "        # Should find process_document method",
        "        func_names = list(metadata['functions'].keys())",
        "        self.assertTrue(",
        "            any('process_document' in name for name in func_names),",
        "            f\"process_document not found in functions: {func_names}\"",
        "        )"
      ],
      "lines_removed": [
        "    def test_cortical_processor_metadata(self):",
        "        \"\"\"Test metadata generation for actual cortical/processor.py.\"\"\"",
        "        processor_path = os.path.join(",
        "            '..', 'cortical', 'processor.py'",
        "        if not os.path.exists(processor_path):",
        "            self.skipTest(\"processor.py not found\")",
        "        analyzer = ModuleAnalyzer(processor_path)",
        "        # Should find the main class",
        "        self.assertIn('CorticalTextProcessor', metadata['classes'])",
        "        # Should find key functions",
        "        self.assertTrue(any('process_document' in name for name in func_names))",
        "        self.assertTrue(any('compute_all' in name for name in func_names))",
        "        compute_all_key = [k for k in func_names if 'compute_all' in k][0]",
        "        self.assertIn('complexity', metadata['functions'][compute_all_key])"
      ],
      "context_before": [
        "        yaml_content = generate_metadata_for_file(self.test_file)",
        "",
        "        # Empty file still has 1 line (empty string split gives [''])",
        "        self.assertIn('lines: 1', yaml_content)",
        "        self.assertIn('functions: {}', yaml_content)",
        "",
        "",
        "class TestIntegration(unittest.TestCase):",
        "    \"\"\"Integration tests for the metadata generator.\"\"\"",
        ""
      ],
      "context_after": [
        "            os.path.dirname(__file__),",
        "        )",
        "",
        "",
        "        metadata = analyzer.generate_metadata()",
        "",
        "",
        "        func_names = list(metadata['functions'].keys())",
        "",
        "        # Should have complexity hints for expensive functions",
        "",
        "",
        "if __name__ == '__main__':",
        "    unittest.main()"
      ],
      "change_type": "modify"
    }
  ],
  "hour_of_day": 16,
  "day_of_week": "Sunday",
  "seconds_since_last_commit": -76605,
  "is_merge": true,
  "is_initial": false,
  "parent_count": 2,
  "session_id": null,
  "related_chats": [],
  "ci_result": null,
  "reverted": false,
  "amended": false
}