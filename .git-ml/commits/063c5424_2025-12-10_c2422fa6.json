{
  "hash": "063c542400da2bc562cb82b61e5f15df7a1c5e65",
  "message": "Add analogy completion using relation matching and vector arithmetic (Task 30)",
  "author": "Claude",
  "timestamp": "2025-12-10 00:28:53 +0000",
  "branch": "claude/multi-index-design-DvifZ",
  "files_changed": [
    "TASK_LIST.md",
    "cortical/processor.py",
    "cortical/query.py",
    "tests/test_processor.py"
  ],
  "insertions": 621,
  "deletions": 14,
  "hunks": [
    {
      "file": "TASK_LIST.md",
      "function": "graph = processor.export_conceptnet_json(",
      "start_line": 1057,
      "lines_added": [
        "**Files:** `cortical/query.py`, `cortical/processor.py`",
        "**Status:** [x] Completed",
        "**Solution Applied:**",
        "1. Added `find_relation_between()` helper function to find semantic relations between two terms",
        "2. Added `find_terms_with_relation()` helper to find terms connected by a specific relation type",
        "3. Added `complete_analogy()` function (~120 lines) with three strategies:",
        "   - **Relation matching**: Find a→b relation, apply to c",
        "   - **Vector arithmetic**: Use embeddings for a - b + c ≈ d",
        "   - **Pattern matching**: Use co-occurrence patterns as fallback",
        "4. Added `complete_analogy_simple()` lightweight version using only co-occurrence patterns",
        "5. Added processor wrapper methods: `complete_analogy()` and `complete_analogy_simple()`",
        "**Files Modified:**",
        "- `cortical/query.py` - Added helper functions and analogy completion (~180 lines)",
        "- `cortical/processor.py` - Added processor wrapper methods (~60 lines)",
        "- `tests/test_processor.py` - Added 14 tests for analogy completion",
        "",
        "**Usage:**",
        "# Full analogy completion with multiple strategies",
        "results = processor.complete_analogy(\"king\", \"queen\", \"man\", top_n=5)",
        "for term, score, method in results:",
        "    print(f\"  {term}: {score:.3f} ({method})\")",
        "",
        "# Simple version (co-occurrence only)",
        "results = processor.complete_analogy_simple(\"neural\", \"networks\", \"knowledge\")",
        "for term, score in results:",
        "    print(f\"  {term}: {score:.3f}\")",
        "",
        "# Control which strategies to use",
        "results = processor.complete_analogy(",
        "    \"neural\", \"networks\", \"knowledge\",",
        "    use_embeddings=True,   # Enable vector arithmetic",
        "    use_relations=True     # Enable relation matching",
        ")"
      ],
      "lines_removed": [
        "**Files:** `cortical/query.py`",
        "**Status:** [ ] Pending",
        "**Implementation Steps:**",
        "1. Add `complete_analogy(a, b, c)` function",
        "2. Find relation between a→b",
        "3. Apply same relation from c to find d",
        "4. Use graph embeddings + relation type matching",
        "5. Return top candidates with confidence",
        "**Example:**",
        "complete_analogy(\"neural\", \"networks\", \"knowledge\")",
        "# → \"graphs\" (both form compound technical terms)"
      ],
      "context_before": [
        "    max_nodes_per_layer=100       # Limit nodes per layer",
        ")",
        "",
        "# Open graph.json in D3.js, Cytoscape.js, or Gephi for visualization",
        "```",
        "",
        "---",
        "",
        "### 30. Add Analogy Completion",
        ""
      ],
      "context_after": [
        "",
        "**Problem:**",
        "ConceptNet enables analogy completion: \"king is to queen as man is to ?\" → \"woman\"",
        "This requires relation-aware vector arithmetic.",
        "",
        "",
        "```python",
        "```",
        "",
        "---",
        "",
        "## Code Review Concerns",
        "",
        "The following concerns were identified during code review and should be addressed in future iterations:",
        "",
        "### 31. Consider Splitting processor.py",
        ""
      ],
      "change_type": "modify"
    },
    {
      "file": "TASK_LIST.md",
      "function": "Semantic bonus is capped at 50% boost (`min(avg_semantic, 0.5)`). This is a reas",
      "start_line": 1159,
      "lines_added": [
        "| Low | Add analogy completion | ✅ Completed | ConceptNet |",
        "**ConceptNet Enhancement Completion:** 12/12 tasks (100%)",
        "Ran 321 tests in 0.280s"
      ],
      "lines_removed": [
        "| Low | Add analogy completion | ⏳ Pending | ConceptNet |",
        "**ConceptNet Enhancement Completion:** 11/12 tasks (92%)",
        "Ran 307 tests in 0.275s"
      ],
      "context_before": [
        "| **Critical** | **Add concept-level lateral connections** | ✅ Completed | **ConceptNet** |",
        "| **Critical** | **Add bigram lateral connections** | ✅ Completed | **ConceptNet** |",
        "| **High** | **Implement relation-weighted PageRank** | ✅ Completed | **ConceptNet** |",
        "| **High** | **Implement cross-layer PageRank propagation** | ✅ Completed | **ConceptNet** |",
        "| **High** | **Add typed edge storage** | ✅ Completed | **ConceptNet** |",
        "| Medium | Implement multi-hop semantic inference | ✅ Completed | ConceptNet |",
        "| Medium | Add relation path scoring | ✅ Completed | ConceptNet |",
        "| Medium | Implement concept inheritance | ✅ Completed | ConceptNet |",
        "| Low | Add commonsense relation extraction | ✅ Completed | ConceptNet |",
        "| Low | Visualize ConceptNet-style graph | ✅ Completed | ConceptNet |"
      ],
      "context_after": [
        "",
        "**Bug Fix Completion:** 7/7 tasks (100%)",
        "**RAG Enhancement Completion:** 8/8 tasks (100%)",
        "",
        "---",
        "",
        "## Test Results",
        "",
        "```",
        "OK",
        "```",
        "",
        "All tests passing as of 2025-12-10.",
        "",
        "---",
        "",
        "*Updated from code review on 2025-12-10*"
      ],
      "change_type": "modify"
    },
    {
      "file": "cortical/processor.py",
      "function": "class CorticalTextProcessor:",
      "start_line": 898,
      "lines_added": [
        "    def complete_analogy(",
        "        self,",
        "        term_a: str,",
        "        term_b: str,",
        "        term_c: str,",
        "        top_n: int = 5,",
        "        use_embeddings: bool = True,",
        "        use_relations: bool = True",
        "    ) -> List[Tuple[str, float, str]]:",
        "        \"\"\"",
        "        Complete an analogy: \"a is to b as c is to ?\"",
        "",
        "        Uses multiple strategies to find the best completion:",
        "        1. Relation matching: Find what relation connects a→b, then find terms",
        "           with the same relation from c",
        "        2. Vector arithmetic: Use embeddings to compute d = c + (b - a)",
        "        3. Pattern matching: Find terms that co-occur with c similarly to how",
        "           b co-occurs with a",
        "",
        "        Args:",
        "            term_a: First term of the known pair (e.g., \"king\")",
        "            term_b: Second term of the known pair (e.g., \"queen\")",
        "            term_c: First term of the query pair (e.g., \"man\")",
        "            top_n: Number of candidates to return",
        "            use_embeddings: Whether to use embedding-based completion",
        "            use_relations: Whether to use relation-based completion",
        "",
        "        Returns:",
        "            List of (candidate_term, confidence, method) tuples, where method",
        "            describes which approach found this candidate ('relation:IsA',",
        "            'embedding', 'pattern')",
        "",
        "        Example:",
        "            >>> processor.extract_corpus_semantics()",
        "            >>> processor.compute_graph_embeddings()",
        "            >>> results = processor.complete_analogy(\"neural\", \"networks\", \"knowledge\")",
        "            >>> for term, score, method in results:",
        "            ...     print(f\"{term}: {score:.3f} ({method})\")",
        "        \"\"\"",
        "        if not self.semantic_relations:",
        "            self.extract_corpus_semantics(verbose=False)",
        "",
        "        return query_module.complete_analogy(",
        "            term_a, term_b, term_c,",
        "            self.layers,",
        "            self.semantic_relations,",
        "            embeddings=self.embeddings,",
        "            top_n=top_n,",
        "            use_embeddings=use_embeddings,",
        "            use_relations=use_relations",
        "        )",
        "",
        "    def complete_analogy_simple(",
        "        self,",
        "        term_a: str,",
        "        term_b: str,",
        "        term_c: str,",
        "        top_n: int = 5",
        "    ) -> List[Tuple[str, float]]:",
        "        \"\"\"",
        "        Simplified analogy completion using only term relationships.",
        "",
        "        A lighter version that doesn't require embeddings. Uses bigram patterns",
        "        and co-occurrence to find analogies.",
        "",
        "        Args:",
        "            term_a: First term of the known pair",
        "            term_b: Second term of the known pair",
        "            term_c: First term of the query pair",
        "            top_n: Number of candidates to return",
        "",
        "        Returns:",
        "            List of (candidate_term, confidence) tuples",
        "",
        "        Example:",
        "            >>> results = processor.complete_analogy_simple(\"neural\", \"networks\", \"knowledge\")",
        "            >>> for term, score in results:",
        "            ...     print(f\"{term}: {score:.3f}\")",
        "        \"\"\"",
        "        return query_module.complete_analogy_simple(",
        "            term_a, term_b, term_c,",
        "            self.layers,",
        "            self.tokenizer,",
        "            semantic_relations=self.semantic_relations,",
        "            top_n=top_n",
        "        )",
        ""
      ],
      "lines_removed": [],
      "context_before": [
        "    ",
        "    def find_similar_by_embedding(self, term: str, top_n: int = 10) -> List[Tuple[str, float]]:",
        "        return emb_module.find_similar_by_embedding(self.embeddings, term, top_n)",
        "    ",
        "    def expand_query(self, query_text: str, max_expansions: int = 10, use_variants: bool = True, verbose: bool = False) -> Dict[str, float]:",
        "        return query_module.expand_query(query_text, self.layers, self.tokenizer, max_expansions=max_expansions, use_variants=use_variants)",
        "    ",
        "    def expand_query_semantic(self, query_text: str, max_expansions: int = 10) -> Dict[str, float]:",
        "        return query_module.expand_query_semantic(query_text, self.layers, self.tokenizer, self.semantic_relations, max_expansions)",
        ""
      ],
      "context_after": [
        "    def expand_query_multihop(",
        "        self,",
        "        query_text: str,",
        "        max_hops: int = 2,",
        "        max_expansions: int = 15,",
        "        decay_factor: float = 0.5,",
        "        min_path_score: float = 0.2",
        "    ) -> Dict[str, float]:",
        "        \"\"\"",
        "        Expand query using multi-hop semantic inference."
      ],
      "change_type": "add"
    },
    {
      "file": "cortical/query.py",
      "function": "def multi_stage_rank_documents(",
      "start_line": 1173,
      "lines_added": [
        "",
        "",
        "def find_relation_between(",
        "    term_a: str,",
        "    term_b: str,",
        "    semantic_relations: List[Tuple[str, str, str, float]]",
        ") -> List[Tuple[str, float]]:",
        "    \"\"\"",
        "    Find semantic relations between two terms.",
        "",
        "    Args:",
        "        term_a: Source term",
        "        term_b: Target term",
        "        semantic_relations: List of (t1, relation, t2, weight) tuples",
        "",
        "    Returns:",
        "        List of (relation_type, weight) tuples",
        "    \"\"\"",
        "    relations = []",
        "    for t1, rel_type, t2, weight in semantic_relations:",
        "        if t1 == term_a and t2 == term_b:",
        "            relations.append((rel_type, weight))",
        "        elif t2 == term_a and t1 == term_b:",
        "            # Reverse direction",
        "            relations.append((rel_type, weight * 0.9))  # Slight penalty for reverse",
        "",
        "    return sorted(relations, key=lambda x: x[1], reverse=True)",
        "",
        "",
        "def find_terms_with_relation(",
        "    term: str,",
        "    relation_type: str,",
        "    semantic_relations: List[Tuple[str, str, str, float]],",
        "    direction: str = 'forward'",
        ") -> List[Tuple[str, float]]:",
        "    \"\"\"",
        "    Find terms connected to a given term by a specific relation type.",
        "",
        "    Args:",
        "        term: Source term",
        "        relation_type: Type of relation to follow",
        "        semantic_relations: List of (t1, relation, t2, weight) tuples",
        "        direction: 'forward' (term→x) or 'backward' (x→term)",
        "",
        "    Returns:",
        "        List of (target_term, weight) tuples",
        "    \"\"\"",
        "    results = []",
        "    for t1, rel_type, t2, weight in semantic_relations:",
        "        if rel_type != relation_type:",
        "            continue",
        "",
        "        if direction == 'forward' and t1 == term:",
        "            results.append((t2, weight))",
        "        elif direction == 'backward' and t2 == term:",
        "            results.append((t1, weight))",
        "",
        "    return sorted(results, key=lambda x: x[1], reverse=True)",
        "",
        "",
        "def complete_analogy(",
        "    term_a: str,",
        "    term_b: str,",
        "    term_c: str,",
        "    layers: Dict[CorticalLayer, HierarchicalLayer],",
        "    semantic_relations: List[Tuple[str, str, str, float]],",
        "    embeddings: Optional[Dict[str, List[float]]] = None,",
        "    top_n: int = 5,",
        "    use_embeddings: bool = True,",
        "    use_relations: bool = True",
        ") -> List[Tuple[str, float, str]]:",
        "    \"\"\"",
        "    Complete an analogy: \"a is to b as c is to ?\"",
        "",
        "    Uses multiple strategies to find the best completion:",
        "    1. Relation matching: Find what relation connects a→b, then find terms with",
        "       the same relation from c",
        "    2. Vector arithmetic: Use embeddings to compute d = c + (b - a)",
        "    3. Pattern matching: Find terms that co-occur with c similar to how b co-occurs with a",
        "",
        "    Example:",
        "        \"neural\" is to \"networks\" as \"knowledge\" is to ?",
        "        → \"graphs\" (both form compound technical terms with similar structure)",
        "",
        "    Args:",
        "        term_a: First term of the known pair",
        "        term_b: Second term of the known pair",
        "        term_c: First term of the query pair",
        "        layers: Dictionary of layers",
        "        semantic_relations: List of (t1, relation, t2, weight) tuples",
        "        embeddings: Optional graph embeddings for vector arithmetic",
        "        top_n: Number of candidates to return",
        "        use_embeddings: Whether to use embedding-based completion",
        "        use_relations: Whether to use relation-based completion",
        "",
        "    Returns:",
        "        List of (candidate_term, confidence, method) tuples, where method describes",
        "        which approach found this candidate ('relation', 'embedding', 'pattern')",
        "    \"\"\"",
        "    layer0 = layers[CorticalLayer.TOKENS]",
        "    candidates: Dict[str, Tuple[float, str]] = {}  # term → (score, method)",
        "",
        "    # Check that terms exist",
        "    if not layer0.get_minicolumn(term_a) or not layer0.get_minicolumn(term_b):",
        "        return []",
        "    if not layer0.get_minicolumn(term_c):",
        "        return []",
        "",
        "    # Strategy 1: Relation-based completion",
        "    if use_relations and semantic_relations:",
        "        # Find relation between a and b",
        "        relations_ab = find_relation_between(term_a, term_b, semantic_relations)",
        "",
        "        for rel_type, rel_weight in relations_ab:",
        "            # Find terms with same relation from c",
        "            c_targets = find_terms_with_relation(",
        "                term_c, rel_type, semantic_relations, direction='forward'",
        "            )",
        "",
        "            for target, target_weight in c_targets:",
        "                # Don't include the input terms",
        "                if target in {term_a, term_b, term_c}:",
        "                    continue",
        "",
        "                score = rel_weight * target_weight",
        "                if target not in candidates or candidates[target][0] < score:",
        "                    candidates[target] = (score, f'relation:{rel_type}')",
        "",
        "    # Strategy 2: Embedding-based completion (vector arithmetic)",
        "    if use_embeddings and embeddings:",
        "        if term_a in embeddings and term_b in embeddings and term_c in embeddings:",
        "            vec_a = embeddings[term_a]",
        "            vec_b = embeddings[term_b]",
        "            vec_c = embeddings[term_c]",
        "",
        "            # d = c + (b - a)  (the analogy vector)",
        "            vec_d = [",
        "                c + (b - a)",
        "                for a, b, c in zip(vec_a, vec_b, vec_c)",
        "            ]",
        "",
        "            # Find nearest terms to vec_d",
        "            best_matches = []",
        "            for term, vec in embeddings.items():",
        "                if term in {term_a, term_b, term_c}:",
        "                    continue",
        "",
        "                # Cosine similarity",
        "                dot = sum(d * v for d, v in zip(vec_d, vec))",
        "                mag_d = sum(d * d for d in vec_d) ** 0.5",
        "                mag_v = sum(v * v for v in vec) ** 0.5",
        "",
        "                if mag_d > 0 and mag_v > 0:",
        "                    similarity = dot / (mag_d * mag_v)",
        "                    best_matches.append((term, similarity))",
        "",
        "            # Sort by similarity and add to candidates",
        "            best_matches.sort(key=lambda x: x[1], reverse=True)",
        "            for term, sim in best_matches[:top_n * 2]:",
        "                if sim > 0.5:  # Only include reasonably similar terms",
        "                    if term not in candidates or candidates[term][0] < sim:",
        "                        candidates[term] = (sim, 'embedding')",
        "",
        "    # Strategy 3: Pattern matching (co-occurrence structure)",
        "    col_a = layer0.get_minicolumn(term_a)",
        "    col_b = layer0.get_minicolumn(term_b)",
        "    col_c = layer0.get_minicolumn(term_c)",
        "",
        "    if col_a and col_b and col_c:",
        "        # Find terms that relate to c similarly to how b relates to a",
        "        # I.e., if b co-occurs strongly with a, find terms that co-occur strongly with c",
        "",
        "        a_neighbors = set(col_a.lateral_connections.keys())",
        "        c_neighbors = set(col_c.lateral_connections.keys())",
        "",
        "        # Look at c's neighbors that aren't a's neighbors (new context)",
        "        for neighbor_id in c_neighbors:",
        "            neighbor = layer0.get_by_id(neighbor_id)",
        "            if not neighbor:",
        "                continue",
        "",
        "            term = neighbor.content",
        "            if term in {term_a, term_b, term_c}:",
        "                continue",
        "",
        "            # Score based on how similar the neighbor's connection to c is",
        "            # compared to b's connection to a",
        "            c_weight = col_c.lateral_connections.get(neighbor_id, 0)",
        "            b_to_a_weight = col_a.lateral_connections.get(col_b.id, 0)",
        "",
        "            if c_weight > 0 and b_to_a_weight > 0:",
        "                # The term should have similar connection strength pattern",
        "                score = min(c_weight, b_to_a_weight) * 0.5",
        "                if score > 0.1:",
        "                    if term not in candidates or candidates[term][0] < score:",
        "                        candidates[term] = (score, 'pattern')",
        "",
        "    # Sort and return top candidates",
        "    results = [",
        "        (term, score, method)",
        "        for term, (score, method) in candidates.items()",
        "    ]",
        "    results.sort(key=lambda x: x[1], reverse=True)",
        "",
        "    return results[:top_n]",
        "",
        "",
        "def complete_analogy_simple(",
        "    term_a: str,",
        "    term_b: str,",
        "    term_c: str,",
        "    layers: Dict[CorticalLayer, HierarchicalLayer],",
        "    tokenizer: Tokenizer,",
        "    semantic_relations: Optional[List[Tuple[str, str, str, float]]] = None,",
        "    top_n: int = 5",
        ") -> List[Tuple[str, float]]:",
        "    \"\"\"",
        "    Simplified analogy completion using only term relationships.",
        "",
        "    A lighter version of complete_analogy that doesn't require embeddings.",
        "    Uses bigram patterns and co-occurrence to find analogies.",
        "",
        "    Example:",
        "        \"neural\" is to \"networks\" as \"knowledge\" is to ?",
        "        → Looks for terms that form similar bigrams with \"knowledge\"",
        "",
        "    Args:",
        "        term_a: First term of the known pair",
        "        term_b: Second term of the known pair",
        "        term_c: First term of the query pair",
        "        layers: Dictionary of layers",
        "        tokenizer: Tokenizer instance",
        "        semantic_relations: Optional semantic relations",
        "        top_n: Number of candidates to return",
        "",
        "    Returns:",
        "        List of (candidate_term, confidence) tuples",
        "    \"\"\"",
        "    layer0 = layers[CorticalLayer.TOKENS]",
        "    layer1 = layers.get(CorticalLayer.BIGRAMS)",
        "",
        "    candidates: Dict[str, float] = {}",
        "",
        "    col_a = layer0.get_minicolumn(term_a)",
        "    col_b = layer0.get_minicolumn(term_b)",
        "    col_c = layer0.get_minicolumn(term_c)",
        "",
        "    if not col_a or not col_b or not col_c:",
        "        return []",
        "",
        "    # Strategy 1: Bigram pattern matching",
        "    if layer1:",
        "        # Find bigrams containing a_b pattern",
        "        ab_bigram = f\"{term_a}_{term_b}\"",
        "        ba_bigram = f\"{term_b}_{term_a}\"",
        "",
        "        ab_col = layer1.get_minicolumn(ab_bigram)",
        "        ba_col = layer1.get_minicolumn(ba_bigram)",
        "",
        "        # If a_b is a bigram, look for c_? bigrams",
        "        if ab_col or ba_col:",
        "            for bigram_col in layer1.minicolumns.values():",
        "                bigram = bigram_col.content",
        "                parts = bigram.split('_')",
        "                if len(parts) != 2:",
        "                    continue",
        "",
        "                first, second = parts",
        "",
        "                # Look for bigrams starting with c",
        "                if first == term_c and second not in {term_a, term_b, term_c}:",
        "                    score = bigram_col.pagerank * 0.8",
        "                    if second not in candidates or candidates[second] < score:",
        "                        candidates[second] = score",
        "",
        "                # Look for bigrams ending with c",
        "                if second == term_c and first not in {term_a, term_b, term_c}:",
        "                    score = bigram_col.pagerank * 0.6",
        "                    if first not in candidates or candidates[first] < score:",
        "                        candidates[first] = score",
        "",
        "    # Strategy 2: Co-occurrence similarity",
        "    # Find terms that co-occur with c like b co-occurs with a",
        "    a_neighbors = col_a.lateral_connections",
        "    c_neighbors = col_c.lateral_connections",
        "",
        "    for neighbor_id, c_weight in c_neighbors.items():",
        "        neighbor = layer0.get_by_id(neighbor_id)",
        "        if not neighbor:",
        "            continue",
        "",
        "        term = neighbor.content",
        "        if term in {term_a, term_b, term_c}:",
        "            continue",
        "",
        "        # Check if this term has similar connection pattern",
        "        score = c_weight * 0.3",
        "        if score > 0.05:",
        "            candidates[term] = candidates.get(term, 0) + score",
        "",
        "    # Strategy 3: Semantic relations (if available)",
        "    if semantic_relations:",
        "        relations_ab = find_relation_between(term_a, term_b, semantic_relations)",
        "        for rel_type, rel_weight in relations_ab[:2]:  # Top 2 relations",
        "            c_targets = find_terms_with_relation(",
        "                term_c, rel_type, semantic_relations, direction='forward'",
        "            )",
        "            for target, target_weight in c_targets[:3]:  # Top 3 targets",
        "                if target not in {term_a, term_b, term_c}:",
        "                    score = rel_weight * target_weight",
        "                    candidates[target] = candidates.get(target, 0) + score",
        "",
        "    # Sort and return",
        "    results = sorted(candidates.items(), key=lambda x: x[1], reverse=True)",
        "    return results[:top_n]"
      ],
      "lines_removed": [],
      "context_before": [
        "",
        "        stage_scores = {",
        "            'concept_score': concept_score,",
        "            'tfidf_score': tfidf_score,",
        "            'combined_score': combined",
        "        }",
        "        results.append((doc_id, combined, stage_scores))",
        "",
        "    results.sort(key=lambda x: x[1], reverse=True)",
        "    return results[:top_n]"
      ],
      "context_after": [],
      "change_type": "add"
    },
    {
      "file": "tests/test_processor.py",
      "function": "class TestMultiHopPathScoring(unittest.TestCase):",
      "start_line": 1854,
      "lines_added": [
        "class TestAnalogyCompletion(unittest.TestCase):",
        "    \"\"\"Test analogy completion functionality.\"\"\"",
        "",
        "    @classmethod",
        "    def setUpClass(cls):",
        "        \"\"\"Set up processor with documents for analogy testing.\"\"\"",
        "        cls.processor = CorticalTextProcessor()",
        "        # Create a corpus with semantic structure for analogies",
        "        cls.processor.process_document(\"doc1\", \"\"\"",
        "            Neural networks are powerful machine learning models.",
        "            Deep learning uses neural networks for complex tasks.",
        "            Knowledge graphs store semantic relationships.",
        "        \"\"\")",
        "        cls.processor.process_document(\"doc2\", \"\"\"",
        "            Machine learning algorithms process data efficiently.",
        "            Pattern recognition helps with image classification.",
        "            Data processing transforms raw information.",
        "        \"\"\")",
        "        cls.processor.process_document(\"doc3\", \"\"\"",
        "            Artificial intelligence enables intelligent systems.",
        "            Natural language processing understands text.",
        "            Computer vision analyzes images and video.",
        "        \"\"\")",
        "        cls.processor.compute_all(verbose=False)",
        "        cls.processor.extract_corpus_semantics(verbose=False)",
        "        cls.processor.compute_graph_embeddings(dimensions=16, verbose=False)",
        "",
        "    def test_complete_analogy_returns_list(self):",
        "        \"\"\"Test that complete_analogy returns a list.\"\"\"",
        "        results = self.processor.complete_analogy(",
        "            \"neural\", \"networks\", \"machine\"",
        "        )",
        "        self.assertIsInstance(results, list)",
        "",
        "    def test_complete_analogy_result_format(self):",
        "        \"\"\"Test that results have correct format (term, score, method).\"\"\"",
        "        results = self.processor.complete_analogy(",
        "            \"neural\", \"networks\", \"machine\", top_n=3",
        "        )",
        "",
        "        for result in results:",
        "            self.assertEqual(len(result), 3)",
        "            term, score, method = result",
        "            self.assertIsInstance(term, str)",
        "            self.assertIsInstance(score, float)",
        "            self.assertIsInstance(method, str)",
        "            self.assertGreater(score, 0)",
        "",
        "    def test_complete_analogy_excludes_input_terms(self):",
        "        \"\"\"Test that input terms are excluded from results.\"\"\"",
        "        results = self.processor.complete_analogy(",
        "            \"neural\", \"networks\", \"machine\"",
        "        )",
        "",
        "        result_terms = [term for term, _, _ in results]",
        "        self.assertNotIn(\"neural\", result_terms)",
        "        self.assertNotIn(\"networks\", result_terms)",
        "        self.assertNotIn(\"machine\", result_terms)",
        "",
        "    def test_complete_analogy_top_n_limit(self):",
        "        \"\"\"Test that top_n limits the number of results.\"\"\"",
        "        results_3 = self.processor.complete_analogy(",
        "            \"neural\", \"networks\", \"machine\", top_n=3",
        "        )",
        "        results_5 = self.processor.complete_analogy(",
        "            \"neural\", \"networks\", \"machine\", top_n=5",
        "        )",
        "",
        "        self.assertLessEqual(len(results_3), 3)",
        "        self.assertLessEqual(len(results_5), 5)",
        "",
        "    def test_complete_analogy_unknown_term(self):",
        "        \"\"\"Test handling of unknown terms.\"\"\"",
        "        results = self.processor.complete_analogy(",
        "            \"xyznonexistent\", \"abcnonexistent\", \"machine\"",
        "        )",
        "        self.assertEqual(results, [])",
        "",
        "    def test_complete_analogy_with_embeddings_only(self):",
        "        \"\"\"Test analogy completion using only embeddings.\"\"\"",
        "        results = self.processor.complete_analogy(",
        "            \"neural\", \"networks\", \"machine\",",
        "            use_embeddings=True,",
        "            use_relations=False",
        "        )",
        "        self.assertIsInstance(results, list)",
        "",
        "    def test_complete_analogy_with_relations_only(self):",
        "        \"\"\"Test analogy completion using only relations.\"\"\"",
        "        results = self.processor.complete_analogy(",
        "            \"neural\", \"networks\", \"machine\",",
        "            use_embeddings=False,",
        "            use_relations=True",
        "        )",
        "        self.assertIsInstance(results, list)",
        "",
        "    def test_complete_analogy_simple_returns_list(self):",
        "        \"\"\"Test that complete_analogy_simple returns a list.\"\"\"",
        "        results = self.processor.complete_analogy_simple(",
        "            \"neural\", \"networks\", \"machine\"",
        "        )",
        "        self.assertIsInstance(results, list)",
        "",
        "    def test_complete_analogy_simple_format(self):",
        "        \"\"\"Test that simple results have correct format (term, score).\"\"\"",
        "        results = self.processor.complete_analogy_simple(",
        "            \"neural\", \"networks\", \"machine\", top_n=3",
        "        )",
        "",
        "        for result in results:",
        "            self.assertEqual(len(result), 2)",
        "            term, score = result",
        "            self.assertIsInstance(term, str)",
        "            self.assertIsInstance(score, float)",
        "",
        "    def test_complete_analogy_simple_excludes_input(self):",
        "        \"\"\"Test that input terms are excluded from simple results.\"\"\"",
        "        results = self.processor.complete_analogy_simple(",
        "            \"neural\", \"networks\", \"machine\"",
        "        )",
        "",
        "        result_terms = [term for term, _ in results]",
        "        self.assertNotIn(\"neural\", result_terms)",
        "        self.assertNotIn(\"networks\", result_terms)",
        "        self.assertNotIn(\"machine\", result_terms)",
        "",
        "",
        "class TestAnalogyHelperFunctions(unittest.TestCase):",
        "    \"\"\"Test analogy helper functions.\"\"\"",
        "",
        "    def test_find_relation_between(self):",
        "        \"\"\"Test finding relations between terms.\"\"\"",
        "        from cortical.query import find_relation_between",
        "",
        "        relations = [",
        "            (\"dog\", \"IsA\", \"animal\", 1.0),",
        "            (\"cat\", \"IsA\", \"animal\", 1.0),",
        "            (\"dog\", \"HasProperty\", \"loyal\", 0.8),",
        "        ]",
        "",
        "        result = find_relation_between(\"dog\", \"animal\", relations)",
        "        self.assertEqual(len(result), 1)",
        "        self.assertEqual(result[0][0], \"IsA\")",
        "",
        "    def test_find_relation_between_no_match(self):",
        "        \"\"\"Test finding relations with no match.\"\"\"",
        "        from cortical.query import find_relation_between",
        "",
        "        relations = [",
        "            (\"dog\", \"IsA\", \"animal\", 1.0),",
        "        ]",
        "",
        "        result = find_relation_between(\"cat\", \"animal\", relations)",
        "        self.assertEqual(len(result), 0)",
        "",
        "    def test_find_terms_with_relation(self):",
        "        \"\"\"Test finding terms with specific relation.\"\"\"",
        "        from cortical.query import find_terms_with_relation",
        "",
        "        relations = [",
        "            (\"dog\", \"IsA\", \"animal\", 1.0),",
        "            (\"cat\", \"IsA\", \"animal\", 0.9),",
        "            (\"bird\", \"IsA\", \"animal\", 0.8),",
        "        ]",
        "",
        "        result = find_terms_with_relation(\"animal\", \"IsA\", relations, direction='backward')",
        "        self.assertEqual(len(result), 3)",
        "        # Should be sorted by weight",
        "        self.assertEqual(result[0][0], \"dog\")",
        "",
        "    def test_find_terms_with_relation_forward(self):",
        "        \"\"\"Test finding terms with forward relation.\"\"\"",
        "        from cortical.query import find_terms_with_relation",
        "",
        "        relations = [",
        "            (\"dog\", \"HasProperty\", \"loyal\", 1.0),",
        "            (\"dog\", \"HasProperty\", \"friendly\", 0.8),",
        "        ]",
        "",
        "        result = find_terms_with_relation(\"dog\", \"HasProperty\", relations, direction='forward')",
        "        self.assertEqual(len(result), 2)",
        "",
        ""
      ],
      "lines_removed": [],
      "context_before": [
        "        self.assertEqual(score, 0.4)  # Default moderate validity",
        "",
        "    def test_valid_relation_chains_constant(self):",
        "        \"\"\"Test that VALID_RELATION_CHAINS is defined.\"\"\"",
        "        from cortical.query import VALID_RELATION_CHAINS",
        "        self.assertIsInstance(VALID_RELATION_CHAINS, dict)",
        "        self.assertIn(('IsA', 'IsA'), VALID_RELATION_CHAINS)",
        "        self.assertIn(('PartOf', 'PartOf'), VALID_RELATION_CHAINS)",
        "",
        ""
      ],
      "context_after": [
        "if __name__ == \"__main__\":",
        "    unittest.main(verbosity=2)"
      ],
      "change_type": "add"
    }
  ],
  "hour_of_day": 0,
  "day_of_week": "Wednesday",
  "seconds_since_last_commit": -479755,
  "is_merge": false,
  "is_initial": false,
  "parent_count": 1,
  "session_id": null,
  "related_chats": [],
  "ci_result": null,
  "reverted": false,
  "amended": false
}