{
  "hash": "d647b5363e7b221d8459a10188f55cdbbc33e97e",
  "message": "feat: Add memory system CLI and improve documentation",
  "author": "Claude",
  "timestamp": "2025-12-14 18:12:01 +0000",
  "branch": "claude/multi-index-design-DvifZ",
  "files_changed": [
    "CLAUDE.md",
    "README.md",
    "scripts/index_codebase.py",
    "scripts/new_memory.py",
    "scripts/search_codebase.py"
  ],
  "insertions": 477,
  "deletions": 16,
  "hunks": [
    {
      "file": "CLAUDE.md",
      "function": "ls cortical/*.ai_meta",
      "start_line": 78,
      "lines_added": [
        "# Get structured overview of any module (processor is now a package)",
        "cat cortical/processor/__init__.py.ai_meta"
      ],
      "lines_removed": [
        "# Get structured overview of any module",
        "cat cortical/processor.py.ai_meta"
      ],
      "context_before": [
        "",
        "# If not present, generate it (~1s)",
        "python scripts/generate_ai_metadata.py",
        "```",
        "",
        "### Step 2: Read Module Metadata First",
        "",
        "Instead of reading entire source files, start with `.ai_meta` files:",
        "",
        "```bash"
      ],
      "context_after": [
        "```",
        "",
        "**What metadata provides:**",
        "- Module docstring and purpose",
        "- Function signatures with `see_also` cross-references",
        "- Class structures with inheritance",
        "- Logical section groupings (Persistence, Query, Analysis, etc.)",
        "- Complexity hints for expensive operations",
        "",
        "### Step 3: Use the Full Toolchain"
      ],
      "change_type": "modify"
    },
    {
      "file": "CLAUDE.md",
      "function": "python scripts/search_codebase.py \"your query here\"",
      "start_line": 111,
      "lines_added": [
        "cat cortical/query/__init__.py.ai_meta | head -100    # Get overview (query is a package)"
      ],
      "lines_removed": [
        "cat cortical/query.py.ai_meta | head -100    # Get overview"
      ],
      "context_before": [
        "1. **Read `.ai_meta` before source code** - Get the map before exploring the territory",
        "2. **Follow `see_also` references** - Functions are cross-linked to related functions",
        "3. **Check `complexity_hints`** - Know which operations are expensive before calling them",
        "4. **Use semantic search** - The codebase is indexed for meaning-based retrieval",
        "5. **Trust the sections** - Functions are grouped by purpose in the metadata",
        "",
        "### Example Workflow",
        "",
        "```bash",
        "# I need to understand how search works"
      ],
      "context_after": [
        "python scripts/search_codebase.py \"expand query\"  # Find specific code",
        "# Then read specific line ranges as needed",
        "```",
        "",
        "---",
        "",
        "## Architecture Map",
        "",
        "```",
        "cortical/"
      ],
      "change_type": "modify"
    },
    {
      "file": "CLAUDE.md",
      "function": "tests/",
      "start_line": 237,
      "lines_added": [
        "| Intent queries | `tests/unit/test_query.py` |"
      ],
      "lines_removed": [
        "| Intent queries | `tests/test_intent_query.py` |"
      ],
      "context_before": [
        "| Persistence/save/load | `tests/test_persistence.py` |",
        "| Tokenization | `tests/test_tokenizer.py` |",
        "| Configuration | `tests/test_config.py` |",
        "| Layers | `tests/test_layers.py` |",
        "| Embeddings | `tests/test_embeddings.py` |",
        "| Gap detection | `tests/test_gaps.py` |",
        "| Fingerprinting | `tests/test_fingerprint.py` |",
        "| Code concepts | `tests/test_code_concepts.py` |",
        "| Chunk indexing | `tests/test_chunk_indexing.py` |",
        "| Incremental updates | `tests/test_incremental_indexing.py` |"
      ],
      "context_after": [
        "",
        "**Running Tests:**",
        "",
        "```bash",
        "# Quick feedback during development",
        "python scripts/run_tests.py smoke        # ~1s - sanity check",
        "python scripts/run_tests.py quick        # smoke + unit",
        "",
        "# Before committing",
        "python scripts/run_tests.py precommit    # smoke + unit + integration"
      ],
      "change_type": "modify"
    },
    {
      "file": "CLAUDE.md",
      "function": "Key defaults to know:",
      "start_line": 538,
      "lines_added": [
        "   # In processor/core.py, add constant:"
      ],
      "lines_removed": [
        "   # In processor.py, add constant:"
      ],
      "context_before": [
        "3. **Build a complete picture** before running fixes",
        "4. **Document findings** - create tasks with `scripts/new_task.py` even if they contradict hypotheses",
        "",
        "### When Implementing Features",
        "",
        "1. **Follow existing patterns** - this codebase is consistent",
        "2. **Add type hints** - the codebase uses them extensively",
        "3. **Write docstrings** - Google style with Args/Returns sections",
        "4. **Update staleness tracking** if adding new computation:",
        "   ```python"
      ],
      "context_after": [
        "   COMP_YOUR_FEATURE = 'your_feature'",
        "   # Mark stale in _mark_all_stale()",
        "   # Mark fresh after computation",
        "   ```",
        "",
        "### After Writing Code",
        "",
        "1. **Run the full test suite**:",
        "   ```bash",
        "   python -m unittest discover -s tests -v"
      ],
      "change_type": "modify"
    },
    {
      "file": "CLAUDE.md",
      "function": "coverage run -m pytest tests/",
      "start_line": 739,
      "lines_added": [
        "2. Add wrapper method to `CorticalTextProcessor` in the `processor/` package (appropriate mixin):",
        "1. Add to the `query/` package following existing patterns (e.g., `query/search.py`)",
        "4. Add wrapper to the `processor/` package (likely `processor/query_api.py`)"
      ],
      "lines_removed": [
        "2. Add wrapper method to `CorticalTextProcessor` in `processor.py`:",
        "1. Add to `query.py` following existing patterns",
        "4. Add wrapper to `processor.py`"
      ],
      "context_before": [
        "   def compute_your_analysis(",
        "       layers: Dict[CorticalLayer, HierarchicalLayer],",
        "       **kwargs",
        "   ) -> Dict[str, Any]:",
        "       \"\"\"Your analysis description.\"\"\"",
        "       layer0 = layers[CorticalLayer.TOKENS]",
        "       # Implementation",
        "       return {'result': ..., 'stats': ...}",
        "   ```",
        ""
      ],
      "context_after": [
        "   ```python",
        "   def compute_your_analysis(self, **kwargs) -> Dict[str, Any]:",
        "       \"\"\"Wrapper with docstring.\"\"\"",
        "       return compute_your_analysis(self.layers, **kwargs)",
        "   ```",
        "",
        "3. Add tests in `tests/test_analysis.py`",
        "",
        "### Adding a New Query Function",
        "",
        "2. Use `get_expanded_query_terms()` helper for query expansion",
        "3. Use `layer.get_by_id()` for O(1) lookups, not iteration",
        "5. Add tests in `tests/test_processor.py`",
        "",
        "### Modifying Minicolumn Structure",
        "",
        "1. Update `Minicolumn` class in `minicolumn.py`",
        "2. Update `to_dict()` and `from_dict()` for persistence",
        "3. Update `__slots__` if adding new fields",
        "4. Increment state version in `persistence.py` if breaking change",
        "5. Add migration logic for backward compatibility",
        ""
      ],
      "change_type": "modify"
    },
    {
      "file": "CLAUDE.md",
      "function": "When completing a task, consider creating a memory entry from the retrospective:",
      "start_line": 1154,
      "lines_added": [
        "- **Main API**: `cortical/processor/` - `CorticalTextProcessor` class (split into mixins)",
        "- **Search**: `cortical/query/` - query expansion, document retrieval (split into 8 modules)"
      ],
      "lines_removed": [
        "- **Main API**: `cortical/processor.py` - `CorticalTextProcessor` class",
        "- **Search**: `cortical/query.py` - query expansion, document retrieval"
      ],
      "context_before": [
        "- What was learned?",
        "- What connections were made?",
        "- What should future developers know?",
        "",
        "See `docs/text-as-memories.md` for the full guide.",
        "",
        "---",
        "",
        "## File Quick Links",
        ""
      ],
      "context_after": [
        "- **Graph algorithms**: `cortical/analysis.py` - PageRank, TF-IDF, clustering",
        "- **Data structures**: `cortical/minicolumn.py` - `Minicolumn`, `Edge`",
        "- **Configuration**: `cortical/config.py` - `CorticalConfig` dataclass",
        "- **Tests**: `tests/test_processor.py` - most comprehensive test file",
        "- **Demo**: `showcase.py` - interactive demonstration",
        "",
        "**Process Documentation:**",
        "- **Getting Started**: `docs/quickstart.md` - 5-minute tutorial for newcomers",
        "- **Contributing**: `CONTRIBUTING.md` - how to contribute (fork, test, PR workflow)",
        "- **Ethics**: `docs/code-of-ethics.md` - documentation, testing, and completion standards",
        "- **Dog-fooding**: `docs/dogfooding-checklist.md` - checklist for testing with real usage"
      ],
      "change_type": "modify"
    },
    {
      "file": "README.md",
      "function": null,
      "start_line": 1,
      "lines_added": [
        "![Tests](https://img.shields.io/badge/tests-2941%20passing-brightgreen.svg)",
        "No PyTorch. No transformers. No API keys. Just 2900+ tests, 19,000+ lines of pure Python, and a data structure that would make a neuroscientist squint approvingly."
      ],
      "lines_removed": [
        "![Tests](https://img.shields.io/badge/tests-1121%20passing-brightgreen.svg)",
        "No PyTorch. No transformers. No API keys. Just 337 tests, 7000 lines of pure Python, and a data structure that would make a neuroscientist squint approvingly."
      ],
      "context_before": [
        "# Cortical Text Processor",
        "",
        "![Python 3.8+](https://img.shields.io/badge/python-3.8%2B-blue.svg)",
        "![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)"
      ],
      "context_after": [
        "![Coverage](https://img.shields.io/badge/coverage-%3E89%25-brightgreen.svg)",
        "![Zero Dependencies](https://img.shields.io/badge/dependencies-zero-orange.svg)",
        "",
        "A neocortex-inspired text processing library with **zero external dependencies** for semantic analysis, document retrieval, and knowledge gap detection.",
        "",
        "---",
        "",
        "> *\"What if we built a text search engine the way evolution built a brain?\"*",
        "",
        "Your visual cortex doesn't grep through pixels looking for cats. It builds hierarchies—edges become patterns, patterns become shapes, shapes become objects. This library applies the same principle to text.",
        "",
        "Feed it documents. It tokenizes them into \"minicolumns\" (Layer 0), connects co-occurring words through Hebbian learning (\"neurons that fire together, wire together\"), clusters them into concepts (Layer 2), and links documents by shared meaning (Layer 3). The result: a graph that understands your corpus well enough to expand queries, complete analogies, and tell you where your knowledge has gaps.",
        "",
        "",
        "---",
        "",
        "## Overview",
        "",
        "This library provides a biologically-inspired approach to text processing, organizing information through a hierarchical structure similar to the visual cortex:",
        "",
        "| Layer | Name | Analogy | Purpose |",
        "|-------|------|---------|---------|",
        "| 0 | Tokens | V1 (edges) | Individual words |"
      ],
      "change_type": "modify"
    },
    {
      "file": "README.md",
      "function": "processor.compute_all(",
      "start_line": 219,
      "lines_added": [
        "| Test coverage | 2900+ tests passing |"
      ],
      "lines_removed": [
        "| Test coverage | 337 tests passing |"
      ],
      "context_before": [
        "## Performance",
        "",
        "Tested with 92 sample documents covering topics from neural networks to medieval falconry to sourdough breadmaking.",
        "",
        "| Metric | Value |",
        "|--------|-------|",
        "| Documents processed | 92 |",
        "| Token minicolumns | 6,506 |",
        "| Bigram minicolumns | 20,114 |",
        "| Lateral connections | 116,332 |"
      ],
      "context_after": [
        "| Graph algorithms | O(1) ID lookups |",
        "",
        "**What the processor discovers:**",
        "- Most central concept: `data` (PageRank: 0.0046)",
        "- Most distinctive terms: `gradient`, `pagerank`, `patent` (high TF-IDF, rare but meaningful)",
        "- Most connected document: `comprehensive_machine_learning` (91 connections to other docs)",
        "- Isolated outliers detected: `sumo_wrestling`, `medieval_falconry` (low similarity to corpus)",
        "",
        "## Package Structure",
        ""
      ],
      "change_type": "modify"
    },
    {
      "file": "README.md",
      "function": "cortical/",
      "start_line": 247,
      "lines_added": [
        "tests/               # 2900+ comprehensive tests"
      ],
      "lines_removed": [
        "tests/               # 337 comprehensive tests"
      ],
      "context_before": [
        "├── analysis.py      # PageRank, TF-IDF, cross-layer propagation",
        "├── semantics.py     # Semantic extraction, inference, analogy",
        "├── embeddings.py    # Graph embeddings with retrofitting",
        "├── query.py         # Search, retrieval, batch processing",
        "├── gaps.py          # Gap detection and anomalies",
        "└── persistence.py   # Save/load with full state",
        "",
        "evaluation/",
        "└── evaluator.py     # Evaluation framework",
        ""
      ],
      "context_after": [
        "showcase.py          # Interactive demonstration (run it!)",
        "samples/             # 92 documents: from quantum computing to cheese affinage",
        "```",
        "",
        "## AI Agent Support",
        "",
        "This project includes tools designed specifically for AI coding assistants:",
        "",
        "### AI Metadata Files (`.ai_meta`)",
        ""
      ],
      "change_type": "modify"
    },
    {
      "file": "README.md",
      "function": "Three Claude Code skills are available in `.claude/skills/`:",
      "start_line": 291,
      "lines_added": [
        "## Text-as-Memories System",
        "",
        "Capture and organize institutional knowledge alongside your code:",
        "",
        "- **Daily Memories** (`samples/memories/YYYY-MM-DD-*.md`) - Learning entries",
        "- **Decision Records** (`samples/decisions/adr-*.md`) - Architectural decisions",
        "- **Concept Documents** - Consolidated knowledge on topics",
        "",
        "```bash",
        "# Create a memory entry",
        "python scripts/new_memory.py \"What I learned about validation\"",
        "",
        "# Create a decision record",
        "python scripts/new_memory.py \"Use JSON over pickle\" --decision",
        "```",
        "",
        "See [docs/text-as-memories.md](docs/text-as-memories.md) for the complete guide.",
        ""
      ],
      "lines_removed": [],
      "context_before": [
        "| `corpus-indexer` | Index/re-index after code changes |",
        "| `ai-metadata` | View and use module metadata |",
        "",
        "### For AI Agents",
        "",
        "See the **AI Agent Onboarding** section in [CLAUDE.md](CLAUDE.md) for:",
        "- Step-by-step setup guide",
        "- Navigation tips for efficient exploration",
        "- Example workflow using metadata",
        ""
      ],
      "context_after": [
        "## Development History",
        "",
        "This project evolved through systematic improvements:",
        "",
        "1. **Initial Release**: Core hierarchical text processing",
        "2. **Code Review & Fixes**: TF-IDF calculation, O(1) lookups, type annotations",
        "3. **RAG Enhancements**: Chunk-level retrieval, metadata support, concept clustering",
        "4. **ConceptNet Integration**: Typed edges, relation-weighted PageRank, multi-hop inference",
        "5. **Connection Strategies**: Multiple strategies for Layer 2 concept connections",
        "6. **Showcase & Polish**: Interactive demo with real corpus analysis"
      ],
      "change_type": "add"
    },
    {
      "file": "README.md",
      "function": "python -m unittest discover -s tests -v",
      "start_line": 391,
      "lines_added": [
        "## Contributing",
        "",
        "We welcome contributions! Please see [CONTRIBUTING.md](CONTRIBUTING.md) for:",
        "- Development setup and workflow",
        "- Code style and testing requirements",
        "- Pull request guidelines",
        "",
        "Quality resources:",
        "- [Definition of Done](docs/definition-of-done.md)",
        "- [Code of Ethics](docs/code-of-ethics.md)",
        ""
      ],
      "lines_removed": [],
      "context_before": [
        "   ```",
        "",
        "3. **For maximum security**: Never load pickle files from:",
        "   - Downloaded files from the internet",
        "   - User uploads",
        "   - Shared network locations with untrusted access",
        "   - Email attachments",
        "",
        "See [Python's pickle documentation](https://docs.python.org/3/library/pickle.html) for more details on pickle security.",
        ""
      ],
      "context_after": [
        "## License",
        "",
        "MIT License"
      ],
      "change_type": "add"
    },
    {
      "file": "scripts/index_codebase.py",
      "function": "def get_doc_files(base_path: Path) -> list:",
      "start_line": 1322,
      "lines_added": [
        "    # Memory documents in samples/memories/",
        "    memories_dir = base_path / 'samples' / 'memories'",
        "    if memories_dir.exists():",
        "        for md_file in memories_dir.glob('*.md'):",
        "            files.append(md_file)",
        "",
        "    # Decision records in samples/decisions/",
        "    decisions_dir = base_path / 'samples' / 'decisions'",
        "    if decisions_dir.exists():",
        "        for md_file in decisions_dir.glob('*.md'):",
        "            files.append(md_file)",
        ""
      ],
      "lines_removed": [],
      "context_before": [
        "        doc_path = base_path / doc",
        "        if doc_path.exists():",
        "            files.append(doc_path)",
        "",
        "    # Intelligence documentation in docs/",
        "    docs_dir = base_path / 'docs'",
        "    if docs_dir.exists():",
        "        for md_file in docs_dir.glob('*.md'):",
        "            files.append(md_file)",
        ""
      ],
      "context_after": [
        "    return files",
        "",
        "",
        "def create_doc_id(file_path: Path, base_path: Path) -> str:",
        "    \"\"\"Create a document ID from file path.\"\"\"",
        "    rel_path = file_path.relative_to(base_path)",
        "    return str(rel_path)",
        "",
        "",
        "def extract_markdown_headings(content: str) -> List[str]:"
      ],
      "change_type": "add"
    },
    {
      "file": "scripts/index_codebase.py",
      "function": "def extract_markdown_headings(content: str) -> List[str]:",
      "start_line": 1344,
      "lines_added": [
        "        One of: 'code', 'test', 'docs', 'root_docs', 'memory', 'decision', 'concept'",
        "    elif doc_id.startswith('samples/memories/'):",
        "        # Check if it's a concept doc",
        "        filename = doc_id.split('/')[-1]",
        "        if filename.startswith('concept-'):",
        "            return 'concept'",
        "        return 'memory'",
        "    elif doc_id.startswith('samples/decisions/'):",
        "        return 'decision'"
      ],
      "lines_removed": [
        "        One of: 'code', 'test', 'docs', 'root_docs'"
      ],
      "context_before": [
        "    # Match ## and ### headings (skip # as it's usually the title)",
        "    headings = re.findall(r'^##+ (.+)$', content, re.MULTILINE)",
        "    return headings",
        "",
        "",
        "def get_doc_type(doc_id: str) -> str:",
        "    \"\"\"",
        "    Determine document type from document ID.",
        "",
        "    Returns:"
      ],
      "context_after": [
        "    \"\"\"",
        "    if doc_id.startswith('tests/'):",
        "        return 'test'",
        "    elif doc_id.startswith('docs/'):",
        "        return 'docs'",
        "    elif doc_id.endswith('.md'):",
        "        return 'root_docs'",
        "    else:",
        "        return 'code'",
        "",
        "",
        "def _extract_file_metadata(",
        "    doc_id: str,"
      ],
      "change_type": "modify"
    },
    {
      "file": "scripts/new_memory.py",
      "function": null,
      "start_line": 0,
      "lines_added": [
        "#!/usr/bin/env python3",
        "\"\"\"",
        "Quick memory and decision record creation from command line.",
        "",
        "Usage:",
        "    # Create a memory entry (interactive prompts)",
        "    python scripts/new_memory.py",
        "",
        "    # Create with title",
        "    python scripts/new_memory.py \"dogfooding session insights\"",
        "",
        "    # Create with tags",
        "    python scripts/new_memory.py \"fuzzing discoveries\" --tags \"security,testing,fuzzing\"",
        "",
        "    # Create a decision record",
        "    python scripts/new_memory.py \"use microseconds in task IDs\" --decision",
        "",
        "    # Dry-run to preview",
        "    python scripts/new_memory.py \"test topic\" --dry-run",
        "",
        "Examples:",
        "    $ python scripts/new_memory.py \"learned about NaN validation\" --tags \"testing,validation\"",
        "    Created: samples/memories/2025-12-14_14-30-52_a1b2-nan-validation.md",
        "",
        "    $ python scripts/new_memory.py \"add microseconds to timestamps\" --decision",
        "    Created: samples/decisions/2025-12-14_14-31-15_c3d4-microseconds-timestamps.md",
        "\"\"\"",
        "",
        "import argparse",
        "import os",
        "import sys",
        "import subprocess",
        "from datetime import datetime",
        "from pathlib import Path",
        "",
        "# Add scripts to path",
        "sys.path.insert(0, str(Path(__file__).parent))",
        "",
        "from task_utils import generate_session_id",
        "",
        "",
        "# Directories for memories and decisions",
        "MEMORIES_DIR = Path(\"samples/memories\")",
        "DECISIONS_DIR = Path(\"samples/decisions\")",
        "",
        "",
        "def get_git_author() -> str:",
        "    \"\"\"Get git author name from config.\"\"\"",
        "    try:",
        "        result = subprocess.run(",
        "            [\"git\", \"config\", \"user.name\"],",
        "            capture_output=True,",
        "            text=True,",
        "            timeout=2",
        "        )",
        "        if result.returncode == 0:",
        "            return result.stdout.strip()",
        "    except (subprocess.TimeoutExpired, FileNotFoundError):",
        "        pass",
        "    return \"Unknown\"",
        "",
        "",
        "def slugify(text: str) -> str:",
        "    \"\"\"Convert text to URL-friendly slug.\"\"\"",
        "    # Simple slugification: lowercase, replace spaces with hyphens",
        "    slug = text.lower().strip()",
        "    slug = slug.replace(\" \", \"-\")",
        "    # Remove non-alphanumeric except hyphens",
        "    slug = \"\".join(c for c in slug if c.isalnum() or c == \"-\")",
        "    # Remove duplicate hyphens",
        "    while \"--\" in slug:",
        "        slug = slug.replace(\"--\", \"-\")",
        "    # Truncate to reasonable length",
        "    return slug[:50]",
        "",
        "",
        "def generate_memory_filename(title: str, is_decision: bool = False) -> str:",
        "    \"\"\"",
        "    Generate merge-safe filename with timestamp and session ID.",
        "",
        "    Format: YYYY-MM-DD_HH-MM-SS_XXXX-topic.md",
        "",
        "    Args:",
        "        title: Topic or title of the memory/decision",
        "        is_decision: If True, generates a decision record filename",
        "",
        "    Returns:",
        "        Filename string",
        "    \"\"\"",
        "    now = datetime.now()",
        "    date_str = now.strftime(\"%Y-%m-%d\")",
        "    time_str = now.strftime(\"%H-%M-%S\")",
        "    session_id = generate_session_id()",
        "    slug = slugify(title)",
        "",
        "    return f\"{date_str}_{time_str}_{session_id}-{slug}.md\"",
        "",
        "",
        "def create_memory_template(title: str, tags: str = \"\", author: str = \"\") -> str:",
        "    \"\"\"",
        "    Create a memory entry template.",
        "",
        "    Args:",
        "        title: Memory title/topic",
        "        tags: Comma-separated tags",
        "        author: Git author name",
        "",
        "    Returns:",
        "        Markdown template string",
        "    \"\"\"",
        "    now = datetime.now()",
        "    date_str = now.strftime(\"%Y-%m-%d\")",
        "    timestamp = now.strftime(\"%Y-%m-%dT%H:%M:%SZ\")",
        "",
        "    # Format tags",
        "    tag_list = \"\"",
        "    if tags:",
        "        tag_items = [f\"`{t.strip()}`\" for t in tags.split(\",\")]",
        "        tag_list = \", \".join(tag_items)",
        "",
        "    template = f\"\"\"# Memory Entry: {date_str} {title.title()}",
        "",
        "**Tags:** {tag_list}",
        "**Related:** [[link-to-related-docs.md]]",
        "",
        "---",
        "",
        "## Context",
        "",
        "What prompted this memory entry?",
        "",
        "## What I Learned",
        "",
        "### 1. Key Insight",
        "",
        "Describe what you learned or discovered.",
        "",
        "### 2. Additional Findings",
        "",
        "Any other important learnings?",
        "",
        "## Connections Made",
        "",
        "- **Concept A → Concept B**: How are they related?",
        "- **Pattern → Implementation**: What patterns emerged?",
        "",
        "## Emotional State",
        "",
        "How did this work feel? What was satisfying or challenging?",
        "",
        "## Future Exploration",
        "",
        "- [ ] Follow-up item 1",
        "- [ ] Follow-up item 2",
        "",
        "## Artifacts Created",
        "",
        "- Files, tasks, or other outputs from this session",
        "",
        "---",
        "",
        "*Committed to memory at: {timestamp}*",
        "\"\"\"",
        "    return template",
        "",
        "",
        "def create_decision_template(title: str, tags: str = \"\", author: str = \"\") -> str:",
        "    \"\"\"",
        "    Create an ADR (Architecture Decision Record) template.",
        "",
        "    Args:",
        "        title: Decision title",
        "        tags: Comma-separated tags",
        "        author: Git author name",
        "",
        "    Returns:",
        "        Markdown template string",
        "    \"\"\"",
        "    now = datetime.now()",
        "    date_str = now.strftime(\"%Y-%m-%d\")",
        "",
        "    # Format tags",
        "    tag_list = \"\"",
        "    if tags:",
        "        tag_items = [f\"`{t.strip()}`\" for t in tags.split(\",\")]",
        "        tag_list = \", \".join(tag_items)",
        "",
        "    # Find next ADR number (simple approach - count existing files)",
        "    try:",
        "        existing = list(DECISIONS_DIR.glob(\"adr-*.md\"))",
        "        numbers = []",
        "        for f in existing:",
        "            parts = f.stem.split(\"-\")",
        "            if len(parts) >= 2 and parts[0] == \"adr\" and parts[1].isdigit():",
        "                numbers.append(int(parts[1]))",
        "        next_num = max(numbers) + 1 if numbers else 1",
        "    except:",
        "        next_num = 1",
        "",
        "    adr_id = f\"ADR-{next_num:03d}\"",
        "",
        "    template = f\"\"\"# {adr_id}: {title.title()}",
        "",
        "**Status:** Proposed",
        "**Date:** {date_str}",
        "**Deciders:** Development team",
        "**Tags:** {tag_list}",
        "",
        "---",
        "",
        "## Context and Problem Statement",
        "",
        "What is the problem we're trying to solve? What factors are influencing this decision?",
        "",
        "## Decision Drivers",
        "",
        "1. **Factor 1**: Description",
        "2. **Factor 2**: Description",
        "3. **Factor 3**: Description",
        "",
        "## Considered Options",
        "",
        "### Option 1: [Name]",
        "",
        "**Pros:**",
        "- Advantage 1",
        "- Advantage 2",
        "",
        "**Cons:**",
        "- Disadvantage 1",
        "- Disadvantage 2",
        "",
        "### Option 2: [Name]",
        "",
        "**Pros:**",
        "- Advantage 1",
        "",
        "**Cons:**",
        "- Disadvantage 1",
        "",
        "## Decision Outcome",
        "",
        "**Chosen Option:** Option X - [Name]",
        "",
        "**Rationale:**",
        "Explain why this option was chosen.",
        "",
        "## Implementation",
        "",
        "```python",
        "# Code example if applicable",
        "```",
        "",
        "## Consequences",
        "",
        "### Positive",
        "- Benefit 1",
        "- Benefit 2",
        "",
        "### Negative",
        "- Trade-off 1",
        "- Trade-off 2",
        "",
        "### Neutral",
        "- Other effects",
        "",
        "## Validation",
        "",
        "How will we verify this decision was correct?",
        "",
        "## Related Decisions",
        "",
        "- Link to related ADRs or documentation",
        "",
        "---",
        "",
        "*Decision recorded on: {date_str}*",
        "\"\"\"",
        "    return template",
        "",
        "",
        "def create_memory(",
        "    title: str,",
        "    tags: str = \"\",",
        "    is_decision: bool = False,",
        "    dry_run: bool = False",
        ") -> Path:",
        "    \"\"\"",
        "    Create a memory entry or decision record.",
        "",
        "    Args:",
        "        title: Title/topic of the memory",
        "        tags: Comma-separated tags",
        "        is_decision: If True, creates a decision record",
        "        dry_run: If True, only shows what would be created",
        "",
        "    Returns:",
        "        Path to created file (or would-be path in dry-run)",
        "    \"\"\"",
        "    # Determine directory and filename",
        "    target_dir = DECISIONS_DIR if is_decision else MEMORIES_DIR",
        "    filename = generate_memory_filename(title, is_decision)",
        "    filepath = target_dir / filename",
        "",
        "    # Get git author",
        "    author = get_git_author()",
        "",
        "    # Create template",
        "    if is_decision:",
        "        content = create_decision_template(title, tags, author)",
        "    else:",
        "        content = create_memory_template(title, tags, author)",
        "",
        "    if dry_run:",
        "        print(\"=== DRY RUN ===\")",
        "        print(f\"Would create: {filepath}\")",
        "        print(f\"\\nContent preview:\\n\")",
        "        print(content[:500] + \"...\" if len(content) > 500 else content)",
        "        return filepath",
        "",
        "    # Create directory if needed",
        "    target_dir.mkdir(parents=True, exist_ok=True)",
        "",
        "    # Write file",
        "    with open(filepath, \"w\") as f:",
        "        f.write(content)",
        "",
        "    return filepath",
        "",
        "",
        "def main():",
        "    parser = argparse.ArgumentParser(",
        "        description=\"Create merge-safe memory entries and decision records\",",
        "        formatter_class=argparse.RawDescriptionHelpFormatter,",
        "        epilog=__doc__",
        "    )",
        "",
        "    parser.add_argument(",
        "        \"title\",",
        "        nargs=\"?\",",
        "        help=\"Memory topic or decision title\"",
        "    )",
        "    parser.add_argument(",
        "        \"-d\", \"--decision\",",
        "        action=\"store_true\",",
        "        help=\"Create a decision record (ADR) instead of memory entry\"",
        "    )",
        "    parser.add_argument(",
        "        \"-t\", \"--tags\",",
        "        default=\"\",",
        "        help=\"Comma-separated tags (e.g., 'security,testing,fuzzing')\"",
        "    )",
        "    parser.add_argument(",
        "        \"--dry-run\",",
        "        action=\"store_true\",",
        "        help=\"Show what would be created without writing file\"",
        "    )",
        "",
        "    args = parser.parse_args()",
        "",
        "    # Ensure directories exist",
        "    MEMORIES_DIR.mkdir(parents=True, exist_ok=True)",
        "    DECISIONS_DIR.mkdir(parents=True, exist_ok=True)",
        "",
        "    if args.title:",
        "        filepath = create_memory(",
        "            title=args.title,",
        "            tags=args.tags,",
        "            is_decision=args.decision,",
        "            dry_run=args.dry_run",
        "        )",
        "",
        "        if not args.dry_run:",
        "            doc_type = \"Decision record\" if args.decision else \"Memory entry\"",
        "            print(f\"Created {doc_type}:\")",
        "            print(f\"  {filepath}\")",
        "            print(f\"\\nEdit with: $EDITOR {filepath}\")",
        "    else:",
        "        # Interactive mode",
        "        doc_type = \"decision record\" if args.decision else \"memory entry\"",
        "        print(f\"Create a new {doc_type} (Ctrl+C to cancel)\\n\")",
        "",
        "        title = input(\"Title/topic: \").strip()",
        "        if not title:",
        "            print(\"Title is required\")",
        "            return",
        "",
        "        tags = input(\"Tags (comma-separated, optional): \").strip()",
        "",
        "        filepath = create_memory(",
        "            title=title,",
        "            tags=tags,",
        "            is_decision=args.decision,",
        "            dry_run=args.dry_run",
        "        )",
        "",
        "        if not args.dry_run:",
        "            print(f\"\\nCreated {doc_type}:\")",
        "            print(f\"  {filepath}\")",
        "            print(f\"\\nEdit with: $EDITOR {filepath}\")",
        "",
        "",
        "if __name__ == \"__main__\":",
        "    main()"
      ],
      "lines_removed": [],
      "context_before": [],
      "context_after": [],
      "change_type": "add"
    },
    {
      "file": "scripts/search_codebase.py",
      "function": "def format_passage(passage: str, max_width: int = 80) -> str:",
      "start_line": 39,
      "lines_added": [
        "    if doc_id.startswith('samples/memories/'):",
        "        # Check if it's a concept doc",
        "        filename = doc_id.split('/')[-1]",
        "        if filename.startswith('concept-'):",
        "            return 'CON'",
        "        return 'MEM'",
        "    elif doc_id.startswith('samples/decisions/'):",
        "        return 'ADR'",
        "    elif doc_id.endswith('.md'):"
      ],
      "lines_removed": [
        "    if doc_id.endswith('.md'):"
      ],
      "context_before": [
        "        if len(line) > max_width:",
        "            line = line[:max_width - 3] + '...'",
        "        formatted.append(line)",
        "    if len(lines) > 10:",
        "        formatted.append(f'  ... ({len(lines) - 10} more lines)')",
        "    return '\\n'.join(formatted)",
        "",
        "",
        "def get_doc_type_label(doc_id: str) -> str:",
        "    \"\"\"Get a display label for document type.\"\"\""
      ],
      "context_after": [
        "        if doc_id.startswith('docs/'):",
        "            return 'DOCS'",
        "        return 'DOC'",
        "    elif doc_id.startswith('tests/'):",
        "        return 'TEST'",
        "    return 'CODE'",
        "",
        "",
        "def find_similar_code(",
        "    processor: CorticalTextProcessor,"
      ],
      "change_type": "modify"
    }
  ],
  "hour_of_day": 18,
  "day_of_week": "Sunday",
  "seconds_since_last_commit": -70367,
  "is_merge": false,
  "is_initial": false,
  "parent_count": 1,
  "session_id": null,
  "related_chats": [],
  "ci_result": null,
  "reverted": false,
  "amended": false
}