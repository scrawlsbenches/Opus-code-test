{
  "hash": "cd21b845bc7e30130f7c643140c008fe5ce03ab9",
  "message": "Merge pull request #6 from scrawlsbenches/claude/implement-next-task-0177breUUGneYQyAe5iVTsLE",
  "author": "scrawlsbenches",
  "timestamp": "2025-12-09 17:55:21 -0500",
  "branch": "claude/multi-index-design-DvifZ",
  "files_changed": [
    "TASK_LIST.md",
    "cortical/analysis.py",
    "cortical/minicolumn.py",
    "cortical/processor.py",
    "cortical/query.py",
    "tests/test_processor.py"
  ],
  "insertions": 2408,
  "deletions": 42,
  "hunks": [
    {
      "file": "TASK_LIST.md",
      "function": "for t, c in layer.minicolumns.items():",
      "start_line": 395,
      "lines_added": [
        "**Status:** [x] Completed",
        "**Solution Applied:**",
        "1. Added staleness tracking with `_stale_computations` set and computation type constants",
        "2. Added `add_document_incremental()` method with selectable recomputation levels:",
        "   - `'none'`: Just add document, mark computations stale (fastest)",
        "   - `'tfidf'`: Recompute TF-IDF only (good for search)",
        "   - `'full'`: Run full `compute_all()` (most accurate)",
        "3. Added `add_documents_batch()` for efficient batch additions with single recomputation",
        "4. Added `recompute()` method with levels: `'stale'`, `'tfidf'`, `'full'`",
        "5. Added helper methods: `is_stale()`, `get_stale_computations()`, `_mark_fresh()`, `_mark_all_stale()`",
        "**Files Modified:**",
        "- `cortical/processor.py` - Added incremental indexing methods (~200 lines)",
        "- `tests/test_processor.py` - Added 15 tests for incremental indexing",
        "",
        "**Usage Examples:**",
        "```python",
        "# Quick incremental update (TF-IDF only)",
        "processor.add_document_incremental(\"new_doc\", \"content\", recompute='tfidf')",
        "",
        "# Batch add with deferred recomputation",
        "processor.add_document_incremental(\"doc1\", \"content1\", recompute='none')",
        "processor.add_document_incremental(\"doc2\", \"content2\", recompute='none')",
        "processor.recompute(level='full')  # Single recomputation for batch",
        "",
        "# Efficient batch API",
        "docs = [(\"doc1\", \"content1\", {\"source\": \"web\"}), (\"doc2\", \"content2\", None)]",
        "processor.add_documents_batch(docs, recompute='full')",
        "```"
      ],
      "lines_removed": [
        "**Status:** [ ] Not Started",
        "**Implementation Steps:**",
        "1. Add `add_document_incremental()` method",
        "2. Support selective recomputation (TF-IDF only, or full)",
        "3. Track which computations are stale",
        "4. Allow batch updates with single recomputation",
        "**Files to Modify:**",
        "- `cortical/processor.py` - Add incremental method (~40 lines)"
      ],
      "context_before": [
        "",
        "# Should use:",
        "neighbor = layer.get_by_id(neighbor_id)",
        "```",
        "",
        "---",
        "",
        "### 15. Add Incremental Document Indexing",
        "",
        "**File:** `cortical/processor.py`"
      ],
      "context_after": [
        "",
        "**Problem:**",
        "Adding a document requires calling `compute_all()` which recomputes everything. For RAG systems with frequent updates, this is inefficient.",
        "",
        "",
        "",
        "---",
        "",
        "## RAG Low Priority",
        "",
        "### 16. Document Magic Numbers in Gap Detection",
        "",
        "**File:** `cortical/gaps.py`",
        "**Lines:** 62, 76, 99",
        "**Status:** [ ] Deferred (carried over)"
      ],
      "change_type": "modify"
    },
    {
      "file": "TASK_LIST.md",
      "function": "Adding a document requires calling `compute_all()` which recomputes everything.",
      "start_line": 430,
      "lines_added": [
        "**Files:** `cortical/query.py`, `cortical/processor.py`",
        "**Status:** [x] Completed",
        "Current ranking is flat (Token TF-IDF → Document Score). Better RAG performance with staged ranking.",
        "",
        "**Solution Applied:**",
        "Implemented a 4-stage ranking pipeline:",
        "",
        "1. **Stage 1 (Concepts):** Find relevant concepts from Layer 2 clusters, score by query term overlap",
        "2. **Stage 2 (Documents):** Rank documents using combined concept + TF-IDF scores",
        "3. **Stage 3 (Chunks):** Score passages within top documents using chunk-level TF-IDF",
        "4. **Stage 4 (Rerank):** Combine all signals (chunk 50%, TF-IDF 30%, concept 20%) for final scoring",
        "**Files Modified:**",
        "- `cortical/query.py` - Added `find_relevant_concepts()`, `multi_stage_rank()`, `multi_stage_rank_documents()` (~300 lines)",
        "- `cortical/processor.py` - Added processor wrapper methods (~90 lines)",
        "- `tests/test_processor.py` - Added 15 tests for multi-stage ranking",
        "",
        "**Usage Examples:**",
        "```python",
        "# Full 4-stage ranking (passages with stage breakdown)",
        "results = processor.multi_stage_rank(\"neural networks\", top_n=5, concept_boost=0.3)",
        "for passage, doc_id, start, end, score, stages in results:",
        "    print(f\"[{doc_id}] Score: {score:.3f}\")",
        "    print(f\"  Concept: {stages['concept_score']:.3f}\")",
        "    print(f\"  Doc: {stages['doc_score']:.3f}\")",
        "    print(f\"  Chunk: {stages['chunk_score']:.3f}\")",
        "",
        "# Document-level ranking (stages 1-2 only)",
        "results = processor.multi_stage_rank_documents(\"neural networks\", top_n=3)",
        "for doc_id, score, stages in results:",
        "    print(f\"{doc_id}: {score:.3f} (concept: {stages['concept_score']:.3f})\")",
        "```",
        "**Status:** [x] Completed",
        "**Solution Applied:**",
        "1. Added `find_documents_batch()` function to `query.py` with expansion caching",
        "2. Added `find_passages_batch()` function to `query.py` with chunk pre-computation",
        "3. Added corresponding methods to `CorticalTextProcessor`",
        "4. Both functions share tokenization and expansion caches across queries",
        "",
        "**Files Modified:**",
        "- `cortical/query.py` - Added batch query functions (~180 lines)",
        "- `cortical/processor.py` - Added processor wrapper methods (~90 lines)",
        "- `tests/test_processor.py` - Added 14 tests for batch query functionality",
        "",
        "**Usage Examples:**",
        "```python",
        "# Batch document search",
        "queries = [\"neural networks\", \"machine learning\", \"data processing\"]",
        "results = processor.find_documents_batch(queries, top_n=3)",
        "for query, docs in zip(queries, results):",
        "    print(f\"{query}: {[doc_id for doc_id, _ in docs]}\")",
        "",
        "# Batch passage search (for RAG)",
        "results = processor.find_passages_batch(queries, top_n=5, chunk_size=512)",
        "for query, passages in zip(queries, results):",
        "    print(f\"{query}: {len(passages)} passages found\")",
        "```",
        "",
        "---",
        "",
        "---",
        "",
        "# ConceptNet-Enhanced PageRank",
        "",
        "The following tasks implement a ConceptNet-like enhanced PageRank algorithm that leverages semantic relations, cross-layer connections, and typed edge weights for improved concept importance scoring.",
        "",
        "---",
        "",
        "## ConceptNet Critical Priority",
        "",
        "### 19. Build Cross-Layer Feedforward Connections",
        "",
        "**Files:** `cortical/analysis.py`, `cortical/processor.py`, `cortical/minicolumn.py`",
        "**Status:** [x] Completed",
        "",
        "**Problem:**",
        "Layers were isolated - concepts didn't connect back to their member tokens, and bigrams didn't link to component unigrams. This broke the hierarchical flow needed for cross-layer PageRank.",
        "",
        "**Solution Applied:**",
        "1. Added `feedforward_connections: Dict[str, float]` to Minicolumn (weighted links to lower layer)",
        "2. Added `feedback_connections: Dict[str, float]` to Minicolumn (weighted links to higher layer)",
        "3. Added helper methods: `add_feedforward_connection()`, `add_feedback_connection()`",
        "4. Updated bigram creation to link to component tokens with weight 1.0 per occurrence",
        "5. Updated document processing to create bidirectional doc↔token connections",
        "6. Updated concept creation to link to member tokens weighted by normalized PageRank",
        "7. Updated `to_dict()`/`from_dict()` for persistence",
        "",
        "**Files Modified:**",
        "- `cortical/minicolumn.py` - Added connection fields and helper methods (~50 lines)",
        "- `cortical/processor.py` - Populate feedforward/feedback during document processing",
        "- `cortical/analysis.py` - Updated `build_concept_clusters()` to create weighted links",
        "- `tests/test_processor.py` - Added 12 tests for cross-layer connections",
        "",
        "**Connection Types:**",
        "```python",
        "# Bigram → Tokens (weight by occurrence count)",
        "bigram.feedforward_connections[\"L0_neural\"] = 2.0  # seen twice",
        "",
        "# Token → Bigrams (feedback)",
        "token.feedback_connections[\"L1_neural_networks\"] = 2.0",
        "",
        "# Document → Tokens (weight by term frequency)",
        "doc.feedforward_connections[\"L0_neural\"] = 3.0  # appears 3 times",
        "",
        "# Concept → Tokens (weight by normalized PageRank)",
        "concept.feedforward_connections[\"L0_neural\"] = 1.0  # highest PR",
        "concept.feedforward_connections[\"L0_networks\"] = 0.7  # lower PR",
        "```",
        "",
        "---",
        "",
        "### 20. Add Concept-Level Lateral Connections",
        "",
        "**Files:** `cortical/analysis.py`, `cortical/processor.py`",
        "**Status:** [x] Completed",
        "",
        "**Problem:**",
        "Layer 2 (Concepts) had 0 lateral connections. Concept clusters should connect to each other based on shared documents and semantic overlap.",
        "",
        "**Solution Applied:**",
        "1. Added `compute_concept_connections()` function to `analysis.py`",
        "2. Connects concepts by Jaccard similarity of document sets",
        "3. Optionally boosts weights using semantic relations between member tokens",
        "4. Relation type weighting: IsA (1.5) > PartOf (1.3) > HasProperty (1.2) > RelatedTo (1.0)",
        "5. Called from `compute_all()` after `build_concept_clusters()`",
        "6. Added `compute_concept_connections()` method to processor with parameters",
        "",
        "**Files Modified:**",
        "- `cortical/analysis.py` - Added `compute_concept_connections()` (~110 lines)",
        "- `cortical/processor.py` - Added processor wrapper method, integrated into `compute_all()`",
        "- `tests/test_processor.py` - Added 8 tests for concept connections",
        "",
        "**Usage:**",
        "```python",
        "# Automatic in compute_all()",
        "processor.compute_all()  # Calls compute_concept_connections() automatically",
        "",
        "# Manual with options",
        "stats = processor.compute_concept_connections(",
        "    use_semantics=True,    # Boost weights with semantic relations",
        "    min_shared_docs=1,     # Minimum shared documents",
        "    min_jaccard=0.1        # Minimum Jaccard similarity",
        ")",
        "```",
        "",
        "---",
        "",
        "### 21. Add Bigram Lateral Connections",
        "",
        "**Files:** `cortical/analysis.py`, `cortical/processor.py`",
        "**Status:** [ ] Pending",
        "",
        "**Problem:**",
        "Layer 1 (Bigrams) has 0 lateral connections. Bigrams should connect when they:",
        "- Share a component term (\"neural_networks\" ↔ \"neural_processing\")",
        "- Co-occur in the same documents",
        "- Form chains (\"machine_learning\" ↔ \"learning_algorithms\")",
        "",
        "**Implementation Steps:**",
        "1. Add `compute_bigram_connections()` function to `analysis.py`",
        "2. Connect bigrams sharing a term (left or right component)",
        "3. Weight by co-occurrence count and component position",
        "4. Add document co-occurrence bonus",
        "5. Call from `compute_all()` after bigram layer is populated",
        "",
        "---",
        "",
        "## ConceptNet High Priority",
        "",
        "### 22. Implement Relation-Weighted PageRank",
        "",
        "**Files:** `cortical/analysis.py`",
        "**Status:** [ ] Pending",
        "",
        "**Problem:**",
        "Current PageRank treats all `lateral_connections` equally. ConceptNet-style PageRank should weight edges by semantic relation type.",
        "",
        "**Current PageRank:**",
        "```python",
        "for target_id, weight in col.lateral_connections.items():",
        "    # All weights treated the same",
        "```",
        "",
        "**Enhanced PageRank:**",
        "```python",
        "RELATION_WEIGHTS = {",
        "    'IsA': 1.5,        # Hypernym relationships are strong",
        "    'PartOf': 1.3,     # Meronym relationships",
        "    'HasProperty': 1.2,",
        "    'RelatedTo': 1.0,  # Default co-occurrence",
        "    'Antonym': 0.5,    # Opposing concepts",
        "}",
        "```",
        "",
        "**Implementation Steps:**",
        "1. Add `relation_type: str` field to connection edges (or use separate dict)",
        "2. Create `compute_semantic_pagerank()` function",
        "3. Apply relation-type multipliers during propagation",
        "4. Use semantic relations from `extract_corpus_semantics()` to label edges",
        "5. Add `pagerank_method` parameter to `compute_all()`: 'standard' | 'semantic'",
        "",
        "---",
        "",
        "### 23. Implement Cross-Layer PageRank Propagation",
        "",
        "**Files:** `cortical/analysis.py`",
        "**Status:** [ ] Pending",
        "",
        "**Problem:**",
        "PageRank only flows within a single layer. Importance should propagate across layers:",
        "- Important tokens boost their bigrams",
        "- Important bigrams boost their concepts",
        "- Important concepts boost their documents (and vice versa)",
        "",
        "**Implementation Steps:**",
        "1. Add `compute_hierarchical_pagerank()` function",
        "2. Iterate: compute layer-local PageRank, then propagate to adjacent layers",
        "3. Use `feedforward_connections` and `feedback_connections` for cross-layer flow",
        "4. Apply damping factor at layer boundaries (e.g., 0.7)",
        "5. Converge when cross-layer changes are minimal",
        "",
        "**Algorithm:**",
        "```",
        "for iteration in range(max_iterations):",
        "    for layer in [TOKENS, BIGRAMS, CONCEPTS, DOCUMENTS]:",
        "        compute_local_pagerank(layer)",
        "    propagate_up(TOKENS → BIGRAMS → CONCEPTS → DOCUMENTS)",
        "    propagate_down(DOCUMENTS → CONCEPTS → BIGRAMS → TOKENS)",
        "    if converged: break",
        "```",
        "",
        "---",
        "",
        "### 24. Add Typed Edge Storage",
        "",
        "**Files:** `cortical/minicolumn.py`, `cortical/analysis.py`",
        "**Status:** [ ] Pending",
        "",
        "**Problem:**",
        "`lateral_connections` only stores `{target_id: weight}`. ConceptNet-style graphs need edge metadata: relation type, confidence, source.",
        "",
        "**Current:**",
        "```python",
        "lateral_connections: Dict[str, float] = {}  # {id: weight}",
        "```",
        "",
        "**Enhanced:**",
        "```python",
        "@dataclass",
        "class Edge:",
        "    target_id: str",
        "    weight: float",
        "    relation_type: str = 'co_occurrence'",
        "    confidence: float = 1.0",
        "    source: str = 'corpus'  # 'corpus', 'semantic', 'inferred'",
        "",
        "typed_connections: Dict[str, Edge] = {}",
        "```",
        "",
        "**Implementation Steps:**",
        "1. Create `Edge` dataclass in `minicolumn.py`",
        "2. Add `typed_connections` field alongside `lateral_connections` (backward compat)",
        "3. Update connection-building code to populate edge metadata",
        "4. Update persistence to save/load typed connections",
        "5. Migrate algorithms to use typed connections when available",
        "",
        "---",
        "",
        "## ConceptNet Medium Priority",
        "",
        "### 25. Implement Multi-Hop Semantic Inference",
        "",
        "**Files:** `cortical/query.py`, `cortical/semantics.py`",
        "**Status:** [ ] Pending",
        "",
        "**Problem:**",
        "Query expansion only follows single-hop connections. ConceptNet enables multi-hop inference:",
        "- \"dog\" → IsA → \"animal\" → HasProperty → \"living\"",
        "- \"car\" → PartOf → \"engine\" → UsedFor → \"transportation\"",
        "",
        "**Implementation Steps:**",
        "1. Add `expand_query_multihop()` function to `query.py`",
        "2. Follow relation chains up to `max_hops` (default: 2)",
        "3. Decay weight by hop distance: `weight *= 0.5 ** hop`",
        "4. Filter by relation path validity (IsA chains are good, random walks less so)",
        "5. Use for enhanced document retrieval",
        "",
        "**Example:**",
        "```python",
        "expand_query_multihop(\"neural\", max_hops=2)",
        "# Hop 1: networks (co-occur), learning (co-occur), brain (RelatedTo)",
        "# Hop 2: deep (via learning), cortex (via brain), AI (via networks)",
        "```",
        "",
        "---",
        "",
        "### 26. Add Relation Path Scoring",
        "",
        "**Files:** `cortical/semantics.py`",
        "**Status:** [ ] Pending",
        "",
        "**Problem:**",
        "Not all relation paths are equally valid for inference. Need to score paths by semantic coherence.",
        "",
        "**Valid Paths:**",
        "- IsA → IsA (transitive hypernymy): \"poodle\" → \"dog\" → \"animal\" ✓",
        "- PartOf → HasA (part inheritance): \"wheel\" → \"car\" → \"engine\" ✓",
        "- RelatedTo → RelatedTo (association): loose but acceptable",
        "",
        "**Invalid Paths:**",
        "- Antonym → IsA: contradictory",
        "- Random oscillation: low confidence",
        "",
        "**Implementation Steps:**",
        "1. Create `VALID_RELATION_CHAINS` matrix defining allowed transitions",
        "2. Add `score_relation_path()` function",
        "3. Penalize invalid transitions, reward coherent chains",
        "4. Use in multi-hop expansion to filter low-quality paths",
        "",
        "---",
        "",
        "### 27. Implement Concept Inheritance",
        "",
        "**Files:** `cortical/analysis.py`, `cortical/semantics.py`",
        "**Status:** [ ] Pending",
        "",
        "**Problem:**",
        "IsA relations should enable property inheritance. If \"dog IsA animal\" and \"animal HasProperty living\", then \"dog\" should inherit \"living\".",
        "",
        "**Implementation Steps:**",
        "1. Build IsA hierarchy from semantic relations",
        "2. Add `inherit_properties()` function",
        "3. Propagate properties down IsA chains with decay",
        "4. Store inherited properties separately from direct properties",
        "5. Use inherited properties in similarity calculations",
        "",
        "---",
        "",
        "## ConceptNet Low Priority",
        "",
        "### 28. Add Commonsense Relation Extraction",
        "",
        "**Files:** `cortical/semantics.py`",
        "**Status:** [ ] Pending",
        "",
        "**Problem:**",
        "Current relation extraction is limited to co-occurrence patterns. Could extract richer relations:",
        "- \"X is a type of Y\" → IsA",
        "- \"X contains Y\" → HasA",
        "- \"X is used for Y\" → UsedFor",
        "- \"X causes Y\" → Causes",
        "",
        "**Implementation Steps:**",
        "1. Add pattern-based relation extraction",
        "2. Create regex/rule patterns for common relation expressions",
        "3. Extract during `extract_corpus_semantics()`",
        "4. Store relation type with confidence score",
        "5. Weight by pattern specificity",
        "",
        "---",
        "",
        "### 29. Visualize ConceptNet-Style Graph",
        "",
        "**Files:** `cortical/persistence.py`",
        "**Status:** [ ] Pending",
        "",
        "**Problem:**",
        "Current `export_graph_json()` doesn't distinguish edge types or layers. Need ConceptNet-style visualization export.",
        "",
        "**Implementation Steps:**",
        "1. Add `export_conceptnet_json()` function",
        "2. Include edge relation types and confidence",
        "3. Color-code by layer (tokens=blue, bigrams=green, concepts=orange, docs=red)",
        "4. Export in format compatible with graph visualization tools (D3.js, Cytoscape)",
        "5. Include cross-layer edges",
        "",
        "---",
        "",
        "### 30. Add Analogy Completion",
        "",
        "**Files:** `cortical/query.py`",
        "**Status:** [ ] Pending",
        "",
        "**Problem:**",
        "ConceptNet enables analogy completion: \"king is to queen as man is to ?\" → \"woman\"",
        "This requires relation-aware vector arithmetic.",
        "",
        "**Implementation Steps:**",
        "1. Add `complete_analogy(a, b, c)` function",
        "2. Find relation between a→b",
        "3. Apply same relation from c to find d",
        "4. Use graph embeddings + relation type matching",
        "5. Return top candidates with confidence",
        "",
        "**Example:**",
        "complete_analogy(\"neural\", \"networks\", \"knowledge\")",
        "# → \"graphs\" (both form compound technical terms)"
      ],
      "lines_removed": [
        "**Files:** `cortical/query.py`",
        "**Status:** [ ] Future Enhancement",
        "Current ranking is flat (Token TF-IDF → Document Score). Better RAG performance with staged ranking:",
        "1. **Stage 1 (Concepts):** Filter by topic relevance",
        "2. **Stage 2 (Documents):** Rank documents in topic",
        "3. **Stage 3 (Chunks):** Rank passages in documents",
        "4. **Stage 4 (Rerank):** Final relevance scoring",
        "**Status:** [ ] Future Enhancement",
        "**Implementation:**",
        "def find_documents_batch(self, queries: List[str], top_n: int = 5):",
        "    \"\"\"Process multiple queries efficiently.\"\"\"",
        "    # Batch tokenization",
        "    # Shared expansion cache",
        "    # Parallel scoring"
      ],
      "context_before": [
        "- `avg_sim < 0.02` - isolation threshold",
        "- `tfidf > 0.005` - weak topic threshold",
        "- `0.005 < sim < 0.03` - bridge opportunity range",
        "",
        "**Implementation:** Add docstrings or make configurable parameters.",
        "",
        "---",
        "",
        "### 17. Add Multi-Stage Ranking Pipeline",
        ""
      ],
      "context_after": [
        "",
        "**Problem:**",
        "",
        "",
        "---",
        "",
        "### 18. Add Batch Query API",
        "",
        "**Files:** `cortical/query.py`, `cortical/processor.py`",
        "",
        "**Problem:**",
        "No efficient way to run multiple queries. Each query repeats tokenization and expansion.",
        "",
        "```python",
        "```",
        "",
        "---",
        "",
        "## Summary",
        "",
        "| Priority | Task | Status | Category |",
        "|----------|------|--------|----------|",
        "| Critical | Fix TF-IDF per-doc calculation | ✅ Completed | Bug Fix |",
        "| High | Add ID lookup optimization | ✅ Completed | Bug Fix |"
      ],
      "change_type": "modify"
    },
    {
      "file": "TASK_LIST.md",
      "function": "def find_documents_batch(self, queries: List[str], top_n: int = 5):",
      "start_line": 479,
      "lines_added": [
        "| Medium | Add incremental indexing | ✅ Completed | RAG |",
        "| Low | Multi-stage ranking pipeline | ✅ Completed | RAG |",
        "| Low | Batch query API | ✅ Completed | RAG |",
        "| **Critical** | **Build cross-layer feedforward connections** | ✅ Completed | **ConceptNet** |",
        "| **Critical** | **Add concept-level lateral connections** | ✅ Completed | **ConceptNet** |",
        "| **Critical** | **Add bigram lateral connections** | ⏳ Pending | **ConceptNet** |",
        "| **High** | **Implement relation-weighted PageRank** | ⏳ Pending | **ConceptNet** |",
        "| **High** | **Implement cross-layer PageRank propagation** | ⏳ Pending | **ConceptNet** |",
        "| **High** | **Add typed edge storage** | ⏳ Pending | **ConceptNet** |",
        "| Medium | Implement multi-hop semantic inference | ⏳ Pending | ConceptNet |",
        "| Medium | Add relation path scoring | ⏳ Pending | ConceptNet |",
        "| Medium | Implement concept inheritance | ⏳ Pending | ConceptNet |",
        "| Low | Add commonsense relation extraction | ⏳ Pending | ConceptNet |",
        "| Low | Visualize ConceptNet-style graph | ⏳ Pending | ConceptNet |",
        "| Low | Add analogy completion | ⏳ Pending | ConceptNet |",
        "**RAG Enhancement Completion:** 8/8 tasks (100%)",
        "**ConceptNet Enhancement Completion:** 2/12 tasks (17%)",
        "Ran 193 tests in 0.162s"
      ],
      "lines_removed": [
        "| Medium | Add incremental indexing | ⬜ Not Started | RAG |",
        "| Low | Multi-stage ranking pipeline | ⬜ Future | RAG |",
        "| Low | Batch query API | ⬜ Future | RAG |",
        "**RAG Enhancement Completion:** 5/8 tasks (63%)",
        "Ran 129 tests in 0.152s"
      ],
      "context_before": [
        "| Medium | Remove unused import | ✅ Completed | Bug Fix |",
        "| Medium | Add verbose parameter | ✅ Completed | Bug Fix |",
        "| Low | Add test coverage | ✅ Completed | Bug Fix |",
        "| **Critical** | **Implement chunk-level retrieval** | ✅ Completed | **RAG** |",
        "| **Critical** | **Add document metadata support** | ✅ Completed | **RAG** |",
        "| **High** | **Activate Layer 2 concepts** | ✅ Completed | **RAG** |",
        "| **High** | **Integrate semantic relations** | ✅ Completed | **RAG** |",
        "| **High** | **Persist full computed state** | ✅ Completed | **RAG** |",
        "| Medium | Fix type annotation (embeddings.py) | ✅ Completed | Bug Fix |",
        "| Medium | Optimize spectral embeddings | ✅ Completed | Performance |"
      ],
      "context_after": [
        "| Low | Document magic numbers | ⏳ Deferred | Documentation |",
        "",
        "**Bug Fix Completion:** 7/7 tasks (100%)",
        "",
        "---",
        "",
        "## Test Results",
        "",
        "```",
        "OK",
        "```",
        "",
        "All tests passing as of 2025-12-09.",
        "",
        "---",
        "",
        "*Updated from code review on 2025-12-09*"
      ],
      "change_type": "modify"
    },
    {
      "file": "cortical/analysis.py",
      "function": "Analysis Module",
      "start_line": 5,
      "lines_added": [
        "from typing import Dict, List, Tuple, Set, Optional, Any"
      ],
      "lines_removed": [
        "from typing import Dict, List, Tuple, Set, Optional"
      ],
      "context_before": [
        "Graph analysis algorithms for the cortical network.",
        "",
        "Contains implementations of:",
        "- PageRank for importance scoring",
        "- TF-IDF for term weighting",
        "- Label propagation for clustering",
        "- Activation propagation for information flow",
        "\"\"\"",
        "",
        "import math"
      ],
      "context_after": [
        "from collections import defaultdict",
        "",
        "from .layers import CorticalLayer, HierarchicalLayer",
        "from .minicolumn import Minicolumn",
        "",
        "",
        "def compute_pagerank(",
        "    layer: HierarchicalLayer,",
        "    damping: float = 0.85,",
        "    iterations: int = 20,"
      ],
      "change_type": "modify"
    },
    {
      "file": "cortical/analysis.py",
      "function": "def build_concept_clusters(",
      "start_line": 305,
      "lines_added": [
        "        # Aggregate properties from members with weighted connections",
        "        max_pagerank = max(c.pagerank for c in member_cols) if member_cols else 1.0",
        "            # Weighted feedforward: concept → token (weight by normalized PageRank)",
        "            weight = col.pagerank / max_pagerank if max_pagerank > 0 else 1.0",
        "            concept.add_feedforward_connection(col.id, weight)",
        "            # Weighted feedback: token → concept (weight by normalized PageRank)",
        "            col.add_feedback_connection(concept.id, weight)",
        "",
        "def compute_concept_connections(",
        "    layers: Dict[CorticalLayer, HierarchicalLayer],",
        "    semantic_relations: List[Tuple[str, str, str, float]] = None,",
        "    min_shared_docs: int = 1,",
        "    min_jaccard: float = 0.1",
        ") -> Dict[str, Any]:",
        "    \"\"\"",
        "    Build lateral connections between concepts in Layer 2.",
        "",
        "    Concepts are connected based on:",
        "    1. Shared documents (Jaccard similarity of document sets)",
        "    2. Semantic relations between member tokens (if provided)",
        "",
        "    Args:",
        "        layers: Dictionary of all layers",
        "        semantic_relations: Optional list of (term1, relation, term2, weight) tuples",
        "        min_shared_docs: Minimum shared documents for connection",
        "        min_jaccard: Minimum Jaccard similarity threshold",
        "",
        "    Returns:",
        "        Statistics about connections created",
        "    \"\"\"",
        "    layer0 = layers[CorticalLayer.TOKENS]",
        "    layer2 = layers[CorticalLayer.CONCEPTS]",
        "",
        "    if layer2.column_count() == 0:",
        "        return {'connections_created': 0, 'concepts': 0}",
        "",
        "    concepts = list(layer2.minicolumns.values())",
        "    connections_created = 0",
        "",
        "    # Build semantic relation lookup for faster access",
        "    semantic_lookup: Dict[str, Dict[str, Tuple[str, float]]] = defaultdict(dict)",
        "    if semantic_relations:",
        "        for t1, relation, t2, weight in semantic_relations:",
        "            # Store relation in both directions",
        "            semantic_lookup[t1][t2] = (relation, weight)",
        "            semantic_lookup[t2][t1] = (relation, weight)",
        "",
        "    # Relation type weights for scoring",
        "    relation_weights = {",
        "        'IsA': 1.5,",
        "        'PartOf': 1.3,",
        "        'HasProperty': 1.2,",
        "        'RelatedTo': 1.0,",
        "        'Antonym': 0.3,",
        "    }",
        "",
        "    # Compare all concept pairs",
        "    for i, concept1 in enumerate(concepts):",
        "        docs1 = concept1.document_ids",
        "",
        "        for concept2 in concepts[i+1:]:",
        "            docs2 = concept2.document_ids",
        "",
        "            # Calculate Jaccard similarity of document sets",
        "            shared_docs = docs1 & docs2",
        "            union_docs = docs1 | docs2",
        "",
        "            if len(shared_docs) < min_shared_docs:",
        "                continue",
        "",
        "            jaccard = len(shared_docs) / len(union_docs) if union_docs else 0",
        "",
        "            if jaccard < min_jaccard:",
        "                continue",
        "",
        "            # Base weight from document overlap",
        "            weight = jaccard",
        "",
        "            # Add semantic relation bonus if available",
        "            if semantic_relations:",
        "                # Get member tokens for each concept",
        "                members1 = set()",
        "                for token_id in concept1.feedforward_connections:",
        "                    token = layer0.get_by_id(token_id)",
        "                    if token:",
        "                        members1.add(token.content)",
        "",
        "                members2 = set()",
        "                for token_id in concept2.feedforward_connections:",
        "                    token = layer0.get_by_id(token_id)",
        "                    if token:",
        "                        members2.add(token.content)",
        "",
        "                # Check for semantic relations between member tokens",
        "                semantic_bonus = 0.0",
        "                relation_count = 0",
        "                for m1 in members1:",
        "                    if m1 in semantic_lookup:",
        "                        for m2 in members2:",
        "                            if m2 in semantic_lookup[m1]:",
        "                                relation, rel_weight = semantic_lookup[m1][m2]",
        "                                rel_multiplier = relation_weights.get(relation, 1.0)",
        "                                semantic_bonus += rel_weight * rel_multiplier",
        "                                relation_count += 1",
        "",
        "                # Normalize and add semantic bonus (max 50% boost)",
        "                if relation_count > 0:",
        "                    avg_semantic = semantic_bonus / relation_count",
        "                    weight *= (1 + min(avg_semantic, 0.5))",
        "",
        "            # Create bidirectional connections",
        "            concept1.add_lateral_connection(concept2.id, weight)",
        "            concept2.add_lateral_connection(concept1.id, weight)",
        "            connections_created += 1",
        "",
        "    return {",
        "        'connections_created': connections_created,",
        "        'concepts': len(concepts)",
        "    }",
        "",
        ""
      ],
      "lines_removed": [
        "        # Aggregate properties from members",
        "        "
      ],
      "context_before": [
        "        member_cols.sort(key=lambda c: c.pagerank, reverse=True)",
        "        ",
        "        # Name concept after top members",
        "        top_names = [c.content for c in member_cols[:3]]",
        "        concept_name = '/'.join(top_names)",
        "        ",
        "        # Create concept minicolumn",
        "        concept = layer2.get_or_create_minicolumn(concept_name)",
        "        concept.cluster_id = cluster_id",
        "        "
      ],
      "context_after": [
        "        for col in member_cols:",
        "            concept.feedforward_sources.add(col.id)",
        "            concept.document_ids.update(col.document_ids)",
        "            concept.activation += col.activation * 0.5",
        "            concept.occurrence_count += col.occurrence_count",
        "        # Set PageRank as average of members",
        "        concept.pagerank = sum(c.pagerank for c in member_cols) / len(member_cols)",
        "",
        "",
        "def compute_document_connections(",
        "    layers: Dict[CorticalLayer, HierarchicalLayer],",
        "    documents: Dict[str, str],",
        "    min_shared_terms: int = 3",
        ") -> None:",
        "    \"\"\"",
        "    Build lateral connections between documents.",
        "    ",
        "    Documents are connected based on shared vocabulary,",
        "    weighted by TF-IDF scores of shared terms."
      ],
      "change_type": "modify"
    },
    {
      "file": "cortical/minicolumn.py",
      "function": "class Minicolumn:",
      "start_line": 25,
      "lines_added": [
        "        feedforward_sources: IDs of columns that feed into this one (deprecated, use feedforward_connections)",
        "        feedforward_connections: Weighted connections to lower layer columns",
        "        feedback_connections: Weighted connections to higher layer columns",
        "        'feedforward_connections', 'feedback_connections',",
        "        self.feedforward_sources: Set[str] = set()  # Deprecated: use feedforward_connections",
        "        self.feedforward_connections: Dict[str, float] = {}  # Weighted links to lower layer",
        "        self.feedback_connections: Dict[str, float] = {}  # Weighted links to higher layer",
        "",
        "",
        "",
        "    def add_feedforward_connection(self, target_id: str, weight: float = 1.0) -> None:",
        "        \"\"\"",
        "        Add or strengthen a feedforward connection to a lower layer column.",
        "",
        "        Feedforward connections link higher-level representations to their",
        "        component parts (e.g., bigram → tokens, concept → tokens).",
        "",
        "        Args:",
        "            target_id: ID of the lower-layer minicolumn",
        "            weight: Connection strength to add",
        "        \"\"\"",
        "        self.feedforward_connections[target_id] = (",
        "            self.feedforward_connections.get(target_id, 0) + weight",
        "        )",
        "        # Also maintain legacy feedforward_sources for backward compatibility",
        "        self.feedforward_sources.add(target_id)",
        "",
        "    def add_feedback_connection(self, target_id: str, weight: float = 1.0) -> None:",
        "        \"\"\"",
        "        Add or strengthen a feedback connection to a higher layer column.",
        "",
        "        Feedback connections link lower-level representations to the",
        "        higher-level structures they participate in (e.g., token → bigrams).",
        "",
        "        Args:",
        "            target_id: ID of the higher-layer minicolumn",
        "            weight: Connection strength to add",
        "        \"\"\"",
        "        self.feedback_connections[target_id] = (",
        "            self.feedback_connections.get(target_id, 0) + weight",
        "        )"
      ],
      "lines_removed": [
        "        feedforward_sources: IDs of columns that feed into this one",
        "        self.feedforward_sources: Set[str] = set()",
        "        ",
        "        "
      ],
      "context_before": [
        "    - Layer 3: A document",
        "    ",
        "    Attributes:",
        "        id: Unique identifier (e.g., \"L0_neural\")",
        "        content: The actual content (word, bigram, doc_id)",
        "        layer: Which layer this column belongs to",
        "        activation: Current activation level (like neural firing rate)",
        "        occurrence_count: How many times this has been observed",
        "        document_ids: Which documents contain this content",
        "        lateral_connections: Connections to other columns at same layer"
      ],
      "context_after": [
        "        tfidf: TF-IDF weight for this term",
        "        tfidf_per_doc: Document-specific TF-IDF scores",
        "        pagerank: Importance score from PageRank algorithm",
        "        cluster_id: Which cluster this belongs to (for Layer 0)",
        "        doc_occurrence_counts: Per-document occurrence counts for accurate TF-IDF",
        "        ",
        "    Example:",
        "        col = Minicolumn(\"L0_neural\", \"neural\", 0)",
        "        col.occurrence_count = 15",
        "        col.add_lateral_connection(\"L0_network\", 0.8)",
        "    \"\"\"",
        "    ",
        "    __slots__ = [",
        "        'id', 'content', 'layer', 'activation', 'occurrence_count',",
        "        'document_ids', 'lateral_connections', 'feedforward_sources',",
        "        'tfidf', 'tfidf_per_doc', 'pagerank', 'cluster_id',",
        "        'doc_occurrence_counts'",
        "    ]",
        "    ",
        "    def __init__(self, id: str, content: str, layer: int):",
        "        \"\"\"",
        "        Initialize a minicolumn.",
        "        ",
        "        Args:",
        "            id: Unique identifier for this column",
        "            content: The content this column represents",
        "            layer: Layer number (0-3)",
        "        \"\"\"",
        "        self.id = id",
        "        self.content = content",
        "        self.layer = layer",
        "        self.activation = 0.0",
        "        self.occurrence_count = 0",
        "        self.document_ids: Set[str] = set()",
        "        self.lateral_connections: Dict[str, float] = {}",
        "        self.tfidf = 0.0",
        "        self.tfidf_per_doc: Dict[str, float] = {}",
        "        self.pagerank = 1.0",
        "        self.cluster_id: Optional[int] = None",
        "        self.doc_occurrence_counts: Dict[str, int] = {}",
        "    ",
        "    def add_lateral_connection(self, target_id: str, weight: float = 1.0) -> None:",
        "        \"\"\"",
        "        Add or strengthen a lateral connection to another column.",
        "        Lateral connections represent associations learned through",
        "        co-occurrence (like Hebbian learning: \"neurons that fire together",
        "        wire together\").",
        "        Args:",
        "            target_id: ID of the target minicolumn",
        "            weight: Connection strength to add",
        "        \"\"\"",
        "        self.lateral_connections[target_id] = (",
        "            self.lateral_connections.get(target_id, 0) + weight",
        "        )",
        "    ",
        "    def connection_count(self) -> int:",
        "        \"\"\"Return the number of lateral connections.\"\"\"",
        "        return len(self.lateral_connections)",
        "    ",
        "    def top_connections(self, n: int = 5) -> list:",
        "        \"\"\"",
        "        Get the strongest lateral connections.",
        "        ",
        "        Args:"
      ],
      "change_type": "modify"
    },
    {
      "file": "cortical/minicolumn.py",
      "function": "class Minicolumn:",
      "start_line": 108,
      "lines_added": [
        "",
        "            'feedforward_connections': self.feedforward_connections,",
        "            'feedback_connections': self.feedback_connections,",
        "",
        "",
        "        col.feedforward_connections = data.get('feedforward_connections', {})",
        "        col.feedback_connections = data.get('feedback_connections', {})"
      ],
      "lines_removed": [
        "        ",
        "        ",
        "            "
      ],
      "context_before": [
        "        sorted_conns = sorted(",
        "            self.lateral_connections.items(),",
        "            key=lambda x: x[1],",
        "            reverse=True",
        "        )",
        "        return sorted_conns[:n]",
        "    ",
        "    def to_dict(self) -> Dict:",
        "        \"\"\"",
        "        Convert to dictionary for serialization."
      ],
      "context_after": [
        "        Returns:",
        "            Dictionary representation of this minicolumn",
        "        \"\"\"",
        "        return {",
        "            'id': self.id,",
        "            'content': self.content,",
        "            'layer': self.layer,",
        "            'activation': self.activation,",
        "            'occurrence_count': self.occurrence_count,",
        "            'document_ids': list(self.document_ids),",
        "            'lateral_connections': self.lateral_connections,",
        "            'feedforward_sources': list(self.feedforward_sources),",
        "            'tfidf': self.tfidf,",
        "            'tfidf_per_doc': self.tfidf_per_doc,",
        "            'pagerank': self.pagerank,",
        "            'cluster_id': self.cluster_id,",
        "            'doc_occurrence_counts': self.doc_occurrence_counts",
        "        }",
        "    ",
        "    @classmethod",
        "    def from_dict(cls, data: Dict) -> 'Minicolumn':",
        "        \"\"\"",
        "        Create a minicolumn from dictionary representation.",
        "        Args:",
        "            data: Dictionary with minicolumn data",
        "        Returns:",
        "            New Minicolumn instance",
        "        \"\"\"",
        "        col = cls(data['id'], data['content'], data['layer'])",
        "        col.activation = data.get('activation', 0.0)",
        "        col.occurrence_count = data.get('occurrence_count', 0)",
        "        col.document_ids = set(data.get('document_ids', []))",
        "        col.lateral_connections = data.get('lateral_connections', {})",
        "        col.feedforward_sources = set(data.get('feedforward_sources', []))",
        "        col.tfidf = data.get('tfidf', 0.0)",
        "        col.tfidf_per_doc = data.get('tfidf_per_doc', {})",
        "        col.pagerank = data.get('pagerank', 1.0)",
        "        col.cluster_id = data.get('cluster_id')",
        "        col.doc_occurrence_counts = data.get('doc_occurrence_counts', {})",
        "        return col",
        "    ",
        "    def __repr__(self) -> str:",
        "        return f\"Minicolumn(id={self.id}, content={self.content}, layer={self.layer})\""
      ],
      "change_type": "modify"
    },
    {
      "file": "cortical/processor.py",
      "function": "from . import analysis",
      "start_line": 14,
      "lines_added": [
        "    # Computation types for tracking staleness",
        "    COMP_TFIDF = 'tfidf'",
        "    COMP_PAGERANK = 'pagerank'",
        "    COMP_ACTIVATION = 'activation'",
        "    COMP_DOC_CONNECTIONS = 'doc_connections'",
        "    COMP_CONCEPTS = 'concepts'",
        "    COMP_EMBEDDINGS = 'embeddings'",
        "    COMP_SEMANTICS = 'semantics'",
        "",
        "        # Track which computations are stale and need recomputation",
        "        self._stale_computations: set = set()"
      ],
      "lines_removed": [],
      "context_before": [
        "from . import semantics",
        "from . import embeddings as emb_module",
        "from . import query as query_module",
        "from . import gaps as gaps_module",
        "from . import persistence",
        "",
        "",
        "class CorticalTextProcessor:",
        "    \"\"\"Neocortex-inspired text processing system.\"\"\"",
        ""
      ],
      "context_after": [
        "    def __init__(self, tokenizer: Optional[Tokenizer] = None):",
        "        self.tokenizer = tokenizer or Tokenizer()",
        "        self.layers: Dict[CorticalLayer, HierarchicalLayer] = {",
        "            CorticalLayer.TOKENS: HierarchicalLayer(CorticalLayer.TOKENS),",
        "            CorticalLayer.BIGRAMS: HierarchicalLayer(CorticalLayer.BIGRAMS),",
        "            CorticalLayer.CONCEPTS: HierarchicalLayer(CorticalLayer.CONCEPTS),",
        "            CorticalLayer.DOCUMENTS: HierarchicalLayer(CorticalLayer.DOCUMENTS),",
        "        }",
        "        self.documents: Dict[str, str] = {}",
        "        self.document_metadata: Dict[str, Dict[str, Any]] = {}",
        "        self.embeddings: Dict[str, List[float]] = {}",
        "        self.semantic_relations: List[Tuple[str, str, str, float]] = []",
        "",
        "    def process_document(",
        "        self,",
        "        doc_id: str,",
        "        content: str,",
        "        metadata: Optional[Dict[str, Any]] = None",
        "    ) -> Dict[str, int]:",
        "        \"\"\"",
        "        Process a document and add it to the corpus.",
        ""
      ],
      "change_type": "add"
    },
    {
      "file": "cortical/processor.py",
      "function": "class CorticalTextProcessor:",
      "start_line": 67,
      "lines_added": [
        "            # Weighted feedforward: document → token (weight by occurrence count)",
        "            doc_col.add_feedforward_connection(col.id, 1.0)",
        "            # Weighted feedback: token → document (weight by occurrence count)",
        "            col.add_feedback_connection(doc_col.id, 1.0)",
        "                    # Weighted feedforward: bigram → tokens (weight 1.0 per occurrence)",
        "                    col.add_feedforward_connection(token_col.id, 1.0)",
        "                    # Weighted feedback: token → bigram (weight 1.0 per occurrence)",
        "                    token_col.add_feedback_connection(col.id, 1.0)",
        "",
        "        # Mark all computations as stale since document corpus changed",
        "        self._mark_all_stale()",
        ""
      ],
      "lines_removed": [
        "            doc_col.feedforward_sources.add(col.id)",
        "                    col.feedforward_sources.add(token_col.id)",
        "        "
      ],
      "context_before": [
        "        layer3 = self.layers[CorticalLayer.DOCUMENTS]",
        "        ",
        "        doc_col = layer3.get_or_create_minicolumn(doc_id)",
        "        doc_col.occurrence_count += 1",
        "        ",
        "        for token in tokens:",
        "            col = layer0.get_or_create_minicolumn(token)",
        "            col.occurrence_count += 1",
        "            col.document_ids.add(doc_id)",
        "            col.activation += 1.0"
      ],
      "context_after": [
        "            # Track per-document occurrence count for accurate TF-IDF",
        "            col.doc_occurrence_counts[doc_id] = col.doc_occurrence_counts.get(doc_id, 0) + 1",
        "        ",
        "        for i, token in enumerate(tokens):",
        "            col = layer0.get_minicolumn(token)",
        "            if col:",
        "                for j in range(max(0, i-3), min(len(tokens), i+4)):",
        "                    if i != j:",
        "                        other = layer0.get_minicolumn(tokens[j])",
        "                        if other:",
        "                            col.add_lateral_connection(other.id, 1.0)",
        "        ",
        "        for bigram in bigrams:",
        "            col = layer1.get_or_create_minicolumn(bigram)",
        "            col.occurrence_count += 1",
        "            col.document_ids.add(doc_id)",
        "            col.activation += 1.0",
        "            for part in bigram.split():",
        "                token_col = layer0.get_minicolumn(part)",
        "                if token_col:",
        "        return {'tokens': len(tokens), 'bigrams': len(bigrams), 'unique_tokens': len(set(tokens))}",
        "",
        "    def set_document_metadata(self, doc_id: str, **kwargs) -> None:",
        "        \"\"\"",
        "        Set or update metadata for a document.",
        "",
        "        Args:",
        "            doc_id: Document identifier",
        "            **kwargs: Metadata key-value pairs to set",
        ""
      ],
      "change_type": "modify"
    },
    {
      "file": "cortical/processor.py",
      "function": "class CorticalTextProcessor:",
      "start_line": 133,
      "lines_added": [
        "    def _mark_all_stale(self) -> None:",
        "        \"\"\"Mark all computations as stale (needing recomputation).\"\"\"",
        "        self._stale_computations = {",
        "            self.COMP_TFIDF,",
        "            self.COMP_PAGERANK,",
        "            self.COMP_ACTIVATION,",
        "            self.COMP_DOC_CONNECTIONS,",
        "            self.COMP_CONCEPTS,",
        "            self.COMP_EMBEDDINGS,",
        "            self.COMP_SEMANTICS,",
        "        }",
        "",
        "    def _mark_fresh(self, *computation_types: str) -> None:",
        "        \"\"\"Mark specified computations as fresh (up-to-date).\"\"\"",
        "        for comp in computation_types:",
        "            self._stale_computations.discard(comp)",
        "",
        "    def is_stale(self, computation_type: str) -> bool:",
        "        \"\"\"",
        "        Check if a specific computation is stale.",
        "",
        "        Args:",
        "            computation_type: One of COMP_TFIDF, COMP_PAGERANK, etc.",
        "",
        "        Returns:",
        "            True if the computation needs to be run again",
        "        \"\"\"",
        "        return computation_type in self._stale_computations",
        "",
        "    def get_stale_computations(self) -> set:",
        "        \"\"\"",
        "        Get the set of computations that are currently stale.",
        "",
        "        Returns:",
        "            Set of computation type strings that need recomputation",
        "        \"\"\"",
        "        return self._stale_computations.copy()",
        "",
        "    def add_document_incremental(",
        "        self,",
        "        doc_id: str,",
        "        content: str,",
        "        metadata: Optional[Dict[str, Any]] = None,",
        "        recompute: str = 'tfidf'",
        "    ) -> Dict[str, int]:",
        "        \"\"\"",
        "        Add a document with selective recomputation for efficiency.",
        "",
        "        Unlike process_document() + compute_all(), this method only recomputes",
        "        what's necessary based on the recompute parameter. This is more efficient",
        "        for RAG systems with frequent document updates.",
        "",
        "        Args:",
        "            doc_id: Unique identifier for the document",
        "            content: Document text content",
        "            metadata: Optional metadata dict (source, timestamp, author, etc.)",
        "            recompute: Level of recomputation to perform:",
        "                - 'none': Just add document, mark all computations stale",
        "                - 'tfidf': Recompute TF-IDF only (fast, updates term weights)",
        "                - 'full': Run compute_all() (slowest, most accurate)",
        "",
        "        Returns:",
        "            Dict with processing statistics (tokens, bigrams, unique_tokens)",
        "",
        "        Example:",
        "            >>> # Quick update for search without full recomputation",
        "            >>> processor.add_document_incremental(\"new_doc\", \"content\", recompute='tfidf')",
        "            >>>",
        "            >>> # Just queue document, recompute later in batch",
        "            >>> processor.add_document_incremental(\"doc1\", \"content1\", recompute='none')",
        "            >>> processor.add_document_incremental(\"doc2\", \"content2\", recompute='none')",
        "            >>> processor.recompute(level='full')  # Batch recomputation",
        "        \"\"\"",
        "        stats = self.process_document(doc_id, content, metadata)",
        "",
        "        if recompute == 'tfidf':",
        "            self.compute_tfidf(verbose=False)",
        "            self._mark_fresh(self.COMP_TFIDF)",
        "        elif recompute == 'full':",
        "            self.compute_all(verbose=False)",
        "            self._stale_computations.clear()",
        "        # 'none' leaves all computations marked as stale",
        "",
        "        return stats",
        "",
        "    def add_documents_batch(",
        "        self,",
        "        documents: List[Tuple[str, str, Optional[Dict[str, Any]]]],",
        "        recompute: str = 'full',",
        "        verbose: bool = True",
        "    ) -> Dict[str, Any]:",
        "        \"\"\"",
        "        Add multiple documents with a single recomputation.",
        "",
        "        More efficient than calling add_document_incremental() multiple times",
        "        when adding many documents at once.",
        "",
        "        Args:",
        "            documents: List of (doc_id, content, metadata) tuples.",
        "                       metadata can be None for documents without metadata.",
        "            recompute: Level of recomputation after all documents are added:",
        "                - 'none': Just add documents, mark all computations stale",
        "                - 'tfidf': Recompute TF-IDF only",
        "                - 'full': Run compute_all()",
        "            verbose: Print progress messages",
        "",
        "        Returns:",
        "            Dict with batch statistics:",
        "                - documents_added: Number of documents added",
        "                - total_tokens: Total tokens across all documents",
        "                - recomputation: Type of recomputation performed",
        "",
        "        Example:",
        "            >>> docs = [",
        "            ...     (\"doc1\", \"First document content\", {\"source\": \"web\"}),",
        "            ...     (\"doc2\", \"Second document content\", None),",
        "            ...     (\"doc3\", \"Third document content\", {\"author\": \"AI\"}),",
        "            ... ]",
        "            >>> processor.add_documents_batch(docs, recompute='full')",
        "        \"\"\"",
        "        total_tokens = 0",
        "        total_bigrams = 0",
        "",
        "        if verbose:",
        "            print(f\"Adding {len(documents)} documents...\")",
        "",
        "        for doc_id, content, metadata in documents:",
        "            # Use process_document directly (not add_document_incremental)",
        "            # to avoid per-document recomputation",
        "            stats = self.process_document(doc_id, content, metadata)",
        "            total_tokens += stats['tokens']",
        "            total_bigrams += stats['bigrams']",
        "",
        "        if verbose:",
        "            print(f\"Processed {total_tokens} tokens, {total_bigrams} bigrams\")",
        "",
        "        # Perform single recomputation for entire batch",
        "        if recompute == 'tfidf':",
        "            if verbose:",
        "                print(\"Recomputing TF-IDF...\")",
        "            self.compute_tfidf(verbose=False)",
        "            self._mark_fresh(self.COMP_TFIDF)",
        "        elif recompute == 'full':",
        "            if verbose:",
        "                print(\"Running full recomputation...\")",
        "            self.compute_all(verbose=False)",
        "            self._stale_computations.clear()",
        "",
        "        if verbose:",
        "            print(\"Done.\")",
        "",
        "        return {",
        "            'documents_added': len(documents),",
        "            'total_tokens': total_tokens,",
        "            'total_bigrams': total_bigrams,",
        "            'recomputation': recompute",
        "        }",
        "",
        "    def recompute(",
        "        self,",
        "        level: str = 'stale',",
        "        verbose: bool = True",
        "    ) -> Dict[str, bool]:",
        "        \"\"\"",
        "        Recompute specified analysis levels.",
        "",
        "        Use this after adding documents with recompute='none' to batch",
        "        the recomputation step.",
        "",
        "        Args:",
        "            level: What to recompute:",
        "                - 'stale': Only recompute what's marked as stale",
        "                - 'tfidf': Only TF-IDF (marks others stale)",
        "                - 'full': Run complete compute_all()",
        "            verbose: Print progress messages",
        "",
        "        Returns:",
        "            Dict indicating what was recomputed",
        "",
        "        Example:",
        "            >>> # Add documents without recomputation",
        "            >>> processor.add_document_incremental(\"doc1\", \"content\", recompute='none')",
        "            >>> processor.add_document_incremental(\"doc2\", \"content\", recompute='none')",
        "            >>> # Batch recompute",
        "            >>> processor.recompute(level='full')",
        "        \"\"\"",
        "        recomputed = {}",
        "",
        "        if level == 'full':",
        "            self.compute_all(verbose=verbose)",
        "            self._stale_computations.clear()",
        "            recomputed = {",
        "                self.COMP_ACTIVATION: True,",
        "                self.COMP_PAGERANK: True,",
        "                self.COMP_TFIDF: True,",
        "                self.COMP_DOC_CONNECTIONS: True,",
        "                self.COMP_CONCEPTS: True,",
        "            }",
        "        elif level == 'tfidf':",
        "            self.compute_tfidf(verbose=verbose)",
        "            self._mark_fresh(self.COMP_TFIDF)",
        "            recomputed[self.COMP_TFIDF] = True",
        "        elif level == 'stale':",
        "            # Recompute only what's stale, in dependency order",
        "            if self.COMP_ACTIVATION in self._stale_computations:",
        "                self.propagate_activation(verbose=verbose)",
        "                self._mark_fresh(self.COMP_ACTIVATION)",
        "                recomputed[self.COMP_ACTIVATION] = True",
        "",
        "            if self.COMP_PAGERANK in self._stale_computations:",
        "                self.compute_importance(verbose=verbose)",
        "                self._mark_fresh(self.COMP_PAGERANK)",
        "                recomputed[self.COMP_PAGERANK] = True",
        "",
        "            if self.COMP_TFIDF in self._stale_computations:",
        "                self.compute_tfidf(verbose=verbose)",
        "                self._mark_fresh(self.COMP_TFIDF)",
        "                recomputed[self.COMP_TFIDF] = True",
        "",
        "            if self.COMP_DOC_CONNECTIONS in self._stale_computations:",
        "                self.compute_document_connections(verbose=verbose)",
        "                self._mark_fresh(self.COMP_DOC_CONNECTIONS)",
        "                recomputed[self.COMP_DOC_CONNECTIONS] = True",
        "",
        "            if self.COMP_CONCEPTS in self._stale_computations:",
        "                self.build_concept_clusters(verbose=verbose)",
        "                self._mark_fresh(self.COMP_CONCEPTS)",
        "                recomputed[self.COMP_CONCEPTS] = True",
        "",
        "            if self.COMP_EMBEDDINGS in self._stale_computations:",
        "                self.compute_graph_embeddings(verbose=verbose)",
        "                self._mark_fresh(self.COMP_EMBEDDINGS)",
        "                recomputed[self.COMP_EMBEDDINGS] = True",
        "",
        "            if self.COMP_SEMANTICS in self._stale_computations:",
        "                self.extract_corpus_semantics(verbose=verbose)",
        "                self._mark_fresh(self.COMP_SEMANTICS)",
        "                recomputed[self.COMP_SEMANTICS] = True",
        "",
        "        return recomputed",
        ""
      ],
      "lines_removed": [],
      "context_before": [
        "    def get_all_document_metadata(self) -> Dict[str, Dict[str, Any]]:",
        "        \"\"\"",
        "        Get metadata for all documents.",
        "",
        "        Returns:",
        "            Dict mapping doc_id to metadata dict (deep copy)",
        "        \"\"\"",
        "        import copy",
        "        return copy.deepcopy(self.document_metadata)",
        ""
      ],
      "context_after": [
        "    def compute_all(self, verbose: bool = True, build_concepts: bool = True) -> None:",
        "        \"\"\"",
        "        Run all computation steps.",
        "",
        "        Args:",
        "            verbose: Print progress messages",
        "            build_concepts: Build concept clusters in Layer 2 (default True)",
        "                           This enables topic-based filtering and hierarchical search.",
        "        \"\"\"",
        "        if verbose:"
      ],
      "change_type": "add"
    },
    {
      "file": "cortical/processor.py",
      "function": "class CorticalTextProcessor:",
      "start_line": 158,
      "lines_added": [
        "            if verbose:",
        "                print(\"Computing concept connections...\")",
        "            self.compute_concept_connections(verbose=False)",
        "        # Mark core computations as fresh",
        "        fresh_comps = [",
        "            self.COMP_ACTIVATION,",
        "            self.COMP_PAGERANK,",
        "            self.COMP_TFIDF,",
        "            self.COMP_DOC_CONNECTIONS,",
        "        ]",
        "        if build_concepts:",
        "            fresh_comps.append(self.COMP_CONCEPTS)",
        "        self._mark_fresh(*fresh_comps)"
      ],
      "lines_removed": [],
      "context_before": [
        "        if verbose:",
        "            print(\"Computing TF-IDF...\")",
        "        self.compute_tfidf(verbose=False)",
        "        if verbose:",
        "            print(\"Computing document connections...\")",
        "        self.compute_document_connections(verbose=False)",
        "        if build_concepts:",
        "            if verbose:",
        "                print(\"Building concept clusters...\")",
        "            self.build_concept_clusters(verbose=False)"
      ],
      "context_after": [
        "        if verbose:",
        "            print(\"Done.\")",
        "    ",
        "    def propagate_activation(self, iterations: int = 3, decay: float = 0.8, verbose: bool = True) -> None:",
        "        analysis.propagate_activation(self.layers, iterations, decay)",
        "        if verbose: print(f\"Propagated activation ({iterations} iterations)\")",
        "    ",
        "    def compute_importance(self, verbose: bool = True) -> None:",
        "        for layer_enum in [CorticalLayer.TOKENS, CorticalLayer.BIGRAMS]:",
        "            analysis.compute_pagerank(self.layers[layer_enum])"
      ],
      "change_type": "add"
    },
    {
      "file": "cortical/processor.py",
      "function": "class CorticalTextProcessor:",
      "start_line": 183,
      "lines_added": [
        "",
        "    def compute_concept_connections(",
        "        self,",
        "        use_semantics: bool = True,",
        "        min_shared_docs: int = 1,",
        "        min_jaccard: float = 0.1,",
        "        verbose: bool = True",
        "    ) -> Dict[str, Any]:",
        "        \"\"\"",
        "        Build lateral connections between concepts based on document overlap and semantics.",
        "",
        "        Args:",
        "            use_semantics: Use semantic relations to boost connection weights",
        "            min_shared_docs: Minimum shared documents for connection",
        "            min_jaccard: Minimum Jaccard similarity threshold",
        "            verbose: Print progress messages",
        "",
        "        Returns:",
        "            Statistics about connections created",
        "        \"\"\"",
        "        semantic_rels = self.semantic_relations if use_semantics else None",
        "        stats = analysis.compute_concept_connections(",
        "            self.layers,",
        "            semantic_relations=semantic_rels,",
        "            min_shared_docs=min_shared_docs,",
        "            min_jaccard=min_jaccard",
        "        )",
        "        if verbose:",
        "            print(f\"Created {stats['connections_created']} concept connections\")",
        "        return stats",
        ""
      ],
      "lines_removed": [
        "    "
      ],
      "context_before": [
        "    ",
        "    def compute_document_connections(self, min_shared_terms: int = 3, verbose: bool = True) -> None:",
        "        analysis.compute_document_connections(self.layers, self.documents, min_shared_terms)",
        "        if verbose: print(\"Computed document connections\")",
        "    ",
        "    def build_concept_clusters(self, verbose: bool = True) -> Dict[int, List[str]]:",
        "        clusters = analysis.cluster_by_label_propagation(self.layers[CorticalLayer.TOKENS])",
        "        analysis.build_concept_clusters(self.layers, clusters)",
        "        if verbose: print(f\"Built {len(clusters)} concept clusters\")",
        "        return clusters"
      ],
      "context_after": [
        "    def extract_corpus_semantics(self, verbose: bool = True) -> int:",
        "        self.semantic_relations = semantics.extract_corpus_semantics(self.layers, self.documents, self.tokenizer)",
        "        if verbose: print(f\"Extracted {len(self.semantic_relations)} semantic relations\")",
        "        return len(self.semantic_relations)",
        "    ",
        "    def retrofit_connections(self, iterations: int = 10, alpha: float = 0.3, verbose: bool = True) -> Dict:",
        "        if not self.semantic_relations: self.extract_corpus_semantics(verbose=False)",
        "        stats = semantics.retrofit_connections(self.layers, self.semantic_relations, iterations, alpha)",
        "        if verbose: print(f\"Retrofitted {stats['tokens_affected']} tokens\")",
        "        return stats"
      ],
      "change_type": "modify"
    },
    {
      "file": "cortical/processor.py",
      "function": "class CorticalTextProcessor:",
      "start_line": 295,
      "lines_added": [
        "",
        "    def find_documents_batch(",
        "        self,",
        "        queries: List[str],",
        "        top_n: int = 5,",
        "        use_expansion: bool = True,",
        "        use_semantic: bool = True",
        "    ) -> List[List[Tuple[str, float]]]:",
        "        \"\"\"",
        "        Find documents for multiple queries efficiently.",
        "",
        "        More efficient than calling find_documents_for_query() multiple times",
        "        because it shares tokenization and expansion caching across queries.",
        "",
        "        Args:",
        "            queries: List of search query strings",
        "            top_n: Number of documents to return per query",
        "            use_expansion: Whether to expand query terms using lateral connections",
        "            use_semantic: Whether to use semantic relations for expansion",
        "",
        "        Returns:",
        "            List of results, one per query. Each result is a list of (doc_id, score) tuples.",
        "",
        "        Example:",
        "            >>> queries = [\"neural networks\", \"machine learning\", \"data processing\"]",
        "            >>> results = processor.find_documents_batch(queries, top_n=3)",
        "            >>> for query, docs in zip(queries, results):",
        "            ...     print(f\"{query}: {[doc_id for doc_id, _ in docs]}\")",
        "        \"\"\"",
        "        return query_module.find_documents_batch(",
        "            queries,",
        "            self.layers,",
        "            self.tokenizer,",
        "            top_n=top_n,",
        "            use_expansion=use_expansion,",
        "            semantic_relations=self.semantic_relations if use_semantic else None,",
        "            use_semantic=use_semantic",
        "        )",
        "",
        "    def find_passages_batch(",
        "        self,",
        "        queries: List[str],",
        "        top_n: int = 5,",
        "        chunk_size: int = 512,",
        "        overlap: int = 128,",
        "        use_expansion: bool = True,",
        "        doc_filter: Optional[List[str]] = None,",
        "        use_semantic: bool = True",
        "    ) -> List[List[Tuple[str, str, int, int, float]]]:",
        "        \"\"\"",
        "        Find passages for multiple queries efficiently.",
        "",
        "        More efficient than calling find_passages_for_query() multiple times",
        "        because it shares chunk computation and expansion caching across queries.",
        "",
        "        Args:",
        "            queries: List of search query strings",
        "            top_n: Number of passages to return per query",
        "            chunk_size: Size of each chunk in characters (default 512)",
        "            overlap: Overlap between chunks in characters (default 128)",
        "            use_expansion: Whether to expand query terms",
        "            doc_filter: Optional list of doc_ids to restrict search to",
        "            use_semantic: Whether to use semantic relations for expansion",
        "",
        "        Returns:",
        "            List of results, one per query. Each result is a list of",
        "            (passage_text, doc_id, start_char, end_char, score) tuples.",
        "",
        "        Example:",
        "            >>> queries = [\"neural networks\", \"deep learning\"]",
        "            >>> results = processor.find_passages_batch(queries)",
        "            >>> for query, passages in zip(queries, results):",
        "            ...     print(f\"{query}: {len(passages)} passages found\")",
        "        \"\"\"",
        "        return query_module.find_passages_batch(",
        "            queries,",
        "            self.layers,",
        "            self.tokenizer,",
        "            self.documents,",
        "            top_n=top_n,",
        "            chunk_size=chunk_size,",
        "            overlap=overlap,",
        "            use_expansion=use_expansion,",
        "            doc_filter=doc_filter,",
        "            semantic_relations=self.semantic_relations if use_semantic else None,",
        "            use_semantic=use_semantic",
        "        )",
        "",
        "    def multi_stage_rank(",
        "        self,",
        "        query_text: str,",
        "        top_n: int = 5,",
        "        chunk_size: int = 512,",
        "        overlap: int = 128,",
        "        concept_boost: float = 0.3,",
        "        use_expansion: bool = True,",
        "        use_semantic: bool = True",
        "    ) -> List[Tuple[str, str, int, int, float, Dict[str, float]]]:",
        "        \"\"\"",
        "        Multi-stage ranking pipeline for improved RAG performance.",
        "",
        "        Uses a 4-stage pipeline combining concept, document, and chunk signals:",
        "        1. Concepts: Filter by topic relevance using Layer 2 clusters",
        "        2. Documents: Rank documents within relevant topics",
        "        3. Chunks: Rank passages within top documents",
        "        4. Rerank: Combine all signals for final scoring",
        "",
        "        Args:",
        "            query_text: Search query",
        "            top_n: Number of passages to return",
        "            chunk_size: Size of each chunk in characters (default 512)",
        "            overlap: Overlap between chunks in characters (default 128)",
        "            concept_boost: Weight for concept relevance (0.0-1.0, default 0.3)",
        "            use_expansion: Whether to expand query terms",
        "            use_semantic: Whether to use semantic relations for expansion",
        "",
        "        Returns:",
        "            List of (passage_text, doc_id, start_char, end_char, final_score, stage_scores)",
        "            tuples. stage_scores contains: concept_score, doc_score, chunk_score, final_score",
        "",
        "        Example:",
        "            >>> results = processor.multi_stage_rank(\"neural networks\", top_n=5)",
        "            >>> for passage, doc_id, start, end, score, stages in results:",
        "            ...     print(f\"[{doc_id}] Final: {score:.3f}, Concept: {stages['concept_score']:.3f}\")",
        "        \"\"\"",
        "        return query_module.multi_stage_rank(",
        "            query_text,",
        "            self.layers,",
        "            self.tokenizer,",
        "            self.documents,",
        "            top_n=top_n,",
        "            chunk_size=chunk_size,",
        "            overlap=overlap,",
        "            concept_boost=concept_boost,",
        "            use_expansion=use_expansion,",
        "            semantic_relations=self.semantic_relations if use_semantic else None,",
        "            use_semantic=use_semantic",
        "        )",
        "",
        "    def multi_stage_rank_documents(",
        "        self,",
        "        query_text: str,",
        "        top_n: int = 5,",
        "        concept_boost: float = 0.3,",
        "        use_expansion: bool = True,",
        "        use_semantic: bool = True",
        "    ) -> List[Tuple[str, float, Dict[str, float]]]:",
        "        \"\"\"",
        "        Multi-stage ranking for documents (without chunk scoring).",
        "",
        "        Uses stages 1-2 of the pipeline for document-level ranking:",
        "        1. Concepts: Filter by topic relevance",
        "        2. Documents: Rank by combined concept + TF-IDF scores",
        "",
        "        Args:",
        "            query_text: Search query",
        "            top_n: Number of documents to return",
        "            concept_boost: Weight for concept relevance (0.0-1.0, default 0.3)",
        "            use_expansion: Whether to expand query terms",
        "            use_semantic: Whether to use semantic relations",
        "",
        "        Returns:",
        "            List of (doc_id, final_score, stage_scores) tuples.",
        "            stage_scores contains: concept_score, tfidf_score, combined_score",
        "",
        "        Example:",
        "            >>> results = processor.multi_stage_rank_documents(\"neural networks\")",
        "            >>> for doc_id, score, stages in results:",
        "            ...     print(f\"{doc_id}: {score:.3f} (concept: {stages['concept_score']:.3f})\")",
        "        \"\"\"",
        "        return query_module.multi_stage_rank_documents(",
        "            query_text,",
        "            self.layers,",
        "            self.tokenizer,",
        "            top_n=top_n,",
        "            concept_boost=concept_boost,",
        "            use_expansion=use_expansion,",
        "            semantic_relations=self.semantic_relations if use_semantic else None,",
        "            use_semantic=use_semantic",
        "        )",
        ""
      ],
      "lines_removed": [
        "    "
      ],
      "context_before": [
        "            self.tokenizer,",
        "            self.documents,",
        "            top_n=top_n,",
        "            chunk_size=chunk_size,",
        "            overlap=overlap,",
        "            use_expansion=use_expansion,",
        "            doc_filter=doc_filter,",
        "            semantic_relations=self.semantic_relations if use_semantic else None,",
        "            use_semantic=use_semantic",
        "        )"
      ],
      "context_after": [
        "    def query_expanded(self, query_text: str, top_n: int = 10, max_expansions: int = 8) -> List[Tuple[str, float]]:",
        "        return query_module.query_with_spreading_activation(query_text, self.layers, self.tokenizer, top_n, max_expansions)",
        "    ",
        "    def find_related_documents(self, doc_id: str) -> List[Tuple[str, float]]:",
        "        return query_module.find_related_documents(doc_id, self.layers)",
        "    ",
        "    def analyze_knowledge_gaps(self) -> Dict:",
        "        return gaps_module.analyze_knowledge_gaps(self.layers, self.documents)",
        "    ",
        "    def detect_anomalies(self, threshold: float = 0.3) -> List[Dict]:"
      ],
      "change_type": "modify"
    },
    {
      "file": "cortical/query.py",
      "function": "def find_passages_for_query(",
      "start_line": 488,
      "lines_added": [
        "",
        "",
        "def find_documents_batch(",
        "    queries: List[str],",
        "    layers: Dict[CorticalLayer, HierarchicalLayer],",
        "    tokenizer: Tokenizer,",
        "    top_n: int = 5,",
        "    use_expansion: bool = True,",
        "    semantic_relations: Optional[List[Tuple[str, str, str, float]]] = None,",
        "    use_semantic: bool = True",
        ") -> List[List[Tuple[str, float]]]:",
        "    \"\"\"",
        "    Find documents for multiple queries efficiently.",
        "",
        "    More efficient than calling find_documents_for_query() multiple times",
        "    because it shares tokenization and expansion caching across queries.",
        "",
        "    Args:",
        "        queries: List of search query strings",
        "        layers: Dictionary of layers",
        "        tokenizer: Tokenizer instance",
        "        top_n: Number of documents to return per query",
        "        use_expansion: Whether to expand query terms",
        "        semantic_relations: Optional list of semantic relations for expansion",
        "        use_semantic: Whether to use semantic relations for expansion",
        "",
        "    Returns:",
        "        List of results, one per query. Each result is a list of (doc_id, score) tuples.",
        "",
        "    Example:",
        "        >>> queries = [\"neural networks\", \"machine learning\", \"data processing\"]",
        "        >>> results = find_documents_batch(queries, layers, tokenizer, top_n=3)",
        "        >>> for query, docs in zip(queries, results):",
        "        ...     print(f\"{query}: {[doc_id for doc_id, _ in docs]}\")",
        "    \"\"\"",
        "    layer0 = layers[CorticalLayer.TOKENS]",
        "",
        "    # Cache for expanded query terms to avoid redundant computation",
        "    expansion_cache: Dict[str, Dict[str, float]] = {}",
        "",
        "    all_results: List[List[Tuple[str, float]]] = []",
        "",
        "    for query_text in queries:",
        "        # Check cache first for expansion",
        "        if use_expansion:",
        "            if query_text in expansion_cache:",
        "                query_terms = expansion_cache[query_text]",
        "            else:",
        "                query_terms = expand_query(query_text, layers, tokenizer, max_expansions=5)",
        "                if use_semantic and semantic_relations:",
        "                    semantic_terms = expand_query_semantic(",
        "                        query_text, layers, tokenizer, semantic_relations, max_expansions=5",
        "                    )",
        "                    for term, weight in semantic_terms.items():",
        "                        if term not in query_terms:",
        "                            query_terms[term] = weight * 0.8",
        "                        else:",
        "                            query_terms[term] = max(query_terms[term], weight * 0.8)",
        "                expansion_cache[query_text] = query_terms",
        "        else:",
        "            tokens = tokenizer.tokenize(query_text)",
        "            query_terms = {t: 1.0 for t in tokens}",
        "",
        "        # Score documents",
        "        doc_scores: Dict[str, float] = defaultdict(float)",
        "        for term, term_weight in query_terms.items():",
        "            col = layer0.get_minicolumn(term)",
        "            if col:",
        "                for doc_id in col.document_ids:",
        "                    tfidf = col.tfidf_per_doc.get(doc_id, col.tfidf)",
        "                    doc_scores[doc_id] += tfidf * term_weight",
        "",
        "        sorted_docs = sorted(doc_scores.items(), key=lambda x: -x[1])",
        "        all_results.append(sorted_docs[:top_n])",
        "",
        "    return all_results",
        "",
        "",
        "def find_passages_batch(",
        "    queries: List[str],",
        "    layers: Dict[CorticalLayer, HierarchicalLayer],",
        "    tokenizer: Tokenizer,",
        "    documents: Dict[str, str],",
        "    top_n: int = 5,",
        "    chunk_size: int = 512,",
        "    overlap: int = 128,",
        "    use_expansion: bool = True,",
        "    doc_filter: Optional[List[str]] = None,",
        "    semantic_relations: Optional[List[Tuple[str, str, str, float]]] = None,",
        "    use_semantic: bool = True",
        ") -> List[List[Tuple[str, str, int, int, float]]]:",
        "    \"\"\"",
        "    Find passages for multiple queries efficiently.",
        "",
        "    More efficient than calling find_passages_for_query() multiple times",
        "    because it shares chunk computation and expansion caching across queries.",
        "",
        "    Args:",
        "        queries: List of search query strings",
        "        layers: Dictionary of layers",
        "        tokenizer: Tokenizer instance",
        "        documents: Dict mapping doc_id to document text",
        "        top_n: Number of passages to return per query",
        "        chunk_size: Size of each chunk in characters",
        "        overlap: Overlap between chunks in characters",
        "        use_expansion: Whether to expand query terms",
        "        doc_filter: Optional list of doc_ids to restrict search to",
        "        semantic_relations: Optional list of semantic relations for expansion",
        "        use_semantic: Whether to use semantic relations for expansion",
        "",
        "    Returns:",
        "        List of results, one per query. Each result is a list of",
        "        (passage_text, doc_id, start_char, end_char, score) tuples.",
        "",
        "    Example:",
        "        >>> queries = [\"neural networks\", \"deep learning\"]",
        "        >>> results = find_passages_batch(queries, layers, tokenizer, documents)",
        "        >>> for query, passages in zip(queries, results):",
        "        ...     print(f\"{query}: {len(passages)} passages found\")",
        "    \"\"\"",
        "    layer0 = layers[CorticalLayer.TOKENS]",
        "",
        "    # Pre-compute chunks for all documents to avoid redundant chunking",
        "    doc_chunks_cache: Dict[str, List[Tuple[str, int, int]]] = {}",
        "    for doc_id, text in documents.items():",
        "        if doc_filter and doc_id not in doc_filter:",
        "            continue",
        "        doc_chunks_cache[doc_id] = create_chunks(text, chunk_size, overlap)",
        "",
        "    # Cache for expanded query terms",
        "    expansion_cache: Dict[str, Dict[str, float]] = {}",
        "",
        "    all_results: List[List[Tuple[str, str, int, int, float]]] = []",
        "",
        "    for query_text in queries:",
        "        # Get expanded query terms (with caching)",
        "        if use_expansion:",
        "            if query_text in expansion_cache:",
        "                query_terms = expansion_cache[query_text]",
        "            else:",
        "                query_terms = expand_query(query_text, layers, tokenizer, max_expansions=5)",
        "                if use_semantic and semantic_relations:",
        "                    semantic_terms = expand_query_semantic(",
        "                        query_text, layers, tokenizer, semantic_relations, max_expansions=5",
        "                    )",
        "                    for term, weight in semantic_terms.items():",
        "                        if term not in query_terms:",
        "                            query_terms[term] = weight * 0.8",
        "                        else:",
        "                            query_terms[term] = max(query_terms[term], weight * 0.8)",
        "                expansion_cache[query_text] = query_terms",
        "        else:",
        "            tokens = tokenizer.tokenize(query_text)",
        "            query_terms = {t: 1.0 for t in tokens}",
        "",
        "        if not query_terms:",
        "            all_results.append([])",
        "            continue",
        "",
        "        # Get candidate documents",
        "        doc_scores = find_documents_for_query(",
        "            query_text, layers, tokenizer,",
        "            top_n=min(len(documents), top_n * 3),",
        "            use_expansion=use_expansion,",
        "            semantic_relations=semantic_relations,",
        "            use_semantic=use_semantic",
        "        )",
        "",
        "        # Apply document filter",
        "        if doc_filter:",
        "            doc_scores = [(doc_id, score) for doc_id, score in doc_scores if doc_id in doc_filter]",
        "",
        "        # Score passages using cached chunks",
        "        passages: List[Tuple[str, str, int, int, float]] = []",
        "",
        "        for doc_id, doc_score in doc_scores:",
        "            if doc_id not in doc_chunks_cache:",
        "                continue",
        "",
        "            for chunk_text, start_char, end_char in doc_chunks_cache[doc_id]:",
        "                chunk_score = score_chunk(",
        "                    chunk_text, query_terms, layer0, tokenizer, doc_id",
        "                )",
        "                combined_score = chunk_score * (1 + doc_score * 0.1)",
        "                passages.append((chunk_text, doc_id, start_char, end_char, combined_score))",
        "",
        "        passages.sort(key=lambda x: x[4], reverse=True)",
        "        all_results.append(passages[:top_n])",
        "",
        "    return all_results",
        "",
        "",
        "def find_relevant_concepts(",
        "    query_terms: Dict[str, float],",
        "    layers: Dict[CorticalLayer, HierarchicalLayer],",
        "    top_n: int = 5",
        ") -> List[Tuple[str, float, set]]:",
        "    \"\"\"",
        "    Stage 1: Find concepts relevant to query terms.",
        "",
        "    Args:",
        "        query_terms: Dict mapping query terms to weights",
        "        layers: Dictionary of layers",
        "        top_n: Maximum number of concepts to return",
        "",
        "    Returns:",
        "        List of (concept_name, relevance_score, document_ids) tuples",
        "    \"\"\"",
        "    layer0 = layers[CorticalLayer.TOKENS]",
        "    layer2 = layers.get(CorticalLayer.CONCEPTS)",
        "",
        "    if not layer2 or layer2.column_count() == 0:",
        "        return []",
        "",
        "    concept_scores: Dict[str, float] = {}",
        "    concept_docs: Dict[str, set] = {}",
        "",
        "    for term, weight in query_terms.items():",
        "        col = layer0.get_minicolumn(term)",
        "        if not col:",
        "            continue",
        "",
        "        # Find concepts that contain this token",
        "        for concept in layer2.minicolumns.values():",
        "            if col.id in concept.feedforward_sources:",
        "                # Score based on term weight, concept PageRank, and concept size",
        "                score = weight * concept.pagerank * (1 + len(concept.feedforward_sources) * 0.01)",
        "                concept_scores[concept.content] = concept_scores.get(concept.content, 0) + score",
        "                if concept.content not in concept_docs:",
        "                    concept_docs[concept.content] = set()",
        "                concept_docs[concept.content].update(concept.document_ids)",
        "",
        "    # Sort by score and return top concepts",
        "    sorted_concepts = sorted(concept_scores.items(), key=lambda x: -x[1])[:top_n]",
        "    return [(name, score, concept_docs.get(name, set())) for name, score in sorted_concepts]",
        "",
        "",
        "def multi_stage_rank(",
        "    query_text: str,",
        "    layers: Dict[CorticalLayer, HierarchicalLayer],",
        "    tokenizer: Tokenizer,",
        "    documents: Dict[str, str],",
        "    top_n: int = 5,",
        "    chunk_size: int = 512,",
        "    overlap: int = 128,",
        "    concept_boost: float = 0.3,",
        "    use_expansion: bool = True,",
        "    semantic_relations: Optional[List[Tuple[str, str, str, float]]] = None,",
        "    use_semantic: bool = True",
        ") -> List[Tuple[str, str, int, int, float, Dict[str, float]]]:",
        "    \"\"\"",
        "    Multi-stage ranking pipeline for improved RAG performance.",
        "",
        "    Unlike flat ranking (TF-IDF → score), this uses a 4-stage pipeline:",
        "    1. Concepts: Filter by topic relevance using Layer 2 clusters",
        "    2. Documents: Rank documents within relevant topics",
        "    3. Chunks: Rank passages within top documents",
        "    4. Rerank: Combine all signals for final scoring",
        "",
        "    Args:",
        "        query_text: Search query",
        "        layers: Dictionary of layers",
        "        tokenizer: Tokenizer instance",
        "        documents: Dict mapping doc_id to document text",
        "        top_n: Number of passages to return",
        "        chunk_size: Size of each chunk in characters",
        "        overlap: Overlap between chunks in characters",
        "        concept_boost: Weight for concept relevance in final score (0.0-1.0)",
        "        use_expansion: Whether to expand query terms",
        "        semantic_relations: Optional list of semantic relations for expansion",
        "        use_semantic: Whether to use semantic relations for expansion",
        "",
        "    Returns:",
        "        List of (passage_text, doc_id, start_char, end_char, final_score, stage_scores) tuples.",
        "        stage_scores dict contains: concept_score, doc_score, chunk_score, final_score",
        "",
        "    Example:",
        "        >>> results = multi_stage_rank(query, layers, tokenizer, documents)",
        "        >>> for passage, doc_id, start, end, score, stages in results:",
        "        ...     print(f\"[{doc_id}] Score: {score:.3f}\")",
        "        ...     print(f\"  Concept: {stages['concept_score']:.3f}\")",
        "        ...     print(f\"  Doc: {stages['doc_score']:.3f}\")",
        "        ...     print(f\"  Chunk: {stages['chunk_score']:.3f}\")",
        "    \"\"\"",
        "    layer0 = layers[CorticalLayer.TOKENS]",
        "",
        "    # Get expanded query terms",
        "    if use_expansion:",
        "        query_terms = expand_query(query_text, layers, tokenizer, max_expansions=5)",
        "        if use_semantic and semantic_relations:",
        "            semantic_terms = expand_query_semantic(",
        "                query_text, layers, tokenizer, semantic_relations, max_expansions=5",
        "            )",
        "            for term, weight in semantic_terms.items():",
        "                if term not in query_terms:",
        "                    query_terms[term] = weight * 0.8",
        "                else:",
        "                    query_terms[term] = max(query_terms[term], weight * 0.8)",
        "    else:",
        "        tokens = tokenizer.tokenize(query_text)",
        "        query_terms = {t: 1.0 for t in tokens}",
        "",
        "    if not query_terms:",
        "        return []",
        "",
        "    # ========== STAGE 1: CONCEPTS ==========",
        "    # Find relevant concepts to identify topic areas",
        "    relevant_concepts = find_relevant_concepts(query_terms, layers, top_n=10)",
        "",
        "    # Build concept score per document",
        "    doc_concept_scores: Dict[str, float] = defaultdict(float)",
        "    if relevant_concepts:",
        "        max_concept_score = max(score for _, score, _ in relevant_concepts) if relevant_concepts else 1.0",
        "        for concept_name, concept_score, doc_ids in relevant_concepts:",
        "            normalized_score = concept_score / max_concept_score if max_concept_score > 0 else 0",
        "            for doc_id in doc_ids:",
        "                doc_concept_scores[doc_id] = max(doc_concept_scores[doc_id], normalized_score)",
        "",
        "    # ========== STAGE 2: DOCUMENTS ==========",
        "    # Score documents using TF-IDF (standard approach)",
        "    doc_tfidf_scores: Dict[str, float] = defaultdict(float)",
        "    for term, term_weight in query_terms.items():",
        "        col = layer0.get_minicolumn(term)",
        "        if col:",
        "            for doc_id in col.document_ids:",
        "                tfidf = col.tfidf_per_doc.get(doc_id, col.tfidf)",
        "                doc_tfidf_scores[doc_id] += tfidf * term_weight",
        "",
        "    # Normalize TF-IDF scores",
        "    max_tfidf = max(doc_tfidf_scores.values()) if doc_tfidf_scores else 1.0",
        "    for doc_id in doc_tfidf_scores:",
        "        doc_tfidf_scores[doc_id] /= max_tfidf if max_tfidf > 0 else 1.0",
        "",
        "    # Combine concept and TF-IDF scores for document ranking",
        "    combined_doc_scores: Dict[str, float] = {}",
        "    all_docs = set(doc_concept_scores.keys()) | set(doc_tfidf_scores.keys())",
        "    for doc_id in all_docs:",
        "        concept_score = doc_concept_scores.get(doc_id, 0.0)",
        "        tfidf_score = doc_tfidf_scores.get(doc_id, 0.0)",
        "        # Weighted combination",
        "        combined_doc_scores[doc_id] = (",
        "            (1 - concept_boost) * tfidf_score +",
        "            concept_boost * concept_score",
        "        )",
        "",
        "    # Get top documents for chunk scoring",
        "    sorted_docs = sorted(combined_doc_scores.items(), key=lambda x: -x[1])",
        "    top_docs = sorted_docs[:min(len(sorted_docs), top_n * 3)]",
        "",
        "    # ========== STAGE 3: CHUNKS ==========",
        "    # Score passages within top documents",
        "    passages: List[Tuple[str, str, int, int, float, Dict[str, float]]] = []",
        "",
        "    for doc_id, doc_score in top_docs:",
        "        if doc_id not in documents:",
        "            continue",
        "",
        "        text = documents[doc_id]",
        "        chunks = create_chunks(text, chunk_size, overlap)",
        "",
        "        for chunk_text, start_char, end_char in chunks:",
        "            chunk_score = score_chunk(chunk_text, query_terms, layer0, tokenizer, doc_id)",
        "",
        "            # ========== STAGE 4: RERANK ==========",
        "            # Combine all signals for final score",
        "            concept_score = doc_concept_scores.get(doc_id, 0.0)",
        "            tfidf_score = doc_tfidf_scores.get(doc_id, 0.0)",
        "",
        "            # Normalize chunk score (avoid division by zero)",
        "            normalized_chunk = chunk_score",
        "",
        "            # Final score combines:",
        "            # - Chunk-level relevance (primary signal)",
        "            # - Document-level TF-IDF (context signal)",
        "            # - Concept relevance (topic signal)",
        "            final_score = (",
        "                0.5 * normalized_chunk +",
        "                0.3 * tfidf_score +",
        "                0.2 * concept_score",
        "            ) * (1 + doc_score * 0.1)  # Slight boost from combined doc score",
        "",
        "            stage_scores = {",
        "                'concept_score': concept_score,",
        "                'doc_score': tfidf_score,",
        "                'chunk_score': chunk_score,",
        "                'combined_doc_score': doc_score,",
        "                'final_score': final_score",
        "            }",
        "",
        "            passages.append((",
        "                chunk_text,",
        "                doc_id,",
        "                start_char,",
        "                end_char,",
        "                final_score,",
        "                stage_scores",
        "            ))",
        "",
        "    # Sort by final score and return top passages",
        "    passages.sort(key=lambda x: x[4], reverse=True)",
        "    return passages[:top_n]",
        "",
        "",
        "def multi_stage_rank_documents(",
        "    query_text: str,",
        "    layers: Dict[CorticalLayer, HierarchicalLayer],",
        "    tokenizer: Tokenizer,",
        "    top_n: int = 5,",
        "    concept_boost: float = 0.3,",
        "    use_expansion: bool = True,",
        "    semantic_relations: Optional[List[Tuple[str, str, str, float]]] = None,",
        "    use_semantic: bool = True",
        ") -> List[Tuple[str, float, Dict[str, float]]]:",
        "    \"\"\"",
        "    Multi-stage ranking for documents (without chunk scoring).",
        "",
        "    Uses the first 2 stages of the pipeline:",
        "    1. Concepts: Filter by topic relevance",
        "    2. Documents: Rank by combined concept + TF-IDF scores",
        "",
        "    Args:",
        "        query_text: Search query",
        "        layers: Dictionary of layers",
        "        tokenizer: Tokenizer instance",
        "        top_n: Number of documents to return",
        "        concept_boost: Weight for concept relevance (0.0-1.0)",
        "        use_expansion: Whether to expand query terms",
        "        semantic_relations: Optional list of semantic relations",
        "        use_semantic: Whether to use semantic relations",
        "",
        "    Returns:",
        "        List of (doc_id, final_score, stage_scores) tuples.",
        "        stage_scores dict contains: concept_score, tfidf_score, combined_score",
        "    \"\"\"",
        "    layer0 = layers[CorticalLayer.TOKENS]",
        "",
        "    # Get expanded query terms",
        "    if use_expansion:",
        "        query_terms = expand_query(query_text, layers, tokenizer, max_expansions=5)",
        "        if use_semantic and semantic_relations:",
        "            semantic_terms = expand_query_semantic(",
        "                query_text, layers, tokenizer, semantic_relations, max_expansions=5",
        "            )",
        "            for term, weight in semantic_terms.items():",
        "                if term not in query_terms:",
        "                    query_terms[term] = weight * 0.8",
        "                else:",
        "                    query_terms[term] = max(query_terms[term], weight * 0.8)",
        "    else:",
        "        tokens = tokenizer.tokenize(query_text)",
        "        query_terms = {t: 1.0 for t in tokens}",
        "",
        "    if not query_terms:",
        "        return []",
        "",
        "    # Stage 1: Concepts",
        "    relevant_concepts = find_relevant_concepts(query_terms, layers, top_n=10)",
        "",
        "    doc_concept_scores: Dict[str, float] = defaultdict(float)",
        "    if relevant_concepts:",
        "        max_concept_score = max(score for _, score, _ in relevant_concepts) if relevant_concepts else 1.0",
        "        for concept_name, concept_score, doc_ids in relevant_concepts:",
        "            normalized_score = concept_score / max_concept_score if max_concept_score > 0 else 0",
        "            for doc_id in doc_ids:",
        "                doc_concept_scores[doc_id] = max(doc_concept_scores[doc_id], normalized_score)",
        "",
        "    # Stage 2: Documents",
        "    doc_tfidf_scores: Dict[str, float] = defaultdict(float)",
        "    for term, term_weight in query_terms.items():",
        "        col = layer0.get_minicolumn(term)",
        "        if col:",
        "            for doc_id in col.document_ids:",
        "                tfidf = col.tfidf_per_doc.get(doc_id, col.tfidf)",
        "                doc_tfidf_scores[doc_id] += tfidf * term_weight",
        "",
        "    # Normalize TF-IDF",
        "    max_tfidf = max(doc_tfidf_scores.values()) if doc_tfidf_scores else 1.0",
        "    for doc_id in doc_tfidf_scores:",
        "        doc_tfidf_scores[doc_id] /= max_tfidf if max_tfidf > 0 else 1.0",
        "",
        "    # Combine scores",
        "    results: List[Tuple[str, float, Dict[str, float]]] = []",
        "    all_docs = set(doc_concept_scores.keys()) | set(doc_tfidf_scores.keys())",
        "",
        "    for doc_id in all_docs:",
        "        concept_score = doc_concept_scores.get(doc_id, 0.0)",
        "        tfidf_score = doc_tfidf_scores.get(doc_id, 0.0)",
        "        combined = (1 - concept_boost) * tfidf_score + concept_boost * concept_score",
        "",
        "        stage_scores = {",
        "            'concept_score': concept_score,",
        "            'tfidf_score': tfidf_score,",
        "            'combined_score': combined",
        "        }",
        "        results.append((doc_id, combined, stage_scores))",
        "",
        "    results.sort(key=lambda x: x[1], reverse=True)",
        "    return results[:top_n]"
      ],
      "lines_removed": [],
      "context_before": [
        "                chunk_text,",
        "                doc_id,",
        "                start_char,",
        "                end_char,",
        "                combined_score",
        "            ))",
        "",
        "    # Sort by score and return top passages",
        "    passages.sort(key=lambda x: x[4], reverse=True)",
        "    return passages[:top_n]"
      ],
      "context_after": [],
      "change_type": "add"
    },
    {
      "file": "tests/test_processor.py",
      "function": "class TestProcessorGaps(unittest.TestCase):",
      "start_line": 353,
      "lines_added": [
        "class TestProcessorBatchQuery(unittest.TestCase):",
        "    \"\"\"Test batch query functionality for efficient multi-query search.\"\"\"",
        "",
        "    @classmethod",
        "    def setUpClass(cls):",
        "        cls.processor = CorticalTextProcessor()",
        "        cls.processor.process_document(\"neural_doc\", \"\"\"",
        "            Neural networks are computational models inspired by biological neurons.",
        "            Deep learning uses many layers to learn hierarchical representations.",
        "            Backpropagation is the key algorithm for training neural networks.",
        "        \"\"\")",
        "        cls.processor.process_document(\"ml_doc\", \"\"\"",
        "            Machine learning algorithms learn patterns from data automatically.",
        "            Supervised learning requires labeled training examples.",
        "            Model evaluation uses metrics like accuracy and precision.",
        "        \"\"\")",
        "        cls.processor.process_document(\"data_doc\", \"\"\"",
        "            Data preprocessing is essential for machine learning pipelines.",
        "            Feature engineering creates meaningful input representations.",
        "            Data normalization scales features to similar ranges.",
        "        \"\"\")",
        "        cls.processor.compute_all(verbose=False)",
        "",
        "    def test_find_documents_batch_returns_list(self):",
        "        \"\"\"Test that find_documents_batch returns a list of results.\"\"\"",
        "        queries = [\"neural networks\", \"machine learning\"]",
        "        results = self.processor.find_documents_batch(queries, top_n=2)",
        "        self.assertIsInstance(results, list)",
        "        self.assertEqual(len(results), 2)",
        "",
        "    def test_find_documents_batch_result_structure(self):",
        "        \"\"\"Test that each result has correct structure.\"\"\"",
        "        queries = [\"neural\", \"data\"]",
        "        results = self.processor.find_documents_batch(queries, top_n=3)",
        "        for result in results:",
        "            self.assertIsInstance(result, list)",
        "            for doc_id, score in result:",
        "                self.assertIsInstance(doc_id, str)",
        "                self.assertIsInstance(score, float)",
        "",
        "    def test_find_documents_batch_returns_relevant_docs(self):",
        "        \"\"\"Test that batch queries return relevant documents.\"\"\"",
        "        queries = [\"neural networks\", \"data preprocessing\"]",
        "        results = self.processor.find_documents_batch(queries, top_n=1)",
        "        # First query should find neural_doc",
        "        self.assertGreater(len(results[0]), 0)",
        "        self.assertEqual(results[0][0][0], \"neural_doc\")",
        "        # Second query should find data_doc",
        "        self.assertGreater(len(results[1]), 0)",
        "        self.assertEqual(results[1][0][0], \"data_doc\")",
        "",
        "    def test_find_documents_batch_top_n(self):",
        "        \"\"\"Test that top_n limits results per query.\"\"\"",
        "        queries = [\"learning\", \"neural\"]",
        "        results = self.processor.find_documents_batch(queries, top_n=2)",
        "        for result in results:",
        "            self.assertLessEqual(len(result), 2)",
        "",
        "    def test_find_documents_batch_empty_query_list(self):",
        "        \"\"\"Test batch with empty query list.\"\"\"",
        "        results = self.processor.find_documents_batch([], top_n=3)",
        "        self.assertEqual(results, [])",
        "",
        "    def test_find_documents_batch_no_expansion(self):",
        "        \"\"\"Test batch query without expansion.\"\"\"",
        "        queries = [\"neural\", \"data\"]",
        "        results = self.processor.find_documents_batch(",
        "            queries, top_n=2, use_expansion=False",
        "        )",
        "        self.assertEqual(len(results), 2)",
        "",
        "    def test_find_passages_batch_returns_list(self):",
        "        \"\"\"Test that find_passages_batch returns a list of results.\"\"\"",
        "        queries = [\"neural networks\", \"machine learning\"]",
        "        results = self.processor.find_passages_batch(queries, top_n=2)",
        "        self.assertIsInstance(results, list)",
        "        self.assertEqual(len(results), 2)",
        "",
        "    def test_find_passages_batch_result_structure(self):",
        "        \"\"\"Test that each passage result has correct structure.\"\"\"",
        "        queries = [\"neural\"]",
        "        results = self.processor.find_passages_batch(queries, top_n=3)",
        "        self.assertEqual(len(results), 1)",
        "        for passage, doc_id, start, end, score in results[0]:",
        "            self.assertIsInstance(passage, str)",
        "            self.assertIsInstance(doc_id, str)",
        "            self.assertIsInstance(start, int)",
        "            self.assertIsInstance(end, int)",
        "            self.assertIsInstance(score, float)",
        "",
        "    def test_find_passages_batch_top_n(self):",
        "        \"\"\"Test that top_n limits passages per query.\"\"\"",
        "        queries = [\"learning\", \"neural\"]",
        "        results = self.processor.find_passages_batch(queries, top_n=2)",
        "        for result in results:",
        "            self.assertLessEqual(len(result), 2)",
        "",
        "    def test_find_passages_batch_chunk_size(self):",
        "        \"\"\"Test that chunk_size is respected.\"\"\"",
        "        queries = [\"neural\"]",
        "        results = self.processor.find_passages_batch(",
        "            queries, top_n=5, chunk_size=100, overlap=20",
        "        )",
        "        for passage, _, _, _, _ in results[0]:",
        "            self.assertLessEqual(len(passage), 100)",
        "",
        "    def test_find_passages_batch_doc_filter(self):",
        "        \"\"\"Test that doc_filter restricts results.\"\"\"",
        "        queries = [\"learning\", \"neural\"]",
        "        results = self.processor.find_passages_batch(",
        "            queries, top_n=10, doc_filter=[\"neural_doc\"]",
        "        )",
        "        for result in results:",
        "            for _, doc_id, _, _, _ in result:",
        "                self.assertEqual(doc_id, \"neural_doc\")",
        "",
        "    def test_find_passages_batch_empty_query_list(self):",
        "        \"\"\"Test batch with empty query list.\"\"\"",
        "        results = self.processor.find_passages_batch([], top_n=3)",
        "        self.assertEqual(results, [])",
        "",
        "    def test_batch_query_consistency(self):",
        "        \"\"\"Test that batch results match individual queries.\"\"\"",
        "        queries = [\"neural networks\", \"data processing\"]",
        "        batch_results = self.processor.find_documents_batch(queries, top_n=3)",
        "",
        "        # Compare with individual queries",
        "        for i, query in enumerate(queries):",
        "            individual_result = self.processor.find_documents_for_query(query, top_n=3)",
        "            # Results should be the same (or very close)",
        "            self.assertEqual(len(batch_results[i]), len(individual_result))",
        "            for j, (doc_id, score) in enumerate(batch_results[i]):",
        "                self.assertEqual(doc_id, individual_result[j][0])",
        "",
        "    def test_batch_handles_nonexistent_terms(self):",
        "        \"\"\"Test that batch handles queries with no matches.\"\"\"",
        "        queries = [\"xyznonexistent123\", \"neural networks\"]",
        "        results = self.processor.find_documents_batch(queries, top_n=3)",
        "        self.assertEqual(len(results), 2)",
        "        self.assertEqual(len(results[0]), 0)  # No matches for nonexistent",
        "        self.assertGreater(len(results[1]), 0)  # Matches for neural networks",
        "",
        "",
        "class TestProcessorMultiStageRanking(unittest.TestCase):",
        "    \"\"\"Test multi-stage ranking pipeline for RAG systems.\"\"\"",
        "",
        "    @classmethod",
        "    def setUpClass(cls):",
        "        cls.processor = CorticalTextProcessor()",
        "        # Create a diverse corpus for testing multi-stage ranking",
        "        cls.processor.process_document(\"neural_doc\", \"\"\"",
        "            Neural networks are computational models inspired by biological neurons.",
        "            Deep learning uses many layers to learn hierarchical representations.",
        "            Backpropagation is the key algorithm for training neural networks.",
        "            Convolutional neural networks excel at image recognition tasks.",
        "        \"\"\")",
        "        cls.processor.process_document(\"ml_doc\", \"\"\"",
        "            Machine learning algorithms learn patterns from data automatically.",
        "            Supervised learning requires labeled training examples.",
        "            Unsupervised learning discovers hidden structure in data.",
        "            Model evaluation uses metrics like accuracy precision and recall.",
        "        \"\"\")",
        "        cls.processor.process_document(\"data_doc\", \"\"\"",
        "            Data preprocessing is essential for machine learning pipelines.",
        "            Feature engineering creates meaningful input representations.",
        "            Data normalization scales features to similar ranges.",
        "            Cross-validation ensures robust model performance estimates.",
        "        \"\"\")",
        "        cls.processor.process_document(\"nlp_doc\", \"\"\"",
        "            Natural language processing enables computers to understand text.",
        "            Word embeddings capture semantic relationships between words.",
        "            Transformers use attention mechanisms for sequence modeling.",
        "            Language models can generate coherent text passages.",
        "        \"\"\")",
        "        cls.processor.compute_all(verbose=False)",
        "",
        "    def test_multi_stage_rank_returns_list(self):",
        "        \"\"\"Test that multi_stage_rank returns a list.\"\"\"",
        "        results = self.processor.multi_stage_rank(\"neural networks\", top_n=3)",
        "        self.assertIsInstance(results, list)",
        "",
        "    def test_multi_stage_rank_result_structure(self):",
        "        \"\"\"Test that results have correct 6-tuple structure.\"\"\"",
        "        results = self.processor.multi_stage_rank(\"neural\", top_n=3)",
        "        self.assertGreater(len(results), 0)",
        "        passage, doc_id, start, end, score, stage_scores = results[0]",
        "        self.assertIsInstance(passage, str)",
        "        self.assertIsInstance(doc_id, str)",
        "        self.assertIsInstance(start, int)",
        "        self.assertIsInstance(end, int)",
        "        self.assertIsInstance(score, float)",
        "        self.assertIsInstance(stage_scores, dict)",
        "",
        "    def test_multi_stage_rank_stage_scores(self):",
        "        \"\"\"Test that stage_scores contains expected keys.\"\"\"",
        "        results = self.processor.multi_stage_rank(\"neural networks\", top_n=3)",
        "        self.assertGreater(len(results), 0)",
        "        _, _, _, _, _, stage_scores = results[0]",
        "        self.assertIn('concept_score', stage_scores)",
        "        self.assertIn('doc_score', stage_scores)",
        "        self.assertIn('chunk_score', stage_scores)",
        "        self.assertIn('final_score', stage_scores)",
        "",
        "    def test_multi_stage_rank_top_n(self):",
        "        \"\"\"Test that top_n limits results.\"\"\"",
        "        results = self.processor.multi_stage_rank(\"learning\", top_n=2)",
        "        self.assertLessEqual(len(results), 2)",
        "",
        "    def test_multi_stage_rank_chunk_size(self):",
        "        \"\"\"Test that chunk_size is respected.\"\"\"",
        "        results = self.processor.multi_stage_rank(",
        "            \"neural\", top_n=5, chunk_size=100, overlap=20",
        "        )",
        "        for passage, _, _, _, _, _ in results:",
        "            self.assertLessEqual(len(passage), 100)",
        "",
        "    def test_multi_stage_rank_concept_boost(self):",
        "        \"\"\"Test that concept_boost parameter is used.\"\"\"",
        "        # Test with high concept boost vs low",
        "        results_high = self.processor.multi_stage_rank(",
        "            \"neural\", top_n=3, concept_boost=0.8",
        "        )",
        "        results_low = self.processor.multi_stage_rank(",
        "            \"neural\", top_n=3, concept_boost=0.1",
        "        )",
        "        # Both should return results (exact ordering may differ)",
        "        self.assertGreater(len(results_high), 0)",
        "        self.assertGreater(len(results_low), 0)",
        "",
        "    def test_multi_stage_rank_sorted_descending(self):",
        "        \"\"\"Test that results are sorted by score descending.\"\"\"",
        "        results = self.processor.multi_stage_rank(\"neural networks\", top_n=5)",
        "        if len(results) > 1:",
        "            scores = [score for _, _, _, _, score, _ in results]",
        "            self.assertEqual(scores, sorted(scores, reverse=True))",
        "",
        "    def test_multi_stage_rank_documents_returns_list(self):",
        "        \"\"\"Test that multi_stage_rank_documents returns a list.\"\"\"",
        "        results = self.processor.multi_stage_rank_documents(\"neural networks\", top_n=3)",
        "        self.assertIsInstance(results, list)",
        "",
        "    def test_multi_stage_rank_documents_structure(self):",
        "        \"\"\"Test that document results have correct 3-tuple structure.\"\"\"",
        "        results = self.processor.multi_stage_rank_documents(\"neural\", top_n=3)",
        "        self.assertGreater(len(results), 0)",
        "        doc_id, score, stage_scores = results[0]",
        "        self.assertIsInstance(doc_id, str)",
        "        self.assertIsInstance(score, float)",
        "        self.assertIsInstance(stage_scores, dict)",
        "",
        "    def test_multi_stage_rank_documents_stage_scores(self):",
        "        \"\"\"Test that document stage_scores contains expected keys.\"\"\"",
        "        results = self.processor.multi_stage_rank_documents(\"neural networks\", top_n=3)",
        "        self.assertGreater(len(results), 0)",
        "        _, _, stage_scores = results[0]",
        "        self.assertIn('concept_score', stage_scores)",
        "        self.assertIn('tfidf_score', stage_scores)",
        "        self.assertIn('combined_score', stage_scores)",
        "",
        "    def test_multi_stage_rank_documents_top_n(self):",
        "        \"\"\"Test that top_n limits document results.\"\"\"",
        "        results = self.processor.multi_stage_rank_documents(\"learning\", top_n=2)",
        "        self.assertLessEqual(len(results), 2)",
        "",
        "    def test_multi_stage_rank_documents_sorted(self):",
        "        \"\"\"Test that document results are sorted by score descending.\"\"\"",
        "        results = self.processor.multi_stage_rank_documents(\"neural networks\", top_n=5)",
        "        if len(results) > 1:",
        "            scores = [score for _, score, _ in results]",
        "            self.assertEqual(scores, sorted(scores, reverse=True))",
        "",
        "    def test_multi_stage_rank_empty_query(self):",
        "        \"\"\"Test handling of query with no matches.\"\"\"",
        "        results = self.processor.multi_stage_rank(\"xyznonexistent123\", top_n=3)",
        "        self.assertEqual(len(results), 0)",
        "",
        "    def test_multi_stage_rank_without_expansion(self):",
        "        \"\"\"Test multi-stage ranking without query expansion.\"\"\"",
        "        results = self.processor.multi_stage_rank(",
        "            \"neural\", top_n=3, use_expansion=False",
        "        )",
        "        self.assertIsInstance(results, list)",
        "",
        "    def test_multi_stage_vs_flat_ranking(self):",
        "        \"\"\"Test that multi-stage ranking produces results comparable to flat ranking.\"\"\"",
        "        # Both should find relevant documents for the same query",
        "        multi_results = self.processor.multi_stage_rank(\"neural networks\", top_n=3)",
        "        flat_results = self.processor.find_passages_for_query(\"neural networks\", top_n=3)",
        "",
        "        # Both should return results",
        "        self.assertGreater(len(multi_results), 0)",
        "        self.assertGreater(len(flat_results), 0)",
        "",
        "        # Both should find the neural_doc",
        "        multi_docs = {doc_id for _, doc_id, _, _, _, _ in multi_results}",
        "        flat_docs = {doc_id for _, doc_id, _, _, _ in flat_results}",
        "        self.assertIn(\"neural_doc\", multi_docs)",
        "        self.assertIn(\"neural_doc\", flat_docs)",
        "",
        "",
        "class TestProcessorIncrementalIndexing(unittest.TestCase):",
        "    \"\"\"Test incremental document indexing functionality.\"\"\"",
        "",
        "    def setUp(self):",
        "        self.processor = CorticalTextProcessor()",
        "",
        "    def test_add_document_incremental_returns_stats(self):",
        "        \"\"\"Test that add_document_incremental returns processing stats.\"\"\"",
        "        stats = self.processor.add_document_incremental(",
        "            \"doc1\", \"Neural networks process information.\", recompute='tfidf'",
        "        )",
        "        self.assertIn('tokens', stats)",
        "        self.assertIn('bigrams', stats)",
        "        self.assertIn('unique_tokens', stats)",
        "        self.assertGreater(stats['tokens'], 0)",
        "",
        "    def test_add_document_incremental_with_metadata(self):",
        "        \"\"\"Test incremental add with metadata.\"\"\"",
        "        self.processor.add_document_incremental(",
        "            \"doc1\",",
        "            \"Test content.\",",
        "            metadata={\"source\": \"test\", \"author\": \"AI\"},",
        "            recompute='tfidf'",
        "        )",
        "        metadata = self.processor.get_document_metadata(\"doc1\")",
        "        self.assertEqual(metadata[\"source\"], \"test\")",
        "        self.assertEqual(metadata[\"author\"], \"AI\")",
        "",
        "    def test_add_document_incremental_recompute_none(self):",
        "        \"\"\"Test that recompute='none' marks computations as stale.\"\"\"",
        "        self.processor.add_document_incremental(",
        "            \"doc1\", \"Test content.\", recompute='none'",
        "        )",
        "        # Should be stale",
        "        self.assertTrue(self.processor.is_stale(CorticalTextProcessor.COMP_TFIDF))",
        "        self.assertTrue(self.processor.is_stale(CorticalTextProcessor.COMP_PAGERANK))",
        "",
        "    def test_add_document_incremental_recompute_tfidf(self):",
        "        \"\"\"Test that recompute='tfidf' only recomputes TF-IDF.\"\"\"",
        "        self.processor.add_document_incremental(",
        "            \"doc1\", \"Test content.\", recompute='tfidf'",
        "        )",
        "        # TF-IDF should be fresh",
        "        self.assertFalse(self.processor.is_stale(CorticalTextProcessor.COMP_TFIDF))",
        "        # Other computations should be stale",
        "        self.assertTrue(self.processor.is_stale(CorticalTextProcessor.COMP_PAGERANK))",
        "",
        "    def test_add_document_incremental_recompute_full(self):",
        "        \"\"\"Test that recompute='full' clears all staleness.\"\"\"",
        "        self.processor.add_document_incremental(",
        "            \"doc1\", \"Test content.\", recompute='full'",
        "        )",
        "        # All should be fresh",
        "        self.assertFalse(self.processor.is_stale(CorticalTextProcessor.COMP_TFIDF))",
        "        self.assertFalse(self.processor.is_stale(CorticalTextProcessor.COMP_PAGERANK))",
        "        self.assertFalse(self.processor.is_stale(CorticalTextProcessor.COMP_ACTIVATION))",
        "",
        "    def test_add_documents_batch_returns_stats(self):",
        "        \"\"\"Test that add_documents_batch returns batch statistics.\"\"\"",
        "        docs = [",
        "            (\"doc1\", \"First document content.\", {\"source\": \"web\"}),",
        "            (\"doc2\", \"Second document content.\", None),",
        "            (\"doc3\", \"Third document content.\", {\"author\": \"AI\"}),",
        "        ]",
        "        stats = self.processor.add_documents_batch(docs, recompute='full', verbose=False)",
        "        self.assertEqual(stats['documents_added'], 3)",
        "        self.assertIn('total_tokens', stats)",
        "        self.assertIn('total_bigrams', stats)",
        "        self.assertEqual(stats['recomputation'], 'full')",
        "",
        "    def test_add_documents_batch_preserves_metadata(self):",
        "        \"\"\"Test that batch add preserves metadata for all documents.\"\"\"",
        "        docs = [",
        "            (\"doc1\", \"First content.\", {\"type\": \"article\"}),",
        "            (\"doc2\", \"Second content.\", {\"type\": \"paper\"}),",
        "        ]",
        "        self.processor.add_documents_batch(docs, recompute='tfidf', verbose=False)",
        "        self.assertEqual(self.processor.get_document_metadata(\"doc1\")[\"type\"], \"article\")",
        "        self.assertEqual(self.processor.get_document_metadata(\"doc2\")[\"type\"], \"paper\")",
        "",
        "    def test_add_documents_batch_recompute_none(self):",
        "        \"\"\"Test batch add with no recomputation.\"\"\"",
        "        docs = [(\"doc1\", \"Content one.\", None), (\"doc2\", \"Content two.\", None)]",
        "        self.processor.add_documents_batch(docs, recompute='none', verbose=False)",
        "        self.assertTrue(self.processor.is_stale(CorticalTextProcessor.COMP_TFIDF))",
        "        self.assertEqual(len(self.processor.documents), 2)",
        "",
        "    def test_recompute_full(self):",
        "        \"\"\"Test recompute with level='full'.\"\"\"",
        "        self.processor.add_document_incremental(\"doc1\", \"Test content.\", recompute='none')",
        "        recomputed = self.processor.recompute(level='full', verbose=False)",
        "        self.assertIn(CorticalTextProcessor.COMP_TFIDF, recomputed)",
        "        self.assertIn(CorticalTextProcessor.COMP_PAGERANK, recomputed)",
        "        self.assertFalse(self.processor.is_stale(CorticalTextProcessor.COMP_TFIDF))",
        "",
        "    def test_recompute_tfidf(self):",
        "        \"\"\"Test recompute with level='tfidf'.\"\"\"",
        "        self.processor.add_document_incremental(\"doc1\", \"Test content.\", recompute='none')",
        "        recomputed = self.processor.recompute(level='tfidf', verbose=False)",
        "        self.assertEqual(recomputed, {CorticalTextProcessor.COMP_TFIDF: True})",
        "        self.assertFalse(self.processor.is_stale(CorticalTextProcessor.COMP_TFIDF))",
        "        # Others still stale",
        "        self.assertTrue(self.processor.is_stale(CorticalTextProcessor.COMP_PAGERANK))",
        "",
        "    def test_recompute_stale_only(self):",
        "        \"\"\"Test recompute with level='stale' (only recomputes stale items).\"\"\"",
        "        self.processor.add_document_incremental(\"doc1\", \"Test content.\", recompute='tfidf')",
        "        # Now only pagerank, activation, etc. are stale",
        "        recomputed = self.processor.recompute(level='stale', verbose=False)",
        "        # TF-IDF should NOT be in recomputed (it was already fresh)",
        "        self.assertNotIn(CorticalTextProcessor.COMP_TFIDF, recomputed)",
        "        # Others should be recomputed",
        "        self.assertIn(CorticalTextProcessor.COMP_PAGERANK, recomputed)",
        "",
        "    def test_get_stale_computations(self):",
        "        \"\"\"Test get_stale_computations returns correct set.\"\"\"",
        "        self.processor.add_document_incremental(\"doc1\", \"Test content.\", recompute='tfidf')",
        "        stale = self.processor.get_stale_computations()",
        "        self.assertNotIn(CorticalTextProcessor.COMP_TFIDF, stale)",
        "        self.assertIn(CorticalTextProcessor.COMP_PAGERANK, stale)",
        "",
        "    def test_is_stale(self):",
        "        \"\"\"Test is_stale returns correct boolean.\"\"\"",
        "        self.processor.add_document_incremental(\"doc1\", \"Test content.\", recompute='none')",
        "        self.assertTrue(self.processor.is_stale(CorticalTextProcessor.COMP_TFIDF))",
        "        self.processor.compute_tfidf(verbose=False)",
        "        self.processor._mark_fresh(CorticalTextProcessor.COMP_TFIDF)",
        "        self.assertFalse(self.processor.is_stale(CorticalTextProcessor.COMP_TFIDF))",
        "",
        "    def test_incremental_workflow(self):",
        "        \"\"\"Test typical incremental indexing workflow.\"\"\"",
        "        # Initial corpus",
        "        self.processor.process_document(\"doc1\", \"Neural networks process information.\")",
        "        self.processor.compute_all(verbose=False)",
        "",
        "        # Add new documents incrementally",
        "        self.processor.add_document_incremental(",
        "            \"doc2\", \"Machine learning algorithms.\", recompute='tfidf'",
        "        )",
        "",
        "        # Search should work",
        "        results = self.processor.find_documents_for_query(\"neural\", top_n=2)",
        "        self.assertIsInstance(results, list)",
        "",
        "        # Full recompute when needed",
        "        self.processor.recompute(level='full', verbose=False)",
        "        self.assertEqual(len(self.processor.get_stale_computations()), 0)",
        "",
        "    def test_batch_then_query(self):",
        "        \"\"\"Test batch add followed by querying.\"\"\"",
        "        docs = [",
        "            (\"neural\", \"Neural networks deep learning AI.\", None),",
        "            (\"ml\", \"Machine learning algorithms models.\", None),",
        "            (\"data\", \"Data processing storage retrieval.\", None),",
        "        ]",
        "        self.processor.add_documents_batch(docs, recompute='full', verbose=False)",
        "",
        "        results = self.processor.find_documents_for_query(\"neural networks\", top_n=3)",
        "        self.assertGreater(len(results), 0)",
        "        # The neural doc should rank highest",
        "        self.assertEqual(results[0][0], \"neural\")",
        "",
        "",
        "class TestCrossLayerConnections(unittest.TestCase):",
        "    \"\"\"Test cross-layer feedforward and feedback connections.\"\"\"",
        "",
        "    def setUp(self):",
        "        self.processor = CorticalTextProcessor()",
        "        self.processor.process_document(\"doc1\", \"Neural networks process information efficiently.\")",
        "        self.processor.process_document(\"doc2\", \"Deep learning neural models are powerful.\")",
        "        self.processor.compute_all(verbose=False)",
        "",
        "    def test_bigram_feedforward_connections(self):",
        "        \"\"\"Test that bigrams have feedforward connections to component tokens.\"\"\"",
        "        layer0 = self.processor.get_layer(CorticalLayer.TOKENS)",
        "        layer1 = self.processor.get_layer(CorticalLayer.BIGRAMS)",
        "",
        "        bigram = layer1.get_minicolumn(\"neural networks\")",
        "        self.assertIsNotNone(bigram)",
        "        self.assertGreater(len(bigram.feedforward_connections), 0)",
        "",
        "        # Should connect to both \"neural\" and \"networks\"",
        "        neural = layer0.get_minicolumn(\"neural\")",
        "        networks = layer0.get_minicolumn(\"networks\")",
        "        self.assertIn(neural.id, bigram.feedforward_connections)",
        "        self.assertIn(networks.id, bigram.feedforward_connections)",
        "",
        "    def test_bigram_feedforward_weights(self):",
        "        \"\"\"Test that bigram feedforward connections have accumulated weights.\"\"\"",
        "        layer1 = self.processor.get_layer(CorticalLayer.BIGRAMS)",
        "",
        "        bigram = layer1.get_minicolumn(\"neural networks\")",
        "        self.assertIsNotNone(bigram)",
        "",
        "        # Weight should be >= 1.0 (accumulated from occurrences)",
        "        for target_id, weight in bigram.feedforward_connections.items():",
        "            self.assertGreaterEqual(weight, 1.0)",
        "",
        "    def test_token_feedback_to_bigrams(self):",
        "        \"\"\"Test that tokens have feedback connections to bigrams.\"\"\"",
        "        layer0 = self.processor.get_layer(CorticalLayer.TOKENS)",
        "        layer1 = self.processor.get_layer(CorticalLayer.BIGRAMS)",
        "",
        "        neural = layer0.get_minicolumn(\"neural\")",
        "        self.assertIsNotNone(neural)",
        "        self.assertGreater(len(neural.feedback_connections), 0)",
        "",
        "        # Should connect back to bigrams containing \"neural\"",
        "        bigram = layer1.get_minicolumn(\"neural networks\")",
        "        if bigram:",
        "            self.assertIn(bigram.id, neural.feedback_connections)",
        "",
        "    def test_document_feedforward_connections(self):",
        "        \"\"\"Test that documents have feedforward connections to tokens.\"\"\"",
        "        layer0 = self.processor.get_layer(CorticalLayer.TOKENS)",
        "        layer3 = self.processor.get_layer(CorticalLayer.DOCUMENTS)",
        "",
        "        doc = layer3.get_minicolumn(\"doc1\")",
        "        self.assertIsNotNone(doc)",
        "        self.assertGreater(len(doc.feedforward_connections), 0)",
        "",
        "        # Document should connect to tokens in its content",
        "        neural = layer0.get_minicolumn(\"neural\")",
        "        self.assertIn(neural.id, doc.feedforward_connections)",
        "",
        "    def test_document_feedforward_weights(self):",
        "        \"\"\"Test that document feedforward weights reflect token frequency.\"\"\"",
        "        layer0 = self.processor.get_layer(CorticalLayer.TOKENS)",
        "        layer3 = self.processor.get_layer(CorticalLayer.DOCUMENTS)",
        "",
        "        doc = layer3.get_minicolumn(\"doc1\")",
        "        neural = layer0.get_minicolumn(\"neural\")",
        "",
        "        # Weight should match occurrence count",
        "        weight = doc.feedforward_connections.get(neural.id, 0)",
        "        self.assertGreaterEqual(weight, 1.0)",
        "",
        "    def test_token_feedback_to_documents(self):",
        "        \"\"\"Test that tokens have feedback connections to documents.\"\"\"",
        "        layer0 = self.processor.get_layer(CorticalLayer.TOKENS)",
        "        layer3 = self.processor.get_layer(CorticalLayer.DOCUMENTS)",
        "",
        "        neural = layer0.get_minicolumn(\"neural\")",
        "        self.assertIsNotNone(neural)",
        "",
        "        # Should connect to documents containing this token",
        "        doc1 = layer3.get_minicolumn(\"doc1\")",
        "        doc2 = layer3.get_minicolumn(\"doc2\")",
        "        self.assertIn(doc1.id, neural.feedback_connections)",
        "        self.assertIn(doc2.id, neural.feedback_connections)",
        "",
        "    def test_concept_feedforward_connections(self):",
        "        \"\"\"Test that concepts have feedforward connections to member tokens.\"\"\"",
        "        layer2 = self.processor.get_layer(CorticalLayer.CONCEPTS)",
        "",
        "        if layer2.column_count() > 0:",
        "            # Get first concept",
        "            concept = list(layer2.minicolumns.values())[0]",
        "            self.assertGreater(len(concept.feedforward_connections), 0)",
        "",
        "            # All feedforward targets should be in feedforward_sources too",
        "            for target_id in concept.feedforward_connections:",
        "                self.assertIn(target_id, concept.feedforward_sources)",
        "",
        "    def test_concept_feedforward_weights_by_pagerank(self):",
        "        \"\"\"Test that concept feedforward weights are based on token PageRank.\"\"\"",
        "        layer0 = self.processor.get_layer(CorticalLayer.TOKENS)",
        "        layer2 = self.processor.get_layer(CorticalLayer.CONCEPTS)",
        "",
        "        if layer2.column_count() > 0:",
        "            concept = list(layer2.minicolumns.values())[0]",
        "",
        "            # Weights should be normalized (max = 1.0)",
        "            max_weight = max(concept.feedforward_connections.values())",
        "            self.assertLessEqual(max_weight, 1.0 + 0.001)  # Allow small float error",
        "",
        "    def test_token_feedback_to_concepts(self):",
        "        \"\"\"Test that tokens have feedback connections to concepts.\"\"\"",
        "        layer0 = self.processor.get_layer(CorticalLayer.TOKENS)",
        "        layer2 = self.processor.get_layer(CorticalLayer.CONCEPTS)",
        "",
        "        if layer2.column_count() > 0:",
        "            concept = list(layer2.minicolumns.values())[0]",
        "",
        "            # Get a member token",
        "            if concept.feedforward_connections:",
        "                member_id = list(concept.feedforward_connections.keys())[0]",
        "                member = layer0.get_by_id(member_id)",
        "                if member:",
        "                    self.assertIn(concept.id, member.feedback_connections)",
        "",
        "    def test_cross_layer_bidirectional(self):",
        "        \"\"\"Test that cross-layer connections are bidirectional.\"\"\"",
        "        layer0 = self.processor.get_layer(CorticalLayer.TOKENS)",
        "        layer1 = self.processor.get_layer(CorticalLayer.BIGRAMS)",
        "",
        "        bigram = layer1.get_minicolumn(\"neural networks\")",
        "        if bigram:",
        "            for target_id in bigram.feedforward_connections:",
        "                token = layer0.get_by_id(target_id)",
        "                if token:",
        "                    self.assertIn(bigram.id, token.feedback_connections)",
        "",
        "    def test_persistence_cross_layer_connections(self):",
        "        \"\"\"Test that cross-layer connections are saved and loaded correctly.\"\"\"",
        "        import tempfile",
        "",
        "        layer1 = self.processor.get_layer(CorticalLayer.BIGRAMS)",
        "        bigram = layer1.get_minicolumn(\"neural networks\")",
        "        original_ff = dict(bigram.feedforward_connections) if bigram else {}",
        "",
        "        with tempfile.NamedTemporaryFile(suffix='.pkl', delete=False) as f:",
        "            path = f.name",
        "",
        "        try:",
        "            self.processor.save(path)",
        "            loaded = CorticalTextProcessor.load(path)",
        "",
        "            loaded_layer1 = loaded.get_layer(CorticalLayer.BIGRAMS)",
        "            loaded_bigram = loaded_layer1.get_minicolumn(\"neural networks\")",
        "",
        "            if bigram and loaded_bigram:",
        "                self.assertEqual(",
        "                    loaded_bigram.feedforward_connections,",
        "                    original_ff",
        "                )",
        "        finally:",
        "            os.unlink(path)",
        "",
        "    def test_cross_layer_connection_count(self):",
        "        \"\"\"Test counting cross-layer connections.\"\"\"",
        "        layer1 = self.processor.get_layer(CorticalLayer.BIGRAMS)",
        "",
        "        total_ff = 0",
        "        for col in layer1.minicolumns.values():",
        "            total_ff += len(col.feedforward_connections)",
        "",
        "        # Each bigram should have 2 feedforward connections (to its 2 tokens)",
        "        # So total should be approximately 2 * number of bigrams",
        "        self.assertGreater(total_ff, 0)",
        "",
        "",
        "class TestConceptConnections(unittest.TestCase):",
        "    \"\"\"Test concept-level lateral connections.\"\"\"",
        "",
        "    def setUp(self):",
        "        self.processor = CorticalTextProcessor()",
        "        # Create documents with overlapping topics",
        "        self.processor.process_document(\"neural_doc\",",
        "            \"Neural networks process information using deep learning algorithms.\")",
        "        self.processor.process_document(\"ml_doc\",",
        "            \"Machine learning algorithms learn patterns from data using neural methods.\")",
        "        self.processor.process_document(\"data_doc\",",
        "            \"Data processing systems analyze information patterns efficiently.\")",
        "        self.processor.process_document(\"unrelated_doc\",",
        "            \"Ancient pottery techniques involve clay and firing in kilns.\")",
        "        self.processor.compute_all(verbose=False)",
        "",
        "    def test_concepts_have_lateral_connections(self):",
        "        \"\"\"Test that concepts have lateral connections when documents overlap.\"\"\"",
        "        # Create a processor with documents that will create multiple overlapping concepts",
        "        processor = CorticalTextProcessor()",
        "        # Add many documents with overlapping terms to force multiple concept clusters",
        "        processor.process_document(\"doc1\", \"Neural networks deep learning artificial intelligence models.\")",
        "        processor.process_document(\"doc2\", \"Machine learning algorithms data science models.\")",
        "        processor.process_document(\"doc3\", \"Deep learning neural networks training optimization.\")",
        "        processor.process_document(\"doc4\", \"Data analysis machine learning statistical models.\")",
        "        processor.process_document(\"doc5\", \"Artificial intelligence reasoning knowledge graphs.\")",
        "        processor.process_document(\"doc6\", \"Knowledge representation semantic networks graphs.\")",
        "        processor.compute_all(verbose=False)",
        "",
        "        layer2 = processor.get_layer(CorticalLayer.CONCEPTS)",
        "",
        "        # If we have multiple concepts with overlapping docs, they should connect",
        "        if layer2.column_count() > 1:",
        "            # Check if any concepts share documents",
        "            concepts = list(layer2.minicolumns.values())",
        "            has_overlap = False",
        "            for i, c1 in enumerate(concepts):",
        "                for c2 in concepts[i+1:]:",
        "                    if c1.document_ids & c2.document_ids:",
        "                        has_overlap = True",
        "                        break",
        "",
        "            if has_overlap:",
        "                total_connections = sum(",
        "                    len(c.lateral_connections) for c in layer2.minicolumns.values()",
        "                )",
        "                self.assertGreater(total_connections, 0)",
        "",
        "    def test_concept_connections_based_on_jaccard(self):",
        "        \"\"\"Test that concept connections are based on document overlap.\"\"\"",
        "        layer2 = self.processor.get_layer(CorticalLayer.CONCEPTS)",
        "",
        "        if layer2.column_count() > 1:",
        "            concepts = list(layer2.minicolumns.values())",
        "            # Find concepts with connections",
        "            connected_concepts = [c for c in concepts if c.lateral_connections]",
        "",
        "            for concept in connected_concepts:",
        "                for target_id, weight in concept.lateral_connections.items():",
        "                    # Weight should be based on Jaccard (0 < weight <= 1.5 with semantic boost)",
        "                    self.assertGreater(weight, 0)",
        "                    self.assertLessEqual(weight, 2.0)  # Max with semantic boost",
        "",
        "    def test_compute_concept_connections_method(self):",
        "        \"\"\"Test the compute_concept_connections method directly.\"\"\"",
        "        # Clear existing connections",
        "        layer2 = self.processor.get_layer(CorticalLayer.CONCEPTS)",
        "        for concept in layer2.minicolumns.values():",
        "            concept.lateral_connections.clear()",
        "",
        "        # Recompute",
        "        stats = self.processor.compute_concept_connections(verbose=False)",
        "",
        "        self.assertIn('connections_created', stats)",
        "        self.assertIn('concepts', stats)",
        "        self.assertGreaterEqual(stats['connections_created'], 0)",
        "",
        "    def test_concept_connections_with_semantics(self):",
        "        \"\"\"Test that semantic relations boost connection weights.\"\"\"",
        "        # Extract semantics first",
        "        self.processor.extract_corpus_semantics(verbose=False)",
        "",
        "        # Clear and recompute with semantics",
        "        layer2 = self.processor.get_layer(CorticalLayer.CONCEPTS)",
        "        for concept in layer2.minicolumns.values():",
        "            concept.lateral_connections.clear()",
        "",
        "        stats_with = self.processor.compute_concept_connections(",
        "            use_semantics=True, verbose=False",
        "        )",
        "",
        "        # Clear and recompute without semantics",
        "        for concept in layer2.minicolumns.values():",
        "            concept.lateral_connections.clear()",
        "",
        "        stats_without = self.processor.compute_concept_connections(",
        "            use_semantics=False, verbose=False",
        "        )",
        "",
        "        # Both should work",
        "        self.assertGreaterEqual(stats_with['connections_created'], 0)",
        "        self.assertGreaterEqual(stats_without['connections_created'], 0)",
        "",
        "    def test_concept_connections_min_jaccard_filter(self):",
        "        \"\"\"Test that min_jaccard threshold filters connections.\"\"\"",
        "        layer2 = self.processor.get_layer(CorticalLayer.CONCEPTS)",
        "",
        "        # Clear connections",
        "        for concept in layer2.minicolumns.values():",
        "            concept.lateral_connections.clear()",
        "",
        "        # With low threshold",
        "        stats_low = self.processor.compute_concept_connections(",
        "            min_jaccard=0.01, verbose=False",
        "        )",
        "",
        "        # Clear again",
        "        for concept in layer2.minicolumns.values():",
        "            concept.lateral_connections.clear()",
        "",
        "        # With high threshold",
        "        stats_high = self.processor.compute_concept_connections(",
        "            min_jaccard=0.9, verbose=False",
        "        )",
        "",
        "        # Low threshold should create >= high threshold connections",
        "        self.assertGreaterEqual(",
        "            stats_low['connections_created'],",
        "            stats_high['connections_created']",
        "        )",
        "",
        "    def test_concept_connections_bidirectional(self):",
        "        \"\"\"Test that concept connections are bidirectional.\"\"\"",
        "        layer2 = self.processor.get_layer(CorticalLayer.CONCEPTS)",
        "",
        "        for concept in layer2.minicolumns.values():",
        "            for target_id, weight in concept.lateral_connections.items():",
        "                target = layer2.get_by_id(target_id)",
        "                if target:",
        "                    # Target should have connection back to this concept",
        "                    self.assertIn(concept.id, target.lateral_connections)",
        "",
        "    def test_concept_connections_empty_layer(self):",
        "        \"\"\"Test concept connections with empty concept layer.\"\"\"",
        "        processor = CorticalTextProcessor()",
        "        processor.process_document(\"doc1\", \"Hello world.\")",
        "        processor.compute_all(verbose=False, build_concepts=False)",
        "",
        "        layer2 = processor.get_layer(CorticalLayer.CONCEPTS)",
        "        self.assertEqual(layer2.column_count(), 0)",
        "",
        "        # Should handle empty layer gracefully",
        "        stats = processor.compute_concept_connections(verbose=False)",
        "        self.assertEqual(stats['connections_created'], 0)",
        "        self.assertEqual(stats['concepts'], 0)",
        "",
        "    def test_isolated_concepts_not_connected(self):",
        "        \"\"\"Test that concepts with no document overlap don't connect.\"\"\"",
        "        # The unrelated_doc about pottery should form isolated concepts",
        "        layer2 = self.processor.get_layer(CorticalLayer.CONCEPTS)",
        "",
        "        if layer2.column_count() > 0:",
        "            # At least some concepts should be isolated if topics are different",
        "            # This is a soft test since clustering may group differently",
        "            pass  # Concept isolation depends on clustering results",
        "",
        ""
      ],
      "lines_removed": [],
      "context_before": [
        "        self.assertIn('isolated_documents', gaps)",
        "        self.assertIn('weak_topics', gaps)",
        "        self.assertIn('coverage_score', gaps)",
        "",
        "    def test_detect_anomalies(self):",
        "        \"\"\"Test anomaly detection.\"\"\"",
        "        anomalies = self.processor.detect_anomalies(threshold=0.1)",
        "        self.assertIsInstance(anomalies, list)",
        "",
        ""
      ],
      "context_after": [
        "if __name__ == \"__main__\":",
        "    unittest.main(verbosity=2)"
      ],
      "change_type": "add"
    }
  ],
  "hour_of_day": 22,
  "day_of_week": "Tuesday",
  "seconds_since_last_commit": -485367,
  "is_merge": true,
  "is_initial": false,
  "parent_count": 2,
  "session_id": null,
  "related_chats": [],
  "ci_result": null,
  "reverted": false,
  "amended": false
}