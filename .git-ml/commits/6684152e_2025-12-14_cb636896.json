{
  "hash": "6684152e326487498276c15c9214db0f1b6aa2ea",
  "message": "feat: Add session handoff, auto-memory, CI link checker, and tests",
  "author": "Claude",
  "timestamp": "2025-12-14 21:42:50 +0000",
  "branch": "claude/multi-index-design-DvifZ",
  "files_changed": [
    ".github/workflows/ci.yml",
    ".markdown-link-check.json",
    "scripts/session_handoff.py",
    "scripts/task_utils.py",
    "tasks/2025-12-14_17-13-01_6aa8.json",
    "tests/unit/test_new_memory.py"
  ],
  "insertions": 1375,
  "deletions": 10,
  "hunks": [
    {
      "file": "workflows/ci.yml b/.github/workflows/ci.yml",
      "function": "jobs:",
      "start_line": 420,
      "lines_added": [
        "",
        "  # ==========================================================================",
        "  # Markdown Link Checker (runs in parallel with all other jobs)",
        "  # Validates all markdown links are valid and not broken",
        "  # Non-blocking initially - will provide informational feedback only",
        "  # ==========================================================================",
        "  markdown-links:",
        "    name: \"ðŸ”— Markdown Links\"",
        "    runs-on: ubuntu-latest",
        "    continue-on-error: true  # Don't fail builds on broken links initially",
        "    steps:",
        "    - uses: actions/checkout@v4",
        "",
        "    - name: Check markdown links",
        "      uses: gaurav-nelson/github-action-markdown-link-check@v1",
        "      with:",
        "        use-quiet-mode: 'yes'",
        "        config-file: '.markdown-link-check.json'",
        "        folder-path: '.'",
        "        file-extension: '.md'"
      ],
      "lines_removed": [],
      "context_before": [
        "            results = data.get('results', {})",
        "            real_secrets = {k: v for k, v in results.items() if not k.startswith('tests/')}",
        "            if real_secrets:",
        "                print('âš ï¸ Potential secrets found in:')",
        "                for file in real_secrets:",
        "                    print(f'  - {file}')",
        "                print('Please review and ensure no real secrets are committed.')",
        "            else:",
        "                print('âœ… No secrets detected in source files')",
        "        PYTHON_SCRIPT"
      ],
      "context_after": [],
      "change_type": "add"
    },
    {
      "file": ".markdown-link-check.json",
      "function": null,
      "start_line": 0,
      "lines_added": [
        "{",
        "  \"ignorePatterns\": [",
        "    {",
        "      \"pattern\": \"^http://localhost\"",
        "    },",
        "    {",
        "      \"pattern\": \"^http://127.0.0.1\"",
        "    }",
        "  ],",
        "  \"replacementPatterns\": [],",
        "  \"httpHeaders\": [],",
        "  \"timeout\": \"10s\",",
        "  \"retryOn429\": true,",
        "  \"retryCount\": 3,",
        "  \"fallbackRetryDelay\": \"5s\",",
        "  \"aliveStatusCodes\": [200, 206]",
        "}"
      ],
      "lines_removed": [],
      "context_before": [],
      "context_after": [],
      "change_type": "add"
    },
    {
      "file": "scripts/session_handoff.py",
      "function": null,
      "start_line": 0,
      "lines_added": [
        "#!/usr/bin/env python3",
        "\"\"\"",
        "Generate session handoff documents for knowledge transfer.",
        "",
        "Creates automatic handoff documents when ending a coding session, capturing:",
        "- Git status and branch information",
        "- Recently completed tasks",
        "- Uncommitted changes",
        "- Suggested next steps",
        "",
        "Usage:",
        "    # Generate handoff for current session",
        "    python scripts/session_handoff.py",
        "",
        "    # Preview without creating",
        "    python scripts/session_handoff.py --dry-run",
        "",
        "    # Custom output location",
        "    python scripts/session_handoff.py --output samples/memories/handoff.md",
        "",
        "Example:",
        "    $ python scripts/session_handoff.py",
        "    Created session handoff: samples/memories/session-handoff-2025-12-14_14-30-52_a1b2.md",
        "\"\"\"",
        "",
        "import argparse",
        "import os",
        "import subprocess",
        "import sys",
        "from datetime import datetime, timedelta",
        "from pathlib import Path",
        "from typing import Dict, List, Optional, Tuple, Any",
        "",
        "# Add scripts to path",
        "sys.path.insert(0, str(Path(__file__).parent))",
        "",
        "from task_utils import load_all_tasks, Task, generate_session_id",
        "",
        "",
        "# Default output directory",
        "MEMORIES_DIR = Path(\"samples/memories\")",
        "",
        "",
        "def gather_session_context() -> Dict[str, Any]:",
        "    \"\"\"",
        "    Gather current session context from git and system.",
        "",
        "    Returns:",
        "        Dictionary with:",
        "        - branch: Current git branch name",
        "        - status_summary: Git status summary",
        "        - uncommitted_files: List of modified/staged files",
        "        - recent_commits: List of (hash, message) tuples for last 5 commits",
        "        - background_processes: Optional list of running processes",
        "    \"\"\"",
        "    context = {",
        "        'branch': None,",
        "        'status_summary': '',",
        "        'uncommitted_files': [],",
        "        'recent_commits': [],",
        "        'background_processes': []",
        "    }",
        "",
        "    # Get current branch",
        "    try:",
        "        result = subprocess.run(",
        "            [\"git\", \"rev-parse\", \"--abbrev-ref\", \"HEAD\"],",
        "            capture_output=True,",
        "            text=True,",
        "            timeout=2",
        "        )",
        "        if result.returncode == 0:",
        "            context['branch'] = result.stdout.strip()",
        "    except (subprocess.TimeoutExpired, FileNotFoundError):",
        "        pass",
        "",
        "    # Get git status",
        "    try:",
        "        result = subprocess.run(",
        "            [\"git\", \"status\", \"--short\"],",
        "            capture_output=True,",
        "            text=True,",
        "            timeout=2",
        "        )",
        "        if result.returncode == 0:",
        "            status_lines = result.stdout.strip().split('\\n')",
        "            context['uncommitted_files'] = [",
        "                line.strip() for line in status_lines if line.strip()",
        "            ]",
        "",
        "            # Create summary",
        "            if context['uncommitted_files']:",
        "                modified = sum(1 for line in context['uncommitted_files'] if line.startswith('M'))",
        "                added = sum(1 for line in context['uncommitted_files'] if line.startswith('A'))",
        "                deleted = sum(1 for line in context['uncommitted_files'] if line.startswith('D'))",
        "                untracked = sum(1 for line in context['uncommitted_files'] if line.startswith('??'))",
        "",
        "                parts = []",
        "                if modified:",
        "                    parts.append(f\"{modified} modified\")",
        "                if added:",
        "                    parts.append(f\"{added} added\")",
        "                if deleted:",
        "                    parts.append(f\"{deleted} deleted\")",
        "                if untracked:",
        "                    parts.append(f\"{untracked} untracked\")",
        "",
        "                context['status_summary'] = ', '.join(parts) if parts else 'clean'",
        "            else:",
        "                context['status_summary'] = 'clean'",
        "    except (subprocess.TimeoutExpired, FileNotFoundError):",
        "        context['status_summary'] = 'unknown'",
        "",
        "    # Get recent commits (last 5)",
        "    try:",
        "        result = subprocess.run(",
        "            [\"git\", \"log\", \"--pretty=format:%h|%s\", \"-n\", \"5\"],",
        "            capture_output=True,",
        "            text=True,",
        "            timeout=2",
        "        )",
        "        if result.returncode == 0:",
        "            for line in result.stdout.strip().split('\\n'):",
        "                if '|' in line:",
        "                    commit_hash, message = line.split('|', 1)",
        "                    context['recent_commits'].append((commit_hash, message))",
        "    except (subprocess.TimeoutExpired, FileNotFoundError):",
        "        pass",
        "",
        "    return context",
        "",
        "",
        "def gather_completed_tasks(tasks_dir: str = \"tasks\") -> List[Task]:",
        "    \"\"\"",
        "    Gather tasks completed today from task session files.",
        "",
        "    Args:",
        "        tasks_dir: Directory containing task session files",
        "",
        "    Returns:",
        "        List of Task objects completed today, sorted by completion time",
        "    \"\"\"",
        "    all_tasks = load_all_tasks(tasks_dir)",
        "",
        "    # Get today's date range",
        "    today = datetime.now().date()",
        "    today_start = datetime.combine(today, datetime.min.time())",
        "    today_end = datetime.combine(today, datetime.max.time())",
        "",
        "    # Filter to completed tasks from today",
        "    completed_today = []",
        "    for task in all_tasks:",
        "        if task.status == 'completed' and task.completed_at:",
        "            try:",
        "                completed_time = datetime.fromisoformat(task.completed_at)",
        "                if today_start <= completed_time <= today_end:",
        "                    completed_today.append(task)",
        "            except (ValueError, TypeError):",
        "                # Skip tasks with invalid completion dates",
        "                continue",
        "",
        "    # Sort by completion time",
        "    completed_today.sort(key=lambda t: t.completed_at or '')",
        "",
        "    return completed_today",
        "",
        "",
        "def generate_handoff_document(",
        "    context: Dict[str, Any],",
        "    completed_tasks: List[Task],",
        "    title: str = \"Session Handoff\"",
        ") -> str:",
        "    \"\"\"",
        "    Generate a handoff document from session context and completed tasks.",
        "",
        "    Args:",
        "        context: Session context from gather_session_context()",
        "        completed_tasks: List of completed tasks from gather_completed_tasks()",
        "        title: Document title (default: \"Session Handoff\")",
        "",
        "    Returns:",
        "        Markdown formatted handoff document",
        "    \"\"\"",
        "    now = datetime.now()",
        "    date_str = now.strftime(\"%Y-%m-%d\")",
        "    timestamp = now.strftime(\"%Y-%m-%dT%H:%M:%SZ\")",
        "",
        "    lines = [",
        "        f\"# {title}: {date_str}\",",
        "        \"\",",
        "        f\"**Date:** {date_str}\",",
        "        f\"**Time:** {timestamp}\",",
        "        f\"**Branch:** {context['branch'] or 'unknown'}\",",
        "        \"\",",
        "        \"---\",",
        "        \"\",",
        "        \"## Summary\",",
        "        \"\"",
        "    ]",
        "",
        "    # Generate summary",
        "    num_tasks = len(completed_tasks)",
        "    if num_tasks > 0:",
        "        lines.append(",
        "            f\"Completed {num_tasks} task{'s' if num_tasks != 1 else ''} this session. \"",
        "            f\"Repository state: {context['status_summary']}.\"",
        "        )",
        "    else:",
        "        lines.append(",
        "            f\"Session focused on exploration and investigation. \"",
        "            f\"Repository state: {context['status_summary']}.\"",
        "        )",
        "",
        "    lines.extend([",
        "        \"\",",
        "        \"## Completed This Session\",",
        "        \"\"",
        "    ])",
        "",
        "    if completed_tasks:",
        "        for task in completed_tasks:",
        "            lines.append(f\"### {task.id}: {task.title}\")",
        "            if task.description:",
        "                lines.append(f\"{task.description}\")",
        "",
        "            # Handle retrospective (must be a dict)",
        "            if task.retrospective and isinstance(task.retrospective, dict):",
        "                if task.retrospective.get('notes'):",
        "                    lines.append(f\"**Notes:** {task.retrospective['notes']}\")",
        "                if task.retrospective.get('files_touched'):",
        "                    files = task.retrospective['files_touched']",
        "                    if files:",
        "                        lines.append(\"**Files modified:**\")",
        "                        for file in files:",
        "                            lines.append(f\"- `{file}`\")",
        "            lines.append(\"\")",
        "    else:",
        "        lines.append(\"*No tasks completed this session*\")",
        "        lines.append(\"\")",
        "",
        "    lines.extend([",
        "        \"## Current State\",",
        "        \"\",",
        "        f\"**Git Status:** {context['status_summary']}\",",
        "        \"\"",
        "    ])",
        "",
        "    if context['uncommitted_files']:",
        "        lines.append(\"**Uncommitted Changes:**\")",
        "        for file_status in context['uncommitted_files']:",
        "            lines.append(f\"- `{file_status}`\")",
        "        lines.append(\"\")",
        "",
        "    if context['recent_commits']:",
        "        lines.extend([",
        "            \"**Recent Commits:**\",",
        "            \"\"",
        "        ])",
        "        for commit_hash, message in context['recent_commits']:",
        "            lines.append(f\"- `{commit_hash}` {message}\")",
        "        lines.append(\"\")",
        "",
        "    lines.extend([",
        "        \"## Suggested Next Steps\",",
        "        \"\"",
        "    ])",
        "",
        "    # Generate suggested next steps based on context",
        "    next_steps = []",
        "",
        "    # Check for uncommitted changes",
        "    if context['uncommitted_files']:",
        "        modified_count = sum(1 for f in context['uncommitted_files'] if f.startswith('M'))",
        "        if modified_count > 0:",
        "            next_steps.append(\"Review and commit uncommitted changes\")",
        "",
        "    # Check for pending tasks",
        "    all_tasks = load_all_tasks(\"tasks\")",
        "    pending = [t for t in all_tasks if t.status == 'pending']",
        "    in_progress = [t for t in all_tasks if t.status == 'in_progress']",
        "",
        "    if in_progress:",
        "        for task in in_progress[:3]:  # Show first 3",
        "            next_steps.append(f\"Continue: {task.title} ({task.id})\")",
        "",
        "    if pending:",
        "        high_priority = [t for t in pending if t.priority == 'high']",
        "        if high_priority:",
        "            for task in high_priority[:2]:  # Show first 2 high priority",
        "                next_steps.append(f\"Start: {task.title} ({task.id})\")",
        "        elif pending:",
        "            next_steps.append(f\"Start next pending task ({len(pending)} available)\")",
        "",
        "    # Add test and documentation reminders",
        "    if completed_tasks:",
        "        next_steps.append(\"Run full test suite to verify changes\")",
        "        next_steps.append(\"Update documentation if needed\")",
        "",
        "    if next_steps:",
        "        for i, step in enumerate(next_steps, 1):",
        "            lines.append(f\"{i}. {step}\")",
        "    else:",
        "        lines.append(\"*Review pending tasks in `tasks/` directory*\")",
        "",
        "    lines.extend([",
        "        \"\",",
        "        \"## Files Modified\",",
        "        \"\"",
        "    ])",
        "",
        "    # Collect all modified files from tasks and git status",
        "    all_files = set()",
        "",
        "    for task in completed_tasks:",
        "        if task.retrospective and isinstance(task.retrospective, dict):",
        "            if task.retrospective.get('files_touched'):",
        "                all_files.update(task.retrospective['files_touched'])",
        "",
        "    # Parse git status files",
        "    for file_status in context['uncommitted_files']:",
        "        # Format: \"XX filename\" where XX is status code",
        "        parts = file_status.split(maxsplit=1)",
        "        if len(parts) == 2:",
        "            all_files.add(parts[1])",
        "",
        "    if all_files:",
        "        for file in sorted(all_files):",
        "            lines.append(f\"- `{file}`\")",
        "    else:",
        "        lines.append(\"*No files modified this session*\")",
        "",
        "    lines.extend([",
        "        \"\",",
        "        \"---\",",
        "        \"\",",
        "        f\"*Session handoff generated at: {timestamp}*\"",
        "    ])",
        "",
        "    return '\\n'.join(lines)",
        "",
        "",
        "def generate_handoff_filename() -> str:",
        "    \"\"\"",
        "    Generate merge-safe handoff filename.",
        "",
        "    Returns:",
        "        Filename in format: session-handoff-YYYY-MM-DD_HH-MM-SS_XXXX.md",
        "    \"\"\"",
        "    now = datetime.now()",
        "    date_str = now.strftime(\"%Y-%m-%d\")",
        "    time_str = now.strftime(\"%H-%M-%S\")",
        "    session_id = generate_session_id()",
        "",
        "    return f\"session-handoff-{date_str}_{time_str}_{session_id}.md\"",
        "",
        "",
        "def main():",
        "    parser = argparse.ArgumentParser(",
        "        description=\"Generate session handoff documents for knowledge transfer\",",
        "        formatter_class=argparse.RawDescriptionHelpFormatter,",
        "        epilog=__doc__",
        "    )",
        "",
        "    parser.add_argument(",
        "        \"--dry-run\",",
        "        action=\"store_true\",",
        "        help=\"Preview handoff document without creating file\"",
        "    )",
        "    parser.add_argument(",
        "        \"--output\",",
        "        type=Path,",
        "        help=\"Custom output file path (default: auto-generated in samples/memories/)\"",
        "    )",
        "    parser.add_argument(",
        "        \"--title\",",
        "        default=\"Session Handoff\",",
        "        help=\"Document title (default: 'Session Handoff')\"",
        "    )",
        "    parser.add_argument(",
        "        \"--tasks-dir\",",
        "        default=\"tasks\",",
        "        help=\"Directory containing task files (default: tasks/)\"",
        "    )",
        "",
        "    args = parser.parse_args()",
        "",
        "    # Gather session information",
        "    print(\"Gathering session context...\")",
        "    context = gather_session_context()",
        "",
        "    print(\"Loading completed tasks...\")",
        "    completed_tasks = gather_completed_tasks(args.tasks_dir)",
        "",
        "    # Generate document",
        "    print(\"Generating handoff document...\")",
        "    document = generate_handoff_document(context, completed_tasks, args.title)",
        "",
        "    # Determine output path",
        "    if args.output:",
        "        output_path = args.output",
        "    else:",
        "        MEMORIES_DIR.mkdir(parents=True, exist_ok=True)",
        "        filename = generate_handoff_filename()",
        "        output_path = MEMORIES_DIR / filename",
        "",
        "    if args.dry_run:",
        "        print(\"\\n=== DRY RUN ===\")",
        "        print(f\"Would create: {output_path}\")",
        "        print(f\"\\nDocument preview:\\n\")",
        "        print(document)",
        "        return",
        "",
        "    # Write file",
        "    output_path.parent.mkdir(parents=True, exist_ok=True)",
        "    with open(output_path, 'w') as f:",
        "        f.write(document)",
        "",
        "    print(f\"\\nCreated session handoff:\")",
        "    print(f\"  {output_path}\")",
        "    print(f\"\\nNext steps:\")",
        "    print(f\"  1. Review: $EDITOR {output_path}\")",
        "    print(f\"  2. Commit: git add {output_path} && git commit -m 'memory: session handoff'\")",
        "    print(f\"  3. Re-index: python scripts/index_codebase.py --incremental\")",
        "",
        "",
        "if __name__ == \"__main__\":",
        "    main()"
      ],
      "lines_removed": [],
      "context_before": [],
      "context_after": [],
      "change_type": "add"
    },
    {
      "file": "scripts/task_utils.py",
      "function": "Usage:",
      "start_line": 29,
      "lines_added": [
        "import sys"
      ],
      "lines_removed": [],
      "context_before": [
        "    task_id = generate_task_id()  # T-20251213-143052-a1b2",
        "",
        "    # Session-based (guaranteed unique within session)",
        "    session = TaskSession()",
        "    task1 = session.new_task_id()  # T-20251213-143052-a1b2-01",
        "    task2 = session.new_task_id()  # T-20251213-143052-a1b2-02",
        "\"\"\"",
        "",
        "import json",
        "import os"
      ],
      "context_after": [
        "import uuid",
        "from dataclasses import dataclass, field, asdict",
        "from datetime import datetime",
        "from pathlib import Path",
        "from typing import Dict, List, Optional, Any",
        "",
        "",
        "# Directory for per-session task files",
        "DEFAULT_TASKS_DIR = \"tasks\"",
        ""
      ],
      "change_type": "add"
    },
    {
      "file": "scripts/task_utils.py",
      "function": "def generate_short_task_id() -> str:",
      "start_line": 83,
      "lines_added": [
        "def slugify(text: str) -> str:",
        "    \"\"\"",
        "    Convert text to URL-friendly slug.",
        "",
        "    Args:",
        "        text: Text to convert to slug",
        "",
        "    Returns:",
        "        Slugified text (lowercase, hyphens, alphanumeric only)",
        "    \"\"\"",
        "    # Simple slugification: lowercase, replace spaces with hyphens",
        "    slug = text.lower().strip()",
        "    slug = slug.replace(\" \", \"-\")",
        "    # Remove non-alphanumeric except hyphens",
        "    slug = \"\".join(c for c in slug if c.isalnum() or c == \"-\")",
        "    # Remove duplicate hyphens",
        "    while \"--\" in slug:",
        "        slug = slug.replace(\"--\", \"-\")",
        "    # Truncate to reasonable length",
        "    return slug[:50]",
        "",
        "",
        "def generate_memory_from_task(task: dict) -> str:",
        "    \"\"\"",
        "    Generate memory entry markdown from a completed task.",
        "",
        "    Args:",
        "        task: Task dictionary with id, title, description, retrospective, etc.",
        "",
        "    Returns:",
        "        Markdown content for the memory entry",
        "    \"\"\"",
        "    now = datetime.now()",
        "    date_str = now.strftime(\"%Y-%m-%d\")",
        "",
        "    # Extract task fields",
        "    task_id = task.get('id', 'Unknown')",
        "    title = task.get('title', 'Untitled Task')",
        "    category = task.get('category', 'general')",
        "    description = task.get('description', 'No description provided')",
        "",
        "    # Extract retrospective notes",
        "    retrospective = task.get('retrospective', {})",
        "    if isinstance(retrospective, dict):",
        "        notes = retrospective.get('notes', 'No retrospective notes provided')",
        "    else:",
        "        notes = str(retrospective) if retrospective else 'No retrospective notes provided'",
        "",
        "    # Extract related files from context or retrospective",
        "    related_files = []",
        "    if 'context' in task and isinstance(task['context'], dict):",
        "        if 'files' in task['context']:",
        "            related_files.extend(task['context']['files'])",
        "    if isinstance(retrospective, dict) and 'files_touched' in retrospective:",
        "        related_files.extend(retrospective['files_touched'])",
        "",
        "    # Remove duplicates and format",
        "    related_files = list(set(related_files))",
        "    files_section = \"\\n\".join(f\"- `{f}`\" for f in related_files) if related_files else \"No files recorded\"",
        "",
        "    # Generate template",
        "    template = f\"\"\"# Task Learning: {title}",
        "",
        "**Task ID:** {task_id}",
        "**Completed:** {date_str}",
        "**Category:** {category}",
        "**Tags:** `{category}`, `task-learning`",
        "",
        "---",
        "",
        "## Task Context",
        "",
        "{description}",
        "",
        "## What Was Learned",
        "",
        "{notes}",
        "",
        "## Related Files",
        "",
        "{files_section}",
        "",
        "---",
        "",
        "*Auto-generated from task completion*",
        "\"\"\"",
        "",
        "    return template",
        "",
        "",
        "def create_memory_for_task(task: dict, output_dir: str = \"samples/memories\") -> str:",
        "    \"\"\"",
        "    Create a memory entry file from a completed task.",
        "",
        "    Args:",
        "        task: Task dictionary",
        "        output_dir: Directory to write memory file to",
        "",
        "    Returns:",
        "        Path to created memory file",
        "    \"\"\"",
        "    # Generate memory content",
        "    content = generate_memory_from_task(task)",
        "",
        "    # Generate merge-safe filename",
        "    now = datetime.now()",
        "    date_str = now.strftime(\"%Y-%m-%d\")",
        "    time_str = now.strftime(\"%H-%M-%S\")",
        "    session_id = generate_session_id()",
        "",
        "    # Use task title for slug",
        "    title = task.get('title', 'task-completion')",
        "    slug = slugify(title)",
        "",
        "    filename = f\"{date_str}_{time_str}_{session_id}-task-{slug}.md\"",
        "",
        "    # Create directory if needed",
        "    output_path = Path(output_dir)",
        "    output_path.mkdir(parents=True, exist_ok=True)",
        "",
        "    # Write file",
        "    filepath = output_path / filename",
        "    with open(filepath, 'w') as f:",
        "        f.write(content)",
        "",
        "    return str(filepath)",
        "",
        ""
      ],
      "lines_removed": [],
      "context_before": [
        "    Returns:",
        "        Task ID in format T-XXXXXXXX",
        "",
        "    Example:",
        "        >>> generate_short_task_id()",
        "        'T-a1b2c3d4'",
        "    \"\"\"",
        "    return f\"T-{uuid.uuid4().hex[:8]}\"",
        "",
        ""
      ],
      "context_after": [
        "@dataclass",
        "class Task:",
        "    \"\"\"A single task with merge-friendly ID.\"\"\"",
        "    id: str",
        "    title: str",
        "    status: str = \"pending\"  # pending, in_progress, completed, deferred",
        "    priority: str = \"medium\"  # high, medium, low",
        "    category: str = \"general\"",
        "    description: str = \"\"",
        "    depends_on: List[str] = field(default_factory=list)"
      ],
      "change_type": "add"
    },
    {
      "file": "scripts/task_utils.py",
      "function": "class TaskSession:",
      "start_line": 318,
      "lines_added": [
        "    def complete_task(",
        "        self,",
        "        task_id: str,",
        "        retrospective: Optional[str] = None,",
        "        create_memory: bool = False",
        "    ) -> Optional[str]:",
        "        \"\"\"",
        "        Mark a task as completed and optionally create a memory entry.",
        "",
        "        Args:",
        "            task_id: The task ID to complete",
        "            retrospective: Optional completion notes/learnings",
        "            create_memory: If True, create a memory entry from the task",
        "",
        "        Returns:",
        "            Path to created memory file if create_memory=True, else None",
        "",
        "        Raises:",
        "            ValueError: If task_id is not found in this session",
        "        \"\"\"",
        "        task = self.get_task(task_id)",
        "        if not task:",
        "            raise ValueError(f\"Task not found: {task_id}\")",
        "",
        "        # Mark task as complete",
        "        task.mark_complete()",
        "",
        "        # Capture retrospective if provided",
        "        if retrospective:",
        "            duration = self._calculate_duration(task.created_at)",
        "            task.retrospective = {",
        "                'notes': retrospective,",
        "                'duration_minutes': duration,",
        "                'files_touched': [],",
        "                'tests_added': 0,",
        "                'commits': [],",
        "                'captured_at': datetime.now().isoformat()",
        "            }",
        "",
        "        # Create memory if requested",
        "        memory_path = None",
        "        if create_memory and task.retrospective:",
        "            memory_path = create_memory_for_task(task.to_dict())",
        "",
        "        return memory_path",
        ""
      ],
      "lines_removed": [],
      "context_before": [
        "",
        "        return {",
        "            'total_completed': len(completed),",
        "            'avg_duration_minutes': round(avg_duration, 1),",
        "            'total_duration_minutes': total_duration,",
        "            'total_tests_added': total_tests,",
        "            'most_touched_files': file_counts.most_common(10),",
        "            'tasks_with_retrospective': [t.id for t in completed]",
        "        }",
        ""
      ],
      "context_after": [
        "    def get_filename(self) -> str:",
        "        \"\"\"Get the session filename.\"\"\"",
        "        dt = datetime.fromisoformat(self.started_at)",
        "        timestamp = dt.strftime(\"%Y-%m-%d_%H-%M-%S\")",
        "        return f\"{timestamp}_{self.session_id}.json\"",
        "",
        "    def save(self, tasks_dir: Optional[str] = None) -> Path:",
        "        \"\"\"",
        "        Save session tasks to a JSON file atomically.",
        ""
      ],
      "change_type": "add"
    },
    {
      "file": "scripts/task_utils.py",
      "function": "if __name__ == \"__main__\":",
      "start_line": 523,
      "lines_added": [
        "    # complete command",
        "    complete_parser = subparsers.add_parser(\"complete\", help=\"Complete a task\")",
        "    complete_parser.add_argument(\"task_id\", help=\"Task ID to complete\")",
        "    complete_parser.add_argument(\"--retrospective\", help=\"Completion notes/learnings\")",
        "    complete_parser.add_argument(\"--create-memory\", action=\"store_true\", help=\"Create memory entry\")",
        "    complete_parser.add_argument(\"--dir\", default=DEFAULT_TASKS_DIR, help=\"Tasks directory\")",
        ""
      ],
      "lines_removed": [],
      "context_before": [
        "    # consolidate command",
        "    cons_parser = subparsers.add_parser(\"consolidate\", help=\"Consolidate task files\")",
        "    cons_parser.add_argument(\"--dir\", default=DEFAULT_TASKS_DIR, help=\"Tasks directory\")",
        "    cons_parser.add_argument(\"--output\", help=\"Output markdown file\")",
        "",
        "    # list command",
        "    list_parser = subparsers.add_parser(\"list\", help=\"List all tasks\")",
        "    list_parser.add_argument(\"--dir\", default=DEFAULT_TASKS_DIR, help=\"Tasks directory\")",
        "    list_parser.add_argument(\"--status\", help=\"Filter by status\")",
        ""
      ],
      "context_after": [
        "    args = parser.parse_args()",
        "",
        "    if args.command == \"generate\":",
        "        if args.short:",
        "            print(generate_short_task_id())",
        "        else:",
        "            print(generate_task_id())",
        "",
        "    elif args.command == \"consolidate\":",
        "        grouped = consolidate_tasks(args.dir, args.output)"
      ],
      "change_type": "add"
    },
    {
      "file": "scripts/task_utils.py",
      "function": "if __name__ == \"__main__\":",
      "start_line": 546,
      "lines_added": [
        "    elif args.command == \"complete\":",
        "        # Find the session file containing this task",
        "        dir_path = Path(args.dir)",
        "        if not dir_path.exists():",
        "            print(f\"Error: Tasks directory not found: {args.dir}\")",
        "            sys.exit(1)",
        "",
        "        session_file = None",
        "        target_session = None",
        "",
        "        for filepath in sorted(dir_path.glob(\"*.json\")):",
        "            try:",
        "                session = TaskSession.load(filepath)",
        "                if session.get_task(args.task_id):",
        "                    session_file = filepath",
        "                    target_session = session",
        "                    break",
        "            except (json.JSONDecodeError, KeyError) as e:",
        "                print(f\"Warning: Could not load {filepath}: {e}\")",
        "                continue",
        "",
        "        if not target_session:",
        "            print(f\"Error: Could not find session containing task {args.task_id}\")",
        "            sys.exit(1)",
        "",
        "        # Complete the task",
        "        memory_path = target_session.complete_task(",
        "            args.task_id,",
        "            retrospective=args.retrospective,",
        "            create_memory=args.create_memory",
        "        )",
        "",
        "        # Save the session",
        "        target_session.save(args.dir)",
        "",
        "        print(f\"âœ“ Task {args.task_id} marked as completed\")",
        "        if memory_path:",
        "            print(f\"âœ“ Memory entry created: {memory_path}\")",
        ""
      ],
      "lines_removed": [],
      "context_before": [
        "            print(f\"\\nWritten to {args.output}\")",
        "",
        "    elif args.command == \"list\":",
        "        tasks = load_all_tasks(args.dir)",
        "        if args.status:",
        "            tasks = [t for t in tasks if t.status == args.status]",
        "",
        "        for task in tasks:",
        "            print(f\"[{task.status}] {task.id}: {task.title}\")",
        ""
      ],
      "context_after": [
        "    else:",
        "        parser.print_help()"
      ],
      "change_type": "add"
    },
    {
      "file": "tasks/2025-12-14_17-13-01_6aa8.json",
      "function": null,
      "start_line": 1,
      "lines_added": [
        "  \"saved_at\": \"2025-12-14T21:37:01.725943\","
      ],
      "lines_removed": [
        "  \"saved_at\": \"2025-12-14T20:56:22.394615\","
      ],
      "context_before": [
        "{",
        "  \"version\": 1,",
        "  \"session_id\": \"6aa8\",",
        "  \"started_at\": \"2025-12-14T17:13:01.505357\","
      ],
      "context_after": [
        "  \"tasks\": [",
        "    {",
        "      \"id\": \"T-20251214-171301-6aa8-001\",",
        "      \"title\": \"Investigate semantic search relevance for domain-specific queries\",",
        "      \"status\": \"pending\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"arch\",",
        "      \"description\": \"During dog-fooding, searching for 'security test fuzzing' returned staleness tests instead of actual security-related code. The search seems to weight common terms like 'test' too heavily.\\n\\nInvestigation areas:\\n- Query expansion may be pulling in too many generic terms\\n- TF-IDF weighting may not properly discount common programming terms\\n- Domain-specific boosting could improve relevance for security/testing queries\\n\\nRelated: The code_concepts.py has programming synonyms but may need security-specific terms.\\n\\nDiscovered during: Dog-fooding session 2025-12-14\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"medium\","
      ],
      "change_type": "modify"
    },
    {
      "file": "tasks/2025-12-14_17-13-01_6aa8.json",
      "function": null,
      "start_line": 45,
      "lines_added": [
        "      \"status\": \"completed\",",
        "      \"completed_at\": \"2025-12-14T21:37:01.725943\",",
        "      \"retrospective\": \"Added generate_memory_from_task() and create_memory_for_task() to task_utils.py\""
      ],
      "lines_removed": [
        "      \"status\": \"pending\",",
        "      \"completed_at\": null,",
        "      \"retrospective\": null"
      ],
      "context_before": [
        "      \"effort\": \"medium\",",
        "      \"created_at\": \"2025-12-14T17:22:12.010789\",",
        "      \"updated_at\": null,",
        "      \"completed_at\": \"2025-12-14T20:56:22.394615\",",
        "      \"context\": {},",
        "      \"retrospective\": \"Completed in Director Mode session. See knowledge transfer: samples/memories/2025-12-14_20-55-23_632e-session-knowledge-transfer-director-mode-orchestra.md\"",
        "    },",
        "    {",
        "      \"id\": \"T-20251214-172216-6aa8-004\",",
        "      \"title\": \"Auto-generate memory entries from completed tasks\","
      ],
      "context_after": [
        "      \"priority\": \"low\",",
        "      \"category\": \"feature\",",
        "      \"description\": \"When a task is marked complete, offer to generate a memory entry:\\n\\n1. Extract task title, description, retrospective\\n2. Create memory document with learnings\\n3. Link to related files from task context\\n4. Add tags from task category\\n\\nIntegration:\\n- TaskSession.complete_task() could trigger this\\n- Optional flag: --create-memory\\n- Template pulls from task retrospective field\\n\\nBenefits:\\n- Captures learnings automatically\\n- Builds institutional memory from task work\\n- Creates searchable knowledge base\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"medium\",",
        "      \"created_at\": \"2025-12-14T17:22:16.074170\",",
        "      \"updated_at\": null,",
        "      \"context\": {},",
        "    },",
        "    {",
        "      \"id\": \"T-20251214-172238-6aa8-005\",",
        "      \"title\": \"Add wiki-link cross-reference resolution\",",
        "      \"status\": \"pending\",",
        "      \"priority\": \"low\",",
        "      \"category\": \"feature\",",
        "      \"description\": \"Parse and resolve [[wiki-style]] links in memory documents:\\n\\n1. Extract [[link]] patterns from markdown files\\n2. Resolve to actual file paths (fuzzy matching)\\n3. Build bidirectional link graph\\n4. Add 'backlinks' section showing what links TO a document\\n\\nUse cases:\\n- [[concepts/pagerank.md]] resolves to actual path\\n- [[2025-12-14]] finds memory entries for that date\\n- Search results show connection strength via links\\n\\nImplementation:\\n- Add link extraction to tokenizer or separate module\\n- Store links as typed_connections (relation_type='references')\\n- Query can traverse link graph for related docs\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"medium\","
      ],
      "change_type": "modify"
    },
    {
      "file": "tasks/2025-12-14_17-13-01_6aa8.json",
      "function": null,
      "start_line": 90,
      "lines_added": [
        "      \"status\": \"completed\",",
        "      \"completed_at\": \"2025-12-14T21:37:01.725943\",",
        "      \"retrospective\": \"Implemented scripts/session_handoff.py with full CLI support\""
      ],
      "lines_removed": [
        "      \"status\": \"pending\",",
        "      \"completed_at\": null,",
        "      \"retrospective\": null"
      ],
      "context_before": [
        "      \"effort\": \"medium\",",
        "      \"created_at\": \"2025-12-14T17:22:43.647861\",",
        "      \"updated_at\": null,",
        "      \"completed_at\": null,",
        "      \"context\": {},",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"T-20251214-172247-6aa8-007\",",
        "      \"title\": \"Session handoff memory generator\","
      ],
      "context_after": [
        "      \"priority\": \"medium\",",
        "      \"category\": \"feature\",",
        "      \"description\": \"Generate memory documents for agent session continuity:\\n\\nWhen ending a session, create a handoff document containing:\\n1. What was accomplished (from completed tasks)\\n2. Current state (uncommitted changes, running processes)\\n3. Blockers or issues encountered\\n4. Suggested next steps\\n5. Key context the next session needs\\n\\nIntegration:\\n- Hook into session end (or manual trigger)\\n- Pull from task retrospectives\\n- Include git status summary\\n- Link to relevant code locations\\n\\nFormat: memories/session-handoff-YYYY-MM-DD-HHMM.md\\n\\nThis enables smooth continuation across agent sessions\\nand builds institutional memory of development flow.\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"medium\",",
        "      \"created_at\": \"2025-12-14T17:22:47.634689\",",
        "      \"updated_at\": null,",
        "      \"context\": {},",
        "    },",
        "    {",
        "      \"id\": \"T-20251214-173831-6aa8-008\",",
        "      \"title\": \"Make memory/decision filenames merge-safe\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"arch\",",
        "      \"description\": \"Apply the same merge-safe pattern from tasks to memories and decisions.\\n\\nCurrent patterns (can conflict):\\n- memories: YYYY-MM-DD-topic.md\\n- decisions: adr-NNN-title.md\\n\\nProposed patterns (merge-safe):\\n- memories: YYYY-MM-DD_HH-MM-SS_XXXX-topic.md\\n- decisions: adr-YYYYMMDD-HHMMSS-XXXX-title.md\\n\\nChanges needed:\\n1. Update memory-manager skill templates\\n2. Update /knowledge-transfer command\\n3. Update docs/text-as-memories.md examples\\n4. Add helper: scripts/new_memory.py with auto-generated safe names\\n5. Add helper: scripts/new_decision.py with auto-generated safe names\\n\\nAlternative: Use topic-hash suffix instead of timestamp\\nExample: 2025-12-14-dogfooding-a1b2.md\\n\\nThe session ID approach mirrors the proven task system design.\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"medium\","
      ],
      "change_type": "modify"
    },
    {
      "file": "tasks/2025-12-14_17-13-01_6aa8.json",
      "function": null,
      "start_line": 150,
      "lines_added": [
        "      \"status\": \"completed\",",
        "      \"completed_at\": \"2025-12-14T21:37:01.725943\",",
        "      \"retrospective\": \"Added markdown-links job to CI with .markdown-link-check.json config\""
      ],
      "lines_removed": [
        "      \"status\": \"pending\",",
        "      \"completed_at\": null,",
        "      \"retrospective\": null"
      ],
      "context_before": [
        "      \"effort\": \"medium\",",
        "      \"created_at\": \"2025-12-14T17:41:12.741156\",",
        "      \"updated_at\": null,",
        "      \"completed_at\": \"2025-12-14T20:56:22.394615\",",
        "      \"context\": {},",
        "      \"retrospective\": \"Completed in Director Mode session. See knowledge transfer: samples/memories/2025-12-14_20-55-23_632e-session-knowledge-transfer-director-mode-orchestra.md\"",
        "    },",
        "    {",
        "      \"id\": \"T-20251214-174116-6aa8-011\",",
        "      \"title\": \"Add markdown link checker to CI\","
      ],
      "context_after": [
        "      \"priority\": \"low\",",
        "      \"category\": \"infra\",",
        "      \"description\": \"Add automated checking for broken links in markdown files.\\n\\nTools to consider:\\n- markdown-link-check (npm)\\n- mlc (rust-based, fast)\\n- lychee (rust-based, comprehensive)\\n\\nCI integration:\\n```yaml\\nmarkdown-lint:\\n  runs-on: ubuntu-latest\\n  steps:\\n    - uses: actions/checkout@v4\\n    - name: Check markdown links\\n      uses: gaurav-nelson/github-action-markdown-link-check@v1\\n      with:\\n        use-quiet-mode: 'yes'\\n        config-file: '.markdown-link-check.json'\\n```\\n\\nConfig file should:\\n- Ignore external URLs (or check with timeout)\\n- Check internal file references\\n- Check anchor links (#section-name)\\n- Whitelist known-good external domains\\n\\nAlso check:\\n- [[wiki-style]] links resolve to real files\\n- Code file references (cortical/foo.py:123) exist\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"medium\",",
        "      \"created_at\": \"2025-12-14T17:41:16.926225\",",
        "      \"updated_at\": null,",
        "      \"context\": {},",
        "    },",
        "    {",
        "      \"id\": \"T-20251214-174530-6aa8-012\",",
        "      \"title\": \"Enhance director orchestration with execution tracking\",",
        "      \"status\": \"pending\",",
        "      \"priority\": \"low\",",
        "      \"category\": \"feature\",",
        "      \"description\": \"Extend the director prompt with tooling support:\\n\\n1. Execution tracking file:\\n   - .claude/orchestration/current-plan.json\\n   - Track: batches, agents, status, results\\n\\n2. Verification automation:\\n   - scripts/verify_batch.py - run standard checks\\n   - Integrate with CI for parallel agent validation\\n\\n3. Replanning assistant:\\n   - Analyze failure patterns\\n   - Suggest alternative approaches\\n   - Track what was tried\\n\\n4. Metrics collection:\\n   - Time per batch\\n   - Success/failure rates\\n   - Common failure modes\\n\\n5. Integration with task system:\\n   - Auto-create tasks for each batch\\n   - Link to parent orchestration task\\n   - Capture retrospectives automatically\\n\\nSee: .claude/commands/director.md for current prompt\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"medium\","
      ],
      "change_type": "modify"
    },
    {
      "file": "tests/unit/test_new_memory.py",
      "function": null,
      "start_line": 0,
      "lines_added": [
        "\"\"\"",
        "Unit tests for scripts/new_memory.py.",
        "",
        "Tests memory and decision record creation utilities including:",
        "- Filename generation with merge-safe timestamps",
        "- Slugification of titles",
        "- Template generation for memories and decisions",
        "- File creation and dry-run mode",
        "\"\"\"",
        "",
        "import os",
        "import sys",
        "import tempfile",
        "import unittest",
        "from datetime import datetime",
        "from pathlib import Path",
        "from unittest.mock import patch, MagicMock",
        "",
        "# Add scripts to path",
        "sys.path.insert(0, str(Path(__file__).parent.parent.parent / \"scripts\"))",
        "",
        "from new_memory import (",
        "    generate_memory_filename,",
        "    slugify,",
        "    get_git_author,",
        "    create_memory_template,",
        "    create_decision_template,",
        "    create_memory,",
        "    MEMORIES_DIR,",
        "    DECISIONS_DIR,",
        ")",
        "",
        "",
        "class TestSlugify(unittest.TestCase):",
        "    \"\"\"Tests for slugify function.\"\"\"",
        "",
        "    def test_converts_spaces_to_hyphens(self):",
        "        \"\"\"Spaces should be converted to hyphens.\"\"\"",
        "        self.assertEqual(slugify(\"hello world\"), \"hello-world\")",
        "        self.assertEqual(slugify(\"foo bar baz\"), \"foo-bar-baz\")",
        "",
        "    def test_removes_special_characters(self):",
        "        \"\"\"Special characters should be removed.\"\"\"",
        "        self.assertEqual(slugify(\"hello!world\"), \"helloworld\")",
        "        self.assertEqual(slugify(\"test@#$%case\"), \"testcase\")",
        "        self.assertEqual(slugify(\"a/b\\\\c*d?e\"), \"abcde\")",
        "",
        "    def test_lowercases_text(self):",
        "        \"\"\"Text should be lowercased.\"\"\"",
        "        self.assertEqual(slugify(\"HELLO\"), \"hello\")",
        "        self.assertEqual(slugify(\"CamelCase\"), \"camelcase\")",
        "        self.assertEqual(slugify(\"MiXeD CaSe\"), \"mixed-case\")",
        "",
        "    def test_handles_empty_string(self):",
        "        \"\"\"Empty string should return empty string.\"\"\"",
        "        self.assertEqual(slugify(\"\"), \"\")",
        "        self.assertEqual(slugify(\"   \"), \"\")",
        "",
        "    def test_removes_duplicate_hyphens(self):",
        "        \"\"\"Duplicate hyphens should be collapsed.\"\"\"",
        "        self.assertEqual(slugify(\"foo--bar\"), \"foo-bar\")",
        "        self.assertEqual(slugify(\"a   b\"), \"a-b\")",
        "        self.assertEqual(slugify(\"hello---world\"), \"hello-world\")",
        "",
        "    def test_truncates_long_strings(self):",
        "        \"\"\"Strings longer than 50 chars should be truncated.\"\"\"",
        "        long_text = \"a\" * 100",
        "        result = slugify(long_text)",
        "        self.assertEqual(len(result), 50)",
        "",
        "    def test_handles_unicode(self):",
        "        \"\"\"Unicode characters should be handled gracefully.\"\"\"",
        "        # Python's isalnum() preserves unicode letters",
        "        self.assertEqual(slugify(\"cafÃ©\"), \"cafÃ©\")",
        "        self.assertEqual(slugify(\"naÃ¯ve\"), \"naÃ¯ve\")",
        "        # Only non-alphanumeric symbols are removed",
        "        self.assertEqual(slugify(\"hello!ä¸–ç•Œ\"), \"helloä¸–ç•Œ\")",
        "",
        "    def test_strips_leading_trailing_whitespace(self):",
        "        \"\"\"Leading/trailing whitespace should be stripped.\"\"\"",
        "        self.assertEqual(slugify(\"  hello  \"), \"hello\")",
        "        self.assertEqual(slugify(\"\\tfoo bar\\n\"), \"foo-bar\")",
        "",
        "    def test_real_world_examples(self):",
        "        \"\"\"Test real-world memory title examples.\"\"\"",
        "        self.assertEqual(",
        "            slugify(\"learned about NaN validation\"),",
        "            \"learned-about-nan-validation\"",
        "        )",
        "        self.assertEqual(",
        "            slugify(\"add microseconds to timestamps\"),",
        "            \"add-microseconds-to-timestamps\"",
        "        )",
        "        self.assertEqual(",
        "            slugify(\"Why we chose PostgreSQL\"),",
        "            \"why-we-chose-postgresql\"",
        "        )",
        "",
        "",
        "class TestGenerateMemoryFilename(unittest.TestCase):",
        "    \"\"\"Tests for generate_memory_filename function.\"\"\"",
        "",
        "    @patch('new_memory.generate_session_id')",
        "    @patch('new_memory.datetime')",
        "    def test_correct_format(self, mock_datetime, mock_session_id):",
        "        \"\"\"Filename should have format YYYY-MM-DD_HH-MM-SS_XXXX-topic.md.\"\"\"",
        "        # Mock datetime",
        "        mock_now = MagicMock()",
        "        mock_now.strftime.side_effect = lambda fmt: {",
        "            \"%Y-%m-%d\": \"2025-12-14\",",
        "            \"%H-%M-%S\": \"14-30-52\"",
        "        }[fmt]",
        "        mock_datetime.now.return_value = mock_now",
        "",
        "        # Mock session ID",
        "        mock_session_id.return_value = \"a1b2\"",
        "",
        "        result = generate_memory_filename(\"test topic\")",
        "        self.assertEqual(result, \"2025-12-14_14-30-52_a1b2-test-topic.md\")",
        "",
        "    @patch('new_memory.generate_session_id')",
        "    @patch('new_memory.datetime')",
        "    def test_handles_empty_topic(self, mock_datetime, mock_session_id):",
        "        \"\"\"Empty topic should still generate valid filename.\"\"\"",
        "        mock_now = MagicMock()",
        "        mock_now.strftime.side_effect = lambda fmt: {",
        "            \"%Y-%m-%d\": \"2025-12-14\",",
        "            \"%H-%M-%S\": \"14-30-52\"",
        "        }[fmt]",
        "        mock_datetime.now.return_value = mock_now",
        "        mock_session_id.return_value = \"a1b2\"",
        "",
        "        result = generate_memory_filename(\"\")",
        "        self.assertEqual(result, \"2025-12-14_14-30-52_a1b2-.md\")",
        "",
        "    @patch('new_memory.generate_session_id')",
        "    @patch('new_memory.datetime')",
        "    def test_handles_special_characters_in_topic(self, mock_datetime, mock_session_id):",
        "        \"\"\"Special characters in topic should be slugified.\"\"\"",
        "        mock_now = MagicMock()",
        "        mock_now.strftime.side_effect = lambda fmt: {",
        "            \"%Y-%m-%d\": \"2025-12-14\",",
        "            \"%H-%M-%S\": \"14-30-52\"",
        "        }[fmt]",
        "        mock_datetime.now.return_value = mock_now",
        "        mock_session_id.return_value = \"a1b2\"",
        "",
        "        result = generate_memory_filename(\"Test! @#$ Topic?\")",
        "        self.assertEqual(result, \"2025-12-14_14-30-52_a1b2-test-topic.md\")",
        "",
        "    @patch('new_memory.generate_session_id')",
        "    @patch('new_memory.datetime')",
        "    def test_decision_flag_ignored_in_filename(self, mock_datetime, mock_session_id):",
        "        \"\"\"is_decision parameter doesn't affect filename format.\"\"\"",
        "        mock_now = MagicMock()",
        "        mock_now.strftime.side_effect = lambda fmt: {",
        "            \"%Y-%m-%d\": \"2025-12-14\",",
        "            \"%H-%M-%S\": \"14-30-52\"",
        "        }[fmt]",
        "        mock_datetime.now.return_value = mock_now",
        "        mock_session_id.return_value = \"a1b2\"",
        "",
        "        # Decision flag doesn't change filename format",
        "        result1 = generate_memory_filename(\"test\", is_decision=False)",
        "        result2 = generate_memory_filename(\"test\", is_decision=True)",
        "        self.assertEqual(result1, result2)",
        "",
        "",
        "class TestGetGitAuthor(unittest.TestCase):",
        "    \"\"\"Tests for get_git_author function.\"\"\"",
        "",
        "    @patch('new_memory.subprocess.run')",
        "    def test_returns_author_on_success(self, mock_run):",
        "        \"\"\"Should return git user.name when command succeeds.\"\"\"",
        "        mock_result = MagicMock()",
        "        mock_result.returncode = 0",
        "        mock_result.stdout = \"John Doe\\n\"",
        "        mock_run.return_value = mock_result",
        "",
        "        result = get_git_author()",
        "        self.assertEqual(result, \"John Doe\")",
        "        mock_run.assert_called_once_with(",
        "            [\"git\", \"config\", \"user.name\"],",
        "            capture_output=True,",
        "            text=True,",
        "            timeout=2",
        "        )",
        "",
        "    @patch('new_memory.subprocess.run')",
        "    def test_returns_unknown_on_failure(self, mock_run):",
        "        \"\"\"Should return 'Unknown' when git command fails.\"\"\"",
        "        mock_result = MagicMock()",
        "        mock_result.returncode = 1",
        "        mock_run.return_value = mock_result",
        "",
        "        result = get_git_author()",
        "        self.assertEqual(result, \"Unknown\")",
        "",
        "    @patch('new_memory.subprocess.run')",
        "    def test_handles_timeout(self, mock_run):",
        "        \"\"\"Should return 'Unknown' on timeout.\"\"\"",
        "        from subprocess import TimeoutExpired",
        "        mock_run.side_effect = TimeoutExpired(\"git\", 2)",
        "",
        "        result = get_git_author()",
        "        self.assertEqual(result, \"Unknown\")",
        "",
        "    @patch('new_memory.subprocess.run')",
        "    def test_handles_file_not_found(self, mock_run):",
        "        \"\"\"Should return 'Unknown' if git not installed.\"\"\"",
        "        mock_run.side_effect = FileNotFoundError()",
        "",
        "        result = get_git_author()",
        "        self.assertEqual(result, \"Unknown\")",
        "",
        "",
        "class TestCreateMemoryTemplate(unittest.TestCase):",
        "    \"\"\"Tests for create_memory_template function.\"\"\"",
        "",
        "    @patch('new_memory.datetime')",
        "    def test_contains_required_sections(self, mock_datetime):",
        "        \"\"\"Template should contain all required memory sections.\"\"\"",
        "        mock_now = MagicMock()",
        "        mock_now.strftime.side_effect = lambda fmt: {",
        "            \"%Y-%m-%d\": \"2025-12-14\",",
        "            \"%Y-%m-%dT%H:%M:%SZ\": \"2025-12-14T14:30:52Z\"",
        "        }[fmt]",
        "        mock_datetime.now.return_value = mock_now",
        "",
        "        template = create_memory_template(\"test topic\")",
        "",
        "        # Check for required sections",
        "        self.assertIn(\"# Memory Entry:\", template)",
        "        self.assertIn(\"**Tags:**\", template)",
        "        self.assertIn(\"**Related:**\", template)",
        "        self.assertIn(\"## Context\", template)",
        "        self.assertIn(\"## What I Learned\", template)",
        "        self.assertIn(\"## Connections Made\", template)",
        "        self.assertIn(\"## Emotional State\", template)",
        "        self.assertIn(\"## Future Exploration\", template)",
        "        self.assertIn(\"## Artifacts Created\", template)",
        "",
        "    @patch('new_memory.datetime')",
        "    def test_includes_title(self, mock_datetime):",
        "        \"\"\"Template should include the provided title.\"\"\"",
        "        mock_now = MagicMock()",
        "        mock_now.strftime.side_effect = lambda fmt: {",
        "            \"%Y-%m-%d\": \"2025-12-14\",",
        "            \"%Y-%m-%dT%H:%M:%SZ\": \"2025-12-14T14:30:52Z\"",
        "        }[fmt]",
        "        mock_datetime.now.return_value = mock_now",
        "",
        "        template = create_memory_template(\"learning about pagerank\")",
        "        self.assertIn(\"Learning About Pagerank\", template)",
        "",
        "    @patch('new_memory.datetime')",
        "    def test_includes_tags_when_provided(self, mock_datetime):",
        "        \"\"\"Template should include formatted tags.\"\"\"",
        "        mock_now = MagicMock()",
        "        mock_now.strftime.side_effect = lambda fmt: {",
        "            \"%Y-%m-%d\": \"2025-12-14\",",
        "            \"%Y-%m-%dT%H:%M:%SZ\": \"2025-12-14T14:30:52Z\"",
        "        }[fmt]",
        "        mock_datetime.now.return_value = mock_now",
        "",
        "        template = create_memory_template(\"test\", tags=\"testing,validation,bugfix\")",
        "        self.assertIn(\"`testing`\", template)",
        "        self.assertIn(\"`validation`\", template)",
        "        self.assertIn(\"`bugfix`\", template)",
        "",
        "    @patch('new_memory.datetime')",
        "    def test_empty_tags_when_not_provided(self, mock_datetime):",
        "        \"\"\"Template should have empty tags section when no tags provided.\"\"\"",
        "        mock_now = MagicMock()",
        "        mock_now.strftime.side_effect = lambda fmt: {",
        "            \"%Y-%m-%d\": \"2025-12-14\",",
        "            \"%Y-%m-%dT%H:%M:%SZ\": \"2025-12-14T14:30:52Z\"",
        "        }[fmt]",
        "        mock_datetime.now.return_value = mock_now",
        "",
        "        template = create_memory_template(\"test\", tags=\"\")",
        "        # Should have Tags: line but empty",
        "        self.assertIn(\"**Tags:**\", template)",
        "        # No backtick-wrapped tags",
        "        self.assertNotIn(\"`test`\", template)",
        "",
        "    @patch('new_memory.datetime')",
        "    def test_includes_timestamp(self, mock_datetime):",
        "        \"\"\"Template should include commit timestamp.\"\"\"",
        "        mock_now = MagicMock()",
        "        mock_now.strftime.side_effect = lambda fmt: {",
        "            \"%Y-%m-%d\": \"2025-12-14\",",
        "            \"%Y-%m-%dT%H:%M:%SZ\": \"2025-12-14T14:30:52Z\"",
        "        }[fmt]",
        "        mock_datetime.now.return_value = mock_now",
        "",
        "        template = create_memory_template(\"test\")",
        "        self.assertIn(\"*Committed to memory at: 2025-12-14T14:30:52Z*\", template)",
        "",
        "    @patch('new_memory.datetime')",
        "    def test_author_parameter_not_used(self, mock_datetime):",
        "        \"\"\"Author parameter exists but is not used in template.\"\"\"",
        "        mock_now = MagicMock()",
        "        mock_now.strftime.side_effect = lambda fmt: {",
        "            \"%Y-%m-%d\": \"2025-12-14\",",
        "            \"%Y-%m-%dT%H:%M:%SZ\": \"2025-12-14T14:30:52Z\"",
        "        }[fmt]",
        "        mock_datetime.now.return_value = mock_now",
        "",
        "        # Author parameter accepted but not used",
        "        template = create_memory_template(\"test\", author=\"John Doe\")",
        "        self.assertNotIn(\"John Doe\", template)",
        "",
        "",
        "class TestCreateDecisionTemplate(unittest.TestCase):",
        "    \"\"\"Tests for create_decision_template function.\"\"\"",
        "",
        "    @patch('new_memory.datetime')",
        "    @patch('new_memory.DECISIONS_DIR')",
        "    def test_contains_adr_sections(self, mock_decisions_dir, mock_datetime):",
        "        \"\"\"Template should contain ADR sections.\"\"\"",
        "        mock_now = MagicMock()",
        "        mock_now.strftime.return_value = \"2025-12-14\"",
        "        mock_datetime.now.return_value = mock_now",
        "",
        "        # Mock no existing ADR files",
        "        mock_decisions_dir.glob.return_value = []",
        "",
        "        template = create_decision_template(\"test decision\")",
        "",
        "        # Check for ADR sections",
        "        self.assertIn(\"ADR-001:\", template)",
        "        self.assertIn(\"**Status:**\", template)",
        "        self.assertIn(\"**Date:**\", template)",
        "        self.assertIn(\"**Deciders:**\", template)",
        "        self.assertIn(\"## Context and Problem Statement\", template)",
        "        self.assertIn(\"## Decision Drivers\", template)",
        "        self.assertIn(\"## Considered Options\", template)",
        "        self.assertIn(\"## Decision Outcome\", template)",
        "        self.assertIn(\"## Implementation\", template)",
        "        self.assertIn(\"## Consequences\", template)",
        "        self.assertIn(\"## Validation\", template)",
        "        self.assertIn(\"## Related Decisions\", template)",
        "",
        "    @patch('new_memory.datetime')",
        "    @patch('new_memory.DECISIONS_DIR')",
        "    def test_adr_number_starts_at_001(self, mock_decisions_dir, mock_datetime):",
        "        \"\"\"First ADR should be numbered 001.\"\"\"",
        "        mock_now = MagicMock()",
        "        mock_now.strftime.return_value = \"2025-12-14\"",
        "        mock_datetime.now.return_value = mock_now",
        "",
        "        # No existing files",
        "        mock_decisions_dir.glob.return_value = []",
        "",
        "        template = create_decision_template(\"test\")",
        "        self.assertIn(\"# ADR-001:\", template)",
        "",
        "    @patch('new_memory.datetime')",
        "    @patch('new_memory.DECISIONS_DIR')",
        "    def test_adr_number_increments(self, mock_decisions_dir, mock_datetime):",
        "        \"\"\"ADR number should increment based on existing files.\"\"\"",
        "        mock_now = MagicMock()",
        "        mock_now.strftime.return_value = \"2025-12-14\"",
        "        mock_datetime.now.return_value = mock_now",
        "",
        "        # Mock existing ADR files",
        "        mock_file1 = MagicMock()",
        "        mock_file1.stem = \"adr-001-first-decision\"",
        "        mock_file2 = MagicMock()",
        "        mock_file2.stem = \"adr-002-second-decision\"",
        "        mock_decisions_dir.glob.return_value = [mock_file1, mock_file2]",
        "",
        "        template = create_decision_template(\"third decision\")",
        "        self.assertIn(\"# ADR-003:\", template)",
        "",
        "    @patch('new_memory.datetime')",
        "    @patch('new_memory.DECISIONS_DIR')",
        "    def test_adr_number_handles_gaps(self, mock_decisions_dir, mock_datetime):",
        "        \"\"\"ADR number should use max + 1 even with gaps.\"\"\"",
        "        mock_now = MagicMock()",
        "        mock_now.strftime.return_value = \"2025-12-14\"",
        "        mock_datetime.now.return_value = mock_now",
        "",
        "        # Mock existing ADR files with gaps",
        "        mock_file1 = MagicMock()",
        "        mock_file1.stem = \"adr-001-first\"",
        "        mock_file2 = MagicMock()",
        "        mock_file2.stem = \"adr-005-fifth\"",
        "        mock_decisions_dir.glob.return_value = [mock_file1, mock_file2]",
        "",
        "        template = create_decision_template(\"next decision\")",
        "        self.assertIn(\"# ADR-006:\", template)",
        "",
        "    @patch('new_memory.datetime')",
        "    @patch('new_memory.DECISIONS_DIR')",
        "    def test_adr_number_ignores_invalid_filenames(self, mock_decisions_dir, mock_datetime):",
        "        \"\"\"Should ignore files that don't match adr-NNN pattern.\"\"\"",
        "        mock_now = MagicMock()",
        "        mock_now.strftime.return_value = \"2025-12-14\"",
        "        mock_datetime.now.return_value = mock_now",
        "",
        "        # Mix of valid and invalid filenames",
        "        mock_file1 = MagicMock()",
        "        mock_file1.stem = \"adr-001-valid\"",
        "        mock_file2 = MagicMock()",
        "        mock_file2.stem = \"not-an-adr\"",
        "        mock_file3 = MagicMock()",
        "        mock_file3.stem = \"adr-abc-invalid\"",
        "        mock_decisions_dir.glob.return_value = [mock_file1, mock_file2, mock_file3]",
        "",
        "        template = create_decision_template(\"test\")",
        "        self.assertIn(\"# ADR-002:\", template)",
        "",
        "    @patch('new_memory.datetime')",
        "    @patch('new_memory.DECISIONS_DIR')",
        "    def test_includes_title(self, mock_decisions_dir, mock_datetime):",
        "        \"\"\"Template should include the decision title.\"\"\"",
        "        mock_now = MagicMock()",
        "        mock_now.strftime.return_value = \"2025-12-14\"",
        "        mock_datetime.now.return_value = mock_now",
        "        mock_decisions_dir.glob.return_value = []",
        "",
        "        template = create_decision_template(\"use postgresql for storage\")",
        "        self.assertIn(\"Use Postgresql For Storage\", template)",
        "",
        "    @patch('new_memory.datetime')",
        "    @patch('new_memory.DECISIONS_DIR')",
        "    def test_includes_tags_when_provided(self, mock_decisions_dir, mock_datetime):",
        "        \"\"\"Template should include formatted tags.\"\"\"",
        "        mock_now = MagicMock()",
        "        mock_now.strftime.return_value = \"2025-12-14\"",
        "        mock_datetime.now.return_value = mock_now",
        "        mock_decisions_dir.glob.return_value = []",
        "",
        "        template = create_decision_template(\"test\", tags=\"architecture,database\")",
        "        self.assertIn(\"`architecture`\", template)",
        "        self.assertIn(\"`database`\", template)",
        "",
        "    @patch('new_memory.datetime')",
        "    @patch('new_memory.DECISIONS_DIR')",
        "    def test_handles_glob_exception(self, mock_decisions_dir, mock_datetime):",
        "        \"\"\"Should handle exceptions when reading existing files.\"\"\"",
        "        mock_now = MagicMock()",
        "        mock_now.strftime.return_value = \"2025-12-14\"",
        "        mock_datetime.now.return_value = mock_now",
        "",
        "        # Simulate exception",
        "        mock_decisions_dir.glob.side_effect = Exception(\"Permission denied\")",
        "",
        "        # Should default to ADR-001",
        "        template = create_decision_template(\"test\")",
        "        self.assertIn(\"# ADR-001:\", template)",
        "",
        "",
        "class TestCreateMemory(unittest.TestCase):",
        "    \"\"\"Tests for create_memory integration function.\"\"\"",
        "",
        "    def setUp(self):",
        "        \"\"\"Create temporary directory for test files.\"\"\"",
        "        self.temp_dir = tempfile.mkdtemp()",
        "        self.original_memories_dir = MEMORIES_DIR",
        "        self.original_decisions_dir = DECISIONS_DIR",
        "",
        "    def tearDown(self):",
        "        \"\"\"Clean up temporary directory.\"\"\"",
        "        import shutil",
        "        shutil.rmtree(self.temp_dir, ignore_errors=True)",
        "",
        "    @patch('new_memory.DECISIONS_DIR', new_callable=lambda: Path(tempfile.mkdtemp()))",
        "    @patch('new_memory.MEMORIES_DIR', new_callable=lambda: Path(tempfile.mkdtemp()))",
        "    @patch('new_memory.get_git_author')",
        "    def test_dry_run_does_not_create_file(self, mock_author, mock_mem_dir, mock_dec_dir):",
        "        \"\"\"Dry-run should not create any files.\"\"\"",
        "        mock_author.return_value = \"Test User\"",
        "",
        "        # Dry-run",
        "        filepath = create_memory(\"test topic\", dry_run=True)",
        "",
        "        # File should not exist",
        "        self.assertFalse(filepath.exists())",
        "",
        "        # Clean up mocked directories",
        "        import shutil",
        "        shutil.rmtree(mock_mem_dir, ignore_errors=True)",
        "        shutil.rmtree(mock_dec_dir, ignore_errors=True)",
        "",
        "    @patch('new_memory.get_git_author')",
        "    def test_creates_memory_file(self, mock_author):",
        "        \"\"\"Should create memory file with correct name.\"\"\"",
        "        mock_author.return_value = \"Test User\"",
        "",
        "        # Create in temp directory",
        "        with patch('new_memory.MEMORIES_DIR', Path(self.temp_dir)):",
        "            filepath = create_memory(\"test topic\")",
        "",
        "            # File should exist",
        "            self.assertTrue(filepath.exists())",
        "",
        "            # Should be in memories directory",
        "            self.assertEqual(filepath.parent, Path(self.temp_dir))",
        "",
        "            # Should be markdown",
        "            self.assertTrue(filepath.name.endswith(\".md\"))",
        "",
        "            # Should contain topic in filename",
        "            self.assertIn(\"test-topic\", filepath.name)",
        "",
        "    @patch('new_memory.get_git_author')",
        "    def test_creates_decision_file(self, mock_author):",
        "        \"\"\"Should create decision file when is_decision=True.\"\"\"",
        "        mock_author.return_value = \"Test User\"",
        "",
        "        with patch('new_memory.DECISIONS_DIR', Path(self.temp_dir)):",
        "            filepath = create_memory(\"test decision\", is_decision=True)",
        "",
        "            # File should exist",
        "            self.assertTrue(filepath.exists())",
        "",
        "            # Should be markdown",
        "            self.assertTrue(filepath.name.endswith(\".md\"))",
        "",
        "    @patch('new_memory.get_git_author')",
        "    def test_file_contains_correct_content_memory(self, mock_author):",
        "        \"\"\"Memory file should contain correct content.\"\"\"",
        "        mock_author.return_value = \"Test User\"",
        "",
        "        with patch('new_memory.MEMORIES_DIR', Path(self.temp_dir)):",
        "            filepath = create_memory(\"test topic\", tags=\"testing,validation\")",
        "",
        "            # Read file",
        "            content = filepath.read_text()",
        "",
        "            # Check content",
        "            self.assertIn(\"# Memory Entry:\", content)",
        "            self.assertIn(\"`testing`\", content)",
        "            self.assertIn(\"`validation`\", content)",
        "            self.assertIn(\"## What I Learned\", content)",
        "",
        "    @patch('new_memory.get_git_author')",
        "    def test_file_contains_correct_content_decision(self, mock_author):",
        "        \"\"\"Decision file should contain ADR content.\"\"\"",
        "        mock_author.return_value = \"Test User\"",
        "",
        "        with patch('new_memory.DECISIONS_DIR', Path(self.temp_dir)):",
        "            filepath = create_memory(\"test decision\", is_decision=True)",
        "",
        "            # Read file",
        "            content = filepath.read_text()",
        "",
        "            # Check content",
        "            self.assertIn(\"# ADR-001:\", content)",
        "            self.assertIn(\"**Status:**\", content)",
        "            self.assertIn(\"## Decision Outcome\", content)",
        "",
        "    @patch('new_memory.get_git_author')",
        "    def test_creates_directory_if_missing(self, mock_author):",
        "        \"\"\"Should create target directory if it doesn't exist.\"\"\"",
        "        mock_author.return_value = \"Test User\"",
        "",
        "        # Use non-existent subdirectory",
        "        new_dir = Path(self.temp_dir) / \"new_memories\"",
        "        self.assertFalse(new_dir.exists())",
        "",
        "        with patch('new_memory.MEMORIES_DIR', new_dir):",
        "            filepath = create_memory(\"test topic\")",
        "",
        "            # Directory should now exist",
        "            self.assertTrue(new_dir.exists())",
        "            self.assertTrue(filepath.exists())",
        "",
        "    @patch('new_memory.get_git_author')",
        "    def test_handles_special_characters_in_title(self, mock_author):",
        "        \"\"\"Should handle special characters in title.\"\"\"",
        "        mock_author.return_value = \"Test User\"",
        "",
        "        with patch('new_memory.MEMORIES_DIR', Path(self.temp_dir)):",
        "            filepath = create_memory(\"Test! @#$ Topic?\")",
        "",
        "            # Should create valid filename",
        "            self.assertTrue(filepath.exists())",
        "            # Special chars should be removed",
        "            self.assertIn(\"test-topic\", filepath.name)",
        "",
        "    @patch('new_memory.get_git_author')",
        "    @patch('new_memory.datetime')",
        "    def test_dry_run_shows_preview(self, mock_datetime, mock_author):",
        "        \"\"\"Dry-run should print preview without creating file.\"\"\"",
        "        import io",
        "        from contextlib import redirect_stdout",
        "",
        "        mock_author.return_value = \"Test User\"",
        "        mock_now = MagicMock()",
        "        mock_now.strftime.side_effect = lambda fmt: {",
        "            \"%Y-%m-%d\": \"2025-12-14\",",
        "            \"%H-%M-%S\": \"14-30-52\",",
        "            \"%Y-%m-%dT%H:%M:%SZ\": \"2025-12-14T14:30:52Z\"",
        "        }.get(fmt, \"2025-12-14\")",
        "        mock_datetime.now.return_value = mock_now",
        "",
        "        with patch('new_memory.MEMORIES_DIR', Path(self.temp_dir)):",
        "            # Capture output",
        "            output = io.StringIO()",
        "            with redirect_stdout(output):",
        "                filepath = create_memory(\"test\", dry_run=True)",
        "",
        "            # Check output",
        "            output_str = output.getvalue()",
        "            self.assertIn(\"DRY RUN\", output_str)",
        "            self.assertIn(\"Would create:\", output_str)",
        "",
        "            # File should not exist",
        "            self.assertFalse(filepath.exists())",
        "",
        "",
        "class TestFilenameFormat(unittest.TestCase):",
        "    \"\"\"Integration tests for filename format consistency.\"\"\"",
        "",
        "    @patch('new_memory.generate_session_id')",
        "    @patch('new_memory.datetime')",
        "    def test_filename_uniqueness(self, mock_datetime, mock_session_id):",
        "        \"\"\"Multiple calls should generate unique filenames.\"\"\"",
        "        # First call",
        "        mock_now1 = MagicMock()",
        "        mock_now1.strftime.side_effect = lambda fmt: {",
        "            \"%Y-%m-%d\": \"2025-12-14\",",
        "            \"%H-%M-%S\": \"14-30-52\"",
        "        }[fmt]",
        "        mock_datetime.now.return_value = mock_now1",
        "        mock_session_id.return_value = \"a1b2\"",
        "",
        "        filename1 = generate_memory_filename(\"test\")",
        "",
        "        # Second call with different session ID",
        "        mock_now2 = MagicMock()",
        "        mock_now2.strftime.side_effect = lambda fmt: {",
        "            \"%Y-%m-%d\": \"2025-12-14\",",
        "            \"%H-%M-%S\": \"14-30-52\"",
        "        }[fmt]",
        "        mock_datetime.now.return_value = mock_now2",
        "        mock_session_id.return_value = \"c3d4\"",
        "",
        "        filename2 = generate_memory_filename(\"test\")",
        "",
        "        # Should be different due to session ID",
        "        self.assertNotEqual(filename1, filename2)",
        "",
        "    @patch('new_memory.generate_session_id')",
        "    @patch('new_memory.datetime')",
        "    def test_filename_parts_accessible(self, mock_datetime, mock_session_id):",
        "        \"\"\"Filename parts should be parseable.\"\"\"",
        "        mock_now = MagicMock()",
        "        mock_now.strftime.side_effect = lambda fmt: {",
        "            \"%Y-%m-%d\": \"2025-12-14\",",
        "            \"%H-%M-%S\": \"14-30-52\"",
        "        }[fmt]",
        "        mock_datetime.now.return_value = mock_now",
        "        mock_session_id.return_value = \"a1b2\"",
        "",
        "        filename = generate_memory_filename(\"test topic\")",
        "",
        "        # Remove .md extension",
        "        base = filename[:-3]",
        "",
        "        # Split parts",
        "        parts = base.split(\"_\")",
        "        self.assertEqual(len(parts), 3)",
        "",
        "        # Date part",
        "        self.assertEqual(parts[0], \"2025-12-14\")",
        "",
        "        # Time part",
        "        self.assertEqual(parts[1], \"14-30-52\")",
        "",
        "        # Session + topic part",
        "        self.assertTrue(parts[2].startswith(\"a1b2-\"))",
        "",
        "",
        "if __name__ == \"__main__\":",
        "    unittest.main()"
      ],
      "lines_removed": [],
      "context_before": [],
      "context_after": [],
      "change_type": "add"
    }
  ],
  "hour_of_day": 21,
  "day_of_week": "Sunday",
  "seconds_since_last_commit": -57718,
  "is_merge": false,
  "is_initial": false,
  "parent_count": 1,
  "session_id": null,
  "related_chats": [],
  "ci_result": null,
  "reverted": false,
  "amended": false
}