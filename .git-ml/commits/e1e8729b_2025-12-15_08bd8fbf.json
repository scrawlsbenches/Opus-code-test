{
  "hash": "e1e8729b1cf9e599f6fe03a15bb9a073f0c93f61",
  "message": "Merge main: BM25 scoring, GB-BM25 search, benchmarks (resolve conflicts by taking main)",
  "author": "Claude",
  "timestamp": "2025-12-15 12:43:12 +0000",
  "branch": "claude/multi-index-design-DvifZ",
  "files_changed": [
    ".github/workflows/ci.yml",
    "CLAUDE.md",
    "CODE_REVIEW.md",
    "README.md",
    "benchmarks/BASELINE_SUMMARY.md",
    "benchmarks/after_bm25.json",
    "benchmarks/baseline_tfidf.json",
    "benchmarks/baseline_tfidf_real.json",
    "cortical/analysis.py",
    "cortical/config.py",
    "cortical/observability.py",
    "cortical/patterns.py",
    "cortical/processor/compute.py",
    "cortical/processor/core.py",
    "cortical/processor/documents.py",
    "cortical/processor/introspection.py",
    "cortical/processor/persistence_api.py",
    "cortical/processor/query_api.py",
    "cortical/query/__init__.py",
    "cortical/query/passages.py",
    "cortical/query/search.py",
    "cortical/semantics.py",
    "docs/DEPENDENCIES_AND_TOOLS.md",
    "docs/PATTERN_DETECTION_GUIDE.md",
    "docs/benchmarks.md",
    "docs/knowledge-transfer-bm25-optimization.md",
    "examples/demo_pattern_detection.py",
    "examples/observability_demo.py",
    "examples/repl_demo.py",
    "samples/customer_service/README.md",
    "samples/customer_service/faq-billing.md",
    "samples/customer_service/faq-shipping.md",
    "samples/customer_service/policy-privacy.md",
    "samples/customer_service/policy-returns.md",
    "samples/customer_service/template-apology.md",
    "samples/customer_service/template-resolution.md",
    "samples/customer_service/troubleshoot-login.md",
    "samples/customer_service/troubleshoot-payment.md",
    "samples/memories/2025-12-14-search-relevance-investigation.md",
    "samples/memories/2025-12-14_20-54-35_3b3a-director-mode-session-group-tasks-orchestration.md",
    "samples/memories/2025-12-14_20-55-23_632e-session-knowledge-transfer-director-mode-orchestra.md",
    "scripts/README_suggest_consolidation.md",
    "scripts/benchmark_scoring.py",
    "scripts/index_codebase.py",
    "scripts/new_memory.py",
    "scripts/repl.py",
    "scripts/resolve_wiki_links.py",
    "scripts/search_codebase.py",
    "scripts/session_handoff.py",
    "scripts/suggest_consolidation.py",
    "scripts/task_utils.py",
    "tasks/2025-12-14_11-11-44_legacy-migration.json",
    "tasks/2025-12-14_17-13-01_6aa8.json",
    "tasks/2025-12-14_23-31-16_3058.json",
    "tasks/2025-12-15_05-23-36_ceac.json",
    "tasks/legacy_migration.json",
    "tests/test_edge_cases.py",
    "tests/unit/test_new_memory.py",
    "tests/unit/test_observability.py",
    "tests/unit/test_patterns.py",
    "tests/unit/test_processor_core.py",
    "tests/unit/test_query_search.py",
    "tests/unit/test_repl.py",
    "tests/unit/test_suggest_consolidation.py"
  ],
  "insertions": 18578,
  "deletions": 574,
  "hunks": [
    {
      "file": "workflows/ci.yml b/.github/workflows/ci.yml",
      "function": "jobs:",
      "start_line": 420,
      "lines_added": [
        "",
        "  # ==========================================================================",
        "  # Markdown Link Checker (runs in parallel with all other jobs)",
        "  # Uses our own Python script - NO external dependencies/actions",
        "  # Principle: Prefer native implementations over 3rd party APIs/actions",
        "  # ==========================================================================",
        "  markdown-links:",
        "    name: \"üîó Markdown Links\"",
        "    runs-on: ubuntu-latest",
        "    continue-on-error: true  # Non-blocking initially",
        "    steps:",
        "    - uses: actions/checkout@v4",
        "",
        "    - name: Set up Python",
        "      uses: actions/setup-python@v5",
        "      with:",
        "        python-version: '3.11'",
        "",
        "    - name: Check wiki-links in markdown files",
        "      run: |",
        "        echo \"Checking wiki-links in documentation...\"",
        "        python scripts/resolve_wiki_links.py --check docs/ || true",
        "        python scripts/resolve_wiki_links.py --check samples/memories/ || true",
        "        python scripts/resolve_wiki_links.py --check samples/decisions/ || true",
        "        echo \"Link check complete (informational only)\""
      ],
      "lines_removed": [],
      "context_before": [
        "            results = data.get('results', {})",
        "            real_secrets = {k: v for k, v in results.items() if not k.startswith('tests/')}",
        "            if real_secrets:",
        "                print('‚ö†Ô∏è Potential secrets found in:')",
        "                for file in real_secrets:",
        "                    print(f'  - {file}')",
        "                print('Please review and ensure no real secrets are committed.')",
        "            else:",
        "                print('‚úÖ No secrets detected in source files')",
        "        PYTHON_SCRIPT"
      ],
      "context_after": [],
      "change_type": "add"
    },
    {
      "file": "CLAUDE.md",
      "function": "You are a **senior computational neuroscience engineer** with deep expertise in:",
      "start_line": 35,
      "lines_added": [
        "**Native Over External**",
        "- Prefer implementing features ourselves over 3rd party APIs/actions",
        "- External dependencies add maintenance burden and security risk",
        "- If we can build it in <20000 lines, build it ourselves",
        "- Avoid deprecated or unmaintained external tools",
        ""
      ],
      "lines_removed": [],
      "context_before": [
        "- Use the system to test itself when possible",
        "- Real usage reveals issues that unit tests miss",
        "- Create tasks using `scripts/new_task.py` or the task-manager skill",
        "- **Use merge-friendly task system** - see `tasks/` directory and `docs/merge-friendly-tasks.md`",
        "",
        "**Honest Assessment**",
        "- Acknowledge when something isn't working",
        "- Say \"I don't know\" when uncertain, then investigate",
        "- Correct course based on evidence, not pride",
        ""
      ],
      "context_after": [
        "When you see \"neural\" or \"cortical\" in this codebase, remember: these are metaphors for standard IR algorithms, not actual neural implementations.",
        "",
        "---",
        "",
        "## Project Overview",
        "",
        "**Cortical Text Processor** is a zero-dependency Python library for hierarchical text analysis. It organizes text through 4 layers inspired by visual cortex organization:",
        "",
        "```",
        "Layer 0 (TOKENS)    ‚Üí Individual words        [V1 analogy: edges]"
      ],
      "change_type": "add"
    },
    {
      "file": "CLAUDE.md",
      "function": "Layer 3 (DOCUMENTS) ‚Üí Full documents          [IT analogy: objects]",
      "start_line": 59,
      "lines_added": [
        "## Development Environment Setup",
        "",
        "**Before running tests with coverage**, install dev dependencies:",
        "",
        "```bash",
        "# Option 1: Install as editable package with dev deps (recommended)",
        "pip install -e \".[dev]\"",
        "",
        "# Option 2: Install from requirements.txt",
        "pip install -r requirements.txt",
        "```",
        "",
        "This installs: `coverage`, `pytest`, `mcp`, `pyyaml`",
        "",
        "**Verify installation:**",
        "```bash",
        "python -c \"import coverage; print('coverage OK')\"",
        "```",
        "",
        "> **Note:** The library itself has zero runtime dependencies. Dev dependencies are only needed for testing and coverage reporting.",
        "",
        "---",
        "",
        "# Get structured overview of any module (processor is now a package)"
      ],
      "lines_removed": [
        "# Get structured overview of any module"
      ],
      "context_before": [
        "",
        "**Core algorithms:**",
        "- **PageRank** for term importance (`analysis.py`)",
        "- **TF-IDF** for document relevance (`analysis.py`)",
        "- **Louvain community detection** for concept clustering (`analysis.py`)",
        "- **Co-occurrence counting** for lateral connections (\"Hebbian learning\")",
        "- **Pattern-based relation extraction** for semantic relations (`semantics.py`)",
        "",
        "---",
        ""
      ],
      "context_after": [
        "## AI Agent Onboarding",
        "",
        "**New to this codebase?** Follow these steps to get oriented quickly:",
        "",
        "### Step 1: Generate AI Metadata (if missing)",
        "",
        "```bash",
        "# Check if metadata exists",
        "ls cortical/*.ai_meta",
        "",
        "# If not present, generate it (~1s)",
        "python scripts/generate_ai_metadata.py",
        "```",
        "",
        "### Step 2: Read Module Metadata First",
        "",
        "Instead of reading entire source files, start with `.ai_meta` files:",
        "",
        "```bash",
        "cat cortical/processor/__init__.py.ai_meta",
        "```",
        "",
        "**What metadata provides:**",
        "- Module docstring and purpose",
        "- Function signatures with `see_also` cross-references",
        "- Class structures with inheritance",
        "- Logical section groupings (Persistence, Query, Analysis, etc.)",
        "- Complexity hints for expensive operations",
        ""
      ],
      "change_type": "modify"
    },
    {
      "file": "CLAUDE.md",
      "function": "python scripts/search_codebase.py \"your query here\"",
      "start_line": 111,
      "lines_added": [
        "cat cortical/query/__init__.py.ai_meta | head -100    # Get overview (query is a package)",
        "‚îÇ   ‚îú‚îÄ‚îÄ __init__.py   # Re-exports CorticalTextProcessor class",
        "‚îÇ   ‚îú‚îÄ‚îÄ core.py       # Initialization, staleness tracking, layer management (~100 lines)",
        "‚îÇ   ‚îú‚îÄ‚îÄ documents.py  # Document processing, add/remove, metadata (~450 lines)",
        "‚îÇ   ‚îú‚îÄ‚îÄ compute.py    # compute_all, PageRank, TF-IDF, clustering (~750 lines)",
        "‚îÇ   ‚îú‚îÄ‚îÄ query_api.py  # Search, expansion, retrieval methods (~550 lines)",
        "‚îÇ   ‚îú‚îÄ‚îÄ introspection.py  # State inspection, fingerprints, summaries (~200 lines)",
        "‚îÇ   ‚îî‚îÄ‚îÄ persistence_api.py # Save/load/export methods (~200 lines)",
        "‚îú‚îÄ‚îÄ observability.py  # Timing, metrics collection, and trace context (374 lines)",
        "**Total:** ~11,100 lines of core library code"
      ],
      "lines_removed": [
        "cat cortical/query/expansion.py.ai_meta | head -100    # Get overview",
        "‚îÇ   ‚îú‚îÄ‚îÄ __init__.py   # Re-exports CorticalTextProcessor class (63 lines)",
        "‚îÇ   ‚îú‚îÄ‚îÄ core.py       # Initialization, staleness tracking, layer management (108 lines)",
        "‚îÇ   ‚îú‚îÄ‚îÄ documents.py  # Document processing, add/remove, metadata (454 lines)",
        "‚îÇ   ‚îú‚îÄ‚îÄ compute.py    # compute_all, PageRank, TF-IDF, clustering (1,033 lines)",
        "‚îÇ   ‚îú‚îÄ‚îÄ query_api.py  # Search, expansion, retrieval methods (699 lines)",
        "‚îÇ   ‚îú‚îÄ‚îÄ introspection.py  # State inspection, fingerprints, summaries (217 lines)",
        "‚îÇ   ‚îî‚îÄ‚îÄ persistence_api.py # Save/load/export methods (243 lines)",
        "**Total:** ~10,700 lines of core library code"
      ],
      "context_before": [
        "1. **Read `.ai_meta` before source code** - Get the map before exploring the territory",
        "2. **Follow `see_also` references** - Functions are cross-linked to related functions",
        "3. **Check `complexity_hints`** - Know which operations are expensive before calling them",
        "4. **Use semantic search** - The codebase is indexed for meaning-based retrieval",
        "5. **Trust the sections** - Functions are grouped by purpose in the metadata",
        "",
        "### Example Workflow",
        "",
        "```bash",
        "# I need to understand how search works"
      ],
      "context_after": [
        "python scripts/search_codebase.py \"expand query\"  # Find specific code",
        "# Then read specific line ranges as needed",
        "```",
        "",
        "---",
        "",
        "## Architecture Map",
        "",
        "```",
        "cortical/",
        "‚îú‚îÄ‚îÄ processor/        # Main orchestrator package - START HERE",
        "‚îÇ   ‚îÇ                 # CorticalTextProcessor is the public API (composed from mixins)",
        "‚îú‚îÄ‚îÄ query/            # Search, retrieval, query expansion (split into 8 modules)",
        "‚îÇ   ‚îú‚îÄ‚îÄ __init__.py   # Re-exports public API",
        "‚îÇ   ‚îú‚îÄ‚îÄ expansion.py  # Query expansion",
        "‚îÇ   ‚îú‚îÄ‚îÄ search.py     # Document search",
        "‚îÇ   ‚îú‚îÄ‚îÄ passages.py   # Passage retrieval",
        "‚îÇ   ‚îú‚îÄ‚îÄ chunking.py   # Text chunking",
        "‚îÇ   ‚îú‚îÄ‚îÄ intent.py     # Intent-based queries",
        "‚îÇ   ‚îú‚îÄ‚îÄ definitions.py # Definition search",
        "‚îÇ   ‚îú‚îÄ‚îÄ ranking.py    # Multi-stage ranking",
        "‚îÇ   ‚îî‚îÄ‚îÄ analogy.py    # Analogy completion",
        "‚îú‚îÄ‚îÄ analysis.py       # Graph algorithms: PageRank, TF-IDF, clustering (1,123 lines)",
        "‚îú‚îÄ‚îÄ semantics.py      # Relation extraction, inheritance, retrofitting (915 lines)",
        "‚îú‚îÄ‚îÄ persistence.py    # Save/load with full state preservation (606 lines)",
        "‚îú‚îÄ‚îÄ chunk_index.py    # Git-friendly chunk-based storage (574 lines)",
        "‚îú‚îÄ‚îÄ tokenizer.py      # Tokenization, stemming, stop word removal (398 lines)",
        "‚îú‚îÄ‚îÄ minicolumn.py     # Core data structure with typed Edge connections (357 lines)",
        "‚îú‚îÄ‚îÄ config.py         # CorticalConfig dataclass with validation (352 lines)",
        "‚îú‚îÄ‚îÄ fingerprint.py    # Semantic fingerprinting and similarity (315 lines)",
        "‚îú‚îÄ‚îÄ layers.py         # HierarchicalLayer with O(1) ID lookups via _id_index (294 lines)",
        "‚îú‚îÄ‚îÄ code_concepts.py  # Programming concept synonyms for code search (249 lines)",
        "‚îú‚îÄ‚îÄ gaps.py           # Knowledge gap detection and anomaly analysis (245 lines)",
        "‚îî‚îÄ‚îÄ embeddings.py     # Graph embeddings (adjacency, spectral, random walk) (209 lines)",
        "```",
        "",
        "",
        "**For detailed architecture documentation**, see [docs/architecture.md](docs/architecture.md), which includes:",
        "- Complete module dependency graphs (ASCII + Mermaid)",
        "- Component interaction patterns",
        "- Data flow diagrams",
        "- Layer hierarchy details",
        "",
        "### Module Purpose Quick Reference",
        "",
        "| If you need to... | Look in... |"
      ],
      "change_type": "modify"
    },
    {
      "file": "CLAUDE.md",
      "function": "cortical/",
      "start_line": 186,
      "lines_added": [
        "| Add observability features | `observability.py` - timing, metrics, traces |"
      ],
      "lines_removed": [],
      "context_before": [
        "| Modify data structures | `minicolumn.py` - Minicolumn, Edge classes |",
        "| Change layer behavior | `layers.py` - HierarchicalLayer class |",
        "| Adjust tokenization | `tokenizer.py` - stemming, stop words, ngrams |",
        "| Change configuration | `config.py` - CorticalConfig dataclass |",
        "| Modify persistence | `persistence.py` - save/load, export formats |",
        "| Add code search features | `code_concepts.py` - programming synonyms |",
        "| Modify embeddings | `embeddings.py` - graph embedding methods |",
        "| Change gap detection | `gaps.py` - knowledge gap analysis |",
        "| Add fingerprinting | `fingerprint.py` - semantic fingerprints |",
        "| Modify chunk storage | `chunk_index.py` - git-friendly indexing |"
      ],
      "context_after": [
        "",
        "**Key data structures:**",
        "- `Minicolumn`: Core unit with `lateral_connections`, `typed_connections`, `feedforward_connections`, `feedback_connections`",
        "- `Edge`: Typed connection with `relation_type`, `weight`, `confidence`, `source`",
        "- `HierarchicalLayer`: Container with `minicolumns` dict and `_id_index` for O(1) lookups",
        "",
        "### Test Organization",
        "",
        "Tests are organized by category for clear CI diagnostics and efficient local development:",
        ""
      ],
      "change_type": "add"
    },
    {
      "file": "CLAUDE.md",
      "function": "tests/",
      "start_line": 237,
      "lines_added": [
        "| Intent queries | `tests/unit/test_query.py` |"
      ],
      "lines_removed": [
        "| Intent queries | `tests/test_intent_query.py` |"
      ],
      "context_before": [
        "| Persistence/save/load | `tests/test_persistence.py` |",
        "| Tokenization | `tests/test_tokenizer.py` |",
        "| Configuration | `tests/test_config.py` |",
        "| Layers | `tests/test_layers.py` |",
        "| Embeddings | `tests/test_embeddings.py` |",
        "| Gap detection | `tests/test_gaps.py` |",
        "| Fingerprinting | `tests/test_fingerprint.py` |",
        "| Code concepts | `tests/test_code_concepts.py` |",
        "| Chunk indexing | `tests/test_chunk_indexing.py` |",
        "| Incremental updates | `tests/test_incremental_indexing.py` |"
      ],
      "context_after": [
        "",
        "**Running Tests:**",
        "",
        "```bash",
        "# Quick feedback during development",
        "python scripts/run_tests.py smoke        # ~1s - sanity check",
        "python scripts/run_tests.py quick        # smoke + unit",
        "",
        "# Before committing",
        "python scripts/run_tests.py precommit    # smoke + unit + integration"
      ],
      "change_type": "modify"
    },
    {
      "file": "CLAUDE.md",
      "function": "coverage run -m pytest tests/",
      "start_line": 739,
      "lines_added": [
        "2. Add wrapper method to `CorticalTextProcessor` in the `processor/` package (appropriate mixin):",
        "1. Add to the `query/` package following existing patterns (e.g., `query/search.py`)",
        "4. Add wrapper to the `processor/` package (likely `processor/query_api.py`)"
      ],
      "lines_removed": [
        "2. Add wrapper method to appropriate mixin in `processor/` package:",
        "   # In processor/compute.py (ComputeMixin)",
        "1. Add to `query/` package following existing patterns",
        "4. Add wrapper to `processor/query_api.py` (QueryMixin)"
      ],
      "context_before": [
        "   def compute_your_analysis(",
        "       layers: Dict[CorticalLayer, HierarchicalLayer],",
        "       **kwargs",
        "   ) -> Dict[str, Any]:",
        "       \"\"\"Your analysis description.\"\"\"",
        "       layer0 = layers[CorticalLayer.TOKENS]",
        "       # Implementation",
        "       return {'result': ..., 'stats': ...}",
        "   ```",
        ""
      ],
      "context_after": [
        "   ```python",
        "   def compute_your_analysis(self, **kwargs) -> Dict[str, Any]:",
        "       \"\"\"Wrapper with docstring.\"\"\"",
        "       return compute_your_analysis(self.layers, **kwargs)",
        "   ```",
        "",
        "3. Add tests in `tests/test_analysis.py`",
        "",
        "### Adding a New Query Function",
        "",
        "2. Use `get_expanded_query_terms()` helper for query expansion",
        "3. Use `layer.get_by_id()` for O(1) lookups, not iteration",
        "5. Add tests in `tests/test_processor.py`",
        "",
        "### Modifying Minicolumn Structure",
        "",
        "1. Update `Minicolumn` class in `minicolumn.py`",
        "2. Update `to_dict()` and `from_dict()` for persistence",
        "3. Update `__slots__` if adding new fields",
        "4. Increment state version in `persistence.py` if breaking change",
        "5. Add migration logic for backward compatibility",
        ""
      ],
      "change_type": "modify"
    },
    {
      "file": "CLAUDE.md",
      "function": "def find_documents(",
      "start_line": 799,
      "lines_added": [
        "## Scoring Algorithms",
        "",
        "The processor supports multiple scoring algorithms for term weighting:",
        "",
        "### BM25 (Default)",
        "",
        "BM25 (Best Match 25) is the default scoring algorithm, optimized for code search:",
        "",
        "```python",
        "from cortical import CorticalTextProcessor",
        "from cortical.config import CorticalConfig",
        "",
        "# BM25 with default parameters (recommended)",
        "config = CorticalConfig(scoring_algorithm='bm25')",
        "",
        "# Tune BM25 parameters if needed",
        "config = CorticalConfig(",
        "    scoring_algorithm='bm25',",
        "    bm25_k1=1.2,  # Term frequency saturation (0.0-3.0, default 1.2)",
        "    bm25_b=0.75   # Length normalization (0.0-1.0, default 0.75)",
        ")",
        "processor = CorticalTextProcessor(config=config)",
        "```",
        "",
        "**Parameters:**",
        "- `bm25_k1`: Controls term frequency saturation. Higher values give more weight to term frequency.",
        "- `bm25_b`: Controls document length normalization. Set to 0.0 to disable length normalization.",
        "",
        "### TF-IDF (Legacy)",
        "",
        "Traditional TF-IDF scoring is still available:",
        "",
        "```python",
        "config = CorticalConfig(scoring_algorithm='tfidf')",
        "```",
        "",
        "### Graph-Boosted Search (GB-BM25)",
        "",
        "A hybrid search combining BM25 with graph signals:",
        "",
        "```python",
        "# Standard search (uses BM25 under the hood)",
        "results = processor.find_documents_for_query(\"query\")",
        "",
        "# Graph-boosted search (adds PageRank + proximity signals)",
        "results = processor.graph_boosted_search(",
        "    \"query\",",
        "    pagerank_weight=0.3,   # Weight for term importance (0-1)",
        "    proximity_weight=0.2   # Weight for connected terms (0-1)",
        ")",
        "```",
        "",
        "**GB-BM25 combines:**",
        "1. BM25 base score (term relevance)",
        "2. PageRank boost (important terms rank higher)",
        "3. Proximity boost (connected query terms boost documents)",
        "4. Coverage boost (documents matching more terms rank higher)",
        "",
        "---",
        "",
        "9. **Use `graph_boosted_search()`** for hybrid scoring with PageRank signals"
      ],
      "lines_removed": [],
      "context_before": [
        "        top_n: Number of results to return",
        "",
        "    Returns:",
        "        List of (doc_id, score) tuples sorted by relevance",
        "    \"\"\"",
        "    # Implementation",
        "```",
        "",
        "---",
        ""
      ],
      "context_after": [
        "## Performance Considerations",
        "",
        "1. **Use `get_by_id()` for ID lookups** - O(1) vs O(n) iteration",
        "2. **Batch document additions** with `add_documents_batch()` for bulk imports",
        "3. **Use incremental updates** with `add_document_incremental()` for live systems",
        "4. **Cache query expansions** when processing multiple similar queries",
        "5. **Pre-compute chunks** in `find_passages_batch()` to avoid redundant work",
        "6. **Use `fast_find_documents()`** for ~2-3x faster search on large corpora",
        "7. **Pre-build index** with `build_search_index()` for fastest repeated queries",
        "8. **Watch for O(n¬≤) patterns** in loops over connections‚Äîuse limits like `max_bigrams_per_term`",
        "",
        "---",
        "",
        "## Code Search Capabilities",
        "",
        "### Code-Aware Tokenization",
        "```python",
        "# Enable identifier splitting for code search",
        "tokenizer = Tokenizer(split_identifiers=True)",
        "tokens = tokenizer.tokenize(\"getUserCredentials\")"
      ],
      "change_type": "add"
    },
    {
      "file": "CLAUDE.md",
      "function": "for t1, rel, t2, weight in processor.semantic_relations[:10]:",
      "start_line": 903,
      "lines_added": [
        "### Observability and Metrics",
        "",
        "The processor includes built-in observability features for tracking performance and operational metrics.",
        "",
        "**Enable metrics collection:**",
        "```python",
        "# Create processor with metrics enabled",
        "processor = CorticalTextProcessor(enable_metrics=True)",
        "",
        "# Process documents and run queries (all operations are timed)",
        "processor.process_document(\"doc1\", \"Neural networks process data.\")",
        "processor.compute_all()",
        "processor.find_documents_for_query(\"neural networks\")",
        "",
        "# Get metrics summary",
        "print(processor.get_metrics_summary())",
        "```",
        "",
        "**Access metrics programmatically:**",
        "```python",
        "metrics = processor.get_metrics()",
        "",
        "# Check specific operation stats",
        "if \"compute_all\" in metrics:",
        "    stats = metrics[\"compute_all\"]",
        "    print(f\"Average: {stats['avg_ms']:.2f}ms\")",
        "    print(f\"Count: {stats['count']}\")",
        "    print(f\"Min: {stats['min_ms']:.2f}ms\")",
        "    print(f\"Max: {stats['max_ms']:.2f}ms\")",
        "",
        "# Check cache performance",
        "if \"query_cache_hits\" in metrics:",
        "    hits = metrics[\"query_cache_hits\"][\"count\"]",
        "    misses = metrics[\"query_cache_misses\"][\"count\"]",
        "    hit_rate = hits / (hits + misses) * 100",
        "    print(f\"Cache hit rate: {hit_rate:.1f}%\")",
        "```",
        "",
        "**Automatically timed operations:**",
        "- `compute_all()` and all compute phases (PageRank, TF-IDF, clustering, etc.)",
        "- `process_document()` with doc_id context",
        "- `find_documents_for_query()` with query context",
        "- `save()` operations",
        "- Query cache hits/misses via `expand_query_cached()`",
        "",
        "**Control metrics collection:**",
        "```python",
        "# Disable metrics temporarily",
        "processor.disable_metrics()",
        "# ... operations not timed ...",
        "processor.enable_metrics()",
        "",
        "# Reset all metrics",
        "processor.reset_metrics()",
        "",
        "# Record custom metrics",
        "processor.record_metric(\"api_calls\", 10)",
        "processor.record_metric(\"documents_processed\", 100)",
        "```",
        "",
        "**Demo:**",
        "```bash",
        "# Run the observability demo",
        "python examples/observability_demo.py",
        "```",
        "",
        "| Hybrid search | `processor.graph_boosted_search(query)` |",
        "| Enable metrics | `processor = CorticalTextProcessor(enable_metrics=True)` |",
        "| Get metrics | `processor.get_metrics()` |",
        "| Metrics summary | `processor.get_metrics_summary()` |",
        "| Reset metrics | `processor.reset_metrics()` |",
        "| Record metric | `processor.record_metric(\"name\", count)` |",
        "| Create memory | `python scripts/new_memory.py \"topic\"` |",
        "| Create decision | `python scripts/new_memory.py \"topic\" --decision` |",
        "| Session handoff | `python scripts/session_handoff.py` |",
        "| Check wiki-links | `python scripts/resolve_wiki_links.py FILE` |",
        "| Find backlinks | `python scripts/resolve_wiki_links.py --backlinks FILE` |",
        "| Complete task with memory | `python scripts/task_utils.py complete TASK_ID --create-memory` |"
      ],
      "lines_removed": [],
      "context_before": [
        "```",
        "",
        "### Profiling Performance",
        "```bash",
        "# Profile full analysis phases with timeout detection",
        "python scripts/profile_full_analysis.py",
        "",
        "# This reveals which phases are slow and helps identify O(n¬≤) bottlenecks",
        "```",
        ""
      ],
      "context_after": [
        "---",
        "",
        "## Quick Reference",
        "",
        "| Task | Command/Method |",
        "|------|----------------|",
        "| Process document | `processor.process_document(id, text)` |",
        "| Build network | `processor.compute_all()` |",
        "| Search | `processor.find_documents_for_query(query)` |",
        "| Fast search | `processor.fast_find_documents(query)` |",
        "| Code search | `processor.expand_query_for_code(query)` |",
        "| Intent search | `processor.search_by_intent(\"where do we...\")` |",
        "| RAG passages | `processor.find_passages_for_query(query)` |",
        "| Fingerprint | `processor.get_fingerprint(text)` |",
        "| Compare | `processor.compare_fingerprints(fp1, fp2)` |",
        "| Save state | `processor.save(\"corpus.pkl\")` |",
        "| Load state | `processor = CorticalTextProcessor.load(\"corpus.pkl\")` |",
        "| Run all tests | `python scripts/run_tests.py all` |",
        "| Run smoke tests | `python scripts/run_tests.py smoke` |",
        "| Run unit tests | `python scripts/run_tests.py unit` |",
        "| Run quick tests | `python scripts/run_tests.py quick` (smoke + unit) |",
        "| Run pre-commit | `python scripts/run_tests.py precommit` (smoke + unit + integration) |",
        "| Run performance | `python scripts/run_tests.py performance` (no coverage) |",
        "| Check coverage | `python -m coverage run --source=cortical -m pytest tests/ && python -m coverage report --include=\"cortical/*\"` |",
        "| Run showcase | `python showcase.py` |",
        "| Profile analysis | `python scripts/profile_full_analysis.py` |",
        "",
        "---",
        "",
        "## Dog-Fooding: Search the Codebase",
        "",
        "The Cortical Text Processor can index and search its own codebase, providing semantic search capabilities during development.",
        "",
        "### Quick Start",
        "",
        "```bash"
      ],
      "change_type": "add"
    },
    {
      "file": "CLAUDE.md",
      "function": "python scripts/search_codebase.py \"what did we learn about validation\"",
      "start_line": 1153,
      "lines_added": [
        "- **Main API**: `cortical/processor/` - `CorticalTextProcessor` class (split into mixins)",
        "- **Search**: `cortical/query/` - query expansion, document retrieval (split into 8 modules)"
      ],
      "lines_removed": [
        "## ML Data Collection: Project-Specific Micro-Model",
        "",
        "The project automatically collects enriched commit and chat data to train a micro-model that learns THIS project's patterns, coding style, and workflows.",
        "",
        "### What Gets Collected",
        "",
        "| Data Type | Location | Contents |",
        "|-----------|----------|----------|",
        "| **Commits** | `.git-ml/commits/` | Git history with diff hunks, temporal context, CI results |",
        "| **Chats** | `.git-ml/chats/` | Query/response pairs with files touched and tools used |",
        "| **Sessions** | `.git-ml/sessions/` | Development sessions linking chats to commits |",
        "| **Actions** | `.git-ml/actions/` | Individual tool uses and operations |",
        "",
        "**Note:** All ML data is stored in `.git-ml/` which is gitignored and regeneratable via backfill.",
        "",
        "### Quick Commands",
        "",
        "```bash",
        "# Check collection progress",
        "python scripts/ml_data_collector.py stats",
        "",
        "# Estimate when training becomes viable",
        "python scripts/ml_data_collector.py estimate",
        "",
        "# Validate collected data",
        "python scripts/ml_data_collector.py validate",
        "",
        "# Session management",
        "python scripts/ml_data_collector.py session status",
        "python scripts/ml_data_collector.py session start",
        "python scripts/ml_data_collector.py session end --summary \"What was accomplished\"",
        "",
        "# Generate session handoff document",
        "python scripts/ml_data_collector.py handoff",
        "",
        "# Record CI results",
        "python scripts/ml_data_collector.py ci set --commit abc123 --result pass --coverage 89.5",
        "",
        "# Backfill historical commits",
        "python scripts/ml_data_collector.py backfill -n 100",
        "```",
        "",
        "### Disabling Collection",
        "",
        "```bash",
        "# Disable for current session",
        "export ML_COLLECTION_ENABLED=0",
        "",
        "# Stats and validation still work when disabled",
        "```",
        "",
        "### Automatic Session Capture",
        "",
        "**Zero-friction capture via Claude Code Stop hook:**",
        "",
        "The ML data collector automatically captures complete session transcripts when Claude Code sessions end. This eliminates manual logging entirely.",
        "",
        "**Setup:**",
        "```bash",
        "# Add to ~/.claude/settings.json or project .claude/settings.json:",
        "{",
        "  \"hooks\": {",
        "    \"Stop\": [",
        "      {",
        "        \"type\": \"command\",",
        "        \"command\": \"/path/to/Opus-code-test/scripts/ml-session-capture-hook.sh\"",
        "      }",
        "    ]",
        "  }",
        "}",
        "```",
        "",
        "**What gets captured automatically:**",
        "- Full query/response pairs from the transcript",
        "- All tool uses (Task, Read, Edit, Bash, Grep, etc.)",
        "- Files referenced and modified",
        "- Thinking blocks (if present)",
        "- Session linkage to commits",
        "",
        "**Process transcript manually:**",
        "```bash",
        "# Process a specific transcript file",
        "python scripts/ml_data_collector.py transcript --file /path/to/transcript.jsonl",
        "",
        "# Dry run (show what would be captured without saving)",
        "python scripts/ml_data_collector.py transcript --file /path/to/transcript.jsonl --dry-run --verbose",
        "```",
        "",
        "### Integration",
        "",
        "Data collection is automatic via hooks:",
        "- **Stop hook**: Captures full session transcripts with all exchanges (recommended)",
        "- **post-commit**: Captures commit metadata with diff hunks",
        "- **pre-push**: Reports collection stats",
        "",
        "See `.claude/skills/ml-logger/SKILL.md` for detailed logging usage.",
        "",
        "",
        "- **Main API**: `cortical/processor/` package - `CorticalTextProcessor` class (mixin-based composition)",
        "- **Search**: `cortical/query/` package - query expansion, document retrieval (8 modules)"
      ],
      "context_before": [
        "",
        "When completing a task, consider creating a memory entry from the retrospective:",
        "- What was learned?",
        "- What connections were made?",
        "- What should future developers know?",
        "",
        "See `docs/text-as-memories.md` for the full guide.",
        "",
        "---",
        ""
      ],
      "context_after": [
        "## File Quick Links",
        "",
        "- **Graph algorithms**: `cortical/analysis.py` - PageRank, TF-IDF, clustering",
        "- **Data structures**: `cortical/minicolumn.py` - `Minicolumn`, `Edge`",
        "- **Configuration**: `cortical/config.py` - `CorticalConfig` dataclass",
        "- **Tests**: `tests/test_processor.py` - most comprehensive test file",
        "- **Demo**: `showcase.py` - interactive demonstration",
        "",
        "**Process Documentation:**",
        "- **Getting Started**: `docs/quickstart.md` - 5-minute tutorial for newcomers",
        "- **Contributing**: `CONTRIBUTING.md` - how to contribute (fork, test, PR workflow)",
        "- **Ethics**: `docs/code-of-ethics.md` - documentation, testing, and completion standards",
        "- **Dog-fooding**: `docs/dogfooding-checklist.md` - checklist for testing with real usage"
      ],
      "change_type": "modify"
    },
    {
      "file": "CODE_REVIEW.md",
      "function": null,
      "start_line": 1,
      "lines_added": [
        "**Date:** 2025-12-15",
        "**Last Updated:** 2025-12-15",
        "This review identifies code quality issues across the Cortical Text Processor codebase. The code is generally well-structured with good documentation. Since the last review, significant improvements have been made, most notably the refactoring of the monolithic `CorticalTextProcessor` class into a modular mixin-based architecture.",
        "| Category | Severity | Count | Status |",
        "|----------|----------|-------|--------|",
        "| God Class | High | 1 | **RESOLVED** |",
        "| Deprecated Code Still Used | Medium | 1 | Open |",
        "| Naming Inconsistencies | Medium | 4 | Open |",
        "| Code Duplication | Medium | 2 | Open |",
        "| Magic Numbers | Low | 3 | Open |",
        "| Minor Clean Code Issues | Low | 4 | Partially Addressed |",
        "## 1. God Class Anti-Pattern - **RESOLVED**",
        "### Previous Issue: CorticalTextProcessor was Too Large",
        "**Previous State:** `cortical/processor.py` - 3115 lines, 70+ methods",
        "### Current State: Refactored into Mixin Architecture",
        "The `CorticalTextProcessor` has been successfully refactored into a package with focused mixins:",
        "**Directory:** `cortical/processor/`",
        "",
        "| File | Lines | Responsibility |",
        "|------|-------|----------------|",
        "| `core.py` | 169 | Initialization, staleness tracking, layer management |",
        "| `documents.py` | 456 | Document processing, add/remove, metadata |",
        "| `compute.py` | 1041 | compute_all, PageRank, TF-IDF, clustering |",
        "| `query_api.py` | 719 | Search, expansion, retrieval methods |",
        "| `introspection.py` | 357 | State inspection, fingerprints, summaries |",
        "| `persistence_api.py` | 245 | Save/load/export methods |",
        "| `__init__.py` | 63 | Re-exports CorticalTextProcessor class |",
        "| **Total** | **3050** | Distributed across focused modules |",
        "",
        "**Benefits Achieved:**",
        "- Each mixin has a single responsibility",
        "- Easier to test individual components",
        "- Improved code navigation",
        "- No single file exceeds 1050 lines",
        "",
        "**Additional Modularization:**",
        "",
        "The `query/` module has also been split into 8 focused modules (3194 total lines):",
        "- `expansion.py` (459 lines) - Query expansion",
        "- `ranking.py` (472 lines) - Multi-stage ranking",
        "- `search.py` (422 lines) - Document search",
        "- `passages.py` (407 lines) - Passage retrieval",
        "- `definitions.py` (375 lines) - Definition search",
        "- `chunking.py` (335 lines) - Text chunking",
        "- `analogy.py` (330 lines) - Analogy completion",
        "- `intent.py` (220 lines) - Intent-based queries",
        "**Current Usage (15+ locations):**",
        "- `minicolumn.py:390-391` - maintained in `add_feedforward_connection()`",
        "- `minicolumn.py:448` - serialized in `to_dict()`",
        "- `minicolumn.py:497` - deserialized in `from_dict()`",
        "- `analysis.py:967, 1507` - used for feedforward iteration",
        "- `query/expansion.py:175-176` - used for concept expansion",
        "- `query/ranking.py:212, 214` - used for scoring",
        "- `proto/serialization.py:270, 335` - protobuf serialization",
        "- Maintenance burden (must keep both `feedforward_sources` and `feedforward_connections` in sync)",
        "1. Remove the deprecated field completely and migrate all usages to `feedforward_connections`",
        "**Current usage:** 200 occurrences across 17 files",
        "",
        "# Common pattern",
        "layer3 = self.layers[CorticalLayer.DOCUMENTS]  # Note: layer2 often skipped",
        "**Files most affected:**",
        "- `cortical/analysis.py` (47 occurrences)",
        "- `cortical/query/search.py` (21 occurrences)",
        "- `cortical/query/analogy.py` (17 occurrences)",
        "- `cortical/processor/documents.py` (16 occurrences)",
        "- `cortical/query/expansion.py` (16 occurrences)"
      ],
      "lines_removed": [
        "**Date:** 2025-12-14",
        "This review identifies code quality issues across the Cortical Text Processor codebase. The code is generally well-structured with good documentation, but several patterns indicate opportunities for improvement.",
        "| Category | Severity | Count |",
        "|----------|----------|-------|",
        "| God Class | High | 1 |",
        "| Deprecated Code Still Used | Medium | 1 |",
        "| Naming Inconsistencies | Medium | 4 |",
        "| Code Duplication | Medium | 3 |",
        "| Magic Numbers | Low | 5 |",
        "| Minor Clean Code Issues | Low | 6 |",
        "## 1. God Class Anti-Pattern",
        "### Issue: CorticalTextProcessor is Too Large",
        "**File:** `cortical/processor.py`",
        "**Lines:** 3115 lines",
        "**Methods:** 70+ public methods",
        "The `CorticalTextProcessor` class violates the Single Responsibility Principle. It handles:",
        "- Document processing",
        "- TF-IDF computation",
        "- PageRank computation",
        "- Query expansion",
        "- Semantic analysis",
        "- Fingerprinting",
        "- Persistence",
        "- Concept clustering",
        "- Graph embeddings",
        "- And more...",
        "**Symptoms:**",
        "- File is over 3000 lines",
        "- Class has 70+ methods",
        "- Many methods are thin delegators to other modules",
        "- Difficult to test individual components",
        "**Recommendation:**",
        "Consider extracting cohesive functionality into separate classes:",
        "```",
        "CorticalTextProcessor (core orchestration only)",
        "‚îú‚îÄ‚îÄ DocumentManager (add/remove/batch documents)",
        "‚îú‚îÄ‚îÄ ComputationEngine (TF-IDF, PageRank, embeddings)",
        "‚îú‚îÄ‚îÄ QueryEngine (search, expansion, ranking)",
        "‚îú‚îÄ‚îÄ SemanticAnalyzer (relations, concepts, retrofitting)",
        "‚îî‚îÄ‚îÄ PersistenceManager (save/load)",
        "```",
        "**Problem:**",
        "The field is marked as deprecated in comments, but:",
        "- It's still maintained in `add_feedforward_connection()` (line 390-391)",
        "- It's still serialized in `to_dict()` (line 448)",
        "- It's still used in `analysis.py:967` and `analysis.py:1507`",
        "- It's used in 20+ test files",
        "- Maintenance burden (must keep both in sync)",
        "1. Remove the deprecated field completely and migrate all usages",
        "# In processor.py",
        "layer3 = self.layers[CorticalLayer.DOCUMENTS]  # Note: layer2 skipped",
        "**Files affected:** `processor.py`, `showcase.py`, `analysis.py`, multiple test files"
      ],
      "context_before": [
        "# Code Quality Review Report",
        ""
      ],
      "context_after": [
        "**Reviewer:** Claude (Automated Code Review)",
        "**Scope:** Code smells, clean code issues, symbolic misinterpretations",
        "",
        "---",
        "",
        "## Executive Summary",
        "",
        "",
        "",
        "---",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "---",
        "",
        "## 2. Deprecated Code Still in Use",
        "",
        "### Issue: feedforward_sources is Deprecated but Actively Used",
        "",
        "**File:** `cortical/minicolumn.py:76, 118`",
        "",
        "```python",
        "feedforward_sources: IDs of columns that feed into this one (deprecated, use feedforward_connections)",
        "...",
        "self.feedforward_sources: Set[str] = set()  # Deprecated: use feedforward_connections",
        "```",
        "",
        "",
        "**Impact:**",
        "- Confusion for developers",
        "- Memory overhead (duplicate data)",
        "",
        "**Recommendation:**",
        "Either:",
        "2. Or remove the deprecation comment if it's still needed",
        "",
        "---",
        "",
        "## 3. Naming Inconsistencies",
        "",
        "### 3.1 Layer Variable Naming",
        "",
        "**Pattern:** `layer0`, `layer1`, `layer2`, `layer3` vs semantic names",
        "",
        "```python",
        "layer0 = self.layers[CorticalLayer.TOKENS]",
        "layer1 = self.layers[CorticalLayer.BIGRAMS]",
        "",
        "# Better naming would be:",
        "token_layer = self.layers[CorticalLayer.TOKENS]",
        "bigram_layer = self.layers[CorticalLayer.BIGRAMS]",
        "document_layer = self.layers[CorticalLayer.DOCUMENTS]",
        "```",
        "",
        "",
        "**Issue:**",
        "- Numeric names don't convey meaning",
        "- `layer2` (CONCEPTS) is often skipped, making the pattern confusing",
        "- Code uses `layer3` for documents but also `doc_layer` in some places",
        "",
        "---",
        "",
        "### 3.2 Inconsistent Abbreviations",
        ""
      ],
      "change_type": "modify"
    },
    {
      "file": "CODE_REVIEW.md",
      "function": "doc_occurrence_counts  # Abbreviated",
      "start_line": 135,
      "lines_added": [
        "**File:** `cortical/processor/query_api.py`"
      ],
      "lines_removed": [
        "**File:** `cortical/processor.py`"
      ],
      "context_before": [
        "",
        "# In analysis.py",
        "col_entries  # Abbreviated",
        "column_count()  # Full name",
        "```",
        "",
        "---",
        "",
        "### 3.3 Boolean Parameter Name Confusion",
        ""
      ],
      "context_after": [
        "",
        "```python",
        "def find_documents_for_query(",
        "    ...",
        "    use_expansion: bool = True,",
        "    use_semantic: bool = True,",
        "    ...",
        ")",
        "```",
        ""
      ],
      "change_type": "modify"
    },
    {
      "file": "CODE_REVIEW.md",
      "function": "The term \"minicolumn\" comes from neuroscience (vertical columns of ~80-100 neuro",
      "start_line": 172,
      "lines_added": [
        "**File:** `cortical/processor/compute.py` (lines 220-420)",
        "The `compute_all()` method has highly repetitive checkpoint handling. The same pattern is repeated ~10 times:",
        "# Repeated pattern for each phase:",
        "def _run_phase(self, phase_name: str, compute_fn: Callable,",
        "               description: str, progress: MultiPhaseProgress,",
        "               completed_phases: Set[str], checkpoint_dir: Optional[str],",
        "               verbose: bool) -> None:",
        "    \"\"\"Execute a computation phase with checkpoint support.\"\"\"",
        "        if verbose:",
        "            logger.info(f\"  Skipping {description} (already checkpointed)\")",
        "        return",
        "    progress.start_phase(description)",
        "    if verbose:",
        "        logger.info(f\"Computing {description}...\")",
        "    compute_fn(verbose=False)",
        "    progress.update(100)",
        "    progress.complete_phase()",
        "    if checkpoint_dir:",
        "        self._save_checkpoint(checkpoint_dir, phase_name, verbose=verbose)",
        "### 4.2 Layer Access Pattern Duplication"
      ],
      "lines_removed": [
        "**File:** `cortical/processor.py` (lines 800-960)",
        "The `compute_all()` method has highly repetitive checkpoint handling:",
        "# Repeated pattern ~10 times:",
        "def _run_phase(self, phase_name, compute_fn, description, ...):",
        "        self._log_skip(phase_name)",
        "    else:",
        "        self._run_and_checkpoint(phase_name, compute_fn, description)",
        "```",
        "",
        "### 4.2 Input Validation Duplication",
        "",
        "**File:** `cortical/processor.py`",
        "",
        "Same validation pattern repeated in multiple methods:",
        "",
        "```python",
        "# Repeated in 10+ methods:",
        "if not isinstance(query_text, str) or not query_text.strip():",
        "    raise ValueError(\"...\")",
        "if not isinstance(top_n, int) or top_n < 1:",
        "    raise ValueError(\"...\")",
        "```",
        "**Recommendation:** Use the existing `validation.py` decorators more consistently:",
        "```python",
        "@validate_params(",
        "    query_text=lambda x: validate_non_empty_string(x, 'query_text'),",
        "    top_n=lambda x: validate_positive_int(x, 'top_n')",
        ")",
        "def find_documents_for_query(self, query_text: str, top_n: int = 5):",
        "    ...",
        "### 4.3 Layer Access Pattern Duplication"
      ],
      "context_before": [
        "**Issue:** The biological analogy breaks down at the document level - documents aren't \"mini\" anything.",
        "",
        "**Recommendation:** Consider renaming to more generic terms like `Node`, `Unit`, or `Feature` for the generic structure, with type-specific terms in documentation.",
        "",
        "---",
        "",
        "## 4. Code Duplication",
        "",
        "### 4.1 Checkpoint Handling Duplication",
        ""
      ],
      "context_after": [
        "",
        "",
        "```python",
        "phase_name = \"phase_x\"",
        "if phase_name in completed_phases:",
        "    if verbose:",
        "        logger.info(\"  Skipping X (already checkpointed)\")",
        "else:",
        "    progress.start_phase(\"X\")",
        "    if verbose:",
        "        logger.info(\"Computing X...\")",
        "    self.compute_x(verbose=False)",
        "    progress.update(100)",
        "    progress.complete_phase()",
        "    if checkpoint_dir:",
        "        self._save_checkpoint(checkpoint_dir, phase_name, verbose=verbose)",
        "```",
        "",
        "**Recommendation:** Extract to a helper method:",
        "```python",
        "    if phase_name in completed_phases:",
        "",
        "",
        "```",
        "",
        "---",
        "",
        "",
        "**Pattern:** Getting layer references is done inconsistently:",
        "",
        "```python",
        "# Pattern 1: Direct dictionary access",
        "layer0 = self.layers[CorticalLayer.TOKENS]",
        "",
        "# Pattern 2: Using get_layer method",
        "token_layer = self.get_layer(CorticalLayer.TOKENS)",
        ""
      ],
      "change_type": "modify"
    },
    {
      "file": "CODE_REVIEW.md",
      "function": "token_layer = self.get_layer(CorticalLayer.TOKENS)",
      "start_line": 252,
      "lines_added": [
        "### 5.1 Hardcoded Cache Size",
        "**File:** `cortical/processor/core.py:68`",
        "# processor/query_api.py",
        "### 6.1 Validation Decorators Underutilized",
        "**File:** `cortical/validation.py`",
        "A validation module exists with decorators like `@validate_params`, but only 3 usages are found in the codebase.",
        "**Current state:** Manual validation patterns are still repeated in multiple methods:",
        "# Repeated in multiple methods:",
        "if not isinstance(query_text, str) or not query_text.strip():",
        "    raise ValueError(\"...\")",
        "if not isinstance(top_n, int) or top_n < 1:",
        "    raise ValueError(\"...\")",
        "**Recommendation:** Use the existing `validation.py` decorators more consistently across the codebase.",
        "### 6.2 Comments That Should Be Code",
        "### 6.3 Inconsistent Error Messages",
        "### 6.4 Return Type Inconsistency",
        "",
        "Some methods return different structures for success vs failure:",
        "",
        "```python",
        "# MCP server returns dict with 'error' key on failure",
        "return {\"error\": str(e), \"results\": [], \"count\": 0}",
        "",
        "# But processor methods raise exceptions",
        "raise ValueError(\"doc_id must be a non-empty string\")",
        "```",
        "",
        "**Recommendation:** Be consistent - either always use exceptions or always use result objects for a given API surface.",
        "",
        "---",
        "",
        "The codebase demonstrates several good practices:",
        "1. **Modular Architecture:** CorticalTextProcessor split into focused mixins",
        "2. **Comprehensive Documentation:** Docstrings with Args, Returns, Examples",
        "3. **Type Hints:** Consistent use of typing annotations",
        "4. **Centralized Configuration:** `CorticalConfig` dataclass with validation",
        "5. **Separation of Concerns:** Query, analysis, persistence in separate modules",
        "6. **Backward Compatibility:** `from_dict` handles old formats gracefully",
        "7. **Test Coverage:** Extensive test suite with unit, integration, and behavioral tests",
        "8. **Validation Module:** Reusable validators in `validation.py`",
        "9. **Observability:** Built-in metrics and timing support via `observability.py`",
        "10. **Progress Tracking:** Multi-phase progress reporting for long operations",
        "### Resolved (since last review)",
        "1. ~~Extract functionality from `CorticalTextProcessor` into focused classes~~ **DONE** - Now uses mixin architecture",
        "",
        "1. Remove or properly deprecate `feedforward_sources`",
        "2. Standardize layer variable naming (use semantic names)",
        "3. Reduce checkpoint handling duplication with helper methods",
        "4. Use `validation.py` decorators consistently",
        "5. Move magic numbers to configuration",
        "6. Standardize error message format",
        "7. Consider renaming \"Minicolumn\" for non-neuroscience contexts",
        "| Metric | Previous | Current | Target |",
        "|--------|----------|---------|--------|",
        "| Largest processor file | 3115 lines | 1041 lines (compute.py) | < 500 lines |",
        "| Processor module files | 1 | 7 | - |",
        "| Methods in single class | 70+ | Distributed across mixins | < 20 per mixin |",
        "| Duplicate checkpoint blocks | ~15 | ~10 | 0 |",
        "| Deprecated code still used | 1 | 1 | 0 |",
        "| Query module files | 1 | 9 | - |",
        "| Total codebase size | ~11,100 lines | ~19,600 lines | - |",
        "",
        "---",
        "",
        "## Change History",
        "",
        "| Date | Change |",
        "|------|--------|",
        "| 2025-12-14 | Initial review |",
        "| 2025-12-15 | Updated to reflect processor package refactoring; God Class marked as RESOLVED |"
      ],
      "lines_removed": [
        "### 5.1 Hardcoded Thresholds",
        "**File:** `cortical/processor.py`",
        "# Line 145: Hardcoded window size",
        "for j in range(max(0, i-3), min(len(tokens), i+4)):  # Magic: 3, 4",
        "",
        "# Line 79: Cache size",
        "    lateral_window_size: int = 3",
        "# processor.py",
        "### 6.1 Long Parameter Lists",
        "",
        "**File:** `cortical/processor.py`",
        "",
        "```python",
        "def compute_all(",
        "    self,",
        "    verbose: bool = True,",
        "    show_progress: bool = True,",
        "    progress_callback: Optional[Callable[[str, float], None]] = None,",
        "    build_concepts: bool = True,",
        "    cluster_strictness: float = 1.0,",
        "    connection_strategy: str = 'hybrid',",
        "    bridge_weight: float = 0.5,",
        "    checkpoint_dir: Optional[str] = None",
        ") -> Dict[str, Any]:",
        "```",
        "",
        "**Issue:** 8 parameters is difficult to remember and use correctly.",
        "",
        "**Recommendation:** Use a configuration object:",
        "```python",
        "@dataclass",
        "class ComputeOptions:",
        "    verbose: bool = True",
        "    show_progress: bool = True",
        "    build_concepts: bool = True",
        "    cluster_strictness: float = 1.0",
        "    connection_strategy: str = 'hybrid'",
        "    bridge_weight: float = 0.5",
        "    checkpoint_dir: Optional[str] = None",
        "",
        "def compute_all(self, options: Optional[ComputeOptions] = None):",
        "    options = options or ComputeOptions()",
        "```",
        "",
        "",
        "### 6.2 Boolean Parameter Confusion",
        "",
        "**File:** `cortical/processor.py`",
        "",
        "```python",
        "# What does this call do?",
        "processor.compute_all(True, True, None, True, 1.0, 'hybrid', 0.5, None)",
        "```",
        "",
        "**Issue:** Positional booleans are unreadable.",
        "**Recommendation:** Always use keyword arguments for booleans:",
        "```python",
        "processor.compute_all(",
        "    verbose=True,",
        "    show_progress=True,",
        "    build_concepts=True",
        ")",
        "```",
        "",
        "### 6.3 Return Type Inconsistency",
        "",
        "Some methods return different structures for success vs failure:",
        "# MCP server returns dict with 'error' key on failure",
        "return {\"error\": str(e), \"results\": [], \"count\": 0}",
        "",
        "# But processor methods raise exceptions",
        "raise ValueError(\"doc_id must be a non-empty string\")",
        "**Recommendation:** Be consistent - either always use exceptions or always use result objects.",
        "### 6.4 Comments That Should Be Code",
        "### 6.5 Dead Code: Unused Imports",
        "",
        "**File:** Various",
        "",
        "```python",
        "# processor.py line 418 - imports inside function",
        "from .layers import CorticalLayer  # Already imported at top of file",
        "```",
        "",
        "",
        "### 6.6 Inconsistent Error Messages",
        "Despite the issues above, the codebase demonstrates several good practices:",
        "1. **Comprehensive Documentation:** Docstrings with Args, Returns, Examples",
        "2. **Type Hints:** Consistent use of typing annotations",
        "3. **Centralized Configuration:** `CorticalConfig` dataclass with validation",
        "4. **Separation of Concerns:** Query, analysis, persistence in separate modules",
        "5. **Backward Compatibility:** `from_dict` handles old formats gracefully",
        "6. **Test Coverage:** Extensive test suite with unit and integration tests",
        "7. **Validation Module:** Reusable validators in `validation.py`",
        "1. Extract functionality from `CorticalTextProcessor` into focused classes",
        "2. Remove or properly deprecate `feedforward_sources`",
        "3. Standardize layer variable naming (use semantic names)",
        "4. Reduce checkpoint handling duplication with helper methods",
        "5. Use `validation.py` decorators consistently",
        "6. Move magic numbers to configuration",
        "7. Standardize error message format",
        "8. Consider renaming \"Minicolumn\" for non-neuroscience contexts",
        "| Metric | Value | Target |",
        "|--------|-------|--------|",
        "| Largest file (processor.py) | 3115 lines | < 500 lines |",
        "| Methods in CorticalTextProcessor | 70+ | < 20 |",
        "| Duplicate validation blocks | ~15 | 0 |",
        "| Deprecated code still used | 1 | 0 |"
      ],
      "context_before": [
        "from .layers import CorticalLayer",
        "layer0 = layers[CorticalLayer.TOKENS]",
        "```",
        "",
        "**Recommendation:** Standardize on one approach, preferably using `get_layer()` for consistency and future extensibility.",
        "",
        "---",
        "",
        "## 5. Magic Numbers",
        ""
      ],
      "context_after": [
        "",
        "",
        "```python",
        "self._query_cache_max_size: int = 100  # Magic: 100",
        "```",
        "",
        "**Recommendation:** Move to `CorticalConfig`:",
        "```python",
        "@dataclass",
        "class CorticalConfig:",
        "    query_cache_max_size: int = 100",
        "```",
        "",
        "---",
        "",
        "### 5.2 Scattered Default Values",
        "",
        "Default values are scattered throughout the codebase:",
        "",
        "```python",
        "def find_documents_for_query(..., doc_name_boost: float = 2.0):",
        "",
        "# query/search.py (same function)",
        "def find_documents_for_query(..., doc_name_boost: float = 2.0):",
        "",
        "# query/ranking.py",
        "candidate_multiplier: int = 3  # Default here too",
        "```",
        "",
        "**Issue:** If defaults need to change, multiple files must be updated.",
        "",
        "**Recommendation:** Centralize in `CorticalConfig` and reference from there.",
        "",
        "---",
        "",
        "## 6. Clean Code Issues",
        "",
        "",
        "",
        "",
        "```python",
        "```",
        "",
        "",
        "---",
        "",
        "",
        "**File:** `cortical/minicolumn.py:390-391`",
        "",
        "```python",
        "# Also maintain legacy feedforward_sources for backward compatibility",
        "self.feedforward_sources.add(target_id)",
        "```",
        "",
        "**Issue:** The comment explains what the code does, not why. The deprecation status should be in a migration plan, not a comment.",
        "",
        "---",
        "",
        "",
        "```python",
        "# Some use 'must be'",
        "raise ValueError(\"doc_id must be a non-empty string\")",
        "",
        "# Some use 'is required'",
        "raise ValueError(\"query_text is required\")",
        "",
        "# Some include type info",
        "raise ValueError(f\"{param_name} must be a string, got {type(value).__name__}\")",
        "",
        "# Some don't",
        "raise ValueError(\"content must be a string\")",
        "```",
        "",
        "**Recommendation:** Standardize error message format.",
        "",
        "---",
        "",
        "## 7. Good Practices Observed",
        "",
        "",
        "",
        "---",
        "",
        "## Recommendations Summary",
        "",
        "### High Priority",
        "",
        "### Medium Priority",
        "",
        "### Low Priority",
        "",
        "---",
        "",
        "## Metrics",
        ""
      ],
      "change_type": "modify"
    },
    {
      "file": "README.md",
      "function": null,
      "start_line": 1,
      "lines_added": [
        "![Tests](https://img.shields.io/badge/tests-3150%20passing-brightgreen.svg)",
        "![Fact Check](https://img.shields.io/badge/fact--check-94%25%20verified-blue.svg)"
      ],
      "lines_removed": [
        "![Tests](https://img.shields.io/badge/tests-1121%20passing-brightgreen.svg)"
      ],
      "context_before": [
        "# Cortical Text Processor",
        "",
        "![Python 3.8+](https://img.shields.io/badge/python-3.8%2B-blue.svg)",
        "![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)"
      ],
      "context_after": [
        "![Coverage](https://img.shields.io/badge/coverage-%3E89%25-brightgreen.svg)",
        "![Zero Dependencies](https://img.shields.io/badge/dependencies-zero-orange.svg)",
        "",
        "## What is this?",
        "",
        "**Cortical Text Processor** is a zero-dependency Python library for hierarchical text analysis and semantic search. Despite the neocortex-inspired naming, it uses proven information retrieval algorithms‚Äî**PageRank**, **TF-IDF**, and **Louvain clustering**‚Äînot neural networks.",
        "",
        "**Key use cases:**",
        "- **Semantic search**: Find documents by meaning, not just keywords",
        "- **Code search**: Search codebases with identifier splitting and programming concept expansion",
        "- **Document retrieval**: RAG system support with chunk-level passage retrieval",
        "- **Knowledge analysis**: Detect gaps, outliers, and missing connections in your corpus"
      ],
      "change_type": "modify"
    },
    {
      "file": "README.md",
      "function": "processor.save(\"my_corpus.pkl\")",
      "start_line": 42,
      "lines_added": [
        "No PyTorch. No transformers. No API keys. Just 3100+ tests, 20,000+ lines of pure Python, and a data structure that would make a neuroscientist squint approvingly."
      ],
      "lines_removed": [
        "No PyTorch. No transformers. No API keys. Just 337 tests, 7000 lines of pure Python, and a data structure that would make a neuroscientist squint approvingly."
      ],
      "context_before": [
        "---",
        "",
        "## Why \"Cortical\"?",
        "",
        "> *\"What if we built a text search engine the way evolution built a brain?\"*",
        "",
        "Your visual cortex doesn't grep through pixels looking for cats. It builds hierarchies‚Äîedges become patterns, patterns become shapes, shapes become objects. This library applies the same principle to text.",
        "",
        "Feed it documents. It tokenizes them into \"minicolumns\" (Layer 0), connects co-occurring words through Hebbian learning (\"neurons that fire together, wire together\"), clusters them into concepts (Layer 2), and links documents by shared meaning (Layer 3). The result: a graph that understands your corpus well enough to expand queries, complete analogies, and tell you where your knowledge has gaps.",
        ""
      ],
      "context_after": [
        "",
        "---",
        "",
        "## Overview",
        "",
        "This library provides a biologically-inspired approach to text processing, organizing information through a hierarchical structure similar to the visual cortex:",
        "",
        "| Layer | Name | Analogy | Purpose |",
        "|-------|------|---------|---------|",
        "| 0 | Tokens | V1 (edges) | Individual words |"
      ],
      "change_type": "modify"
    },
    {
      "file": "README.md",
      "function": "This library provides a biologically-inspired approach to text processing, organ",
      "start_line": 76,
      "lines_added": [
        "## Use Cases & When to Use",
        "",
        "### Ideal Use Cases",
        "",
        "| Use Case | Why It's a Good Fit |",
        "|----------|---------------------|",
        "| **Internal Documentation Search** | Understands domain-specific terminology through corpus-derived semantics; no training data needed |",
        "| **Knowledge Base Q&A** | Query expansion finds related documents even when exact keywords don't match |",
        "| **Code Repository Search** | Built-in code tokenization splits `getUserName` ‚Üí `get`, `user`, `name`; programming synonym expansion |",
        "| **Research Paper Organization** | Concept clustering automatically groups related papers; gap detection finds missing coverage |",
        "| **RAG/LLM Context Retrieval** | Chunk-level passage retrieval with relevance scoring; designed for retrieval-augmented generation |",
        "| **Offline/Air-gapped Environments** | Zero dependencies, no API calls, works completely offline |",
        "| **Privacy-Sensitive Applications** | All processing happens locally; no data leaves your machine |",
        "| **Educational Projects** | Clean, well-documented codebase demonstrates IR algorithms (PageRank, TF-IDF, Louvain clustering) |",
        "",
        "### Good Fit For Developers Who...",
        "",
        "- **Need explainable search** - Every result can be traced through the graph; see exactly why documents matched",
        "- **Want to avoid ML complexity** - No model training, GPU requirements, or hyperparameter tuning",
        "- **Work with specialized domains** - Corpus-derived semantics adapts to your terminology automatically",
        "- **Need lightweight deployment** - Single Python package, no Docker, no external services",
        "- **Value reproducibility** - Deterministic algorithms produce consistent results",
        "- **Build RAG pipelines** - First-class support for passage retrieval with configurable chunking",
        "",
        "### When NOT to Use",
        "",
        "| Scenario | Better Alternative |",
        "|----------|-------------------|",
        "| Need state-of-the-art semantic similarity | Use sentence transformers or OpenAI embeddings |",
        "| Processing millions of documents | Use Elasticsearch, Meilisearch, or vector databases |",
        "| Need real-time indexing at scale | Use purpose-built search infrastructure |",
        "| Require cross-lingual search | Use multilingual embedding models |",
        "| Need image/multimodal search | Use CLIP or similar multimodal models |",
        "",
        "### Example: Building a Documentation Search",
        "",
        "```python",
        "from cortical import CorticalTextProcessor",
        "import os",
        "",
        "# Initialize processor",
        "processor = CorticalTextProcessor()",
        "",
        "# Index your documentation",
        "for filename in os.listdir(\"docs/\"):",
        "    if filename.endswith(\".md\"):",
        "        with open(f\"docs/{filename}\") as f:",
        "            processor.process_document(filename, f.read())",
        "",
        "# Build the semantic network",
        "processor.compute_all(verbose=False)",
        "",
        "# Search with query expansion",
        "results = processor.find_documents_for_query(\"authentication setup\")",
        "# Finds docs about \"auth\", \"login\", \"credentials\" even if \"authentication\" isn't mentioned",
        "",
        "# Get relevant passages for RAG",
        "passages = processor.find_passages_for_query(\"how to configure OAuth\", top_n=3)",
        "for passage, score, doc_id in passages:",
        "    print(f\"[{doc_id}] {passage[:100]}...\")",
        "```",
        "",
        "### Example: Code Search with Intent",
        "",
        "```python",
        "from cortical import CorticalTextProcessor",
        "from cortical.tokenizer import Tokenizer",
        "import glob",
        "",
        "# Enable code-aware tokenization (splits getUserName ‚Üí get, user, name)",
        "code_tokenizer = Tokenizer(split_identifiers=True)",
        "processor = CorticalTextProcessor(tokenizer=code_tokenizer)",
        "",
        "# Index source files",
        "for filepath in glob.glob(\"src/**/*.py\", recursive=True):",
        "    with open(filepath) as f:",
        "        processor.process_document(filepath, f.read())",
        "",
        "processor.compute_all()",
        "",
        "# Intent-based search understands natural language questions",
        "results = processor.search_by_intent(\"where do we handle user authentication?\")",
        "# Returns files dealing with auth, login, session management",
        "",
        "# Code-specific query expansion",
        "expanded = processor.expand_query_for_code(\"fetch data\")",
        "# Expands to include: get, load, retrieve, request, download",
        "```",
        "",
        "Run the showcase to see the processor analyze 176 documents covering everything from neural networks to medieval falconry:"
      ],
      "lines_removed": [
        "Run the showcase to see the processor analyze 92 documents covering everything from neural networks to medieval falconry:"
      ],
      "context_before": [
        "- **Analogy Completion**: Relation matching and vector arithmetic for analogical reasoning",
        "- **Code Search**: Identifier splitting, programming concept expansion, and intent-based queries",
        "- **Semantic Fingerprinting**: Compare document similarity with explanations",
        "- **Fast Search**: Pre-built indexes for 2-3x faster repeated queries",
        "- **Incremental Updates**: Add documents without full recomputation",
        "- **Gap Detection**: Find weak spots and isolated documents in your corpus",
        "- **Query Expansion**: Smart retrieval with synonym handling and semantic relations",
        "- **RAG System Support**: Chunk-level passage retrieval, document metadata, and multi-stage ranking",
        "- **Zero Dependencies**: Pure Python, no pip installs required",
        ""
      ],
      "context_after": [
        "## Installation",
        "",
        "Install from source:",
        "",
        "```bash",
        "git clone <repository-url>",
        "cd cortical-text-processor",
        "pip install -e .",
        "```",
        "",
        "Or simply copy the `cortical/` directory into your project‚Äîzero dependencies means no pip required.",
        "",
        "## Quick Start",
        "",
        "",
        "```bash",
        "python showcase.py",
        "```",
        "",
        "**Output:**",
        "```",
        "    ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó",
        "    ‚ïë            üß†  CORTICAL TEXT PROCESSOR SHOWCASE  üß†                  ‚ïë",
        "    ‚ïë     Mimicking how the neocortex processes and understands text       ‚ïë"
      ],
      "change_type": "modify"
    },
    {
      "file": "README.md",
      "function": "processor.compute_all(",
      "start_line": 248,
      "lines_added": [
        "Tested with 176 sample documents covering topics from neural networks to medieval falconry to sourdough breadmaking.",
        "| Sample documents | 176 |",
        "| Test functions | 3,150+ |",
        "| Lines of code | 20,000+ |",
        "*Note: Token/bigram/connection counts vary based on corpus content.*",
        "",
        "‚îú‚îÄ‚îÄ __init__.py          # Public API exports",
        "‚îú‚îÄ‚îÄ processor/           # Main orchestrator (mixin-based architecture)",
        "‚îÇ   ‚îú‚îÄ‚îÄ __init__.py      # CorticalTextProcessor class composition",
        "‚îÇ   ‚îú‚îÄ‚îÄ core.py          # Initialization, staleness tracking (169 lines)",
        "‚îÇ   ‚îú‚îÄ‚îÄ documents.py     # Document add/remove/batch (456 lines)",
        "‚îÇ   ‚îú‚îÄ‚îÄ compute.py       # PageRank, TF-IDF, clustering (1041 lines)",
        "‚îÇ   ‚îú‚îÄ‚îÄ query_api.py     # Search, expansion, retrieval (719 lines)",
        "‚îÇ   ‚îú‚îÄ‚îÄ introspection.py # State inspection, summaries (357 lines)",
        "‚îÇ   ‚îî‚îÄ‚îÄ persistence_api.py # Save/load/export (245 lines)",
        "‚îú‚îÄ‚îÄ query/               # Search & retrieval (8 focused modules)",
        "‚îÇ   ‚îú‚îÄ‚îÄ expansion.py     # Query expansion (459 lines)",
        "‚îÇ   ‚îú‚îÄ‚îÄ search.py        # Document search (422 lines)",
        "‚îÇ   ‚îú‚îÄ‚îÄ ranking.py       # Multi-stage ranking (472 lines)",
        "‚îÇ   ‚îú‚îÄ‚îÄ passages.py      # RAG passage retrieval (407 lines)",
        "‚îÇ   ‚îú‚îÄ‚îÄ chunking.py      # Text chunking (335 lines)",
        "‚îÇ   ‚îú‚îÄ‚îÄ intent.py        # Intent-based queries (220 lines)",
        "‚îÇ   ‚îú‚îÄ‚îÄ definitions.py   # Definition search (375 lines)",
        "‚îÇ   ‚îî‚îÄ‚îÄ analogy.py       # Analogy completion (330 lines)",
        "‚îú‚îÄ‚îÄ analysis.py          # Graph algorithms: PageRank, TF-IDF, Louvain",
        "‚îú‚îÄ‚îÄ semantics.py         # Relation extraction, inference, retrofitting",
        "‚îú‚îÄ‚îÄ minicolumn.py        # Core data structure with typed edges",
        "‚îú‚îÄ‚îÄ layers.py            # Hierarchical layers with O(1) lookups",
        "‚îú‚îÄ‚îÄ tokenizer.py         # Tokenization, stemming, code splitting",
        "‚îú‚îÄ‚îÄ embeddings.py        # Graph embeddings with retrofitting",
        "‚îú‚îÄ‚îÄ fingerprint.py       # Semantic fingerprinting",
        "‚îú‚îÄ‚îÄ gaps.py              # Gap detection and anomalies",
        "‚îú‚îÄ‚îÄ persistence.py       # Save/load with full state",
        "‚îú‚îÄ‚îÄ config.py            # CorticalConfig with validation",
        "‚îú‚îÄ‚îÄ observability.py     # Metrics, timing, tracing",
        "‚îî‚îÄ‚îÄ code_concepts.py     # Programming synonym expansion",
        "",
        "tests/                   # 2900+ tests (smoke, unit, integration, behavioral)",
        "‚îú‚îÄ‚îÄ smoke/               # Quick sanity checks",
        "‚îú‚îÄ‚îÄ unit/                # Fast isolated tests",
        "‚îú‚îÄ‚îÄ integration/         # Component interaction tests",
        "‚îú‚îÄ‚îÄ performance/         # Timing regression tests",
        "‚îî‚îÄ‚îÄ behavioral/          # Search quality tests",
        "",
        "showcase.py              # Interactive demonstration (run it!)",
        "samples/                 # 176 documents: quantum computing to cheese affinage",
        "scripts/                 # Developer tools (indexing, profiling, tasks)",
        "cat cortical/processor/__init__.py.ai_meta",
        "cat cortical/query/search.py.ai_meta",
        "Four Claude Code skills are available in `.claude/skills/`:",
        "| `task-manager` | Manage tasks with merge-friendly IDs |",
        "## Text-as-Memories System",
        "",
        "Capture and organize institutional knowledge alongside your code:",
        "",
        "- **Daily Memories** (`samples/memories/YYYY-MM-DD-*.md`) - Learning entries",
        "- **Decision Records** (`samples/decisions/adr-*.md`) - Architectural decisions",
        "- **Concept Documents** - Consolidated knowledge on topics",
        "",
        "```bash",
        "# Create a memory entry",
        "python scripts/new_memory.py \"What I learned about validation\"",
        "",
        "# Create a decision record",
        "python scripts/new_memory.py \"Use JSON over pickle\" --decision",
        "```",
        "",
        "See [docs/text-as-memories.md](docs/text-as-memories.md) for the complete guide.",
        "",
        "The showcase processes 176 diverse sample documents and demonstrates every major feature. Here's what you'll see:"
      ],
      "lines_removed": [
        "Tested with 92 sample documents covering topics from neural networks to medieval falconry to sourdough breadmaking.",
        "| Documents processed | 92 |",
        "| Token minicolumns | 6,506 |",
        "| Bigram minicolumns | 20,114 |",
        "| Lateral connections | 116,332 |",
        "| Test coverage | 337 tests passing |",
        "‚îú‚îÄ‚îÄ __init__.py      # Public API (v2.0.0)",
        "‚îú‚îÄ‚îÄ processor.py     # Main orchestrator",
        "‚îú‚îÄ‚îÄ tokenizer.py     # Tokenization + stemming",
        "‚îú‚îÄ‚îÄ minicolumn.py    # Core data structure with typed edges",
        "‚îú‚îÄ‚îÄ layers.py        # Hierarchical layers with O(1) lookups",
        "‚îú‚îÄ‚îÄ analysis.py      # PageRank, TF-IDF, cross-layer propagation",
        "‚îú‚îÄ‚îÄ semantics.py     # Semantic extraction, inference, analogy",
        "‚îú‚îÄ‚îÄ embeddings.py    # Graph embeddings with retrofitting",
        "‚îú‚îÄ‚îÄ query.py         # Search, retrieval, batch processing",
        "‚îú‚îÄ‚îÄ gaps.py          # Gap detection and anomalies",
        "‚îî‚îÄ‚îÄ persistence.py   # Save/load with full state",
        "",
        "evaluation/",
        "‚îî‚îÄ‚îÄ evaluator.py     # Evaluation framework",
        "",
        "tests/               # 337 comprehensive tests",
        "showcase.py          # Interactive demonstration (run it!)",
        "samples/             # 92 documents: from quantum computing to cheese affinage",
        "cat cortical/processor.py.ai_meta",
        "Three Claude Code skills are available in `.claude/skills/`:",
        "The showcase processes 92 diverse sample documents and demonstrates every major feature. Here's what you'll see:"
      ],
      "context_before": [
        "",
        "| Strategy | Description |",
        "|----------|-------------|",
        "| `document_overlap` | Traditional Jaccard similarity (default) |",
        "| `semantic` | Connect via semantic relations between members |",
        "| `embedding` | Connect via embedding centroid similarity |",
        "| `hybrid` | Combine all three for maximum connectivity |",
        "",
        "## Performance",
        ""
      ],
      "context_after": [
        "",
        "| Metric | Value |",
        "|--------|-------|",
        "| Graph algorithms | O(1) ID lookups |",
        "",
        "**What the processor discovers:**",
        "- Most central concept: `data` (PageRank: 0.0046)",
        "- Most distinctive terms: `gradient`, `pagerank`, `patent` (high TF-IDF, rare but meaningful)",
        "- Most connected document: `comprehensive_machine_learning` (91 connections to other docs)",
        "- Isolated outliers detected: `sumo_wrestling`, `medieval_falconry` (low similarity to corpus)",
        "",
        "## Package Structure",
        "",
        "```",
        "cortical/",
        "```",
        "",
        "## AI Agent Support",
        "",
        "This project includes tools designed specifically for AI coding assistants:",
        "",
        "### AI Metadata Files (`.ai_meta`)",
        "",
        "Pre-generated metadata files provide structured navigation for AI agents:",
        "",
        "```bash",
        "# Generate metadata for rapid module understanding",
        "python scripts/generate_ai_metadata.py",
        "",
        "# View a module's structure without reading source",
        "```",
        "",
        "**What metadata provides:**",
        "- Function signatures with `see_also` cross-references",
        "- Class structures with inheritance",
        "- Complexity hints for expensive operations",
        "- Logical section groupings",
        "",
        "### Claude Skills",
        "",
        "",
        "| Skill | Purpose |",
        "|-------|---------|",
        "| `codebase-search` | Semantic search over the codebase |",
        "| `corpus-indexer` | Index/re-index after code changes |",
        "| `ai-metadata` | View and use module metadata |",
        "",
        "### For AI Agents",
        "",
        "See the **AI Agent Onboarding** section in [CLAUDE.md](CLAUDE.md) for:",
        "- Step-by-step setup guide",
        "- Navigation tips for efficient exploration",
        "- Example workflow using metadata",
        "",
        "## Development History",
        "",
        "This project evolved through systematic improvements:",
        "",
        "1. **Initial Release**: Core hierarchical text processing",
        "2. **Code Review & Fixes**: TF-IDF calculation, O(1) lookups, type annotations",
        "3. **RAG Enhancements**: Chunk-level retrieval, metadata support, concept clustering",
        "4. **ConceptNet Integration**: Typed edges, relation-weighted PageRank, multi-hop inference",
        "5. **Connection Strategies**: Multiple strategies for Layer 2 concept connections",
        "6. **Showcase & Polish**: Interactive demo with real corpus analysis",
        "",
        "## Running the Showcase",
        "",
        "```bash",
        "python showcase.py",
        "```",
        "",
        "",
        "### Concept Associations (Hebbian Learning)",
        "",
        "The processor discovers that `neural` connects to `networks` (weight: 23), `artificial` (7), `knowledge` (7)‚Äîwhile `bread` meekly connects to `beer`, `wine`, and `pyruvate` (weight: 1 each). Neurons that fire together really do wire together.",
        "",
        "### Query Expansion in Action",
        "",
        "```",
        "üîç Query: 'neural networks'",
        "   Expanded with: knowledge, data, graph, network, deep, artificial"
      ],
      "change_type": "modify"
    },
    {
      "file": "README.md",
      "function": "python -m unittest discover -s tests -v",
      "start_line": 428,
      "lines_added": [
        "## Roadmap",
        "",
        "### Current Focus (v2.x)",
        "- [ ] Remove deprecated `feedforward_sources` field (migrate to `feedforward_connections`)",
        "- [ ] Reduce checkpoint handling code duplication in `compute.py`",
        "- [ ] Standardize layer variable naming (semantic names vs `layer0`, `layer1`)",
        "- [ ] Move magic numbers to `CorticalConfig`",
        "",
        "### Planned Features (v3.x)",
        "- [ ] **Streaming document processing** - Process large documents in chunks without loading entirely into memory",
        "- [ ] **Incremental clustering** - Update concept clusters without full recomputation",
        "- [ ] **Query result explanations** - Human-readable explanations for why documents matched",
        "- [ ] **Export to NetworkX** - Direct graph export for visualization and analysis",
        "- [ ] **Async API** - Async versions of compute-heavy methods",
        "",
        "### Under Consideration",
        "- [ ] **Optional sentence-transformers integration** - Hybrid retrieval combining graph + embeddings",
        "- [ ] **WASM build** - Run in browser via WebAssembly",
        "- [ ] **REST API wrapper** - Simple HTTP server for non-Python clients",
        "- [ ] **Multi-corpus federation** - Query across multiple independent corpora",
        "",
        "### Not Planned",
        "- Cloud/SaaS dependencies (against zero-dependency philosophy)",
        "- GPU acceleration (keep it simple and portable)",
        "- Real-time collaborative editing (out of scope)",
        "",
        "See [CODE_REVIEW.md](CODE_REVIEW.md) for technical debt and improvement opportunities.",
        "",
        "---",
        "",
        "## Fact Check",
        "",
        "*Last verified: 2025-12-15 | Score: 94% accurate*",
        "",
        "| Claim | Status | Notes |",
        "|-------|--------|-------|",
        "| Zero external dependencies | ‚úÖ Verified | Production code uses only stdlib |",
        "| 3,150+ tests | ‚úÖ Verified | `grep -r \"def test_\" tests/ \\| wc -l` = 3,150 |",
        "| 20,000+ lines of code | ‚úÖ Verified | `wc -l cortical/**/*.py` = 20,245 |",
        "| 176 sample documents | ‚úÖ Verified | `ls samples/*.txt \\| wc -l` = 176 |",
        "| >89% coverage | ‚ö†Ô∏è Unverified | Requires test run to confirm |",
        "| O(1) ID lookups | ‚úÖ Verified | `_id_index` dict in `layers.py` |",
        "| `split_identifiers` tokenization | ‚úÖ Verified | In `Tokenizer` class, not processor |",
        "| Package structure line counts | ‚úÖ Verified | All counts match actual files |",
        "| All documented methods exist | ‚úÖ Verified | Grep confirms all API methods |",
        "| `sumo_wrestling.txt` exists | ‚úÖ Verified | Present in samples/ |",
        "| `medieval_falconry.txt` exists | ‚úÖ Verified | Present in samples/ |",
        "",
        "**Methodology:** Claims verified by running shell commands against the codebase. Dynamic values (PageRank scores, connection counts) depend on corpus content and are representative examples.",
        "",
        "---",
        "",
        "## Contributing",
        "",
        "We welcome contributions! Please see [CONTRIBUTING.md](CONTRIBUTING.md) for:",
        "- Development setup and workflow",
        "- Code style and testing requirements",
        "- Pull request guidelines",
        "",
        "Quality resources:",
        "- [Definition of Done](docs/definition-of-done.md)",
        "- [Code of Ethics](docs/code-of-ethics.md)",
        ""
      ],
      "lines_removed": [],
      "context_before": [
        "   ```",
        "",
        "3. **For maximum security**: Never load pickle files from:",
        "   - Downloaded files from the internet",
        "   - User uploads",
        "   - Shared network locations with untrusted access",
        "   - Email attachments",
        "",
        "See [Python's pickle documentation](https://docs.python.org/3/library/pickle.html) for more details on pickle security.",
        ""
      ],
      "context_after": [
        "## License",
        "",
        "MIT License"
      ],
      "change_type": "add"
    },
    {
      "file": "benchmarks/BASELINE_SUMMARY.md",
      "function": null,
      "start_line": 0,
      "lines_added": [
        "# Scoring Algorithm Performance Comparison",
        "",
        "**Date:** 2025-12-15",
        "**Algorithms Compared:** TF-IDF vs BM25",
        "**Default Algorithm:** BM25 (as of this commit)",
        "",
        "## Executive Summary",
        "",
        "### TF-IDF vs BM25 Comparison",
        "",
        "| Metric | TF-IDF | BM25 | Change |",
        "|--------|--------|------|--------|",
        "| Score Computation (100 docs) | 0.72ms | 1.26ms | +75% |",
        "| Search Latency | 0.15ms | 0.15ms | +0.8% |",
        "| Mean P@3 | 0.75 | 0.75 | 0% |",
        "| Mean MRR | 0.78 | 0.78 | 0% |",
        "| Scaling Complexity | O(n) | O(n) | Same |",
        "",
        "### Key Findings",
        "",
        "1. **BM25 computation is ~60-90% slower** than TF-IDF due to length normalization overhead",
        "2. **Search latency is virtually identical** (< 1% difference)",
        "3. **Relevance metrics are the same** on the synthetic corpus (uniform document lengths)",
        "4. **Both algorithms scale linearly** with corpus size",
        "",
        "### Why Use BM25 Despite Slower Computation?",
        "",
        "1. **Term frequency saturation**: Prevents single repeated terms from dominating scores",
        "2. **Length normalization**: Fair comparison across documents of different sizes",
        "3. **Industry standard**: Used by Elasticsearch, Lucene, and most modern search engines",
        "4. **Real-world relevance**: Benefits appear with variable document lengths",
        "",
        "## Detailed Benchmarks",
        "",
        "### Score Computation Time",
        "",
        "| Corpus Size | TF-IDF (ms) | BM25 (ms) | Overhead |",
        "|-------------|-------------|-----------|----------|",
        "| 25 docs | 0.20 | 0.33 | +65% |",
        "| 50 docs | 0.38 | 0.62 | +63% |",
        "| 100 docs | 0.72 | 1.26 | +75% |",
        "| 200 docs | 1.42 | 2.73 | +92% |",
        "| **Real (150 docs)** | **16.3** | **25.6** | **+57%** |",
        "",
        "**Note:** The overhead comes from the length normalization calculation in BM25.",
        "",
        "### Search Query Latency",
        "",
        "Both algorithms have nearly identical search latency:",
        "",
        "| Algorithm | Mean Latency | Throughput |",
        "|-----------|--------------|------------|",
        "| TF-IDF | 0.15ms | 6,507 QPS |",
        "| BM25 | 0.15ms | 6,374 QPS |",
        "",
        "Search uses pre-computed scores, so the algorithm choice doesn't affect query time.",
        "",
        "### Search Relevance Quality",
        "",
        "On the synthetic corpus (uniform document lengths):",
        "",
        "| Metric | TF-IDF | BM25 |",
        "|--------|--------|------|",
        "| Mean P@1 | 0.75 | 0.75 |",
        "| Mean P@3 | 0.75 | 0.75 |",
        "| Mean MRR | 0.78 | 0.78 |",
        "| Term Recall | 0.80 | 0.80 |",
        "",
        "**Note:** Relevance is identical on synthetic corpus because documents have uniform lengths. BM25's benefits appear with variable document lengths.",
        "",
        "### Memory Footprint",
        "",
        "| Corpus Size | TF-IDF (KB) | BM25 (KB) |",
        "|-------------|-------------|-----------|",
        "| 100 docs | 193.7 | 193.8 |",
        "| 200 docs | 398.6 | 398.7 |",
        "",
        "Memory usage is essentially identical. The doc_lengths dictionary adds negligible overhead.",
        "",
        "### Scaling Behavior",
        "",
        "| Algorithm | Scaling Exponent | Complexity |",
        "|-----------|-----------------|------------|",
        "| TF-IDF | 0.94 | O(n) |",
        "| BM25 | 0.96 | O(n) |",
        "",
        "Both algorithms maintain linear scaling with corpus size.",
        "",
        "## Configuration",
        "",
        "BM25 is now the default. To switch algorithms:",
        "",
        "```python",
        "from cortical import CorticalTextProcessor",
        "from cortical.config import CorticalConfig",
        "",
        "# Use BM25 (default)",
        "processor = CorticalTextProcessor()",
        "",
        "# Use TF-IDF",
        "config = CorticalConfig(scoring_algorithm='tfidf')",
        "processor = CorticalTextProcessor(config=config)",
        "",
        "# Tune BM25 parameters",
        "config = CorticalConfig(",
        "    scoring_algorithm='bm25',",
        "    bm25_k1=1.5,  # Term frequency saturation (default: 1.2)",
        "    bm25_b=0.75   # Length normalization (default: 0.75)",
        ")",
        "```",
        "",
        "### BM25 Parameters",
        "",
        "| Parameter | Default | Range | Effect |",
        "|-----------|---------|-------|--------|",
        "| `bm25_k1` | 1.2 | 0-3 | Term frequency saturation. Higher = more weight to term frequency |",
        "| `bm25_b` | 0.75 | 0-1 | Length normalization. 0 = none, 1 = full |",
        "",
        "## Files",
        "",
        "- `baseline_tfidf.json` - TF-IDF benchmark results",
        "- `baseline_tfidf_real.json` - TF-IDF real corpus results",
        "- `after_bm25.json` - BM25 benchmark results",
        "",
        "## How to Run Benchmarks",
        "",
        "```bash",
        "# Run with current default algorithm (BM25)",
        "python scripts/benchmark_scoring.py --output benchmarks/current.json",
        "",
        "# Run with specific algorithm",
        "python scripts/benchmark_scoring.py --algorithm tfidf --output benchmarks/tfidf.json",
        "python scripts/benchmark_scoring.py --algorithm bm25 --output benchmarks/bm25.json",
        "",
        "# Compare two benchmark runs",
        "python scripts/benchmark_scoring.py --compare benchmarks/baseline_tfidf.json benchmarks/after_bm25.json",
        "```",
        "",
        "## Implementation Notes",
        "",
        "### What Changed",
        "",
        "1. **config.py**: Added `scoring_algorithm`, `bm25_k1`, `bm25_b` parameters",
        "2. **analysis.py**: Added `compute_bm25()` and `_bm25_core()` functions",
        "3. **processor/core.py**: Added `doc_lengths` and `avg_doc_length` tracking",
        "4. **processor/documents.py**: Track document lengths during processing",
        "5. **processor/compute.py**: `compute_tfidf()` now respects `scoring_algorithm` config",
        "6. **processor/persistence_api.py**: Save/restore document lengths",
        "",
        "### BM25 Formula",
        "",
        "```",
        "BM25(t, d) = IDF(t) √ó (tf(t,d) √ó (k1 + 1)) / (tf(t,d) + k1 √ó (1 - b + b √ó |d|/avgdl))",
        "",
        "Where:",
        "- IDF(t) = log((N - df + 0.5) / (df + 0.5) + 1)",
        "- tf(t,d) = term frequency in document",
        "- |d| = document length (in tokens)",
        "- avgdl = average document length",
        "- k1 = term frequency saturation parameter",
        "- b = length normalization parameter",
        "```",
        "",
        "### Backward Compatibility",
        "",
        "- Scores are stored in the same `col.tfidf` and `col.tfidf_per_doc` fields",
        "- All existing search functions work unchanged",
        "- Old pickle files are compatible (doc_lengths are recomputed on load)"
      ],
      "lines_removed": [],
      "context_before": [],
      "context_after": [],
      "change_type": "add"
    },
    {
      "file": "benchmarks/after_bm25.json",
      "function": null,
      "start_line": 0,
      "lines_added": [
        "{",
        "  \"version\": \"1.0\",",
        "  \"algorithm\": \"bm25\",",
        "  \"timestamp\": \"2025-12-15T04:45:14.336647\",",
        "  \"system_info\": {",
        "    \"python_version\": \"3.11.14\",",
        "    \"platform\": \"Linux-4.4.0-x86_64-with-glibc2.39\",",
        "    \"processor\": \"x86_64\"",
        "  },",
        "  \"results\": [",
        "    {",
        "      \"name\": \"compute_scores\",",
        "      \"algorithm\": \"bm25\",",
        "      \"timestamp\": \"2025-12-15T04:45:14.406581\",",
        "      \"corpus_size\": 25,",
        "      \"vocabulary_size\": 64,",
        "      \"metrics\": {",
        "        \"corpus_size\": 25,",
        "        \"vocabulary_size\": 64,",
        "        \"mean_time_ms\": 0.3291995999688879,",
        "        \"std_time_ms\": 0.020515947884730667,",
        "        \"min_time_ms\": 0.31208699999751843,",
        "        \"max_time_ms\": 0.3623689999585622,",
        "        \"time_per_doc_ms\": 0.013167983998755517,",
        "        \"time_per_term_us\": 5.143743749513874",
        "      }",
        "    },",
        "    {",
        "      \"name\": \"compute_scores\",",
        "      \"algorithm\": \"bm25\",",
        "      \"timestamp\": \"2025-12-15T04:45:14.507138\",",
        "      \"corpus_size\": 50,",
        "      \"vocabulary_size\": 64,",
        "      \"metrics\": {",
        "        \"corpus_size\": 50,",
        "        \"vocabulary_size\": 64,",
        "        \"mean_time_ms\": 0.6236895999791159,",
        "        \"std_time_ms\": 0.009425228295778567,",
        "        \"min_time_ms\": 0.6114489999617945,",
        "        \"max_time_ms\": 0.6329369999775736,",
        "        \"time_per_doc_ms\": 0.012473791999582318,",
        "        \"time_per_term_us\": 9.745149999673686",
        "      }",
        "    },",
        "    {",
        "      \"name\": \"compute_scores\",",
        "      \"algorithm\": \"bm25\",",
        "      \"timestamp\": \"2025-12-15T04:45:14.693444\",",
        "      \"corpus_size\": 100,",
        "      \"vocabulary_size\": 64,",
        "      \"metrics\": {",
        "        \"corpus_size\": 100,",
        "        \"vocabulary_size\": 64,",
        "        \"mean_time_ms\": 1.2571063999757826,",
        "        \"std_time_ms\": 0.04260392122155854,",
        "        \"min_time_ms\": 1.2077509999244285,",
        "        \"max_time_ms\": 1.3081880000527235,",
        "        \"time_per_doc_ms\": 0.012571063999757826,",
        "        \"time_per_term_us\": 19.642287499621602",
        "      }",
        "    },",
        "    {",
        "      \"name\": \"compute_scores\",",
        "      \"algorithm\": \"bm25\",",
        "      \"timestamp\": \"2025-12-15T04:45:15.054362\",",
        "      \"corpus_size\": 200,",
        "      \"vocabulary_size\": 64,",
        "      \"metrics\": {",
        "        \"corpus_size\": 200,",
        "        \"vocabulary_size\": 64,",
        "        \"mean_time_ms\": 2.7318268000044554,",
        "        \"std_time_ms\": 0.38535747660282266,",
        "        \"min_time_ms\": 2.4955750000117405,",
        "        \"max_time_ms\": 3.4158199999865246,",
        "        \"time_per_doc_ms\": 0.013659134000022277,",
        "        \"time_per_term_us\": 42.684793750069616",
        "      }",
        "    },",
        "    {",
        "      \"name\": \"search_latency\",",
        "      \"algorithm\": \"bm25\",",
        "      \"timestamp\": \"2025-12-15T04:45:16.118779\",",
        "      \"corpus_size\": 100,",
        "      \"vocabulary_size\": 64,",
        "      \"metrics\": {",
        "        \"corpus_size\": 100,",
        "        \"vocabulary_size\": 64,",
        "        \"num_queries\": 8,",
        "        \"mean_latency_ms\": 0.15497148750540646,",
        "        \"median_latency_ms\": 0.1494892500033984,",
        "        \"p95_latency_ms\": 0.18840760000102819,",
        "        \"max_latency_ms\": 0.18840760000102819,",
        "        \"min_latency_ms\": 0.14132020000943157,",
        "        \"throughput_qps\": 6452.799905951171",
        "      }",
        "    },",
        "    {",
        "      \"name\": \"search_relevance\",",
        "      \"algorithm\": \"bm25\",",
        "      \"timestamp\": \"2025-12-15T04:45:17.204662\",",
        "      \"corpus_size\": 100,",
        "      \"vocabulary_size\": 64,",
        "      \"metrics\": {",
        "        \"corpus_size\": 100,",
        "        \"num_queries\": 4,",
        "        \"mean_p@1\": 0.75,",
        "        \"mean_p@3\": 0.75,",
        "        \"mean_p@5\": 0.75,",
        "        \"mean_mrr\": 0.7777777777777778,",
        "        \"mean_term_recall\": 0.8,",
        "        \"per_query\": [",
        "          {",
        "            \"query\": \"neural network training\",",
        "            \"domain\": \"ml\",",
        "            \"p@1\": 0.0,",
        "            \"p@3\": 0.0,",
        "            \"p@5\": 0.0,",
        "            \"mrr\": 0.1111111111111111,",
        "            \"term_recall\": 0.8",
        "          },",
        "          {",
        "            \"query\": \"database query optimization\",",
        "            \"domain\": \"db\",",
        "            \"p@1\": 1.0,",
        "            \"p@3\": 1.0,",
        "            \"p@5\": 1.0,",
        "            \"mrr\": 1.0,",
        "            \"term_recall\": 0.8",
        "          },",
        "          {",
        "            \"query\": \"process memory management\",",
        "            \"domain\": \"sys\",",
        "            \"p@1\": 1.0,",
        "            \"p@3\": 1.0,",
        "            \"p@5\": 1.0,",
        "            \"mrr\": 1.0,",
        "            \"term_recall\": 0.8",
        "          },",
        "          {",
        "            \"query\": \"api authentication\",",
        "            \"domain\": \"web\",",
        "            \"p@1\": 1.0,",
        "            \"p@3\": 1.0,",
        "            \"p@5\": 1.0,",
        "            \"mrr\": 1.0,",
        "            \"term_recall\": 0.8",
        "          }",
        "        ]",
        "      }",
        "    },",
        "    {",
        "      \"name\": \"memory_footprint\",",
        "      \"algorithm\": \"bm25\",",
        "      \"timestamp\": \"2025-12-15T04:45:17.481222\",",
        "      \"corpus_size\": 25,",
        "      \"vocabulary_size\": 64,",
        "      \"metrics\": {",
        "        \"corpus_size\": 25,",
        "        \"vocabulary_size\": 64,",
        "        \"score_memory_bytes\": 53184,",
        "        \"score_memory_kb\": 51.9375,",
        "        \"total_tfidf_entries\": 995,",
        "        \"bytes_per_entry\": 53.451256281407034,",
        "        \"bytes_per_term\": 831.0",
        "      }",
        "    },",
        "    {",
        "      \"name\": \"memory_footprint\",",
        "      \"algorithm\": \"bm25\",",
        "      \"timestamp\": \"2025-12-15T04:45:17.967628\",",
        "      \"corpus_size\": 50,",
        "      \"vocabulary_size\": 64,",
        "      \"metrics\": {",
        "        \"corpus_size\": 50,",
        "        \"vocabulary_size\": 64,",
        "        \"score_memory_bytes\": 101568,",
        "        \"score_memory_kb\": 99.1875,",
        "        \"total_tfidf_entries\": 1988,",
        "        \"bytes_per_entry\": 51.09054325955734,",
        "        \"bytes_per_term\": 1587.0",
        "      }",
        "    },",
        "    {",
        "      \"name\": \"memory_footprint\",",
        "      \"algorithm\": \"bm25\",",
        "      \"timestamp\": \"2025-12-15T04:45:18.912447\",",
        "      \"corpus_size\": 100,",
        "      \"vocabulary_size\": 64,",
        "      \"metrics\": {",
        "        \"corpus_size\": 100,",
        "        \"vocabulary_size\": 64,",
        "        \"score_memory_bytes\": 198432,",
        "        \"score_memory_kb\": 193.78125,",
        "        \"total_tfidf_entries\": 4010,",
        "        \"bytes_per_entry\": 49.48428927680798,",
        "        \"bytes_per_term\": 3100.5",
        "      }",
        "    },",
        "    {",
        "      \"name\": \"memory_footprint\",",
        "      \"algorithm\": \"bm25\",",
        "      \"timestamp\": \"2025-12-15T04:45:20.819995\",",
        "      \"corpus_size\": 200,",
        "      \"vocabulary_size\": 64,",
        "      \"metrics\": {",
        "        \"corpus_size\": 200,",
        "        \"vocabulary_size\": 64,",
        "        \"score_memory_bytes\": 408312,",
        "        \"score_memory_kb\": 398.7421875,",
        "        \"total_tfidf_entries\": 8043,",
        "        \"bytes_per_entry\": 50.76613204028347,",
        "        \"bytes_per_term\": 6379.875",
        "      }",
        "    },",
        "    {",
        "      \"name\": \"scaling_behavior\",",
        "      \"algorithm\": \"bm25\",",
        "      \"timestamp\": \"2025-12-15T04:45:21.684457\",",
        "      \"corpus_size\": 200,",
        "      \"vocabulary_size\": 64,",
        "      \"metrics\": {",
        "        \"data_points\": [",
        "          {",
        "            \"n_docs\": 10,",
        "            \"vocab_size\": 64,",
        "            \"time_ms\": 0.14531600004374923",
        "          },",
        "          {",
        "            \"n_docs\": 25,",
        "            \"vocab_size\": 64,",
        "            \"time_ms\": 0.309473666637435",
        "          },",
        "          {",
        "            \"n_docs\": 50,",
        "            \"vocab_size\": 64,",
        "            \"time_ms\": 0.5840006666251915",
        "          },",
        "          {",
        "            \"n_docs\": 100,",
        "            \"vocab_size\": 64,",
        "            \"time_ms\": 1.267608999986199",
        "          },",
        "          {",
        "            \"n_docs\": 150,",
        "            \"vocab_size\": 64,",
        "            \"time_ms\": 1.775815666633207",
        "          },",
        "          {",
        "            \"n_docs\": 200,",
        "            \"vocab_size\": 64,",
        "            \"time_ms\": 2.5024700000055113",
        "          }",
        "        ],",
        "        \"scaling_exponent\": 0.9558648590683401,",
        "        \"estimated_complexity\": \"O(n)\"",
        "      }",
        "    },",
        "    {",
        "      \"name\": \"real_corpus\",",
        "      \"algorithm\": \"bm25\",",
        "      \"timestamp\": \"2025-12-15T04:45:26.225935\",",
        "      \"corpus_size\": 150,",
        "      \"vocabulary_size\": 11862,",
        "      \"metrics\": {",
        "        \"corpus_size\": 150,",
        "        \"vocabulary_size\": 11862,",
        "        \"compute_time_ms\": 25.580323666683096,",
        "        \"mean_query_time_ms\": 0.37774209999383856,",
        "        \"max_query_time_ms\": 0.5424007999863534,",
        "        \"queries_tested\": 8",
        "      }",
        "    }",
        "  ]",
        "}"
      ],
      "lines_removed": [],
      "context_before": [],
      "context_after": [],
      "change_type": "add"
    },
    {
      "file": "benchmarks/baseline_tfidf.json",
      "function": null,
      "start_line": 0,
      "lines_added": [
        "{",
        "  \"version\": \"1.0\",",
        "  \"algorithm\": \"tfidf\",",
        "  \"timestamp\": \"2025-12-15T04:17:28.406343\",",
        "  \"system_info\": {",
        "    \"python_version\": \"3.11.14\",",
        "    \"platform\": \"Linux-4.4.0-x86_64-with-glibc2.39\",",
        "    \"processor\": \"x86_64\"",
        "  },",
        "  \"results\": [",
        "    {",
        "      \"name\": \"compute_scores\",",
        "      \"algorithm\": \"tfidf\",",
        "      \"timestamp\": \"2025-12-15T04:17:28.472214\",",
        "      \"corpus_size\": 25,",
        "      \"vocabulary_size\": 64,",
        "      \"metrics\": {",
        "        \"corpus_size\": 25,",
        "        \"vocabulary_size\": 64,",
        "        \"mean_time_ms\": 0.20012960000030944,",
        "        \"std_time_ms\": 0.018232865339288584,",
        "        \"min_time_ms\": 0.18339399997557848,",
        "        \"max_time_ms\": 0.22034799997072696,",
        "        \"time_per_doc_ms\": 0.008005184000012378,",
        "        \"time_per_term_us\": 3.127025000004835",
        "      }",
        "    },",
        "    {",
        "      \"name\": \"compute_scores\",",
        "      \"algorithm\": \"tfidf\",",
        "      \"timestamp\": \"2025-12-15T04:17:28.565169\",",
        "      \"corpus_size\": 50,",
        "      \"vocabulary_size\": 64,",
        "      \"metrics\": {",
        "        \"corpus_size\": 50,",
        "        \"vocabulary_size\": 64,",
        "        \"mean_time_ms\": 0.38337980001870164,",
        "        \"std_time_ms\": 0.010113204743546902,",
        "        \"min_time_ms\": 0.3726560000245627,",
        "        \"max_time_ms\": 0.39955299996563554,",
        "        \"time_per_doc_ms\": 0.007667596000374033,",
        "        \"time_per_term_us\": 5.990309375292213",
        "      }",
        "    },",
        "    {",
        "      \"name\": \"compute_scores\",",
        "      \"algorithm\": \"tfidf\",",
        "      \"timestamp\": \"2025-12-15T04:17:28.736963\",",
        "      \"corpus_size\": 100,",
        "      \"vocabulary_size\": 64,",
        "      \"metrics\": {",
        "        \"corpus_size\": 100,",
        "        \"vocabulary_size\": 64,",
        "        \"mean_time_ms\": 0.7150193999791554,",
        "        \"std_time_ms\": 0.01533470549806313,",
        "        \"min_time_ms\": 0.6907419999606645,",
        "        \"max_time_ms\": 0.7290339999599382,",
        "        \"time_per_doc_ms\": 0.007150193999791554,",
        "        \"time_per_term_us\": 11.172178124674303",
        "      }",
        "    },",
        "    {",
        "      \"name\": \"compute_scores\",",
        "      \"algorithm\": \"tfidf\",",
        "      \"timestamp\": \"2025-12-15T04:17:29.081526\",",
        "      \"corpus_size\": 200,",
        "      \"vocabulary_size\": 64,",
        "      \"metrics\": {",
        "        \"corpus_size\": 200,",
        "        \"vocabulary_size\": 64,",
        "        \"mean_time_ms\": 1.4186690000087765,",
        "        \"std_time_ms\": 0.05244864629302831,",
        "        \"min_time_ms\": 1.360104000013962,",
        "        \"max_time_ms\": 1.486779000003935,",
        "        \"time_per_doc_ms\": 0.0070933450000438825,",
        "        \"time_per_term_us\": 22.166703125137133",
        "      }",
        "    },",
        "    {",
        "      \"name\": \"search_latency\",",
        "      \"algorithm\": \"tfidf\",",
        "      \"timestamp\": \"2025-12-15T04:17:30.094282\",",
        "      \"corpus_size\": 100,",
        "      \"vocabulary_size\": 64,",
        "      \"metrics\": {",
        "        \"corpus_size\": 100,",
        "        \"vocabulary_size\": 64,",
        "        \"num_queries\": 8,",
        "        \"mean_latency_ms\": 0.15369055000178378,",
        "        \"median_latency_ms\": 0.14959700000360954,",
        "        \"p95_latency_ms\": 0.17851069999892388,",
        "        \"max_latency_ms\": 0.17851069999892388,",
        "        \"min_latency_ms\": 0.14334240000266618,",
        "        \"throughput_qps\": 6506.580918530083",
        "      }",
        "    },",
        "    {",
        "      \"name\": \"search_relevance\",",
        "      \"algorithm\": \"tfidf\",",
        "      \"timestamp\": \"2025-12-15T04:17:31.080923\",",
        "      \"corpus_size\": 100,",
        "      \"vocabulary_size\": 64,",
        "      \"metrics\": {",
        "        \"corpus_size\": 100,",
        "        \"num_queries\": 4,",
        "        \"mean_p@1\": 0.75,",
        "        \"mean_p@3\": 0.75,",
        "        \"mean_p@5\": 0.75,",
        "        \"mean_mrr\": 0.7777777777777778,",
        "        \"mean_term_recall\": 0.8,",
        "        \"per_query\": [",
        "          {",
        "            \"query\": \"neural network training\",",
        "            \"domain\": \"ml\",",
        "            \"p@1\": 0.0,",
        "            \"p@3\": 0.0,",
        "            \"p@5\": 0.0,",
        "            \"mrr\": 0.1111111111111111,",
        "            \"term_recall\": 0.8",
        "          },",
        "          {",
        "            \"query\": \"database query optimization\",",
        "            \"domain\": \"db\",",
        "            \"p@1\": 1.0,",
        "            \"p@3\": 1.0,",
        "            \"p@5\": 1.0,",
        "            \"mrr\": 1.0,",
        "            \"term_recall\": 0.8",
        "          },",
        "          {",
        "            \"query\": \"process memory management\",",
        "            \"domain\": \"sys\",",
        "            \"p@1\": 1.0,",
        "            \"p@3\": 1.0,",
        "            \"p@5\": 1.0,",
        "            \"mrr\": 1.0,",
        "            \"term_recall\": 0.8",
        "          },",
        "          {",
        "            \"query\": \"api authentication\",",
        "            \"domain\": \"web\",",
        "            \"p@1\": 1.0,",
        "            \"p@3\": 1.0,",
        "            \"p@5\": 1.0,",
        "            \"mrr\": 1.0,",
        "            \"term_recall\": 0.8",
        "          }",
        "        ]",
        "      }",
        "    },",
        "    {",
        "      \"name\": \"memory_footprint\",",
        "      \"algorithm\": \"tfidf\",",
        "      \"timestamp\": \"2025-12-15T04:17:31.291935\",",
        "      \"corpus_size\": 25,",
        "      \"vocabulary_size\": 64,",
        "      \"metrics\": {",
        "        \"corpus_size\": 25,",
        "        \"vocabulary_size\": 64,",
        "        \"score_memory_bytes\": 53088,",
        "        \"score_memory_kb\": 51.84375,",
        "        \"total_tfidf_entries\": 995,",
        "        \"bytes_per_entry\": 53.35477386934674,",
        "        \"bytes_per_term\": 829.5",
        "      }",
        "    },",
        "    {",
        "      \"name\": \"memory_footprint\",",
        "      \"algorithm\": \"tfidf\",",
        "      \"timestamp\": \"2025-12-15T04:17:31.688317\",",
        "      \"corpus_size\": 50,",
        "      \"vocabulary_size\": 64,",
        "      \"metrics\": {",
        "        \"corpus_size\": 50,",
        "        \"vocabulary_size\": 64,",
        "        \"score_memory_bytes\": 101472,",
        "        \"score_memory_kb\": 99.09375,",
        "        \"total_tfidf_entries\": 1988,",
        "        \"bytes_per_entry\": 51.04225352112676,",
        "        \"bytes_per_term\": 1585.5",
        "      }",
        "    },",
        "    {",
        "      \"name\": \"memory_footprint\",",
        "      \"algorithm\": \"tfidf\",",
        "      \"timestamp\": \"2025-12-15T04:17:32.496817\",",
        "      \"corpus_size\": 100,",
        "      \"vocabulary_size\": 64,",
        "      \"metrics\": {",
        "        \"corpus_size\": 100,",
        "        \"vocabulary_size\": 64,",
        "        \"score_memory_bytes\": 198336,",
        "        \"score_memory_kb\": 193.6875,",
        "        \"total_tfidf_entries\": 4010,",
        "        \"bytes_per_entry\": 49.46034912718204,",
        "        \"bytes_per_term\": 3099.0",
        "      }",
        "    },",
        "    {",
        "      \"name\": \"memory_footprint\",",
        "      \"algorithm\": \"tfidf\",",
        "      \"timestamp\": \"2025-12-15T04:17:34.129549\",",
        "      \"corpus_size\": 200,",
        "      \"vocabulary_size\": 64,",
        "      \"metrics\": {",
        "        \"corpus_size\": 200,",
        "        \"vocabulary_size\": 64,",
        "        \"score_memory_bytes\": 408216,",
        "        \"score_memory_kb\": 398.6484375,",
        "        \"total_tfidf_entries\": 8043,",
        "        \"bytes_per_entry\": 50.75419619544946,",
        "        \"bytes_per_term\": 6378.375",
        "      }",
        "    },",
        "    {",
        "      \"name\": \"scaling_behavior\",",
        "      \"algorithm\": \"tfidf\",",
        "      \"timestamp\": \"2025-12-15T04:17:34.914271\",",
        "      \"corpus_size\": 200,",
        "      \"vocabulary_size\": 64,",
        "      \"metrics\": {",
        "        \"data_points\": [",
        "          {",
        "            \"n_docs\": 10,",
        "            \"vocab_size\": 64,",
        "            \"time_ms\": 0.0802899999901759",
        "          },",
        "          {",
        "            \"n_docs\": 25,",
        "            \"vocab_size\": 64,",
        "            \"time_ms\": 0.16422099997726036",
        "          },",
        "          {",
        "            \"n_docs\": 50,",
        "            \"vocab_size\": 64,",
        "            \"time_ms\": 0.3338203333100864",
        "          },",
        "          {",
        "            \"n_docs\": 100,",
        "            \"vocab_size\": 64,",
        "            \"time_ms\": 0.6225586666725272",
        "          },",
        "          {",
        "            \"n_docs\": 150,",
        "            \"vocab_size\": 64,",
        "            \"time_ms\": 0.986785666649818",
        "          },",
        "          {",
        "            \"n_docs\": 200,",
        "            \"vocab_size\": 64,",
        "            \"time_ms\": 1.2952903333219485",
        "          }",
        "        ],",
        "        \"scaling_exponent\": 0.9389157086150623,",
        "        \"estimated_complexity\": \"O(n)\"",
        "      }",
        "    }",
        "  ]",
        "}"
      ],
      "lines_removed": [],
      "context_before": [],
      "context_after": [],
      "change_type": "add"
    },
    {
      "file": "benchmarks/baseline_tfidf_real.json",
      "function": null,
      "start_line": 0,
      "lines_added": [
        "{",
        "  \"version\": \"1.0\",",
        "  \"algorithm\": \"tfidf\",",
        "  \"timestamp\": \"2025-12-15T04:18:12.435168\",",
        "  \"system_info\": {",
        "    \"python_version\": \"3.11.14\",",
        "    \"platform\": \"Linux-4.4.0-x86_64-with-glibc2.39\",",
        "    \"processor\": \"x86_64\"",
        "  },",
        "  \"results\": [",
        "    {",
        "      \"name\": \"real_corpus\",",
        "      \"algorithm\": \"tfidf\",",
        "      \"timestamp\": \"2025-12-15T04:18:16.392542\",",
        "      \"corpus_size\": 150,",
        "      \"vocabulary_size\": 11862,",
        "      \"metrics\": {",
        "        \"corpus_size\": 150,",
        "        \"vocabulary_size\": 11862,",
        "        \"compute_time_ms\": 16.29648966665324,",
        "        \"mean_query_time_ms\": 0.36824840000662107,",
        "        \"max_query_time_ms\": 0.5212204000144993,",
        "        \"queries_tested\": 8",
        "      }",
        "    }",
        "  ]",
        "}"
      ],
      "lines_removed": [],
      "context_before": [],
      "context_after": [],
      "change_type": "add"
    },
    {
      "file": "cortical/analysis.py",
      "function": "def compute_tfidf(",
      "start_line": 916,
      "lines_added": [
        "def _bm25_core(",
        "    term_stats: Dict[str, Tuple[int, int, Dict[str, int]]],",
        "    num_docs: int,",
        "    doc_lengths: Dict[str, int],",
        "    avg_doc_length: float,",
        "    k1: float = 1.2,",
        "    b: float = 0.75",
        ") -> Dict[str, Tuple[float, Dict[str, float]]]:",
        "    \"\"\"",
        "    Pure BM25 calculation.",
        "",
        "    BM25 (Best Match 25) is a ranking function that improves on TF-IDF by:",
        "    - Term frequency saturation: diminishing returns for repeated terms",
        "    - Document length normalization: fair comparison across different lengths",
        "",
        "    This core function takes primitive types and can be unit tested without",
        "    needing HierarchicalLayer objects.",
        "",
        "    Args:",
        "        term_stats: Dictionary mapping term to (occurrence_count, doc_frequency, {doc_id: count})",
        "                   - occurrence_count: total times term appears in corpus",
        "                   - doc_frequency: number of documents containing term",
        "                   - doc_counts: per-document occurrence counts",
        "        num_docs: Total number of documents in corpus",
        "        doc_lengths: Dictionary mapping doc_id to document length (in tokens)",
        "        avg_doc_length: Average document length across corpus",
        "        k1: Term frequency saturation parameter (0.0-3.0, typical 1.2-2.0)",
        "            - Higher k1 = more weight to term frequency",
        "            - k1=0 = binary model (presence/absence only)",
        "        b: Length normalization parameter (0.0-1.0)",
        "            - b=0 = no length normalization",
        "            - b=1 = full length normalization",
        "",
        "    Returns:",
        "        Dictionary mapping term to (global_bm25, {doc_id: per_doc_bm25})",
        "",
        "    Example:",
        "        >>> stats = {",
        "        ...     \"rare\": (5, 1, {\"doc1\": 5}),",
        "        ...     \"common\": (100, 10, {\"doc1\": 10, \"doc2\": 10, ...})",
        "        ... }",
        "        >>> doc_lengths = {\"doc1\": 100, \"doc2\": 150}",
        "        >>> results = _bm25_core(stats, num_docs=10, doc_lengths=doc_lengths, avg_doc_length=125)",
        "        >>> assert results[\"rare\"][0] > results[\"common\"][0]",
        "    \"\"\"",
        "    if num_docs == 0 or avg_doc_length == 0:",
        "        return {}",
        "",
        "    results = {}",
        "",
        "    for term, (occurrence_count, doc_frequency, doc_counts) in term_stats.items():",
        "        if doc_frequency > 0:",
        "            # IDF component (same as TF-IDF but can use BM25 variant)",
        "            # Standard BM25 IDF: log((N - df + 0.5) / (df + 0.5))",
        "            # This can go negative for very common terms, so we use a floor",
        "            idf = math.log((num_docs - doc_frequency + 0.5) / (doc_frequency + 0.5) + 1)",
        "",
        "            # Global BM25 (using total occurrence count and average length)",
        "            # This is an approximation for global term importance",
        "            tf_global = occurrence_count / num_docs  # Average TF across docs",
        "            global_bm25 = idf * ((tf_global * (k1 + 1)) / (tf_global + k1))",
        "",
        "            # Per-document BM25",
        "            per_doc_bm25 = {}",
        "            for doc_id, tf in doc_counts.items():",
        "                doc_len = doc_lengths.get(doc_id, avg_doc_length)",
        "                # Length normalization factor",
        "                len_norm = 1 - b + b * (doc_len / avg_doc_length)",
        "                # BM25 score for this document",
        "                numerator = tf * (k1 + 1)",
        "                denominator = tf + k1 * len_norm",
        "                per_doc_bm25[doc_id] = idf * (numerator / denominator)",
        "",
        "            results[term] = (global_bm25, per_doc_bm25)",
        "        else:",
        "            results[term] = (0.0, {})",
        "",
        "    return results",
        "",
        "",
        "def compute_bm25(",
        "    layers: Dict[CorticalLayer, HierarchicalLayer],",
        "    documents: Dict[str, str],",
        "    doc_lengths: Dict[str, int],",
        "    avg_doc_length: float,",
        "    k1: float = 1.2,",
        "    b: float = 0.75",
        ") -> None:",
        "    \"\"\"",
        "    Compute BM25 scores for tokens.",
        "",
        "    BM25 (Best Match 25) is a ranking function that addresses TF-IDF limitations:",
        "    - Term frequency saturation: prevents domination by repeated terms",
        "    - Document length normalization: fair comparison across different lengths",
        "",
        "    This stores scores in the same fields as TF-IDF (tfidf, tfidf_per_doc)",
        "    for backward compatibility with existing search functions.",
        "",
        "    Args:",
        "        layers: Dictionary of layers (needs TOKENS layer)",
        "        documents: Dictionary mapping doc_id to content",
        "        doc_lengths: Dictionary mapping doc_id to token count",
        "        avg_doc_length: Average document length in tokens",
        "        k1: Term frequency saturation (0-3, default 1.2)",
        "        b: Length normalization (0-1, default 0.75)",
        "    \"\"\"",
        "    layer0 = layers[CorticalLayer.TOKENS]",
        "    num_docs = len(documents)",
        "",
        "    if num_docs == 0 or avg_doc_length == 0:",
        "        return",
        "",
        "    for col in layer0.minicolumns.values():",
        "        # Document frequency",
        "        df = len(col.document_ids)",
        "",
        "        if df > 0:",
        "            # IDF component",
        "            # BM25 IDF: log((N - df + 0.5) / (df + 0.5) + 1)",
        "            # The +1 ensures non-negative values for common terms",
        "            idf = math.log((num_docs - df + 0.5) / (df + 0.5) + 1)",
        "",
        "            # Global BM25 (approximation using average TF)",
        "            avg_tf = col.occurrence_count / num_docs",
        "            col.tfidf = idf * ((avg_tf * (k1 + 1)) / (avg_tf + k1))",
        "",
        "            # Per-document BM25",
        "            for doc_id in col.document_ids:",
        "                tf = col.doc_occurrence_counts.get(doc_id, 1)",
        "                doc_len = doc_lengths.get(doc_id, avg_doc_length)",
        "                # Length normalization factor",
        "                len_norm = 1 - b + b * (doc_len / avg_doc_length)",
        "                # BM25 score",
        "                numerator = tf * (k1 + 1)",
        "                denominator = tf + k1 * len_norm",
        "                col.tfidf_per_doc[doc_id] = idf * (numerator / denominator)",
        "",
        ""
      ],
      "lines_removed": [],
      "context_before": [
        "            # TF-IDF",
        "            col.tfidf = tf * idf",
        "            ",
        "            # Per-document TF-IDF using actual occurrence counts",
        "            for doc_id in col.document_ids:",
        "                # Get actual term frequency in this document",
        "                doc_tf = col.doc_occurrence_counts.get(doc_id, 1)",
        "                col.tfidf_per_doc[doc_id] = math.log1p(doc_tf) * idf",
        "",
        ""
      ],
      "context_after": [
        "def propagate_activation(",
        "    layers: Dict[CorticalLayer, HierarchicalLayer],",
        "    iterations: int = 3,",
        "    decay: float = 0.8,",
        "    lateral_weight: float = 0.3",
        ") -> None:",
        "    \"\"\"",
        "    Propagate activation through the network.",
        "    ",
        "    This simulates how information flows through cortical layers:"
      ],
      "change_type": "add"
    },
    {
      "file": "cortical/analysis.py",
      "function": "def compute_bigram_connections(",
      "start_line": 1874,
      "lines_added": [
        "    # OPTIMIZED: Use inverted index approach instead of O(n¬≤) matrix multiplication",
        "    # Additional optimization: importance-based filtering and early termination",
        "    skipped_low_importance = 0",
        "    # Build inverted index: doc_id -> list of bigram minicolumns",
        "    # Sort by TF-IDF importance within each document for priority processing",
        "    doc_to_bigrams: Dict[str, List[Minicolumn]] = defaultdict(list)",
        "        for doc_id in bigram.document_ids:",
        "            doc_to_bigrams[doc_id].append(bigram)",
        "",
        "    # Compute importance threshold (median TF-IDF) for filtering",
        "    tfidf_values = [b.tfidf for b in bigrams if b.tfidf > 0]",
        "    importance_threshold = sorted(tfidf_values)[len(tfidf_values) // 4] if tfidf_values else 0",
        "",
        "    # Process each document's bigram pairs",
        "    for doc_id, doc_bigrams in doc_to_bigrams.items():",
        "        # Skip large documents to avoid O(n¬≤) explosion",
        "        if len(doc_bigrams) > max_bigrams_per_doc:",
        "        # Filter to important bigrams only (reduces pairs quadratically)",
        "        important_bigrams = [b for b in doc_bigrams if b.tfidf >= importance_threshold]",
        "        if len(important_bigrams) < 2:",
        "            continue",
        "        # Sort by importance for priority connections",
        "        important_bigrams.sort(key=lambda b: b.tfidf, reverse=True)",
        "        # Connect pairs of important bigrams in this document",
        "        # Limit to top connections per bigram to avoid explosion",
        "        for i, b1 in enumerate(important_bigrams):",
        "            # Early termination if this bigram is at connection limit",
        "            if connection_counts[b1.id] >= max_connections_per_bigram:",
        "                continue",
        "            for b2 in important_bigrams[i+1:]:",
        "                if connection_counts[b2.id] >= max_connections_per_bigram:",
        "                    continue",
        "                # Fast path: they share at least this document",
        "                if len(shared_docs) < min_shared_docs:",
        "                    continue"
      ],
      "lines_removed": [
        "    # Use sparse matrix multiplication for efficient co-occurrence computation",
        "    # Build document-term matrix using sparse representation",
        "    # Create mappings: doc_id -> row index, bigram -> col index",
        "    doc_to_row: Dict[str, int] = {}",
        "    bigram_to_col: Dict[str, int] = {}",
        "",
        "    # Collect all documents first",
        "    all_docs: Set[str] = set()",
        "        all_docs.update(bigram.document_ids)",
        "",
        "    # Assign row indices to documents (excluding large docs)",
        "    row_idx = 0",
        "    for doc_id in sorted(all_docs):",
        "        # Count bigrams in this doc",
        "        doc_bigram_count = sum(1 for b in bigrams if doc_id in b.document_ids)",
        "        if doc_bigram_count > max_bigrams_per_doc:",
        "        doc_to_row[doc_id] = row_idx",
        "        row_idx += 1",
        "",
        "    # Assign column indices to bigrams",
        "    for col_idx, bigram in enumerate(bigrams):",
        "        bigram_to_col[bigram.id] = col_idx",
        "",
        "    # Build sparse document-term matrix",
        "    # Rows = documents, Cols = bigrams",
        "    # Entry [d, b] = 1 if bigram b appears in document d",
        "    if doc_to_row:  # Only if we have valid documents",
        "        doc_term_matrix = SparseMatrix(len(doc_to_row), len(bigrams))",
        "",
        "        for bigram in bigrams:",
        "            col_idx = bigram_to_col[bigram.id]",
        "            for doc_id in bigram.document_ids:",
        "                if doc_id in doc_to_row:  # Skip large docs",
        "                    row_idx = doc_to_row[doc_id]",
        "                    doc_term_matrix.set(row_idx, col_idx, 1.0)",
        "",
        "        # Compute bigram-bigram co-occurrence matrix: D^T * D",
        "        # Result[i, j] = number of shared documents between bigram i and bigram j",
        "        cooccur_matrix = doc_term_matrix.multiply_transpose()",
        "",
        "        # Create inverse mapping: col_idx -> bigram",
        "        col_to_bigram = {col_idx: bigram for bigram, col_idx in bigram_to_col.items()}",
        "",
        "        # Process co-occurrence matrix to create connections",
        "        for col1, col2, shared_count in cooccur_matrix.get_nonzero():",
        "            # Skip diagonal (bigram with itself)",
        "            if col1 == col2:",
        "                continue",
        "",
        "            # Skip if below threshold",
        "            if shared_count < min_shared_docs:",
        "                continue",
        "            # Get bigrams",
        "            bigram1_id = col_to_bigram[col1]",
        "            bigram2_id = col_to_bigram[col2]",
        "            # Find the actual minicolumn objects",
        "            b1 = layer1.get_by_id(bigram1_id)",
        "            b2 = layer1.get_by_id(bigram2_id)",
        "            if b1 and b2:",
        "                # Compute Jaccard similarity"
      ],
      "context_before": [
        "            # Skip overly common terms",
        "            if len(left_index[term]) > max_bigrams_per_term or len(right_index[term]) > max_bigrams_per_term:",
        "                continue",
        "            # term appears as right component in some bigrams and left in others",
        "            for b_left in right_index[term]:  # ends with term",
        "                for b_right in left_index[term]:  # starts with term",
        "                    if b_left.id != b_right.id:",
        "                        add_connection(b_left, b_right, chain_weight, 'chain')",
        "",
        "    # 3. Connect bigrams that co-occur in the same documents"
      ],
      "context_after": [
        "    skipped_large_docs = 0",
        "",
        "    for bigram in bigrams:",
        "            skipped_large_docs += 1",
        "            continue",
        "",
        "",
        "",
        "                docs1 = b1.document_ids",
        "                docs2 = b2.document_ids",
        "                shared_docs = docs1 & docs2",
        "                jaccard = len(shared_docs) / len(docs1 | docs2)",
        "                weight = cooccurrence_weight * jaccard",
        "                add_connection(b1, b2, weight, 'cooccurrence')",
        "",
        "    return {",
        "        'connections_created': len(connected_pairs),",
        "        'bigrams': len(bigrams),",
        "        'component_connections': component_connections,",
        "        'chain_connections': chain_connections,",
        "        'cooccurrence_connections': cooccurrence_connections,"
      ],
      "change_type": "modify"
    },
    {
      "file": "cortical/config.py",
      "function": "class CorticalConfig:",
      "start_line": 98,
      "lines_added": [
        "    # Scoring algorithm settings",
        "    scoring_algorithm: str = 'bm25'  # 'tfidf' or 'bm25'",
        "    bm25_k1: float = 1.2  # Term frequency saturation parameter (0.0-3.0, typical 1.2-2.0)",
        "    bm25_b: float = 0.75  # Length normalization parameter (0.0-1.0)",
        ""
      ],
      "lines_removed": [],
      "context_before": [
        "    bridge_similarity_max: float = 0.03",
        "",
        "    # Chunking settings for RAG",
        "    chunk_size: int = 512",
        "    chunk_overlap: int = 128",
        "",
        "    # Query expansion settings",
        "    max_query_expansions: int = 10",
        "    semantic_expansion_discount: float = 0.7",
        ""
      ],
      "context_after": [
        "    # Cross-layer propagation",
        "    cross_layer_damping: float = 0.7",
        "",
        "    # Bigram connection weights",
        "    bigram_component_weight: float = 0.5",
        "    bigram_chain_weight: float = 0.7",
        "    bigram_cooccurrence_weight: float = 0.3",
        "",
        "    # Concept connection thresholds",
        "    concept_min_shared_docs: int = 1"
      ],
      "change_type": "add"
    },
    {
      "file": "cortical/config.py",
      "function": "class CorticalConfig:",
      "start_line": 232,
      "lines_added": [
        "        # BM25 validation",
        "        if self.scoring_algorithm not in ('tfidf', 'bm25'):",
        "            raise ValueError(",
        "                f\"scoring_algorithm must be 'tfidf' or 'bm25', got {self.scoring_algorithm}\"",
        "            )",
        "        if not (0 <= self.bm25_k1 <= 3):",
        "            raise ValueError(",
        "                f\"bm25_k1 must be between 0 and 3, got {self.bm25_k1}\"",
        "            )",
        "        if not (0 <= self.bm25_b <= 1):",
        "            raise ValueError(",
        "                f\"bm25_b must be between 0 and 1, got {self.bm25_b}\"",
        "            )",
        ""
      ],
      "lines_removed": [],
      "context_before": [
        "            raise ValueError(",
        "                f\"semantic_expansion_discount must be between 0 and 1, got {self.semantic_expansion_discount}\"",
        "            )",
        "",
        "        # Cross-layer damping validation",
        "        if not (0 < self.cross_layer_damping < 1):",
        "            raise ValueError(",
        "                f\"cross_layer_damping must be between 0 and 1, got {self.cross_layer_damping}\"",
        "            )",
        ""
      ],
      "context_after": [
        "    def copy(self) -> 'CorticalConfig':",
        "        \"\"\"",
        "        Create a copy of this configuration.",
        "",
        "        Returns:",
        "            A new CorticalConfig instance with the same values.",
        "        \"\"\"",
        "        return CorticalConfig(",
        "            pagerank_damping=self.pagerank_damping,",
        "            pagerank_iterations=self.pagerank_iterations,"
      ],
      "change_type": "add"
    },
    {
      "file": "cortical/config.py",
      "function": "class CorticalConfig:",
      "start_line": 255,
      "lines_added": [
        "            scoring_algorithm=self.scoring_algorithm,",
        "            bm25_k1=self.bm25_k1,",
        "            bm25_b=self.bm25_b,"
      ],
      "lines_removed": [],
      "context_before": [
        "            louvain_resolution=self.louvain_resolution,",
        "            isolation_threshold=self.isolation_threshold,",
        "            well_connected_threshold=self.well_connected_threshold,",
        "            weak_topic_tfidf_threshold=self.weak_topic_tfidf_threshold,",
        "            bridge_similarity_min=self.bridge_similarity_min,",
        "            bridge_similarity_max=self.bridge_similarity_max,",
        "            chunk_size=self.chunk_size,",
        "            chunk_overlap=self.chunk_overlap,",
        "            max_query_expansions=self.max_query_expansions,",
        "            semantic_expansion_discount=self.semantic_expansion_discount,"
      ],
      "context_after": [
        "            cross_layer_damping=self.cross_layer_damping,",
        "            bigram_component_weight=self.bigram_component_weight,",
        "            bigram_chain_weight=self.bigram_chain_weight,",
        "            bigram_cooccurrence_weight=self.bigram_cooccurrence_weight,",
        "            concept_min_shared_docs=self.concept_min_shared_docs,",
        "            concept_min_jaccard=self.concept_min_jaccard,",
        "            concept_embedding_threshold=self.concept_embedding_threshold,",
        "            multihop_max_hops=self.multihop_max_hops,",
        "            multihop_decay_factor=self.multihop_decay_factor,",
        "            multihop_min_path_score=self.multihop_min_path_score,"
      ],
      "change_type": "add"
    },
    {
      "file": "cortical/config.py",
      "function": "class CorticalConfig:",
      "start_line": 294,
      "lines_added": [
        "            'scoring_algorithm': self.scoring_algorithm,",
        "            'bm25_k1': self.bm25_k1,",
        "            'bm25_b': self.bm25_b,"
      ],
      "lines_removed": [],
      "context_before": [
        "            'louvain_resolution': self.louvain_resolution,",
        "            'isolation_threshold': self.isolation_threshold,",
        "            'well_connected_threshold': self.well_connected_threshold,",
        "            'weak_topic_tfidf_threshold': self.weak_topic_tfidf_threshold,",
        "            'bridge_similarity_min': self.bridge_similarity_min,",
        "            'bridge_similarity_max': self.bridge_similarity_max,",
        "            'chunk_size': self.chunk_size,",
        "            'chunk_overlap': self.chunk_overlap,",
        "            'max_query_expansions': self.max_query_expansions,",
        "            'semantic_expansion_discount': self.semantic_expansion_discount,"
      ],
      "context_after": [
        "            'cross_layer_damping': self.cross_layer_damping,",
        "            'bigram_component_weight': self.bigram_component_weight,",
        "            'bigram_chain_weight': self.bigram_chain_weight,",
        "            'bigram_cooccurrence_weight': self.bigram_cooccurrence_weight,",
        "            'concept_min_shared_docs': self.concept_min_shared_docs,",
        "            'concept_min_jaccard': self.concept_min_jaccard,",
        "            'concept_embedding_threshold': self.concept_embedding_threshold,",
        "            'multihop_max_hops': self.multihop_max_hops,",
        "            'multihop_decay_factor': self.multihop_decay_factor,",
        "            'multihop_min_path_score': self.multihop_min_path_score,"
      ],
      "change_type": "add"
    },
    {
      "file": "cortical/observability.py",
      "function": null,
      "start_line": 0,
      "lines_added": [
        "\"\"\"",
        "Observability Module",
        "====================",
        "",
        "Provides timing hooks, metrics collection, and trace context for monitoring",
        "the Cortical Text Processor's performance and operations.",
        "",
        "This module follows the \"Native Over External\" principle - no external",
        "dependencies required. Uses only Python's standard library.",
        "",
        "Example:",
        "    from cortical import CorticalTextProcessor",
        "",
        "    # Enable metrics collection",
        "    processor = CorticalTextProcessor(enable_metrics=True)",
        "    processor.process_document(\"doc1\", \"Neural networks process data.\")",
        "    processor.compute_all()",
        "",
        "    # Get metrics",
        "    metrics = processor.get_metrics()",
        "    print(f\"compute_all took {metrics['compute_all']['avg_ms']:.2f}ms\")",
        "",
        "    # Get metrics summary",
        "    print(processor.get_metrics_summary())",
        "\"\"\"",
        "",
        "import time",
        "import functools",
        "import logging",
        "from typing import Dict, Any, Optional, Callable, List",
        "from collections import defaultdict",
        "from contextlib import contextmanager",
        "",
        "logger = logging.getLogger(__name__)",
        "",
        "",
        "class MetricsCollector:",
        "    \"\"\"",
        "    Collects and aggregates timing and count metrics for operations.",
        "",
        "    Thread-safe for single-threaded use. For multi-threaded applications,",
        "    wrap method calls with appropriate locking.",
        "",
        "    Attributes:",
        "        enabled: Whether metrics collection is active",
        "        operations: Dict mapping operation names to timing/count data",
        "        traces: Dict mapping trace IDs to operation logs",
        "    \"\"\"",
        "",
        "    def __init__(self, enabled: bool = True):",
        "        \"\"\"",
        "        Initialize metrics collector.",
        "",
        "        Args:",
        "            enabled: Start with metrics collection enabled",
        "        \"\"\"",
        "        self.enabled = enabled",
        "        # operation_name -> {'count': int, 'total_ms': float, 'min_ms': float, 'max_ms': float, 'timings': list}",
        "        self.operations: Dict[str, Dict[str, Any]] = defaultdict(lambda: {",
        "            'count': 0,",
        "            'total_ms': 0.0,",
        "            'min_ms': float('inf'),",
        "            'max_ms': 0.0,",
        "            'timings': []",
        "        })",
        "        # trace_id -> list of (operation, duration_ms, context) tuples",
        "        self.traces: Dict[str, List[tuple]] = defaultdict(list)",
        "        self._current_trace_id: Optional[str] = None",
        "",
        "    def record_timing(",
        "        self,",
        "        operation: str,",
        "        duration_ms: float,",
        "        trace_id: Optional[str] = None,",
        "        context: Optional[Dict[str, Any]] = None",
        "    ) -> None:",
        "        \"\"\"",
        "        Record a timing measurement for an operation.",
        "",
        "        Args:",
        "            operation: Name of the operation (e.g., \"compute_all\")",
        "            duration_ms: Duration in milliseconds",
        "            trace_id: Optional trace ID for request tracing",
        "            context: Optional context dict (doc_id, query, etc.)",
        "        \"\"\"",
        "        if not self.enabled:",
        "            return",
        "",
        "        op_data = self.operations[operation]",
        "        op_data['count'] += 1",
        "        op_data['total_ms'] += duration_ms",
        "        op_data['min_ms'] = min(op_data['min_ms'], duration_ms)",
        "        op_data['max_ms'] = max(op_data['max_ms'], duration_ms)",
        "        op_data['timings'].append(duration_ms)",
        "",
        "        # Record trace if trace_id is provided or active",
        "        effective_trace_id = trace_id or self._current_trace_id",
        "        if effective_trace_id:",
        "            self.traces[effective_trace_id].append((operation, duration_ms, context or {}))",
        "",
        "    def record_count(self, metric_name: str, count: int = 1) -> None:",
        "        \"\"\"",
        "        Record a simple count metric.",
        "",
        "        Args:",
        "            metric_name: Name of the metric (e.g., \"cache_hits\")",
        "            count: Count to add (default 1)",
        "        \"\"\"",
        "        if not self.enabled:",
        "            return",
        "",
        "        # Store counts separately from timings",
        "        if metric_name not in self.operations:",
        "            self.operations[metric_name] = {'count': 0}",
        "",
        "        if 'count' in self.operations[metric_name]:",
        "            self.operations[metric_name]['count'] += count",
        "        else:",
        "            self.operations[metric_name]['count'] = count",
        "",
        "    def get_operation_stats(self, operation: str) -> Dict[str, Any]:",
        "        \"\"\"",
        "        Get statistics for a specific operation.",
        "",
        "        Args:",
        "            operation: Operation name",
        "",
        "        Returns:",
        "            Dict with count, total_ms, avg_ms, min_ms, max_ms",
        "        \"\"\"",
        "        if operation not in self.operations:",
        "            return {}",
        "",
        "        op_data = self.operations[operation]",
        "        stats = {",
        "            'count': op_data['count']",
        "        }",
        "",
        "        # Only add timing stats if they exist",
        "        if 'total_ms' in op_data:",
        "            stats['total_ms'] = op_data['total_ms']",
        "            stats['avg_ms'] = op_data['total_ms'] / op_data['count'] if op_data['count'] > 0 else 0.0",
        "            stats['min_ms'] = op_data['min_ms'] if op_data['min_ms'] != float('inf') else 0.0",
        "            stats['max_ms'] = op_data['max_ms']",
        "",
        "        return stats",
        "",
        "    def get_all_stats(self) -> Dict[str, Dict[str, Any]]:",
        "        \"\"\"",
        "        Get statistics for all operations.",
        "",
        "        Returns:",
        "            Dict mapping operation names to their stats",
        "        \"\"\"",
        "        return {op: self.get_operation_stats(op) for op in self.operations}",
        "",
        "    def get_trace(self, trace_id: str) -> List[tuple]:",
        "        \"\"\"",
        "        Get all operations recorded for a trace ID.",
        "",
        "        Args:",
        "            trace_id: Trace identifier",
        "",
        "        Returns:",
        "            List of (operation, duration_ms, context) tuples",
        "        \"\"\"",
        "        return self.traces.get(trace_id, [])",
        "",
        "    def reset(self) -> None:",
        "        \"\"\"Clear all collected metrics.\"\"\"",
        "        self.operations.clear()",
        "        self.traces.clear()",
        "        self._current_trace_id = None",
        "",
        "    def enable(self) -> None:",
        "        \"\"\"Enable metrics collection.\"\"\"",
        "        self.enabled = True",
        "",
        "    def disable(self) -> None:",
        "        \"\"\"Disable metrics collection.\"\"\"",
        "        self.enabled = False",
        "",
        "    @contextmanager",
        "    def trace_context(self, trace_id: str):",
        "        \"\"\"",
        "        Context manager for tracing a block of operations.",
        "",
        "        Args:",
        "            trace_id: Unique trace identifier",
        "",
        "        Example:",
        "            >>> with metrics.trace_context(\"request-123\"):",
        "            ...     processor.find_documents_for_query(\"neural\")",
        "            >>> print(metrics.get_trace(\"request-123\"))",
        "        \"\"\"",
        "        previous_trace = self._current_trace_id",
        "        self._current_trace_id = trace_id",
        "        try:",
        "            yield",
        "        finally:",
        "            self._current_trace_id = previous_trace",
        "",
        "    def get_summary(self) -> str:",
        "        \"\"\"",
        "        Get a human-readable summary of all metrics.",
        "",
        "        Returns:",
        "            Formatted string with metrics table",
        "        \"\"\"",
        "        if not self.operations:",
        "            return \"No metrics collected.\"",
        "",
        "        lines = [\"Metrics Summary\", \"=\" * 80]",
        "",
        "        # Separate timing operations from counts",
        "        timing_ops = []",
        "        count_ops = []",
        "",
        "        for op_name in sorted(self.operations.keys()):",
        "            stats = self.get_operation_stats(op_name)",
        "            if 'total_ms' in stats:",
        "                timing_ops.append((op_name, stats))",
        "            else:",
        "                count_ops.append((op_name, stats))",
        "",
        "        # Display timing operations",
        "        if timing_ops:",
        "            lines.append(\"\\nTiming Operations:\")",
        "            lines.append(f\"{'Operation':<30} {'Count':>8} {'Avg(ms)':>10} {'Min(ms)':>10} {'Max(ms)':>10} {'Total(ms)':>12}\")",
        "            lines.append(\"-\" * 80)",
        "",
        "            for op_name, stats in timing_ops:",
        "                lines.append(",
        "                    f\"{op_name:<30} {stats['count']:>8} \"",
        "                    f\"{stats['avg_ms']:>10.2f} {stats['min_ms']:>10.2f} \"",
        "                    f\"{stats['max_ms']:>10.2f} {stats['total_ms']:>12.2f}\"",
        "                )",
        "",
        "        # Display count operations",
        "        if count_ops:",
        "            lines.append(\"\\nCount Metrics:\")",
        "            lines.append(f\"{'Metric':<40} {'Count':>10}\")",
        "            lines.append(\"-\" * 50)",
        "",
        "            for op_name, stats in count_ops:",
        "                lines.append(f\"{op_name:<40} {stats['count']:>10}\")",
        "",
        "        # Display trace summary",
        "        if self.traces:",
        "            lines.append(f\"\\nActive Traces: {len(self.traces)}\")",
        "",
        "        return \"\\n\".join(lines)",
        "",
        "",
        "class TraceContext:",
        "    \"\"\"",
        "    Context for request tracing across operations.",
        "",
        "    Stores trace ID and optional metadata for correlating operations.",
        "    \"\"\"",
        "",
        "    def __init__(self, trace_id: str, metadata: Optional[Dict[str, Any]] = None):",
        "        \"\"\"",
        "        Initialize trace context.",
        "",
        "        Args:",
        "            trace_id: Unique identifier for this trace",
        "            metadata: Optional metadata (user_id, session_id, etc.)",
        "        \"\"\"",
        "        self.trace_id = trace_id",
        "        self.metadata = metadata or {}",
        "        self.start_time = time.time()",
        "",
        "    def elapsed_ms(self) -> float:",
        "        \"\"\"Get elapsed time since trace started in milliseconds.\"\"\"",
        "        return (time.time() - self.start_time) * 1000.0",
        "",
        "",
        "def timed(operation_name: Optional[str] = None, include_args: bool = False):",
        "    \"\"\"",
        "    Decorator for timing method calls and recording to metrics.",
        "",
        "    Args:",
        "        operation_name: Custom name for the operation (defaults to function name)",
        "        include_args: Include function arguments in trace context",
        "",
        "    Example:",
        "        >>> class MyClass:",
        "        ...     @timed(\"my_operation\")",
        "        ...     def my_method(self):",
        "        ...         time.sleep(0.1)",
        "        ...         return \"done\"",
        "    \"\"\"",
        "    def decorator(func: Callable) -> Callable:",
        "        op_name = operation_name or func.__name__",
        "",
        "        @functools.wraps(func)",
        "        def wrapper(self, *args, **kwargs):",
        "            # Check if instance has metrics enabled",
        "            metrics = getattr(self, '_metrics', None)",
        "",
        "            if not metrics or not metrics.enabled:",
        "                # No metrics collection, just run the function",
        "                return func(self, *args, **kwargs)",
        "",
        "            # Prepare context",
        "            context = {}",
        "            if include_args and args:",
        "                # Include first few args in context (avoid huge dumps)",
        "                context['args'] = str(args[:3])",
        "            if include_args and kwargs:",
        "                # Include important kwargs",
        "                for key in ['doc_id', 'query', 'query_text', 'top_n']:",
        "                    if key in kwargs:",
        "                        context[key] = kwargs[key]",
        "",
        "            # Time the operation",
        "            start = time.perf_counter()",
        "            try:",
        "                result = func(self, *args, **kwargs)",
        "                return result",
        "            finally:",
        "                duration_ms = (time.perf_counter() - start) * 1000.0",
        "                metrics.record_timing(op_name, duration_ms, context=context)",
        "",
        "        return wrapper",
        "    return decorator",
        "",
        "",
        "def measure_time(func: Callable) -> Callable:",
        "    \"\"\"",
        "    Simple timing decorator that logs execution time.",
        "",
        "    Useful for debugging without full metrics collection.",
        "",
        "    Args:",
        "        func: Function to time",
        "",
        "    Returns:",
        "        Wrapped function that logs its execution time",
        "    \"\"\"",
        "    @functools.wraps(func)",
        "    def wrapper(*args, **kwargs):",
        "        start = time.perf_counter()",
        "        result = func(*args, **kwargs)",
        "        duration_ms = (time.perf_counter() - start) * 1000.0",
        "        logger.debug(f\"{func.__name__} took {duration_ms:.2f}ms\")",
        "        return result",
        "    return wrapper",
        "",
        "",
        "# Convenience functions for standalone usage",
        "",
        "_global_metrics = MetricsCollector(enabled=False)",
        "",
        "",
        "def get_global_metrics() -> MetricsCollector:",
        "    \"\"\"Get the global metrics collector instance.\"\"\"",
        "    return _global_metrics",
        "",
        "",
        "def enable_global_metrics() -> None:",
        "    \"\"\"Enable global metrics collection.\"\"\"",
        "    _global_metrics.enable()",
        "",
        "",
        "def disable_global_metrics() -> None:",
        "    \"\"\"Disable global metrics collection.\"\"\"",
        "    _global_metrics.disable()",
        "",
        "",
        "def reset_global_metrics() -> None:",
        "    \"\"\"Reset global metrics.\"\"\"",
        "    _global_metrics.reset()"
      ],
      "lines_removed": [],
      "context_before": [],
      "context_after": [],
      "change_type": "add"
    },
    {
      "file": "cortical/patterns.py",
      "function": null,
      "start_line": 0,
      "lines_added": [
        "\"\"\"",
        "Code Pattern Detection Module",
        "==============================",
        "",
        "Detects common programming patterns in indexed code.",
        "",
        "Identifies design patterns, idioms, and code structures including:",
        "- Singleton pattern",
        "- Factory pattern",
        "- Decorator usage",
        "- Context managers",
        "- Error handling patterns",
        "- Generator patterns",
        "- Async patterns",
        "- Property patterns",
        "- Class patterns",
        "\"\"\"",
        "",
        "import re",
        "from typing import Dict, List, Set, Tuple, Optional",
        "from collections import defaultdict",
        "",
        "",
        "# =============================================================================",
        "# PATTERN DEFINITIONS",
        "# =============================================================================",
        "",
        "# Pattern name -> (regex pattern, description, category)",
        "PATTERN_DEFINITIONS: Dict[str, Tuple[str, str, str]] = {",
        "    # Creational Patterns",
        "    'singleton': (",
        "        r'(_instance\\s*=\\s*None|__new__.*cls\\._instance|if\\s+not\\s+hasattr\\(cls,\\s*[\"\\']_instance|'",
        "        r'def\\s+__new__\\s*\\(\\s*cls.*\\).*return.*cls\\._instance)',",
        "        'Singleton pattern (single instance control)',",
        "        'creational'",
        "    ),",
        "    'factory': (",
        "        r'(def\\s+(create|make|build|get)_\\w+|class\\s+\\w*Factory\\w*|'",
        "        r'@staticmethod\\s+def\\s+(create|make|build))',",
        "        'Factory pattern (object creation)',",
        "        'creational'",
        "    ),",
        "    'builder': (",
        "        r'(def\\s+with_\\w+\\(self|def\\s+set_\\w+\\(self.*return\\s+self|'",
        "        r'class\\s+\\w*Builder\\w*)',",
        "        'Builder pattern (fluent construction)',",
        "        'creational'",
        "    ),",
        "",
        "    # Structural Patterns",
        "    'decorator': (",
        "        r'(@\\w+\\s*(\\(.*\\))?\\s*\\n\\s*def\\s+\\w+|'",
        "        r'def\\s+\\w+\\s*\\([^)]*\\)\\s*:\\s*def\\s+wrapper|'",
        "        r'@(property|staticmethod|classmethod|wraps))',",
        "        'Decorator pattern (wrapping behavior)',",
        "        'structural'",
        "    ),",
        "    'adapter': (",
        "        r'(class\\s+\\w*Adapter\\w*|def\\s+adapt\\w*\\()',",
        "        'Adapter pattern (interface conversion)',",
        "        'structural'",
        "    ),",
        "    'proxy': (",
        "        r'(class\\s+\\w*Proxy\\w*|def\\s+__getattr__)',",
        "        'Proxy pattern (access control)',",
        "        'structural'",
        "    ),",
        "",
        "    # Behavioral Patterns",
        "    'context_manager': (",
        "        r'(def\\s+__enter__|def\\s+__exit__|@contextmanager|'",
        "        r'with\\s+\\w+.*as\\s+\\w+:)',",
        "        'Context manager (resource management)',",
        "        'behavioral'",
        "    ),",
        "    'generator': (",
        "        r'(yield\\s+\\w|yield\\s+from\\s+|yield\\s*$|'",
        "        r'def\\s+\\w+.*\\):.*yield)',",
        "        'Generator pattern (lazy iteration)',",
        "        'behavioral'",
        "    ),",
        "    'iterator': (",
        "        r'(def\\s+__iter__|def\\s+__next__|class\\s+\\w*Iterator\\w*)',",
        "        'Iterator pattern (custom iteration)',",
        "        'behavioral'",
        "    ),",
        "    'observer': (",
        "        r'(def\\s+(notify|subscribe|unsubscribe|attach|detach)|(on|handle)_\\w+_event|'",
        "        r'class\\s+\\w*(Observer|Subject|Publisher)\\w*)',",
        "        'Observer pattern (event notification)',",
        "        'behavioral'",
        "    ),",
        "    'strategy': (",
        "        r'(class\\s+\\w*Strategy\\w*|def\\s+set_strategy)',",
        "        'Strategy pattern (algorithm selection)',",
        "        'behavioral'",
        "    ),",
        "",
        "    # Concurrency Patterns",
        "    'async_await': (",
        "        r'(async\\s+def\\s+\\w+|await\\s+\\w+|async\\s+with|async\\s+for)',",
        "        'Async/await pattern (asynchronous code)',",
        "        'concurrency'",
        "    ),",
        "    'thread_safety': (",
        "        r'(threading\\.Lock|threading\\.RLock|threading\\.Semaphore|'",
        "        r'with\\s+\\w*lock\\w*:|@synchronized)',",
        "        'Thread safety (locks and synchronization)',",
        "        'concurrency'",
        "    ),",
        "    'concurrent_futures': (",
        "        r'(concurrent\\.futures|ThreadPoolExecutor|ProcessPoolExecutor|'",
        "        r'executor\\.submit|executor\\.map)',",
        "        'Concurrent futures (thread/process pools)',",
        "        'concurrency'",
        "    ),",
        "",
        "    # Error Handling",
        "    'error_handling': (",
        "        r'(try\\s*:|except\\s+\\w+:|except\\s*:|finally\\s*:|raise\\s+\\w+)',",
        "        'Error handling (try/except blocks)',",
        "        'error_handling'",
        "    ),",
        "    'custom_exception': (",
        "        r'(class\\s+\\w*(Error|Exception)\\w*\\s*\\(.*Exception|raise\\s+\\w+Error\\()',",
        "        'Custom exception classes',",
        "        'error_handling'",
        "    ),",
        "    'assertion': (",
        "        r'(assert\\s+\\w+|AssertionError)',",
        "        'Assertions (runtime checks)',",
        "        'error_handling'",
        "    ),",
        "",
        "    # Python-Specific Idioms",
        "    'property_decorator': (",
        "        r'(@property|@\\w+\\.setter|@\\w+\\.deleter)',",
        "        'Property decorator (computed attributes)',",
        "        'idiom'",
        "    ),",
        "    'dataclass': (",
        "        r'(@dataclass|@dataclasses\\.dataclass)',",
        "        'Dataclass (structured data)',",
        "        'idiom'",
        "    ),",
        "    'slots': (",
        "        r'(__slots__\\s*=)',",
        "        'Slots (memory optimization)',",
        "        'idiom'",
        "    ),",
        "    'magic_methods': (",
        "        r'(def\\s+__(repr|str|eq|lt|le|gt|ge|hash|bool|len|getitem|setitem|delitem|call)__)',",
        "        'Magic methods (operator overloading)',",
        "        'idiom'",
        "    ),",
        "    'comprehension': (",
        "        r'(\\[.+for\\s+\\w+\\s+in\\s+.+\\]|\\{.+for\\s+\\w+\\s+in\\s+.+\\}|'",
        "        r'\\(.+for\\s+\\w+\\s+in\\s+.+\\))',",
        "        'List/dict/set comprehension',",
        "        'idiom'",
        "    ),",
        "    'unpacking': (",
        "        r'(\\*args|\\*\\*kwargs|\\*\\w+,|def\\s+\\w+\\([^)]*\\*|'",
        "        r'\\w+,\\s*\\*\\w+\\s*=)',",
        "        'Argument unpacking (*args, **kwargs)',",
        "        'idiom'",
        "    ),",
        "",
        "    # Testing Patterns",
        "    'unittest_class': (",
        "        r'(class\\s+Test\\w+\\(.*TestCase|def\\s+test_\\w+\\(self|'",
        "        r'def\\s+setUp\\(self|def\\s+tearDown\\(self)',",
        "        'Unittest test class',",
        "        'testing'",
        "    ),",
        "    'pytest_test': (",
        "        r'(def\\s+test_\\w+\\(|@pytest\\.\\w+|assert\\s+\\w+\\s*(==|!=|is|in))',",
        "        'Pytest test function',",
        "        'testing'",
        "    ),",
        "    'mock_usage': (",
        "        r'(@mock\\.|Mock\\(|MagicMock\\(|patch\\(|@patch)',",
        "        'Mocking (test doubles)',",
        "        'testing'",
        "    ),",
        "    'fixture': (",
        "        r'(@pytest\\.fixture|@fixture)',",
        "        'Pytest fixture (test setup)',",
        "        'testing'",
        "    ),",
        "",
        "    # Functional Programming",
        "    'lambda': (",
        "        r'(lambda\\s+\\w+:|lambda\\s*:)',",
        "        'Lambda functions (anonymous functions)',",
        "        'functional'",
        "    ),",
        "    'map_filter_reduce': (",
        "        r'(map\\(|filter\\(|reduce\\(|functools\\.reduce)',",
        "        'Map/filter/reduce (functional operations)',",
        "        'functional'",
        "    ),",
        "    'partial_application': (",
        "        r'(functools\\.partial|partial\\()',",
        "        'Partial application (currying)',",
        "        'functional'",
        "    ),",
        "",
        "    # Type Annotations",
        "    'type_hints': (",
        "        r'(def\\s+\\w+\\([^)]*:\\s*\\w+|def\\s+\\w+.*->\\s*\\w+:|'",
        "        r'from\\s+typing\\s+import|List\\[|Dict\\[|Optional\\[|Union\\[)',",
        "        'Type hints (static typing)',",
        "        'typing'",
        "    ),",
        "    'type_checking': (",
        "        r'(if\\s+TYPE_CHECKING:|from\\s+typing\\s+import\\s+TYPE_CHECKING)',",
        "        'TYPE_CHECKING guard (import-time types)',",
        "        'typing'",
        "    ),",
        "}",
        "",
        "",
        "# Pattern categories for grouping",
        "PATTERN_CATEGORIES: Dict[str, List[str]] = defaultdict(list)",
        "for pattern_name, (_, _, category) in PATTERN_DEFINITIONS.items():",
        "    PATTERN_CATEGORIES[category].append(pattern_name)",
        "",
        "",
        "# =============================================================================",
        "# PATTERN DETECTION FUNCTIONS",
        "# =============================================================================",
        "",
        "",
        "def detect_patterns_in_text(text: str, patterns: Optional[List[str]] = None) -> Dict[str, List[int]]:",
        "    \"\"\"",
        "    Detect programming patterns in a text string.",
        "",
        "    Args:",
        "        text: Source code text to analyze",
        "        patterns: Specific pattern names to search for (None = all patterns)",
        "",
        "    Returns:",
        "        Dict mapping pattern names to list of line numbers where found",
        "",
        "    Example:",
        "        >>> code = \"async def fetch():\\\\n    await get_data()\"",
        "        >>> patterns = detect_patterns_in_text(code)",
        "        >>> 'async_await' in patterns",
        "        True",
        "    \"\"\"",
        "    if patterns is None:",
        "        patterns = list(PATTERN_DEFINITIONS.keys())",
        "",
        "    results: Dict[str, List[int]] = {}",
        "    lines = text.split('\\n')",
        "",
        "    for pattern_name in patterns:",
        "        if pattern_name not in PATTERN_DEFINITIONS:",
        "            continue",
        "",
        "        regex_pattern, _, _ = PATTERN_DEFINITIONS[pattern_name]",
        "        pattern = re.compile(regex_pattern, re.MULTILINE | re.DOTALL)",
        "",
        "        # Track which lines match this pattern",
        "        matching_lines: Set[int] = set()",
        "",
        "        # Search line by line for better line number tracking",
        "        for line_num, line in enumerate(lines, start=1):",
        "            if pattern.search(line):",
        "                matching_lines.add(line_num)",
        "",
        "        # Also search the full text for multi-line patterns",
        "        for match in pattern.finditer(text):",
        "            # Find which line this match starts on",
        "            start_pos = match.start()",
        "            line_num = text[:start_pos].count('\\n') + 1",
        "            matching_lines.add(line_num)",
        "",
        "        if matching_lines:",
        "            results[pattern_name] = sorted(matching_lines)",
        "",
        "    return results",
        "",
        "",
        "def detect_patterns_in_documents(",
        "    documents: Dict[str, str],",
        "    patterns: Optional[List[str]] = None",
        ") -> Dict[str, Dict[str, List[int]]]:",
        "    \"\"\"",
        "    Detect patterns across multiple documents.",
        "",
        "    Args:",
        "        documents: Dict mapping doc_id to content",
        "        patterns: Specific pattern names to search for (None = all patterns)",
        "",
        "    Returns:",
        "        Dict mapping doc_id to pattern detection results",
        "",
        "    Example:",
        "        >>> docs = {'file1.py': 'async def foo(): pass'}",
        "        >>> results = detect_patterns_in_documents(docs)",
        "        >>> 'async_await' in results['file1.py']",
        "        True",
        "    \"\"\"",
        "    results = {}",
        "    for doc_id, content in documents.items():",
        "        patterns_found = detect_patterns_in_text(content, patterns)",
        "        if patterns_found:",
        "            results[doc_id] = patterns_found",
        "",
        "    return results",
        "",
        "",
        "def get_pattern_summary(",
        "    pattern_results: Dict[str, List[int]]",
        ") -> Dict[str, int]:",
        "    \"\"\"",
        "    Summarize pattern detection results by counting occurrences.",
        "",
        "    Args:",
        "        pattern_results: Output from detect_patterns_in_text()",
        "",
        "    Returns:",
        "        Dict mapping pattern names to occurrence counts",
        "",
        "    Example:",
        "        >>> results = {'async_await': [1, 5, 10], 'generator': [3]}",
        "        >>> summary = get_pattern_summary(results)",
        "        >>> summary['async_await']",
        "        3",
        "    \"\"\"",
        "    return {",
        "        pattern_name: len(line_numbers)",
        "        for pattern_name, line_numbers in pattern_results.items()",
        "    }",
        "",
        "",
        "def get_patterns_by_category(",
        "    pattern_results: Dict[str, List[int]]",
        ") -> Dict[str, Dict[str, int]]:",
        "    \"\"\"",
        "    Group pattern results by category.",
        "",
        "    Args:",
        "        pattern_results: Output from detect_patterns_in_text()",
        "",
        "    Returns:",
        "        Dict mapping category to {pattern_name: count}",
        "",
        "    Example:",
        "        >>> results = {'async_await': [1, 2], 'generator': [3]}",
        "        >>> by_category = get_patterns_by_category(results)",
        "        >>> 'concurrency' in by_category",
        "        True",
        "    \"\"\"",
        "    categorized: Dict[str, Dict[str, int]] = defaultdict(dict)",
        "",
        "    for pattern_name, line_numbers in pattern_results.items():",
        "        if pattern_name in PATTERN_DEFINITIONS:",
        "            _, _, category = PATTERN_DEFINITIONS[pattern_name]",
        "            count = len(line_numbers)",
        "            categorized[category][pattern_name] = count",
        "",
        "    return dict(categorized)",
        "",
        "",
        "def get_pattern_description(pattern_name: str) -> Optional[str]:",
        "    \"\"\"",
        "    Get the description for a pattern.",
        "",
        "    Args:",
        "        pattern_name: Name of the pattern",
        "",
        "    Returns:",
        "        Description string, or None if pattern not found",
        "",
        "    Example:",
        "        >>> get_pattern_description('singleton')",
        "        'Singleton pattern (single instance control)'",
        "    \"\"\"",
        "    if pattern_name in PATTERN_DEFINITIONS:",
        "        _, description, _ = PATTERN_DEFINITIONS[pattern_name]",
        "        return description",
        "    return None",
        "",
        "",
        "def get_pattern_category(pattern_name: str) -> Optional[str]:",
        "    \"\"\"",
        "    Get the category for a pattern.",
        "",
        "    Args:",
        "        pattern_name: Name of the pattern",
        "",
        "    Returns:",
        "        Category string, or None if pattern not found",
        "",
        "    Example:",
        "        >>> get_pattern_category('singleton')",
        "        'creational'",
        "    \"\"\"",
        "    if pattern_name in PATTERN_DEFINITIONS:",
        "        _, _, category = PATTERN_DEFINITIONS[pattern_name]",
        "        return category",
        "    return None",
        "",
        "",
        "def list_all_patterns() -> List[str]:",
        "    \"\"\"",
        "    List all available pattern names.",
        "",
        "    Returns:",
        "        Sorted list of pattern names",
        "",
        "    Example:",
        "        >>> patterns = list_all_patterns()",
        "        >>> 'singleton' in patterns",
        "        True",
        "    \"\"\"",
        "    return sorted(PATTERN_DEFINITIONS.keys())",
        "",
        "",
        "def list_patterns_by_category(category: str) -> List[str]:",
        "    \"\"\"",
        "    List all patterns in a specific category.",
        "",
        "    Args:",
        "        category: Category name",
        "",
        "    Returns:",
        "        Sorted list of pattern names in that category",
        "",
        "    Example:",
        "        >>> patterns = list_patterns_by_category('creational')",
        "        >>> 'singleton' in patterns",
        "        True",
        "    \"\"\"",
        "    return sorted(PATTERN_CATEGORIES.get(category, []))",
        "",
        "",
        "def list_all_categories() -> List[str]:",
        "    \"\"\"",
        "    List all pattern categories.",
        "",
        "    Returns:",
        "        Sorted list of category names",
        "",
        "    Example:",
        "        >>> categories = list_all_categories()",
        "        >>> 'creational' in categories",
        "        True",
        "    \"\"\"",
        "    return sorted(PATTERN_CATEGORIES.keys())",
        "",
        "",
        "def format_pattern_report(",
        "    pattern_results: Dict[str, List[int]],",
        "    show_lines: bool = False",
        ") -> str:",
        "    \"\"\"",
        "    Format pattern detection results as a human-readable report.",
        "",
        "    Args:",
        "        pattern_results: Output from detect_patterns_in_text()",
        "        show_lines: Whether to show line numbers",
        "",
        "    Returns:",
        "        Formatted report string",
        "",
        "    Example:",
        "        >>> results = {'async_await': [1, 5], 'generator': [10]}",
        "        >>> report = format_pattern_report(results)",
        "        >>> 'async_await' in report",
        "        True",
        "    \"\"\"",
        "    if not pattern_results:",
        "        return \"No patterns detected.\"",
        "",
        "    lines = []",
        "    lines.append(f\"Detected {len(pattern_results)} pattern types:\")",
        "    lines.append(\"\")",
        "",
        "    # Group by category",
        "    by_category = get_patterns_by_category(pattern_results)",
        "",
        "    for category in sorted(by_category.keys()):",
        "        lines.append(f\"{category.upper()}:\")",
        "        patterns_in_cat = by_category[category]",
        "",
        "        for pattern_name in sorted(patterns_in_cat.keys()):",
        "            count = patterns_in_cat[pattern_name]",
        "            description = get_pattern_description(pattern_name)",
        "",
        "            if show_lines and pattern_name in pattern_results:",
        "                line_nums = pattern_results[pattern_name]",
        "                lines.append(f\"  - {pattern_name}: {count} occurrences\")",
        "                lines.append(f\"    {description}\")",
        "                lines.append(f\"    Lines: {', '.join(map(str, line_nums[:10]))}\")",
        "                if len(line_nums) > 10:",
        "                    lines.append(f\"    ... and {len(line_nums) - 10} more\")",
        "            else:",
        "                lines.append(f\"  - {pattern_name}: {count} occurrences - {description}\")",
        "",
        "        lines.append(\"\")",
        "",
        "    return '\\n'.join(lines)",
        "",
        "",
        "def get_corpus_pattern_statistics(",
        "    doc_patterns: Dict[str, Dict[str, List[int]]]",
        ") -> Dict[str, any]:",
        "    \"\"\"",
        "    Compute statistics across all documents.",
        "",
        "    Args:",
        "        doc_patterns: Output from detect_patterns_in_documents()",
        "",
        "    Returns:",
        "        Dict with corpus-wide statistics",
        "",
        "    Example:",
        "        >>> docs = {'f1.py': {'async_await': [1]}, 'f2.py': {'async_await': [2]}}",
        "        >>> stats = get_corpus_pattern_statistics(docs)",
        "        >>> stats['total_documents']",
        "        2",
        "    \"\"\"",
        "    pattern_doc_counts: Dict[str, int] = defaultdict(int)",
        "    pattern_total_occurrences: Dict[str, int] = defaultdict(int)",
        "",
        "    for doc_id, doc_patterns_result in doc_patterns.items():",
        "        for pattern_name, line_numbers in doc_patterns_result.items():",
        "            pattern_doc_counts[pattern_name] += 1",
        "            pattern_total_occurrences[pattern_name] += len(line_numbers)",
        "",
        "    return {",
        "        'total_documents': len(doc_patterns),",
        "        'patterns_found': len(pattern_doc_counts),",
        "        'pattern_document_counts': dict(pattern_doc_counts),",
        "        'pattern_occurrences': dict(pattern_total_occurrences),",
        "        'most_common_pattern': max(pattern_total_occurrences.items(), key=lambda x: x[1])[0]",
        "            if pattern_total_occurrences else None,",
        "    }"
      ],
      "lines_removed": [],
      "context_before": [],
      "context_after": [],
      "change_type": "add"
    },
    {
      "file": "cortical/processor/compute.py",
      "function": "from typing import Dict, List, Tuple, Optional, Any, Set",
      "start_line": 14,
      "lines_added": [
        "from ..observability import timed"
      ],
      "lines_removed": [],
      "context_before": [
        "from ..layers import CorticalLayer",
        "from .. import analysis",
        "from .. import semantics",
        "from .. import embeddings as emb_module",
        "from ..progress import (",
        "    ProgressReporter,",
        "    ConsoleProgressReporter,",
        "    SilentProgressReporter,",
        "    MultiPhaseProgress",
        ")"
      ],
      "context_after": [
        "",
        "logger = logging.getLogger(__name__)",
        "",
        "",
        "class ComputeMixin:",
        "    \"\"\"",
        "    Mixin providing computation functionality.",
        "",
        "    Requires CoreMixin to be present (provides layers, documents, tokenizer,",
        "    config, COMP_*, _mark_all_stale, _mark_fresh, _stale_computations)."
      ],
      "change_type": "add"
    },
    {
      "file": "cortical/processor/compute.py",
      "function": "class ComputeMixin:",
      "start_line": 115,
      "lines_added": [
        "    @timed(\"compute_all\")"
      ],
      "lines_removed": [],
      "context_before": [
        "                self._mark_fresh(self.COMP_EMBEDDINGS)",
        "                recomputed[self.COMP_EMBEDDINGS] = True",
        "",
        "            if self.COMP_SEMANTICS in self._stale_computations:",
        "                self.extract_corpus_semantics(verbose=verbose)",
        "                self._mark_fresh(self.COMP_SEMANTICS)",
        "                recomputed[self.COMP_SEMANTICS] = True",
        "",
        "        return recomputed",
        ""
      ],
      "context_after": [
        "    def compute_all(",
        "        self,",
        "        verbose: bool = True,",
        "        build_concepts: bool = True,",
        "        pagerank_method: str = 'standard',",
        "        connection_strategy: str = 'document_overlap',",
        "        cluster_strictness: float = 1.0,",
        "        bridge_weight: float = 0.0,",
        "        progress_callback: Optional[ProgressReporter] = None,",
        "        show_progress: bool = False,"
      ],
      "change_type": "add"
    },
    {
      "file": "cortical/processor/compute.py",
      "function": "class ComputeMixin:",
      "start_line": 539,
      "lines_added": [
        "    @timed(\"propagate_activation\")",
        "    @timed(\"compute_importance\")"
      ],
      "lines_removed": [],
      "context_before": [
        "        # Load the processor state from JSON",
        "        processor = cls.load_json(checkpoint_dir, config=config, verbose=verbose)",
        "",
        "        # Load and display progress",
        "        progress = processor._load_checkpoint_progress(checkpoint_dir)",
        "        if verbose and progress:",
        "            logger.info(f\"Found {len(progress)} completed phases: {', '.join(sorted(progress))}\")",
        "",
        "        return processor",
        ""
      ],
      "context_after": [
        "    def propagate_activation(self, iterations: int = 3, decay: float = 0.8, verbose: bool = True) -> None:",
        "        analysis.propagate_activation(self.layers, iterations, decay)",
        "        if verbose:",
        "            logger.info(f\"Propagated activation ({iterations} iterations)\")",
        "",
        "    def compute_importance(self, verbose: bool = True) -> None:",
        "        for layer_enum in [CorticalLayer.TOKENS, CorticalLayer.BIGRAMS]:",
        "            analysis.compute_pagerank(self.layers[layer_enum])",
        "        if verbose:",
        "            logger.info(\"Computed PageRank importance\")",
        "",
        "    def compute_semantic_importance(",
        "        self,",
        "        relation_weights: Optional[Dict[str, float]] = None,",
        "        verbose: bool = True"
      ],
      "change_type": "add"
    },
    {
      "file": "cortical/processor/compute.py",
      "function": "class ComputeMixin:",
      "start_line": 647,
      "lines_added": [
        "    @timed(\"compute_tfidf\")",
        "        \"\"\"",
        "        Compute document relevance scores using the configured algorithm.",
        "",
        "        Uses the scoring_algorithm from config ('tfidf' or 'bm25').",
        "        BM25 provides improved relevance through term frequency saturation",
        "        and document length normalization.",
        "",
        "        Args:",
        "            verbose: Print progress messages",
        "        \"\"\"",
        "        if self.config.scoring_algorithm == 'bm25':",
        "            analysis.compute_bm25(",
        "                self.layers,",
        "                self.documents,",
        "                self.doc_lengths,",
        "                self.avg_doc_length,",
        "                k1=self.config.bm25_k1,",
        "                b=self.config.bm25_b",
        "            )",
        "            if verbose:",
        "                logger.info(f\"Computed BM25 scores (k1={self.config.bm25_k1}, b={self.config.bm25_b})\")",
        "        else:",
        "            analysis.compute_tfidf(self.layers, self.documents)",
        "            if verbose:",
        "                logger.info(\"Computed TF-IDF scores\")",
        "",
        "    @timed(\"compute_bm25\")",
        "    def compute_bm25(",
        "        self,",
        "        k1: float = None,",
        "        b: float = None,",
        "        verbose: bool = True",
        "    ) -> None:",
        "        \"\"\"",
        "        Compute BM25 scores for document relevance ranking.",
        "",
        "        BM25 (Best Match 25) improves on TF-IDF by:",
        "        - Term frequency saturation: diminishing returns for repeated terms",
        "        - Document length normalization: fair comparison across lengths",
        "",
        "        Args:",
        "            k1: Term frequency saturation (0-3). Default from config (1.2)",
        "            b: Length normalization (0-1). Default from config (0.75)",
        "            verbose: Print progress messages",
        "        \"\"\"",
        "        k1 = k1 if k1 is not None else self.config.bm25_k1",
        "        b = b if b is not None else self.config.bm25_b",
        "",
        "        analysis.compute_bm25(",
        "            self.layers,",
        "            self.documents,",
        "            self.doc_lengths,",
        "            self.avg_doc_length,",
        "            k1=k1,",
        "            b=b",
        "        )",
        "            logger.info(f\"Computed BM25 scores (k1={k1}, b={b})\")",
        "    @timed(\"compute_document_connections\")",
        "    @timed(\"compute_bigram_connections\")"
      ],
      "lines_removed": [
        "        analysis.compute_tfidf(self.layers, self.documents)",
        "            logger.info(\"Computed TF-IDF scores\")"
      ],
      "context_before": [
        "            global_iterations=global_iterations,",
        "            cross_layer_damping=cross_layer_damping",
        "        )",
        "",
        "        if verbose:",
        "            status = \"converged\" if result['converged'] else \"did not converge\"",
        "            logger.info(f\"Computed hierarchical PageRank ({result['iterations_run']} iterations, {status})\")",
        "",
        "        return result",
        ""
      ],
      "context_after": [
        "    def compute_tfidf(self, verbose: bool = True) -> None:",
        "        if verbose:",
        "",
        "    def compute_document_connections(self, min_shared_terms: int = 3, verbose: bool = True) -> None:",
        "        analysis.compute_document_connections(self.layers, self.documents, min_shared_terms)",
        "        if verbose:",
        "            logger.info(\"Computed document connections\")",
        "",
        "    def compute_bigram_connections(",
        "        self,",
        "        min_shared_docs: int = 1,",
        "        component_weight: float = 0.5,",
        "        chain_weight: float = 0.7,",
        "        cooccurrence_weight: float = 0.3,",
        "        max_bigrams_per_term: int = 100,",
        "        max_bigrams_per_doc: int = 500,",
        "        max_connections_per_bigram: int = 50,",
        "        verbose: bool = True"
      ],
      "change_type": "modify"
    },
    {
      "file": "cortical/processor/compute.py",
      "function": "class ComputeMixin:",
      "start_line": 712,
      "lines_added": [
        "    @timed(\"build_concept_clusters\")"
      ],
      "lines_removed": [],
      "context_before": [
        "                skip_parts.append(f\"{skipped_docs} large docs\")",
        "            if skipped_conns:",
        "                skip_parts.append(f\"{skipped_conns} over-limit\")",
        "            skip_msg = f\", skipped {', '.join(skip_parts)}\" if skip_parts else \"\"",
        "            logger.info(f\"Created {stats['connections_created']} bigram connections \"",
        "                        f\"(component: {stats['component_connections']}, \"",
        "                        f\"chain: {stats['chain_connections']}, \"",
        "                        f\"cooccur: {stats['cooccurrence_connections']}{skip_msg})\")",
        "        return stats",
        ""
      ],
      "context_after": [
        "    def build_concept_clusters(",
        "        self,",
        "        min_cluster_size: Optional[int] = None,",
        "        clustering_method: str = 'louvain',",
        "        cluster_strictness: Optional[float] = None,",
        "        bridge_weight: float = 0.0,",
        "        resolution: Optional[float] = None,",
        "        verbose: bool = True",
        "    ) -> Dict[int, List[str]]:",
        "        \"\"\""
      ],
      "change_type": "add"
    },
    {
      "file": "cortical/processor/core.py",
      "function": "This module contains the base class definition and core infrastructure that all",
      "start_line": 5,
      "lines_added": [
        "from ..observability import MetricsCollector"
      ],
      "lines_removed": [],
      "context_before": [
        "other processor mixins depend on.",
        "\"\"\"",
        "",
        "import logging",
        "from typing import Dict, Optional, Any",
        "",
        "from ..tokenizer import Tokenizer",
        "from ..minicolumn import Minicolumn",
        "from ..layers import CorticalLayer, HierarchicalLayer",
        "from ..config import CorticalConfig"
      ],
      "context_after": [
        "",
        "logger = logging.getLogger(__name__)",
        "",
        "",
        "class CoreMixin:",
        "    \"\"\"",
        "    Core mixin providing initialization and staleness tracking.",
        "",
        "    This mixin defines the fundamental attributes and methods that all other",
        "    processor functionality depends on."
      ],
      "change_type": "add"
    },
    {
      "file": "cortical/processor/core.py",
      "function": "class CoreMixin:",
      "start_line": 30,
      "lines_added": [
        "        config: Optional[CorticalConfig] = None,",
        "        enable_metrics: bool = False",
        "            enable_metrics: Enable timing and metrics collection for observability.",
        "        # Document length tracking for BM25",
        "        self.doc_lengths: Dict[str, int] = {}  # doc_id -> token count",
        "        self.avg_doc_length: float = 0.0  # Average document length in tokens",
        "        # Observability: metrics collection",
        "        self._metrics = MetricsCollector(enabled=enable_metrics)"
      ],
      "lines_removed": [
        "        config: Optional[CorticalConfig] = None"
      ],
      "context_before": [
        "    COMP_ACTIVATION = 'activation'",
        "    COMP_DOC_CONNECTIONS = 'doc_connections'",
        "    COMP_BIGRAM_CONNECTIONS = 'bigram_connections'",
        "    COMP_CONCEPTS = 'concepts'",
        "    COMP_EMBEDDINGS = 'embeddings'",
        "    COMP_SEMANTICS = 'semantics'",
        "",
        "    def __init__(",
        "        self,",
        "        tokenizer: Optional[Tokenizer] = None,"
      ],
      "context_after": [
        "    ):",
        "        \"\"\"",
        "        Initialize the Cortical Text Processor.",
        "",
        "        Args:",
        "            tokenizer: Optional custom tokenizer. Defaults to standard Tokenizer.",
        "            config: Optional configuration. Defaults to CorticalConfig with defaults.",
        "        \"\"\"",
        "        self.tokenizer = tokenizer or Tokenizer()",
        "        self.config = config or CorticalConfig()",
        "        self.layers: Dict[CorticalLayer, HierarchicalLayer] = {",
        "            CorticalLayer.TOKENS: HierarchicalLayer(CorticalLayer.TOKENS),",
        "            CorticalLayer.BIGRAMS: HierarchicalLayer(CorticalLayer.BIGRAMS),",
        "            CorticalLayer.CONCEPTS: HierarchicalLayer(CorticalLayer.CONCEPTS),",
        "            CorticalLayer.DOCUMENTS: HierarchicalLayer(CorticalLayer.DOCUMENTS),",
        "        }",
        "        self.documents: Dict[str, str] = {}",
        "        self.document_metadata: Dict[str, Dict[str, Any]] = {}",
        "        self.embeddings: Dict[str, list] = {}",
        "        self.semantic_relations: list = []",
        "        # Track which computations are stale and need recomputation",
        "        self._stale_computations: set = set()",
        "        # LRU cache for query expansion results",
        "        self._query_expansion_cache: Dict[str, Dict[str, float]] = {}",
        "        self._query_cache_max_size: int = 100",
        "",
        "    def _mark_all_stale(self) -> None:",
        "        \"\"\"Mark all computations as stale (needing recomputation).\"\"\"",
        "        self._stale_computations = {",
        "            self.COMP_TFIDF,",
        "            self.COMP_PAGERANK,",
        "            self.COMP_ACTIVATION,",
        "            self.COMP_DOC_CONNECTIONS,",
        "            self.COMP_BIGRAM_CONNECTIONS,",
        "            self.COMP_CONCEPTS,"
      ],
      "change_type": "modify"
    },
    {
      "file": "cortical/processor/core.py",
      "function": "class CoreMixin:",
      "start_line": 99,
      "lines_added": [
        "",
        "    def get_metrics(self) -> Dict[str, Dict[str, Any]]:",
        "        \"\"\"",
        "        Get all collected metrics.",
        "",
        "        Returns:",
        "            Dict mapping operation names to their statistics",
        "            (count, total_ms, avg_ms, min_ms, max_ms)",
        "",
        "        Example:",
        "            >>> processor = CorticalTextProcessor(enable_metrics=True)",
        "            >>> processor.compute_all()",
        "            >>> metrics = processor.get_metrics()",
        "            >>> print(f\"compute_all: {metrics['compute_all']['avg_ms']:.2f}ms\")",
        "        \"\"\"",
        "        return self._metrics.get_all_stats()",
        "",
        "    def get_metrics_summary(self) -> str:",
        "        \"\"\"",
        "        Get a human-readable summary of all metrics.",
        "",
        "        Returns:",
        "            Formatted string with metrics table",
        "",
        "        Example:",
        "            >>> processor = CorticalTextProcessor(enable_metrics=True)",
        "            >>> processor.compute_all()",
        "            >>> print(processor.get_metrics_summary())",
        "        \"\"\"",
        "        return self._metrics.get_summary()",
        "",
        "    def reset_metrics(self) -> None:",
        "        \"\"\"Clear all collected metrics.\"\"\"",
        "        self._metrics.reset()",
        "",
        "    def enable_metrics(self) -> None:",
        "        \"\"\"Enable metrics collection.\"\"\"",
        "        self._metrics.enable()",
        "",
        "    def disable_metrics(self) -> None:",
        "        \"\"\"Disable metrics collection.\"\"\"",
        "        self._metrics.disable()",
        "",
        "    def record_metric(self, metric_name: str, count: int = 1) -> None:",
        "        \"\"\"",
        "        Record a custom count metric.",
        "",
        "        Args:",
        "            metric_name: Name of the metric",
        "            count: Count to add (default 1)",
        "",
        "        Example:",
        "            >>> processor.record_metric(\"cache_hits\")",
        "            >>> processor.record_metric(\"documents_processed\", count=10)",
        "        \"\"\"",
        "        self._metrics.record_count(metric_name, count)"
      ],
      "lines_removed": [],
      "context_before": [
        "        Get the set of computations that are currently stale.",
        "",
        "        Returns:",
        "            Set of computation type strings that need recomputation",
        "        \"\"\"",
        "        return self._stale_computations.copy()",
        "",
        "    def get_layer(self, layer: CorticalLayer) -> HierarchicalLayer:",
        "        \"\"\"Get a specific layer by enum.\"\"\"",
        "        return self.layers[layer]"
      ],
      "context_after": [],
      "change_type": "add"
    },
    {
      "file": "cortical/processor/documents.py",
      "function": null,
      "start_line": 2,
      "lines_added": [
        "from ..observability import timed",
        "    @timed(\"process_document\", include_args=True)"
      ],
      "lines_removed": [],
      "context_before": [
        "Document management: processing, adding, removing, and metadata handling.",
        "",
        "This module contains all methods related to managing documents in the corpus.",
        "\"\"\"",
        "",
        "import copy",
        "import logging",
        "from typing import Dict, List, Tuple, Optional, Any",
        "",
        "from ..layers import CorticalLayer"
      ],
      "context_after": [
        "",
        "logger = logging.getLogger(__name__)",
        "",
        "",
        "class DocumentsMixin:",
        "    \"\"\"",
        "    Mixin providing document management functionality.",
        "",
        "    Requires CoreMixin to be present (provides tokenizer, layers, documents,",
        "    document_metadata, _mark_all_stale, _query_expansion_cache).",
        "    \"\"\"",
        "",
        "    def process_document(",
        "        self,",
        "        doc_id: str,",
        "        content: str,",
        "        metadata: Optional[Dict[str, Any]] = None",
        "    ) -> Dict[str, int]:",
        "        \"\"\"",
        "        Process a document and add it to the corpus.",
        "",
        "        Args:"
      ],
      "change_type": "add"
    },
    {
      "file": "cortical/processor/documents.py",
      "function": "class DocumentsMixin:",
      "start_line": 53,
      "lines_added": [
        "        # Track document length for BM25",
        "        self.doc_lengths[doc_id] = len(tokens)",
        "        # Update average document length",
        "        if self.doc_lengths:",
        "            self.avg_doc_length = sum(self.doc_lengths.values()) / len(self.doc_lengths)",
        ""
      ],
      "lines_removed": [],
      "context_before": [
        "",
        "        # Store metadata if provided",
        "        if metadata:",
        "            self.document_metadata[doc_id] = metadata.copy()",
        "        elif doc_id not in self.document_metadata:",
        "            self.document_metadata[doc_id] = {}",
        "",
        "        tokens = self.tokenizer.tokenize(content)",
        "        bigrams = self.tokenizer.extract_ngrams(tokens, n=2)",
        ""
      ],
      "context_after": [
        "        layer0 = self.layers[CorticalLayer.TOKENS]",
        "        layer1 = self.layers[CorticalLayer.BIGRAMS]",
        "        layer3 = self.layers[CorticalLayer.DOCUMENTS]",
        "",
        "        doc_col = layer3.get_or_create_minicolumn(doc_id)",
        "        doc_col.occurrence_count += 1",
        "        # Cache tokenized document name for fast doc_name_boost in search",
        "        # This avoids re-tokenizing the doc_id on every query",
        "        doc_col.name_tokens = set(self.tokenizer.tokenize(doc_id.replace('_', ' ')))",
        ""
      ],
      "change_type": "add"
    },
    {
      "file": "cortical/processor/introspection.py",
      "function": "comparing texts/documents.",
      "start_line": 6,
      "lines_added": [
        "from .. import patterns as patterns_module"
      ],
      "lines_removed": [],
      "context_before": [
        "\"\"\"",
        "",
        "import re",
        "import logging",
        "from typing import Dict, List, Tuple, Optional, Any, TYPE_CHECKING",
        "",
        "from ..layers import CorticalLayer",
        "from .. import gaps as gaps_module",
        "from .. import fingerprint as fp_module",
        "from .. import persistence"
      ],
      "context_after": [
        "",
        "if TYPE_CHECKING:",
        "    from . import CorticalTextProcessor",
        "",
        "logger = logging.getLogger(__name__)",
        "",
        "",
        "class IntrospectionMixin:",
        "    \"\"\"",
        "    Mixin providing introspection functionality."
      ],
      "change_type": "add"
    },
    {
      "file": "cortical/processor/introspection.py",
      "function": "class IntrospectionMixin:",
      "start_line": 205,
      "lines_added": [
        "    # Pattern detection methods",
        "    def detect_patterns(",
        "        self,",
        "        doc_id: str,",
        "        patterns: Optional[List[str]] = None",
        "    ) -> Dict[str, List[int]]:",
        "        \"\"\"",
        "        Detect programming patterns in a specific document.",
        "",
        "        Args:",
        "            doc_id: Document identifier",
        "            patterns: Specific pattern names to search for (None = all patterns)",
        "",
        "        Returns:",
        "            Dict mapping pattern names to list of line numbers where found",
        "",
        "        Example:",
        "            >>> processor.process_document(\"code.py\", \"async def fetch(): await get()\")",
        "            >>> patterns = processor.detect_patterns(\"code.py\")",
        "            >>> 'async_await' in patterns",
        "            True",
        "        \"\"\"",
        "        if doc_id not in self.documents:",
        "            return {}",
        "",
        "        content = self.documents[doc_id]",
        "        return patterns_module.detect_patterns_in_text(content, patterns)",
        "",
        "    def detect_patterns_in_corpus(",
        "        self,",
        "        patterns: Optional[List[str]] = None",
        "    ) -> Dict[str, Dict[str, List[int]]]:",
        "        \"\"\"",
        "        Detect patterns across all documents in the corpus.",
        "",
        "        Args:",
        "            patterns: Specific pattern names to search for (None = all patterns)",
        "",
        "        Returns:",
        "            Dict mapping doc_id to pattern detection results",
        "",
        "        Example:",
        "            >>> results = processor.detect_patterns_in_corpus()",
        "            >>> for doc_id, patterns in results.items():",
        "            ...     print(f\"{doc_id}: {list(patterns.keys())}\")",
        "        \"\"\"",
        "        return patterns_module.detect_patterns_in_documents(self.documents, patterns)",
        "",
        "    def get_pattern_summary(",
        "        self,",
        "        doc_id: str",
        "    ) -> Dict[str, int]:",
        "        \"\"\"",
        "        Get a summary of pattern occurrences in a document.",
        "",
        "        Args:",
        "            doc_id: Document identifier",
        "",
        "        Returns:",
        "            Dict mapping pattern names to occurrence counts",
        "",
        "        Example:",
        "            >>> summary = processor.get_pattern_summary(\"code.py\")",
        "            >>> summary['async_await']",
        "            3",
        "        \"\"\"",
        "        patterns = self.detect_patterns(doc_id)",
        "        return patterns_module.get_pattern_summary(patterns)",
        "",
        "    def get_corpus_pattern_statistics(self) -> Dict[str, Any]:",
        "        \"\"\"",
        "        Get pattern statistics across the entire corpus.",
        "",
        "        Returns:",
        "            Dict with corpus-wide statistics including:",
        "            - total_documents: Number of documents analyzed",
        "            - patterns_found: Number of distinct patterns detected",
        "            - pattern_document_counts: How many docs contain each pattern",
        "            - pattern_occurrences: Total occurrences of each pattern",
        "            - most_common_pattern: Most frequently occurring pattern",
        "",
        "        Example:",
        "            >>> stats = processor.get_corpus_pattern_statistics()",
        "            >>> stats['most_common_pattern']",
        "            'error_handling'",
        "        \"\"\"",
        "        doc_patterns = self.detect_patterns_in_corpus()",
        "        return patterns_module.get_corpus_pattern_statistics(doc_patterns)",
        "",
        "    def format_pattern_report(",
        "        self,",
        "        doc_id: str,",
        "        show_lines: bool = False",
        "    ) -> str:",
        "        \"\"\"",
        "        Format pattern detection results as a human-readable report.",
        "",
        "        Args:",
        "            doc_id: Document identifier",
        "            show_lines: Whether to show line numbers in the report",
        "",
        "        Returns:",
        "            Formatted report string",
        "",
        "        Example:",
        "            >>> report = processor.format_pattern_report(\"code.py\", show_lines=True)",
        "            >>> print(report)",
        "        \"\"\"",
        "        patterns = self.detect_patterns(doc_id)",
        "        return patterns_module.format_pattern_report(patterns, show_lines)",
        "",
        "    def list_available_patterns(self) -> List[str]:",
        "        \"\"\"",
        "        List all available pattern names that can be detected.",
        "",
        "        Returns:",
        "            Sorted list of pattern names",
        "",
        "        Example:",
        "            >>> patterns = processor.list_available_patterns()",
        "            >>> 'singleton' in patterns",
        "            True",
        "        \"\"\"",
        "        return patterns_module.list_all_patterns()",
        "",
        "    def list_pattern_categories(self) -> List[str]:",
        "        \"\"\"",
        "        List all pattern categories.",
        "",
        "        Returns:",
        "            Sorted list of category names",
        "",
        "        Example:",
        "            >>> categories = processor.list_pattern_categories()",
        "            >>> 'creational' in categories",
        "            True",
        "        \"\"\"",
        "        return patterns_module.list_all_categories()",
        ""
      ],
      "lines_removed": [],
      "context_before": [
        "        layer0 = self.layers[CorticalLayer.TOKENS]",
        "        scored = []",
        "        for sent in sentences:",
        "            tokens = self.tokenizer.tokenize(sent)",
        "            score = sum(layer0.get_minicolumn(t).tfidf if layer0.get_minicolumn(t) else 0 for t in tokens)",
        "            scored.append((sent, score))",
        "        scored.sort(key=lambda x: x[1], reverse=True)",
        "        top = [s for s, _ in scored[:num_sentences]]",
        "        return ' '.join([s for s in sentences if s in top])",
        ""
      ],
      "context_after": [
        "    def __repr__(self) -> str:",
        "        stats = self.get_corpus_summary()",
        "        return f\"CorticalTextProcessor(documents={stats['documents']}, columns={stats['total_columns']})\""
      ],
      "change_type": "add"
    },
    {
      "file": "cortical/processor/persistence_api.py",
      "function": "Persistence API: save, load, export, and migration methods.",
      "start_line": 4,
      "lines_added": [
        "from ..observability import timed",
        "    @timed(\"save\")"
      ],
      "lines_removed": [],
      "context_before": [
        "This module contains all methods related to saving and loading processor state.",
        "\"\"\"",
        "",
        "import logging",
        "from typing import Dict, Optional, Any, TYPE_CHECKING",
        "",
        "from ..layers import CorticalLayer",
        "from ..config import CorticalConfig",
        "from .. import persistence",
        "from .. import state_storage"
      ],
      "context_after": [
        "",
        "if TYPE_CHECKING:",
        "    from . import CorticalTextProcessor",
        "",
        "logger = logging.getLogger(__name__)",
        "",
        "",
        "class PersistenceMixin:",
        "    \"\"\"",
        "    Mixin providing persistence functionality.",
        "",
        "    Requires CoreMixin to be present (provides layers, documents, document_metadata,",
        "    embeddings, semantic_relations, config, _stale_computations).",
        "    \"\"\"",
        "",
        "    def save(",
        "        self,",
        "        filepath: str,",
        "        verbose: bool = True,",
        "        signing_key: Optional[bytes] = None",
        "    ) -> None:",
        "        \"\"\"",
        "        Save processor state to a file.",
        "",
        "        Saves all computed state including embeddings, semantic relations,"
      ],
      "change_type": "add"
    },
    {
      "file": "cortical/processor/persistence_api.py",
      "function": "class PersistenceMixin:",
      "start_line": 40,
      "lines_added": [
        "            'config': self.config.to_dict(),",
        "            'doc_lengths': self.doc_lengths,",
        "            'avg_doc_length': self.avg_doc_length"
      ],
      "lines_removed": [
        "            'config': self.config.to_dict()"
      ],
      "context_before": [
        "",
        "        Args:",
        "            filepath: Path to save file",
        "            verbose: Print progress",
        "            signing_key: Optional HMAC key for signing pickle files (SEC-003).",
        "                If provided, creates a .sig file alongside the pickle file.",
        "        \"\"\"",
        "        metadata = {",
        "            'has_embeddings': bool(self.embeddings),",
        "            'has_relations': bool(self.semantic_relations),"
      ],
      "context_after": [
        "        }",
        "        persistence.save_processor(",
        "            filepath,",
        "            self.layers,",
        "            self.documents,",
        "            self.document_metadata,",
        "            self.embeddings,",
        "            self.semantic_relations,",
        "            metadata,",
        "            verbose,"
      ],
      "change_type": "modify"
    },
    {
      "file": "cortical/processor/persistence_api.py",
      "function": "class PersistenceMixin:",
      "start_line": 93,
      "lines_added": [
        "",
        "        # Restore BM25 document length data if available",
        "        if metadata:",
        "            processor.doc_lengths = metadata.get('doc_lengths', {})",
        "            processor.avg_doc_length = metadata.get('avg_doc_length', 0.0)",
        "",
        "        # Recompute doc_lengths if not in metadata (backward compatibility)",
        "        if not processor.doc_lengths and processor.documents:",
        "            from ..tokenizer import Tokenizer",
        "            tokenizer = processor.tokenizer if hasattr(processor, 'tokenizer') else Tokenizer()",
        "            for doc_id, content in processor.documents.items():",
        "                tokens = tokenizer.tokenize(content)",
        "                processor.doc_lengths[doc_id] = len(tokens)",
        "            if processor.doc_lengths:",
        "                processor.avg_doc_length = sum(processor.doc_lengths.values()) / len(processor.doc_lengths)",
        ""
      ],
      "lines_removed": [],
      "context_before": [
        "                config = CorticalConfig.from_dict(metadata['config'])",
        "            except (KeyError, TypeError):",
        "                config = None",
        "",
        "        processor = cls(config=config)",
        "        processor.layers = layers",
        "        processor.documents = documents",
        "        processor.document_metadata = document_metadata",
        "        processor.embeddings = embeddings",
        "        processor.semantic_relations = semantic_relations"
      ],
      "context_after": [
        "        return processor",
        "",
        "    def save_json(self, state_dir: str, force: bool = False, verbose: bool = True) -> Dict[str, bool]:",
        "        \"\"\"",
        "        Save processor state to git-friendly JSON format.",
        "",
        "        Instead of a single monolithic pickle file, creates a directory with:",
        "        - manifest.json: Version, checksums, staleness tracking",
        "        - documents.json: Document content and metadata",
        "        - layers/*.json: One file per layer"
      ],
      "change_type": "add"
    },
    {
      "file": "cortical/processor/query_api.py",
      "function": null,
      "start_line": 1,
      "lines_added": [
        "from ..observability import timed"
      ],
      "lines_removed": [],
      "context_before": [
        "\"\"\"",
        "Query API: search, expansion, and retrieval methods.",
        "",
        "This module contains all query-related methods that delegate to the query module.",
        "\"\"\"",
        "",
        "import logging",
        "from typing import Dict, List, Tuple, Optional, Any",
        "",
        "from .. import query as query_module"
      ],
      "context_after": [
        "",
        "logger = logging.getLogger(__name__)",
        "",
        "",
        "class QueryMixin:",
        "    \"\"\"",
        "    Mixin providing query functionality.",
        "",
        "    Requires CoreMixin to be present (provides layers, documents, tokenizer,",
        "    config, semantic_relations, embeddings, _query_expansion_cache, _query_cache_max_size)."
      ],
      "change_type": "add"
    },
    {
      "file": "cortical/processor/query_api.py",
      "function": "class QueryMixin:",
      "start_line": 104,
      "lines_added": [
        "            self._metrics.record_count(\"query_cache_hits\")",
        "        self._metrics.record_count(\"query_cache_misses\")"
      ],
      "lines_removed": [],
      "context_before": [
        "",
        "        Returns:",
        "            Dict mapping terms to weights",
        "        \"\"\"",
        "        if max_expansions is None:",
        "            max_expansions = self.config.max_query_expansions",
        "",
        "        cache_key = f\"{query_text}|{max_expansions}|{use_variants}|{use_code_concepts}\"",
        "",
        "        if cache_key in self._query_expansion_cache:"
      ],
      "context_after": [
        "            return self._query_expansion_cache[cache_key].copy()",
        "",
        "        result = query_module.expand_query(",
        "            query_text,",
        "            self.layers,",
        "            self.tokenizer,",
        "            max_expansions=max_expansions,",
        "            use_variants=use_variants,",
        "            use_code_concepts=use_code_concepts",
        "        )",
        "",
        "        if len(self._query_expansion_cache) >= self._query_cache_max_size:"
      ],
      "change_type": "add"
    },
    {
      "file": "cortical/processor/query_api.py",
      "function": "class QueryMixin:",
      "start_line": 293,
      "lines_added": [
        "    @timed(\"find_documents_for_query\", include_args=True)",
        "        use_semantic: bool = True,",
        "        filter_code_stop_words: bool = True,",
        "        test_file_penalty: float = 0.8",
        "            filter_code_stop_words: Filter ubiquitous code tokens (self, def, return)",
        "                                    from expansion. Reduces noise in code search. (default True)",
        "            test_file_penalty: Multiplier for test files to rank them lower (default 0.8).",
        "                               Set to 1.0 to disable penalty.",
        "            use_semantic=use_semantic,",
        "            filter_code_stop_words=filter_code_stop_words,",
        "            test_file_penalty=test_file_penalty"
      ],
      "lines_removed": [
        "        use_semantic: bool = True",
        "            use_semantic=use_semantic"
      ],
      "context_before": [
        "            query_text,",
        "            self.layers,",
        "            self.tokenizer,",
        "            self.semantic_relations,",
        "            max_hops=max_hops,",
        "            max_expansions=max_expansions,",
        "            decay_factor=decay_factor,",
        "            min_path_score=min_path_score",
        "        )",
        ""
      ],
      "context_after": [
        "    def find_documents_for_query(",
        "        self,",
        "        query_text: str,",
        "        top_n: int = 5,",
        "        use_expansion: bool = True,",
        "    ) -> List[Tuple[str, float]]:",
        "        \"\"\"",
        "        Find documents most relevant to a query.",
        "",
        "        Args:",
        "            query_text: Search query",
        "            top_n: Number of documents to return",
        "            use_expansion: Whether to expand query terms",
        "            use_semantic: Whether to use semantic relations for expansion",
        "",
        "        Returns:",
        "            List of (doc_id, score) tuples ranked by relevance",
        "",
        "        Raises:",
        "            ValueError: If query_text is empty or top_n is not positive",
        "        \"\"\"",
        "        if not isinstance(query_text, str) or not query_text.strip():",
        "            raise ValueError(\"query_text must be a non-empty string\")",
        "        if not isinstance(top_n, int) or top_n < 1:",
        "            raise ValueError(\"top_n must be a positive integer\")",
        "",
        "        return query_module.find_documents_for_query(",
        "            query_text,",
        "            self.layers,",
        "            self.tokenizer,",
        "            top_n=top_n,",
        "            use_expansion=use_expansion,",
        "            semantic_relations=self.semantic_relations if use_semantic else None,",
        "        )",
        "",
        "    def fast_find_documents(",
        "        self,",
        "        query_text: str,",
        "        top_n: int = 5,",
        "        candidate_multiplier: int = 3,",
        "        use_code_concepts: bool = True",
        "    ) -> List[Tuple[str, float]]:",
        "        \"\"\""
      ],
      "change_type": "modify"
    },
    {
      "file": "cortical/processor/query_api.py",
      "function": "class QueryMixin:",
      "start_line": 368,
      "lines_added": [
        "    def graph_boosted_search(",
        "        self,",
        "        query_text: str,",
        "        top_n: int = 5,",
        "        pagerank_weight: float = 0.3,",
        "        proximity_weight: float = 0.2,",
        "        use_expansion: bool = True",
        "    ) -> List[Tuple[str, float]]:",
        "        \"\"\"",
        "        Graph-Boosted BM25 (GB-BM25): Hybrid scoring combining BM25 with graph signals.",
        "",
        "        This algorithm combines multiple signals for improved code search:",
        "        1. BM25/TF-IDF base score (term relevance)",
        "        2. PageRank boost (matched term importance)",
        "        3. Proximity boost (query terms connected in graph)",
        "        4. Coverage boost (documents with more unique query term matches)",
        "",
        "        Args:",
        "            query_text: Search query",
        "            top_n: Number of results to return",
        "            pagerank_weight: Weight for PageRank boost (0-1, default 0.3)",
        "            proximity_weight: Weight for term proximity boost (0-1, default 0.2)",
        "            use_expansion: Whether to use query expansion",
        "",
        "        Returns:",
        "            List of (doc_id, score) tuples ranked by combined relevance",
        "",
        "        Raises:",
        "            ValueError: If query_text is empty or parameters are invalid",
        "        \"\"\"",
        "        if not isinstance(query_text, str) or not query_text.strip():",
        "            raise ValueError(\"query_text must be a non-empty string\")",
        "        if not isinstance(top_n, int) or top_n < 1:",
        "            raise ValueError(\"top_n must be a positive integer\")",
        "        if not 0 <= pagerank_weight <= 1:",
        "            raise ValueError(\"pagerank_weight must be between 0 and 1\")",
        "        if not 0 <= proximity_weight <= 1:",
        "            raise ValueError(\"proximity_weight must be between 0 and 1\")",
        "",
        "        return query_module.graph_boosted_search(",
        "            query_text,",
        "            self.layers,",
        "            self.tokenizer,",
        "            top_n=top_n,",
        "            pagerank_weight=pagerank_weight,",
        "            proximity_weight=proximity_weight,",
        "            use_expansion=use_expansion,",
        "            semantic_relations=self.semantic_relations",
        "        )",
        ""
      ],
      "lines_removed": [],
      "context_before": [
        "",
        "        return query_module.fast_find_documents(",
        "            query_text,",
        "            self.layers,",
        "            self.tokenizer,",
        "            top_n=top_n,",
        "            candidate_multiplier=candidate_multiplier,",
        "            use_code_concepts=use_code_concepts",
        "        )",
        ""
      ],
      "context_after": [
        "    def quick_search(self, query: str, top_n: int = 5) -> List[str]:",
        "        \"\"\"",
        "        One-call document search with sensible defaults.",
        "",
        "        Args:",
        "            query: Search query string",
        "            top_n: Number of results to return (default 5)",
        "",
        "        Returns:",
        "            List of document IDs ranked by relevance"
      ],
      "change_type": "add"
    },
    {
      "file": "cortical/processor/query_api.py",
      "function": "class QueryMixin:",
      "start_line": 512,
      "lines_added": [
        "        use_code_aware_chunks: bool = True,",
        "        filter_code_stop_words: bool = True,",
        "        test_file_penalty: float = 0.8",
        "            filter_code_stop_words: Filter ubiquitous code tokens (self, def, return)",
        "                                    from expansion. Reduces noise in code search. (default True)",
        "            test_file_penalty: Multiplier for test files to rank them lower (default 0.8).",
        "                               Set to 1.0 to disable penalty."
      ],
      "lines_removed": [
        "        use_code_aware_chunks: bool = True"
      ],
      "context_before": [
        "        overlap: Optional[int] = None,",
        "        use_expansion: bool = True,",
        "        doc_filter: Optional[List[str]] = None,",
        "        use_semantic: bool = True,",
        "        use_definition_search: bool = True,",
        "        definition_boost: float = 5.0,",
        "        apply_doc_boost: bool = True,",
        "        auto_detect_intent: bool = True,",
        "        prefer_docs: bool = False,",
        "        custom_boosts: Optional[Dict[str, float]] = None,"
      ],
      "context_after": [
        "    ) -> List[Tuple[str, str, int, int, float]]:",
        "        \"\"\"",
        "        Find text passages most relevant to a query (for RAG systems).",
        "",
        "        Args:",
        "            query_text: Search query",
        "            top_n: Number of passages to return",
        "            chunk_size: Size of each chunk in characters (default from config)",
        "            overlap: Overlap between chunks in characters (default from config)",
        "            use_expansion: Whether to expand query terms",
        "            doc_filter: Optional list of doc_ids to restrict search to",
        "            use_semantic: Whether to use semantic relations for expansion",
        "            use_definition_search: Whether to search for definition patterns",
        "            definition_boost: Score boost for definition matches",
        "            apply_doc_boost: Whether to apply document-type boosting",
        "            auto_detect_intent: Auto-detect conceptual queries and boost docs",
        "            prefer_docs: Always boost documentation",
        "            custom_boosts: Optional custom boost factors for doc types",
        "            use_code_aware_chunks: Use semantic boundaries for code files",
        "",
        "        Returns:",
        "            List of (passage_text, doc_id, start_char, end_char, score) tuples",
        "",
        "        Raises:",
        "            ValueError: If query_text is empty or parameters are invalid",
        "        \"\"\"",
        "        if not isinstance(query_text, str) or not query_text.strip():",
        "            raise ValueError(\"query_text must be a non-empty string\")",
        "        if not isinstance(top_n, int) or top_n < 1:"
      ],
      "change_type": "modify"
    },
    {
      "file": "cortical/processor/query_api.py",
      "function": "class QueryMixin:",
      "start_line": 577,
      "lines_added": [
        "            use_code_aware_chunks=use_code_aware_chunks,",
        "            filter_code_stop_words=filter_code_stop_words,",
        "            test_file_penalty=test_file_penalty"
      ],
      "lines_removed": [
        "            use_code_aware_chunks=use_code_aware_chunks"
      ],
      "context_before": [
        "            doc_filter=doc_filter,",
        "            semantic_relations=self.semantic_relations if use_semantic else None,",
        "            use_semantic=use_semantic,",
        "            use_definition_search=use_definition_search,",
        "            definition_boost=definition_boost,",
        "            apply_doc_boost=apply_doc_boost,",
        "            doc_metadata=self.document_metadata,",
        "            auto_detect_intent=auto_detect_intent,",
        "            prefer_docs=prefer_docs,",
        "            custom_boosts=custom_boosts,"
      ],
      "context_after": [
        "        )",
        "",
        "    def is_definition_query(self, query_text: str) -> Tuple[bool, Optional[str], Optional[str]]:",
        "        \"\"\"Detect if a query is looking for a code definition.\"\"\"",
        "        return query_module.is_definition_query(query_text)",
        "",
        "    def find_definition_passages(",
        "        self,",
        "        query_text: str,",
        "        context_chars: int = 500,"
      ],
      "change_type": "modify"
    },
    {
      "file": "cortical/query/__init__.py",
      "function": "from .expansion import (",
      "start_line": 59,
      "lines_added": [
        "    graph_boosted_search,"
      ],
      "lines_removed": [],
      "context_before": [
        ")",
        "",
        "# Document search",
        "from .search import (",
        "    find_documents_for_query,",
        "    fast_find_documents,",
        "    build_document_index,",
        "    search_with_index,",
        "    query_with_spreading_activation,",
        "    find_related_documents,"
      ],
      "context_after": [
        ")",
        "",
        "# Document type boosting and ranking",
        "from .ranking import (",
        "    DOC_TYPE_BOOSTS,",
        "    CONCEPTUAL_KEYWORDS,",
        "    IMPLEMENTATION_KEYWORDS,",
        "    is_conceptual_query,",
        "    get_doc_type_boost,",
        "    apply_doc_type_boost,"
      ],
      "change_type": "add"
    },
    {
      "file": "cortical/query/__init__.py",
      "function": "__all__ = [",
      "start_line": 136,
      "lines_added": [
        "    'graph_boosted_search',"
      ],
      "lines_removed": [],
      "context_before": [
        "    'expand_query_semantic',",
        "    'expand_query_multihop',",
        "    'get_expanded_query_terms',",
        "    # Search",
        "    'find_documents_for_query',",
        "    'fast_find_documents',",
        "    'build_document_index',",
        "    'search_with_index',",
        "    'query_with_spreading_activation',",
        "    'find_related_documents',"
      ],
      "context_after": [
        "    # Ranking",
        "    'DOC_TYPE_BOOSTS',",
        "    'CONCEPTUAL_KEYWORDS',",
        "    'IMPLEMENTATION_KEYWORDS',",
        "    'is_conceptual_query',",
        "    'get_doc_type_boost',",
        "    'apply_doc_type_boost',",
        "    'find_documents_with_boost',",
        "    'find_relevant_concepts',",
        "    'multi_stage_rank',"
      ],
      "change_type": "add"
    },
    {
      "file": "cortical/query/passages.py",
      "function": "def find_passages_for_query(",
      "start_line": 47,
      "lines_added": [
        "    use_code_aware_chunks: bool = True,",
        "    filter_code_stop_words: bool = True,",
        "    test_file_penalty: float = 0.8"
      ],
      "lines_removed": [
        "    use_code_aware_chunks: bool = True"
      ],
      "context_before": [
        "    doc_filter: Optional[List[str]] = None,",
        "    semantic_relations: Optional[List[Tuple[str, str, str, float]]] = None,",
        "    use_semantic: bool = True,",
        "    use_definition_search: bool = True,",
        "    definition_boost: float = DEFINITION_BOOST,",
        "    apply_doc_boost: bool = True,",
        "    doc_metadata: Optional[Dict[str, Dict[str, Any]]] = None,",
        "    auto_detect_intent: bool = True,",
        "    prefer_docs: bool = False,",
        "    custom_boosts: Optional[Dict[str, float]] = None,"
      ],
      "context_after": [
        ") -> List[Tuple[str, str, int, int, float]]:",
        "    \"\"\"",
        "    Find text passages most relevant to a query.",
        "",
        "    This is the key function for RAG systems - instead of returning document IDs,",
        "    it returns actual text passages with position information for citations.",
        "",
        "    For definition queries (e.g., \"class Minicolumn\", \"def compute_pagerank\"),",
        "    this function will directly search for the definition pattern and inject",
        "    those results with a high score, ensuring definitions appear in top results."
      ],
      "change_type": "modify"
    },
    {
      "file": "cortical/query/passages.py",
      "function": "def find_passages_for_query(",
      "start_line": 86,
      "lines_added": [
        "        filter_code_stop_words: Filter ubiquitous code tokens (self, def, return)",
        "                                from expansion. Reduces noise in code search. (default True)",
        "        test_file_penalty: Multiplier for test files to rank them lower (default 0.8).",
        "                           Set to 1.0 to disable penalty."
      ],
      "lines_removed": [],
      "context_before": [
        "        semantic_relations: Optional list of semantic relations for expansion",
        "        use_semantic: Whether to use semantic relations for expansion (if available)",
        "        use_definition_search: Whether to search for definition patterns (default True)",
        "        definition_boost: Score boost for definition matches (default 5.0)",
        "        apply_doc_boost: Whether to apply document-type boosting (default True)",
        "        doc_metadata: Optional metadata dict {doc_id: {doc_type: ..., ...}}",
        "        auto_detect_intent: Auto-detect conceptual queries and boost docs (default True)",
        "        prefer_docs: Always boost documentation regardless of query type (default False)",
        "        custom_boosts: Optional custom boost factors for doc types",
        "        use_code_aware_chunks: Use semantic boundaries for code files (default True)"
      ],
      "context_after": [
        "",
        "    Returns:",
        "        List of (passage_text, doc_id, start_char, end_char, score) tuples",
        "        ranked by relevance",
        "    \"\"\"",
        "    layer0 = layers[CorticalLayer.TOKENS]",
        "",
        "    # Determine if we should apply doc-type boosting",
        "    should_boost = apply_doc_boost and (",
        "        prefer_docs or (auto_detect_intent and is_conceptual_query(query_text))"
      ],
      "change_type": "add"
    },
    {
      "file": "cortical/query/passages.py",
      "function": "def find_passages_for_query(",
      "start_line": 113,
      "lines_added": [
        "        use_semantic=use_semantic,",
        "        filter_code_stop_words=filter_code_stop_words"
      ],
      "lines_removed": [
        "        use_semantic=use_semantic"
      ],
      "context_before": [
        "            docs_to_search = {k: v for k, v in documents.items() if k in doc_filter}",
        "        definition_passages = find_definition_passages(",
        "            query_text, docs_to_search, chunk_size, definition_boost",
        "        )",
        "",
        "    # Get expanded query terms",
        "    query_terms = get_expanded_query_terms(",
        "        query_text, layers, tokenizer,",
        "        use_expansion=use_expansion,",
        "        semantic_relations=semantic_relations,"
      ],
      "context_after": [
        "    )",
        "",
        "    if not query_terms and not definition_passages:",
        "        return []",
        "",
        "    # If we only have definition results, apply boosting and return",
        "    if not query_terms:",
        "        if should_boost:",
        "            definition_passages = [",
        "                (p[0], p[1], p[2], p[3], p[4] * get_doc_type_boost(p[1], doc_metadata, custom_boosts))"
      ],
      "change_type": "modify"
    },
    {
      "file": "cortical/query/passages.py",
      "function": "def find_passages_for_query(",
      "start_line": 144,
      "lines_added": [
        "            use_semantic=use_semantic,",
        "            filter_code_stop_words=filter_code_stop_words,",
        "            test_file_penalty=test_file_penalty"
      ],
      "lines_removed": [
        "            use_semantic=use_semantic"
      ],
      "context_before": [
        "        # Use provided filter directly as candidates (caller may have pre-boosted)",
        "        # Assign dummy scores since we'll re-score passages anyway",
        "        doc_scores = [(doc_id, 1.0) for doc_id in doc_filter if doc_id in documents]",
        "    else:",
        "        # No filter - get candidates via document search",
        "        doc_scores = find_documents_for_query(",
        "            query_text, layers, tokenizer,",
        "            top_n=min(len(documents), top_n * 3),",
        "            use_expansion=use_expansion,",
        "            semantic_relations=semantic_relations,"
      ],
      "context_after": [
        "        )",
        "",
        "    # Score passages within candidate documents",
        "    passages: List[Tuple[str, str, int, int, float]] = []",
        "",
        "    # Track definition passage locations to avoid duplicates",
        "    def_locations = {(p[1], p[2], p[3]) for p in definition_passages}",
        "",
        "    for doc_id, doc_score in doc_scores:",
        "        if doc_id not in documents:"
      ],
      "change_type": "modify"
    },
    {
      "file": "cortical/query/search.py",
      "function": "from .expansion import expand_query, get_expanded_query_terms",
      "start_line": 23,
      "lines_added": [
        "    doc_name_boost: float = 2.0,",
        "    filter_code_stop_words: bool = True,",
        "    test_file_penalty: float = 0.8",
        "        filter_code_stop_words: Filter ubiquitous code tokens (self, def, return)",
        "                                from expansion candidates. Reduces noise in code search. (default True)",
        "        test_file_penalty: Multiplier for test files to rank them lower (default 0.8).",
        "                           Set to 1.0 to disable penalty.",
        "        use_semantic=use_semantic,",
        "        filter_code_stop_words=filter_code_stop_words"
      ],
      "lines_removed": [
        "    doc_name_boost: float = 2.0",
        "        use_semantic=use_semantic"
      ],
      "context_before": [
        "",
        "",
        "def find_documents_for_query(",
        "    query_text: str,",
        "    layers: Dict[CorticalLayer, HierarchicalLayer],",
        "    tokenizer: Tokenizer,",
        "    top_n: int = 5,",
        "    use_expansion: bool = True,",
        "    semantic_relations: Optional[List[Tuple[str, str, str, float]]] = None,",
        "    use_semantic: bool = True,"
      ],
      "context_after": [
        ") -> List[Tuple[str, float]]:",
        "    \"\"\"",
        "    Find documents most relevant to a query using TF-IDF and optional expansion.",
        "",
        "    Args:",
        "        query_text: Search query",
        "        layers: Dictionary of layers",
        "        tokenizer: Tokenizer instance",
        "        top_n: Number of documents to return",
        "        use_expansion: Whether to expand query terms using lateral connections",
        "        semantic_relations: Optional list of semantic relations for expansion",
        "        use_semantic: Whether to use semantic relations for expansion (if available)",
        "        doc_name_boost: Multiplier for documents whose name matches query terms (default 2.0)",
        "",
        "    Returns:",
        "        List of (doc_id, score) tuples ranked by relevance",
        "    \"\"\"",
        "    layer0 = layers[CorticalLayer.TOKENS]",
        "    layer3 = layers[CorticalLayer.DOCUMENTS]",
        "",
        "    query_terms = get_expanded_query_terms(",
        "        query_text, layers, tokenizer,",
        "        use_expansion=use_expansion,",
        "        semantic_relations=semantic_relations,",
        "    )",
        "",
        "    # Score each document",
        "    doc_scores: Dict[str, float] = defaultdict(float)",
        "",
        "    for term, term_weight in query_terms.items():",
        "        col = layer0.get_minicolumn(term)",
        "        if col:",
        "            for doc_id in col.document_ids:",
        "                tfidf = col.tfidf_per_doc.get(doc_id, col.tfidf)"
      ],
      "change_type": "modify"
    },
    {
      "file": "cortical/query/search.py",
      "function": "def find_documents_for_query(",
      "start_line": 101,
      "lines_added": [
        "    # Apply test file penalty to reduce test file ranking",
        "    if test_file_penalty < 1.0:",
        "        for doc_id in list(doc_scores.keys()):",
        "            # Detect test files by path patterns",
        "            if (doc_id.startswith('tests/') or",
        "                doc_id.startswith('test_') or",
        "                '/test_' in doc_id or",
        "                '/tests/' in doc_id):",
        "                doc_scores[doc_id] *= test_file_penalty",
        ""
      ],
      "lines_removed": [],
      "context_before": [
        "        for doc_id in exact_matches:",
        "            # For exact matches, add max_score to ensure they rank first",
        "            # This guarantees exact match beats all other documents",
        "            doc_scores[doc_id] += max_score * doc_name_boost",
        "",
        "        for doc_id, match_ratio in partial_matches:",
        "            # Partial matches use proportional boost",
        "            boost = 1 + (doc_name_boost - 1) * match_ratio",
        "            doc_scores[doc_id] *= boost",
        ""
      ],
      "context_after": [
        "    sorted_docs = sorted(doc_scores.items(), key=lambda x: -x[1])",
        "    return sorted_docs[:top_n]",
        "",
        "",
        "def fast_find_documents(",
        "    query_text: str,",
        "    layers: Dict[CorticalLayer, HierarchicalLayer],",
        "    tokenizer: Tokenizer,",
        "    top_n: int = 5,",
        "    candidate_multiplier: int = 3,"
      ],
      "change_type": "add"
    },
    {
      "file": "cortical/query/search.py",
      "function": "def find_related_documents(",
      "start_line": 396,
      "lines_added": [
        "",
        "",
        "def graph_boosted_search(",
        "    query_text: str,",
        "    layers: Dict[CorticalLayer, HierarchicalLayer],",
        "    tokenizer: Tokenizer,",
        "    top_n: int = 5,",
        "    pagerank_weight: float = 0.3,",
        "    proximity_weight: float = 0.2,",
        "    use_expansion: bool = True,",
        "    semantic_relations: Optional[List[Tuple[str, str, str, float]]] = None",
        ") -> List[Tuple[str, float]]:",
        "    \"\"\"",
        "    Graph-Boosted BM25 (GB-BM25): Hybrid scoring combining BM25 with graph signals.",
        "",
        "    This creative algorithm combines multiple signals:",
        "    1. BM25/TF-IDF base score (term relevance)",
        "    2. PageRank boost (matched term importance)",
        "    3. Proximity boost (query terms connected in graph)",
        "    4. Coverage boost (documents with more unique query term matches)",
        "",
        "    This approach is designed for code search where:",
        "    - Important functions/classes should rank higher (PageRank)",
        "    - Related concepts should boost each other (graph connections)",
        "    - Comprehensive matches beat partial matches (coverage)",
        "",
        "    Args:",
        "        query_text: Search query",
        "        layers: Dictionary of layers",
        "        tokenizer: Tokenizer instance",
        "        top_n: Number of results to return",
        "        pagerank_weight: Weight for PageRank boost (0-1, default 0.3)",
        "        proximity_weight: Weight for term proximity boost (0-1, default 0.2)",
        "        use_expansion: Whether to use query expansion",
        "        semantic_relations: Optional semantic relations for expansion",
        "",
        "    Returns:",
        "        List of (doc_id, score) tuples ranked by combined relevance",
        "    \"\"\"",
        "    layer0 = layers[CorticalLayer.TOKENS]",
        "    layer3 = layers[CorticalLayer.DOCUMENTS]",
        "",
        "    # Get expanded query terms",
        "    query_terms = get_expanded_query_terms(",
        "        query_text, layers, tokenizer,",
        "        use_expansion=use_expansion,",
        "        semantic_relations=semantic_relations,",
        "        use_semantic=True",
        "    )",
        "",
        "    if not query_terms:",
        "        return []",
        "",
        "    # Phase 1: Compute base BM25/TF-IDF scores per document",
        "    doc_scores: Dict[str, float] = defaultdict(float)",
        "    doc_term_matches: Dict[str, set] = defaultdict(set)  # Track unique term matches",
        "    doc_pagerank_sum: Dict[str, float] = defaultdict(float)  # Sum of PageRank for matched terms",
        "",
        "    for term, term_weight in query_terms.items():",
        "        col = layer0.get_minicolumn(term)",
        "        if col:",
        "            # Get term's PageRank importance",
        "            term_pagerank = getattr(col, 'pagerank', 0.0) or 0.0",
        "",
        "            for doc_id in col.document_ids:",
        "                # Base BM25/TF-IDF score",
        "                tfidf = col.tfidf_per_doc.get(doc_id, col.tfidf)",
        "                doc_scores[doc_id] += tfidf * term_weight",
        "",
        "                # Track term match for coverage",
        "                doc_term_matches[doc_id].add(term)",
        "",
        "                # Accumulate PageRank boost",
        "                doc_pagerank_sum[doc_id] += term_pagerank * term_weight",
        "",
        "    if not doc_scores:",
        "        return []",
        "",
        "    # Phase 2: Compute proximity boost using lateral connections",
        "    # Boost documents where query terms are connected in the graph",
        "    proximity_scores: Dict[str, float] = defaultdict(float)",
        "",
        "    original_tokens = tokenizer.tokenize(query_text)",
        "    if len(original_tokens) > 1:",
        "        # Check if query terms have lateral connections to each other",
        "        for i, t1 in enumerate(original_tokens):",
        "            col1 = layer0.get_minicolumn(t1)",
        "            if not col1:",
        "                continue",
        "",
        "            for t2 in original_tokens[i+1:]:",
        "                col2 = layer0.get_minicolumn(t2)",
        "                if not col2:",
        "                    continue",
        "",
        "                # Check for connection between terms",
        "                conn_weight = col1.lateral_connections.get(col2.id, 0.0)",
        "                if conn_weight > 0:",
        "                    # Boost documents containing both terms",
        "                    shared_docs = col1.document_ids & col2.document_ids",
        "                    for doc_id in shared_docs:",
        "                        proximity_scores[doc_id] += conn_weight",
        "",
        "    # Phase 3: Combine all signals",
        "    max_base_score = max(doc_scores.values()) if doc_scores else 1.0",
        "    max_pagerank = max(doc_pagerank_sum.values()) if doc_pagerank_sum else 1.0",
        "    max_proximity = max(proximity_scores.values()) if proximity_scores else 1.0",
        "",
        "    final_scores: Dict[str, float] = {}",
        "    num_query_terms = len(set(original_tokens))",
        "",
        "    for doc_id, base_score in doc_scores.items():",
        "        # Normalize base score",
        "        norm_base = base_score / max_base_score if max_base_score > 0 else 0",
        "",
        "        # Normalize PageRank boost",
        "        pagerank_boost = doc_pagerank_sum.get(doc_id, 0.0)",
        "        norm_pagerank = pagerank_boost / max_pagerank if max_pagerank > 0 else 0",
        "",
        "        # Normalize proximity boost",
        "        prox_boost = proximity_scores.get(doc_id, 0.0)",
        "        norm_proximity = prox_boost / max_proximity if max_proximity > 0 else 0",
        "",
        "        # Coverage boost: reward documents matching more unique query terms",
        "        coverage = len(doc_term_matches.get(doc_id, set())) / num_query_terms if num_query_terms > 0 else 0",
        "",
        "        # Combine signals with weights",
        "        # Base score dominates, with boosts from graph signals",
        "        combined = (",
        "            (1 - pagerank_weight - proximity_weight) * norm_base +",
        "            pagerank_weight * norm_pagerank +",
        "            proximity_weight * norm_proximity",
        "        )",
        "",
        "        # Apply coverage multiplier (0.5 to 1.5 range)",
        "        coverage_mult = 0.5 + coverage",
        "",
        "        # Final score preserves relative magnitude",
        "        final_scores[doc_id] = combined * coverage_mult * max_base_score",
        "",
        "    sorted_docs = sorted(final_scores.items(), key=lambda x: -x[1])",
        "    return sorted_docs[:top_n]"
      ],
      "lines_removed": [],
      "context_before": [
        "        return []",
        "",
        "    related = []",
        "    for neighbor_id, weight in col.lateral_connections.items():",
        "        # Use O(1) ID lookup instead of linear search",
        "        neighbor = layer3.get_by_id(neighbor_id)",
        "        if neighbor:",
        "            related.append((neighbor.content, weight))",
        "",
        "    return sorted(related, key=lambda x: -x[1])"
      ],
      "context_after": [],
      "change_type": "add"
    },
    {
      "file": "cortical/semantics.py",
      "function": "def extract_corpus_semantics(",
      "start_line": 309,
      "lines_added": [
        "        # Pre-filter terms by minimum context keys AND TF-IDF importance",
        "        tfidf_scores: Dict[str, float] = {}",
        "            # Get TF-IDF score for importance ranking",
        "            col = layer0.get_minicolumn(term)",
        "            tfidf_scores[term] = col.tfidf if col else 0.0",
        "        # Get filtered terms with enough context, sorted by importance",
        "        # OPTIMIZATION: Sort by TF-IDF importance and limit to top terms",
        "        # This focuses similarity computation on the most important terms",
        "        filtered_terms.sort(key=lambda t: tfidf_scores.get(t, 0), reverse=True)",
        "",
        "        # Limit to top N important terms to avoid O(n¬≤) explosion",
        "        # sqrt(max_similarity_pairs) gives balanced coverage",
        "        max_terms = int(math.sqrt(max_similarity_pairs * 2)) if max_similarity_pairs > 0 else len(filtered_terms)",
        "        filtered_terms = filtered_terms[:max_terms]",
        ""
      ],
      "lines_removed": [
        "        # Pre-filter terms by minimum context keys",
        "        # Get filtered terms with enough context"
      ],
      "context_before": [
        "        for i in range(n_terms):",
        "            row_i = nonzero_counts[i]",
        "            for j in range(i + 1, n_terms):",
        "                if similarities[i, j] > 0.3:",
        "                    common_count = np.sum(row_i & nonzero_counts[j])",
        "                    if common_count >= 3:",
        "                        relations.append((terms[i], 'SimilarTo', terms[j], float(similarities[i, j])))",
        "",
        "    elif n_terms > 1:",
        "        # Fallback: pure Python implementation with optimizations"
      ],
      "context_after": [
        "        key_sets: Dict[str, set] = {}",
        "        magnitudes: Dict[str, float] = {}",
        "",
        "        for term in terms:",
        "            vec = context_vectors[term]",
        "            keys = set(vec.keys())",
        "            # Skip terms with too few context keys (can't meet min_context_keys threshold)",
        "            if len(keys) < min_context_keys:",
        "                continue",
        "            key_sets[term] = keys",
        "            mag = math.sqrt(sum(v * v for v in vec.values()))",
        "            magnitudes[term] = mag",
        "",
        "        filtered_terms = [t for t in terms if t in key_sets and magnitudes.get(t, 0) > 0]",
        "",
        "        # Track pairs checked for early termination",
        "        pairs_checked = 0",
        "",
        "        for i, t1 in enumerate(filtered_terms):",
        "            vec1 = context_vectors[t1]",
        "            mag1 = magnitudes[t1]",
        "            keys1 = key_sets[t1]",
        "",
        "            for t2 in filtered_terms[i+1:]:",
        "                # Check pair limit"
      ],
      "change_type": "modify"
    },
    {
      "file": "docs/DEPENDENCIES_AND_TOOLS.md",
      "function": null,
      "start_line": 0,
      "lines_added": [
        "# Project Dependencies, Tools, APIs & Code Execution Mechanisms",
        "",
        "> **Generated:** 2025-12-14",
        "> **Purpose:** Exhaustive inventory of everything that executes code on behalf of the Cortical Text Processor project",
        "",
        "---",
        "",
        "## Table of Contents",
        "",
        "1. [Runtime Dependencies](#1-runtime-dependencies)",
        "2. [Development Dependencies](#2-development-dependencies)",
        "3. [Optional Dependencies](#3-optional-dependencies)",
        "4. [Build System Tools](#4-build-system-tools)",
        "5. [CI/CD Automation](#5-cicd-automation)",
        "6. [Development Scripts](#6-development-scripts)",
        "7. [Claude Code Integration](#7-claude-code-integration)",
        "8. [MCP Server (Model Context Protocol)](#8-mcp-server-model-context-protocol)",
        "9. [Code Execution Mechanisms](#9-code-execution-mechanisms)",
        "10. [External Services & APIs](#10-external-services--apis)",
        "11. [Security Tools](#11-security-tools)",
        "12. [Test Frameworks & Runners](#12-test-frameworks--runners)",
        "",
        "---",
        "",
        "## 1. Runtime Dependencies",
        "",
        "**ZERO RUNTIME DEPENDENCIES** - This is a core design principle.",
        "",
        "The library uses **only Python standard library modules**:",
        "- `collections` (defaultdict, Counter)",
        "- `dataclasses`",
        "- `enum`",
        "- `functools`",
        "- `hashlib`",
        "- `json`",
        "- `logging`",
        "- `math`",
        "- `os`",
        "- `pathlib`",
        "- `pickle`",
        "- `random`",
        "- `re`",
        "- `string`",
        "- `time`",
        "- `typing`",
        "- `uuid`",
        "",
        "**Python Version Requirement:** `>=3.9` (supports 3.9, 3.10, 3.11, 3.12)",
        "",
        "---",
        "",
        "## 2. Development Dependencies",
        "",
        "Defined in `pyproject.toml` under `[project.optional-dependencies].dev`:",
        "",
        "| Package | Version | Purpose |",
        "|---------|---------|---------|",
        "| `coverage` | `>=7.0` | Test coverage reporting |",
        "| `pytest` | `>=7.0` | Test framework (used by `tests/unit/`, `tests/integration/`, etc.) |",
        "| `mcp` | `>=1.0` | MCP server tests (Model Context Protocol SDK) |",
        "| `pyyaml` | `>=6.0` | Workflow integration tests (`.claude/workflows/*.yaml`) |",
        "",
        "**Installation:**",
        "```bash",
        "pip install -e \".[dev]\"",
        "```",
        "",
        "---",
        "",
        "## 3. Optional Dependencies",
        "",
        "Listed in `requirements.txt` as optional:",
        "",
        "| Package | Version | Purpose |",
        "|---------|---------|---------|",
        "| `protobuf` | `>=4.0` | Protocol Buffers serialization for cross-language support |",
        "| `grpcio-tools` | `>=1.0` | Protocol Buffers compiler for schema compilation |",
        "",
        "**Schema Location:** `cortical/proto/schema.proto`",
        "**Generated Code:** `cortical/proto/schema_pb2.py` (gitignored, regenerated at runtime)",
        "",
        "---",
        "",
        "## 4. Build System Tools",
        "",
        "### setuptools (Build Backend)",
        "- **Config:** `pyproject.toml`",
        "- **Requires:** `setuptools>=61.0`",
        "- **Backend:** `setuptools.build_meta`",
        "",
        "### Package Structure",
        "```",
        "cortical/",
        "‚îú‚îÄ‚îÄ __init__.py        # Re-exports public API",
        "‚îú‚îÄ‚îÄ processor/         # Main package (split into mixins)",
        "‚îú‚îÄ‚îÄ query/             # Search functions (8 modules)",
        "‚îú‚îÄ‚îÄ proto/             # Optional protobuf serialization",
        "‚îî‚îÄ‚îÄ py.typed           # PEP 561 type marker",
        "```",
        "",
        "---",
        "",
        "## 5. CI/CD Automation",
        "",
        "### GitHub Actions Workflows",
        "",
        "#### `.github/workflows/ci.yml` - Main Test Suite",
        "**Triggers:** Push to any branch, PRs to main, manual dispatch",
        "",
        "| Job | Purpose | Time |",
        "|-----|---------|------|",
        "| `validate-task-list` | Validate task list consistency | < 5s |",
        "| `smoke-tests` | Quick sanity checks | < 30s |",
        "| `unit-tests` | Fast isolated tests (with coverage) | < 2 min |",
        "| `integration-tests` | Component interaction tests (with coverage) | < 3 min |",
        "| `regression-tests` | Bug-specific regression tests | < 1 min |",
        "| `behavioral-tests` | User workflow quality tests | < 2 min |",
        "| `performance-tests` | Timing-based tests (no coverage) | < 1 min |",
        "| `coverage-report` | Combine coverage data | - |",
        "| `showcase` | Run demo script | - |",
        "| `security-scan` | Static analysis + dependency audit | - |",
        "",
        "**Dependency Graph:**",
        "```",
        "validate-task-list    smoke-tests      showcase    security-scan",
        "      ‚îÇ                    ‚îÇ               ‚îÇ              ‚îÇ",
        "      ‚îÇ                    ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§",
        "      ‚îÇ                    ‚îÇ       ‚îÇ       ‚îÇ              ‚îÇ",
        "      ‚ñº                    ‚ñº       ‚ñº       ‚ñº              ‚ñº",
        "(continues)          unit-tests  integration  regression  behavioral",
        "                          ‚îÇ           ‚îÇ          ‚îÇ           ‚îÇ",
        "                          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò          ‚îÇ           ‚îÇ",
        "                                ‚ñº                ‚îÇ           ‚îÇ",
        "                         coverage-report        ‚ñº           ‚ñº",
        "                                           (parallel)   (parallel)",
        "```",
        "",
        "#### `.github/workflows/showcase.yml` - Demo Runner",
        "**Triggers:** Push to main, manual dispatch",
        "**Runs:** `python showcase.py`",
        "",
        "### GitHub Actions Used",
        "",
        "| Action | Version | Purpose |",
        "|--------|---------|---------|",
        "| `actions/checkout` | `v4` | Clone repository |",
        "| `actions/setup-python` | `v5` | Install Python 3.11 |",
        "| `actions/upload-artifact` | `v4` | Upload coverage data |",
        "| `actions/download-artifact` | `v4` | Download coverage data |",
        "",
        "---",
        "",
        "## 6. Development Scripts",
        "",
        "Located in `scripts/`:",
        "",
        "### Test & Quality",
        "",
        "| Script | Purpose | Subprocess Calls |",
        "|--------|---------|------------------|",
        "| `run_tests.py` | Test runner with categories | `pytest`, `coverage` |",
        "| `profile_full_analysis.py` | Performance profiling | None (pure Python) |",
        "| `validate_task_list.py` | CI task list validation | None |",
        "| `ci_task_report.py` | CI task reporting | None |",
        "",
        "### Codebase Indexing & Search",
        "",
        "| Script | Purpose | Subprocess Calls |",
        "|--------|---------|------------------|",
        "| `index_codebase.py` | Index codebase for semantic search | None |",
        "| `search_codebase.py` | Search indexed codebase | None |",
        "| `generate_ai_metadata.py` | Generate `.ai_meta` files | None |",
        "| `ask_codebase.py` | Natural language queries | None |",
        "",
        "### Task Management",
        "",
        "| Script | Purpose | Subprocess Calls |",
        "|--------|---------|------------------|",
        "| `task_utils.py` | Task CRUD operations | None |",
        "| `new_task.py` | Create new tasks | None |",
        "| `consolidate_tasks.py` | Merge task sessions | None |",
        "| `select_task.py` | Interactive task selection | None |",
        "| `suggest_tasks.py` | AI-powered task suggestions | `git` commands |",
        "| `migrate_legacy_tasks.py` | Migrate from TASK_LIST.md | None |",
        "| `ci_task_create.py` | Create tasks from CI | None |",
        "| `task_graph.py` | Visualize task dependencies | None |",
        "",
        "### Analysis & Exploration",
        "",
        "| Script | Purpose | Subprocess Calls |",
        "|--------|---------|------------------|",
        "| `analyze_louvain_resolution.py` | Analyze clustering resolution | None |",
        "| `analyze_cross_domain_bridges.py` | Find cross-domain connections | None |",
        "| `evaluate_cluster.py` | Evaluate clustering quality | None |",
        "| `find_similar.py` | Find similar code | None |",
        "| `explain_code.py` | Generate code explanations | None |",
        "| `suggest_related.py` | Suggest related content | None |",
        "| `corpus_health.py` | Check corpus health | None |",
        "",
        "### Context & Session",
        "",
        "| Script | Purpose | Subprocess Calls |",
        "|--------|---------|------------------|",
        "| `session_context.py` | Session context management | `git` commands |",
        "| `workflow.py` | Workflow execution | `python` (task scripts) |",
        "| `cli_wrappers.py` | CLI wrapper utilities | Various (via `run()`) |",
        "",
        "---",
        "",
        "## 7. Claude Code Integration",
        "",
        "### Skills (`.claude/skills/`)",
        "",
        "| Skill | Purpose | Allowed Tools |",
        "|-------|---------|---------------|",
        "| `task-manager` | Merge-friendly task management | Read, Bash, Write |",
        "| `corpus-indexer` | Index codebase for search | Bash |",
        "| `codebase-search` | Semantic code search | Read, Bash, Glob |",
        "| `ai-metadata` | View module metadata | Read, Bash, Glob |",
        "| `memory-manager` | Knowledge memory management | Read, Bash, Write |",
        "",
        "### Workflows (`.claude/workflows/`)",
        "",
        "| Workflow | Purpose | Tasks Created |",
        "|----------|---------|---------------|",
        "| `feature.yaml` | Feature implementation | design ‚Üí implement ‚Üí tests ‚Üí docs |",
        "| `bugfix.yaml` | Bug fixing | investigate ‚Üí fix ‚Üí test ‚Üí document |",
        "| `refactor.yaml` | Code refactoring | analyze ‚Üí refactor ‚Üí verify ‚Üí cleanup |",
        "",
        "### Commands (`.claude/commands/`)",
        "",
        "| Command | Purpose |",
        "|---------|---------|",
        "| `director.md` | Multi-agent orchestration prompt |",
        "| `knowledge-transfer.md` | Generate knowledge transfer docs |",
        "| `project/director-agent-continuation.md` | Agent continuation context |",
        "",
        "---",
        "",
        "## 8. MCP Server (Model Context Protocol)",
        "",
        "### Server Implementation",
        "**Location:** `cortical/mcp_server.py`",
        "**Class:** `CorticalMCPServer`",
        "**Entry Point:** `python -m cortical.mcp_server`",
        "",
        "### Configuration",
        "**Files:**",
        "- `mcp_config.json` - Production config",
        "- `mcp_config_example.json` - Example config",
        "",
        "### Environment Variables",
        "",
        "| Variable | Purpose | Default |",
        "|----------|---------|---------|",
        "| `CORTICAL_CORPUS_PATH` | Path to corpus pickle file | None (empty corpus) |",
        "| `CORTICAL_LOG_LEVEL` | Logging level | `INFO` |",
        "",
        "### MCP Tools Exposed",
        "",
        "| Tool | Description | Parameters |",
        "|------|-------------|------------|",
        "| `search` | Search documents for query | `query`, `top_n` |",
        "| `passages` | Retrieve RAG-ready passages | `query`, `top_n`, `chunk_size` |",
        "| `expand_query` | Get query expansion terms | `query`, `max_expansions` |",
        "| `corpus_stats` | Get corpus statistics | None |",
        "| `add_document` | Index new document | `doc_id`, `content`, `recompute` |",
        "",
        "### Dependencies",
        "- `mcp` package (`FastMCP` server framework)",
        "",
        "---",
        "",
        "## 9. Code Execution Mechanisms",
        "",
        "### Subprocess Execution",
        "",
        "| Location | Commands Executed | Purpose |",
        "|----------|-------------------|---------|",
        "| `cortical/cli_wrapper.py` | Any shell command | CLI wrapper framework |",
        "| `cortical/chunk_index.py` | None | Pure Python |",
        "| `cortical/proto/serialization.py` | `protoc` (optional) | Compile proto schema |",
        "| `scripts/run_tests.py` | `pytest`, `coverage` | Test execution |",
        "| `scripts/session_context.py` | `git` commands | Git context collection |",
        "| `scripts/suggest_tasks.py` | `git log`, `git diff` | Task suggestions |",
        "| `evaluation/evaluator.py` | Test commands | Evaluation framework |",
        "",
        "### CLI Wrapper Framework (`cortical/cli_wrapper.py`)",
        "",
        "The CLI wrapper provides:",
        "- **Simple execution:** `run(\"command\")` ‚Üí `subprocess.run()`",
        "- **Git context:** `run(\"cmd\", git=True)` ‚Üí Collects git state",
        "- **Session tracking:** `with Session()` ‚Üí Track multiple commands",
        "- **Hooks:** `@wrapper.on_success()` ‚Üí Post-execution callbacks",
        "",
        "```python",
        "# Simple usage",
        "from cortical.cli_wrapper import run",
        "result = run(\"pytest tests/\")",
        "",
        "# With session tracking",
        "with Session() as s:",
        "    s.run(\"pytest tests/\")",
        "    s.run(\"git add -A\")",
        "```",
        "",
        "### Git Hooks",
        "",
        "**Location:** `.git/hooks/` (sample files only, no active hooks)",
        "",
        "Available hook samples:",
        "- `pre-commit.sample`",
        "- `commit-msg.sample`",
        "- `pre-push.sample`",
        "- `prepare-commit-msg.sample`",
        "- `post-update.sample`",
        "",
        "**No custom hooks are active by default.**",
        "",
        "---",
        "",
        "## 10. External Services & APIs",
        "",
        "### GitHub APIs (via `gh` CLI in CI)",
        "- Used for: PR creation, issue management",
        "- Accessed through: GitHub Actions environment",
        "",
        "### No External HTTP APIs",
        "The codebase makes **no external HTTP requests**:",
        "- No `requests` library",
        "- No `urllib` usage for external APIs",
        "- No `aiohttp` or similar",
        "",
        "**Verification:**",
        "```bash",
        "grep -r \"import requests\\|import urllib\\|import http.client\\|import aiohttp\" cortical/ scripts/",
        "# Returns empty - confirmed zero external dependencies",
        "```",
        "",
        "---",
        "",
        "## 11. Security Tools",
        "",
        "Used in CI (`.github/workflows/ci.yml`):",
        "",
        "| Tool | Version | Purpose | Install |",
        "|------|---------|---------|---------|",
        "| `bandit` | Latest | SAST (Static Analysis) | `pip install bandit` |",
        "| `pip-audit` | Latest | Dependency vulnerability scanning | `pip install pip-audit` |",
        "| `detect-secrets` | Latest | Secret scanning | `pip install detect-secrets` |",
        "",
        "### Bandit Configuration",
        "- Severity: Medium and higher (`-ll`)",
        "- Skipped: B101 (assert statements)",
        "",
        "### Secret Scanning",
        "- Excludes: `.git/`, `*.pkl`, `*.json`, `tests/`",
        "",
        "---",
        "",
        "## 12. Test Frameworks & Runners",
        "",
        "### Test Organization",
        "",
        "```",
        "tests/",
        "‚îú‚îÄ‚îÄ smoke/           # Quick sanity checks (< 30s)",
        "‚îú‚îÄ‚îÄ unit/            # Fast isolated tests (< 1 min)",
        "‚îú‚îÄ‚îÄ integration/     # Component interaction (< 3 min)",
        "‚îú‚îÄ‚îÄ performance/     # Timing tests (< 1 min)",
        "‚îú‚îÄ‚îÄ regression/      # Bug-specific tests (< 1 min)",
        "‚îú‚îÄ‚îÄ behavioral/      # User workflow tests (< 2 min)",
        "‚îú‚îÄ‚îÄ fixtures/        # Shared test data",
        "‚îî‚îÄ‚îÄ *.py             # Legacy tests (still run)",
        "```",
        "",
        "### Test Fixtures (`tests/fixtures/`)",
        "",
        "| Fixture | Scope | Description |",
        "|---------|-------|-------------|",
        "| `small_processor` | session | 25-doc synthetic corpus |",
        "| `shared_processor` | session | Full samples/ corpus |",
        "| `fresh_processor` | function | Empty processor |",
        "| `small_corpus_docs` | function | Raw document dict |",
        "",
        "### Running Tests",
        "",
        "```bash",
        "# Quick feedback",
        "python scripts/run_tests.py smoke        # ~1s",
        "python scripts/run_tests.py quick        # smoke + unit",
        "",
        "# Before commit",
        "python scripts/run_tests.py precommit    # smoke + unit + integration",
        "",
        "# Full suite",
        "python -m pytest tests/ -v               # All tests",
        "",
        "# With coverage",
        "python -m coverage run -m pytest tests/",
        "python -m coverage report --include=\"cortical/*\"",
        "```",
        "",
        "### Coverage Configuration (`pyproject.toml`)",
        "",
        "```toml",
        "[tool.coverage.run]",
        "source = [\"cortical\"]",
        "branch = true",
        "omit = [\"*/tests/*\", \"*/__pycache__/*\", \"cortical/types.py\", \"cortical/cli_wrapper.py\"]",
        "",
        "[tool.coverage.report]",
        "exclude_lines = [",
        "    \"pragma: no cover\",",
        "    \"def __repr__\",",
        "    \"raise NotImplementedError\",",
        "    \"if TYPE_CHECKING:\",",
        "    \"if __name__ == .__main__.:\",",
        "]",
        "```",
        "",
        "**Coverage Threshold:** 89% (enforced in CI)",
        "",
        "---",
        "",
        "## Summary Tables",
        "",
        "### All Python Packages",
        "",
        "| Category | Package | Required | Purpose |",
        "|----------|---------|----------|---------|",
        "| Runtime | (none) | - | Zero dependencies |",
        "| Dev | coverage | ‚úì | Test coverage |",
        "| Dev | pytest | ‚úì | Test framework |",
        "| Dev | mcp | ‚úì | MCP server tests |",
        "| Dev | pyyaml | ‚úì | Workflow parsing |",
        "| Optional | protobuf | ‚úó | Cross-language serialization |",
        "| Optional | grpcio-tools | ‚úó | Proto compilation |",
        "| Security | bandit | CI only | SAST |",
        "| Security | pip-audit | CI only | Dependency audit |",
        "| Security | detect-secrets | CI only | Secret scanning |",
        "",
        "### All Code Execution Entry Points",
        "",
        "| Entry Point | Type | Executes |",
        "|-------------|------|----------|",
        "| `python -m cortical.mcp_server` | MCP Server | Corpus operations |",
        "| `python scripts/run_tests.py` | Script | pytest/unittest |",
        "| `python scripts/index_codebase.py` | Script | Indexing (pure Python) |",
        "| `python scripts/search_codebase.py` | Script | Search (pure Python) |",
        "| `python scripts/workflow.py` | Script | Task scripts |",
        "| `cortical.cli_wrapper.run()` | Function | Any shell command |",
        "| GitHub Actions | CI | pytest, coverage, security tools |",
        "",
        "### Files That Use Subprocess",
        "",
        "```",
        "cortical/cli_wrapper.py       # General CLI wrapper",
        "cortical/proto/serialization.py  # protoc (optional)",
        "scripts/run_tests.py          # pytest, coverage",
        "scripts/session_context.py    # git commands",
        "scripts/suggest_tasks.py      # git commands",
        "evaluation/evaluator.py       # test commands",
        "```",
        "",
        "---",
        "",
        "## Appendix: Environment Variables",
        "",
        "| Variable | Used In | Purpose |",
        "|----------|---------|---------|",
        "| `CORTICAL_CORPUS_PATH` | mcp_server.py | Corpus file path |",
        "| `CORTICAL_LOG_LEVEL` | mcp_server.py | Logging level |",
        "| `GITHUB_STEP_SUMMARY` | CI | GitHub Actions summary |",
        "",
        "---",
        "",
        "*This document was generated by analyzing the project structure, configuration files, CI workflows, and source code.*"
      ],
      "lines_removed": [],
      "context_before": [],
      "context_after": [],
      "change_type": "add"
    },
    {
      "file": "docs/PATTERN_DETECTION_GUIDE.md",
      "function": null,
      "start_line": 0,
      "lines_added": [
        "# Code Pattern Detection Guide",
        "",
        "## Overview",
        "",
        "The Cortical Text Processor now includes comprehensive code pattern detection capabilities. This feature can identify 32+ common programming patterns across 9 categories, making it easier to understand and analyze codebases.",
        "",
        "## Supported Patterns",
        "",
        "### Creational Patterns",
        "- **Singleton**: Single instance control patterns",
        "- **Factory**: Object creation patterns",
        "- **Builder**: Fluent construction patterns",
        "",
        "### Structural Patterns",
        "- **Decorator**: Wrapping behavior patterns",
        "- **Adapter**: Interface conversion patterns",
        "- **Proxy**: Access control patterns",
        "",
        "### Behavioral Patterns",
        "- **Context Manager**: Resource management (with/as, __enter__/__exit__)",
        "- **Generator**: Lazy iteration (yield)",
        "- **Iterator**: Custom iteration (__iter__/__next__)",
        "- **Observer**: Event notification patterns",
        "- **Strategy**: Algorithm selection patterns",
        "",
        "### Concurrency Patterns",
        "- **Async/Await**: Asynchronous code patterns",
        "- **Thread Safety**: Locks and synchronization",
        "- **Concurrent Futures**: Thread/process pools",
        "",
        "### Error Handling",
        "- **Error Handling**: Try/except blocks",
        "- **Custom Exception**: Custom exception classes",
        "- **Assertion**: Runtime checks",
        "",
        "### Python Idioms",
        "- **Property Decorator**: Computed attributes (@property)",
        "- **Dataclass**: Structured data (@dataclass)",
        "- **Slots**: Memory optimization (__slots__)",
        "- **Magic Methods**: Operator overloading (__repr__, __eq__, etc.)",
        "- **Comprehension**: List/dict/set comprehensions",
        "- **Unpacking**: *args, **kwargs patterns",
        "",
        "### Testing Patterns",
        "- **Unittest Class**: unittest.TestCase classes",
        "- **Pytest Test**: pytest test functions",
        "- **Mock Usage**: unittest.mock patterns",
        "- **Fixture**: pytest fixtures",
        "",
        "### Functional Programming",
        "- **Lambda**: Anonymous functions",
        "- **Map/Filter/Reduce**: Functional operations",
        "- **Partial Application**: Currying patterns",
        "",
        "### Type Annotations",
        "- **Type Hints**: Static typing annotations",
        "- **TYPE_CHECKING**: Import-time type guards",
        "",
        "## Quick Start",
        "",
        "```python",
        "from cortical.processor import CorticalTextProcessor",
        "",
        "# Create processor and add code",
        "processor = CorticalTextProcessor()",
        "processor.process_document('mycode.py', \"\"\"",
        "async def fetch_users():",
        "    try:",
        "        users = await api.get_users()",
        "        for user in users:",
        "            yield user",
        "    except Exception as e:",
        "        raise FetchError(e)",
        "\"\"\")",
        "",
        "# Detect patterns in the document",
        "patterns = processor.detect_patterns('mycode.py')",
        "print(patterns)",
        "# Output: {",
        "#     'async_await': [2, 4],",
        "#     'error_handling': [3, 7],",
        "#     'generator': [5],",
        "#     'custom_exception': [7]",
        "# }",
        "```",
        "",
        "## Usage Examples",
        "",
        "### 1. Detect Patterns in a Single Document",
        "",
        "```python",
        "patterns = processor.detect_patterns('file.py')",
        "",
        "for pattern_name, line_numbers in patterns.items():",
        "    print(f\"{pattern_name}: found on lines {line_numbers}\")",
        "```",
        "",
        "### 2. Get Pattern Summary",
        "",
        "```python",
        "summary = processor.get_pattern_summary('file.py')",
        "# Returns: {'async_await': 3, 'generator': 2, ...}",
        "",
        "for pattern, count in summary.items():",
        "    print(f\"{pattern}: {count} occurrences\")",
        "```",
        "",
        "### 3. Generate Human-Readable Report",
        "",
        "```python",
        "# Without line numbers",
        "report = processor.format_pattern_report('file.py')",
        "print(report)",
        "",
        "# With line numbers",
        "report = processor.format_pattern_report('file.py', show_lines=True)",
        "print(report)",
        "```",
        "",
        "### 4. Corpus-Wide Pattern Analysis",
        "",
        "```python",
        "# Detect patterns across all documents",
        "corpus_patterns = processor.detect_patterns_in_corpus()",
        "",
        "for doc_id, patterns in corpus_patterns.items():",
        "    print(f\"{doc_id}: {list(patterns.keys())}\")",
        "",
        "# Get corpus statistics",
        "stats = processor.get_corpus_pattern_statistics()",
        "print(f\"Total documents: {stats['total_documents']}\")",
        "print(f\"Patterns found: {stats['patterns_found']}\")",
        "print(f\"Most common: {stats['most_common_pattern']}\")",
        "```",
        "",
        "### 5. Filter for Specific Patterns",
        "",
        "```python",
        "# Only detect async patterns",
        "async_patterns = processor.detect_patterns(",
        "    'file.py',",
        "    patterns=['async_await', 'concurrent_futures']",
        ")",
        "",
        "# Find all files with a specific pattern",
        "corpus_patterns = processor.detect_patterns_in_corpus(",
        "    patterns=['singleton']",
        ")",
        "singleton_files = [",
        "    doc_id for doc_id, patterns in corpus_patterns.items()",
        "    if 'singleton' in patterns",
        "]",
        "```",
        "",
        "### 6. List Available Patterns",
        "",
        "```python",
        "# List all pattern names",
        "patterns = processor.list_available_patterns()",
        "print(f\"Total patterns: {len(patterns)}\")",
        "",
        "# List all categories",
        "categories = processor.list_pattern_categories()",
        "print(f\"Categories: {', '.join(categories)}\")",
        "```",
        "",
        "### 7. Pattern Metadata",
        "",
        "```python",
        "from cortical.patterns import (",
        "    get_pattern_description,",
        "    get_pattern_category,",
        "    list_patterns_by_category",
        ")",
        "",
        "# Get pattern info",
        "desc = get_pattern_description('singleton')",
        "cat = get_pattern_category('singleton')",
        "",
        "# List patterns in a category",
        "creational = list_patterns_by_category('creational')",
        "# Returns: ['builder', 'factory', 'singleton']",
        "```",
        "",
        "## Advanced Usage",
        "",
        "### Finding Similar Code Patterns",
        "",
        "```python",
        "# Find all files using async patterns",
        "corpus_patterns = processor.detect_patterns_in_corpus(",
        "    patterns=['async_await', 'concurrent_futures']",
        ")",
        "",
        "async_files = {}",
        "for doc_id, patterns in corpus_patterns.items():",
        "    if any(p in patterns for p in ['async_await', 'concurrent_futures']):",
        "        async_files[doc_id] = patterns",
        "",
        "print(f\"Found {len(async_files)} files using async patterns\")",
        "```",
        "",
        "### Pattern-Based Code Search",
        "",
        "```python",
        "# Find all factory implementations",
        "factories = processor.detect_patterns_in_corpus(patterns=['factory'])",
        "",
        "for doc_id, patterns in factories.items():",
        "    if 'factory' in patterns:",
        "        print(f\"{doc_id}: Factory pattern on lines {patterns['factory']}\")",
        "```",
        "",
        "### Code Quality Analysis",
        "",
        "```python",
        "stats = processor.get_corpus_pattern_statistics()",
        "",
        "# Find documents with good test coverage",
        "corpus_patterns = processor.detect_patterns_in_corpus(",
        "    patterns=['pytest_test', 'unittest_class', 'mock_usage']",
        ")",
        "",
        "test_files = [",
        "    doc_id for doc_id, patterns in corpus_patterns.items()",
        "    if any(p in patterns for p in ['pytest_test', 'unittest_class'])",
        "]",
        "",
        "print(f\"Test files: {len(test_files)}\")",
        "```",
        "",
        "## Integration with Search",
        "",
        "Pattern detection works seamlessly with the existing search capabilities:",
        "",
        "```python",
        "# Index your codebase",
        "for filepath in get_python_files():",
        "    with open(filepath) as f:",
        "        processor.process_document(filepath, f.read())",
        "",
        "# Find files and their patterns",
        "results = processor.find_documents_for_query(\"authentication\")",
        "",
        "for doc_id, score in results:",
        "    patterns = processor.detect_patterns(doc_id)",
        "    print(f\"{doc_id} (score: {score:.2f})\")",
        "    if patterns:",
        "        print(f\"  Patterns: {', '.join(patterns.keys())}\")",
        "```",
        "",
        "## Pattern Categories",
        "",
        "The 9 pattern categories are:",
        "",
        "1. **behavioral** - Behavioral design patterns",
        "2. **concurrency** - Async/threading patterns",
        "3. **creational** - Object creation patterns",
        "4. **error_handling** - Error handling patterns",
        "5. **functional** - Functional programming patterns",
        "6. **idiom** - Python-specific idioms",
        "7. **structural** - Structural design patterns",
        "8. **testing** - Testing patterns",
        "9. **typing** - Type annotation patterns",
        "",
        "## Performance Notes",
        "",
        "- Pattern detection uses regex-based matching (no AST parsing)",
        "- Very fast: can analyze thousands of lines per second",
        "- Line numbers are accurately tracked for all matches",
        "- Multi-line patterns are supported",
        "",
        "## Demo Script",
        "",
        "Run the included demo script to see pattern detection in action:",
        "",
        "```bash",
        "python demo_pattern_detection.py",
        "```",
        "",
        "This will demonstrate:",
        "- Pattern detection across multiple files",
        "- Report generation",
        "- Corpus-wide statistics",
        "- Pattern filtering",
        "- Category grouping",
        "",
        "## Module Reference",
        "",
        "### Main Functions",
        "",
        "- `detect_patterns(doc_id, patterns=None)` - Detect patterns in a document",
        "- `detect_patterns_in_corpus(patterns=None)` - Detect in all documents",
        "- `get_pattern_summary(doc_id)` - Count occurrences per pattern",
        "- `get_corpus_pattern_statistics()` - Corpus-wide statistics",
        "- `format_pattern_report(doc_id, show_lines=False)` - Human-readable report",
        "- `list_available_patterns()` - List all pattern names",
        "- `list_pattern_categories()` - List all categories",
        "",
        "### Direct Module Access",
        "",
        "```python",
        "from cortical.patterns import (",
        "    detect_patterns_in_text,",
        "    detect_patterns_in_documents,",
        "    get_pattern_description,",
        "    get_pattern_category,",
        "    format_pattern_report,",
        "    list_all_patterns,",
        "    list_all_categories,",
        ")",
        "",
        "# Analyze text directly without a processor",
        "code = \"async def fetch(): pass\"",
        "patterns = detect_patterns_in_text(code)",
        "```",
        "",
        "## Implementation Notes",
        "",
        "The pattern detection is implemented in:",
        "- `cortical/patterns.py` - Core pattern detection logic (32 patterns)",
        "- `cortical/processor/introspection.py` - Processor integration",
        "- `tests/unit/test_patterns.py` - Comprehensive test suite",
        "",
        "All patterns are defined with:",
        "- Regex pattern (for matching)",
        "- Description (human-readable)",
        "- Category (for grouping)"
      ],
      "lines_removed": [],
      "context_before": [],
      "context_after": [],
      "change_type": "add"
    },
    {
      "file": "docs/benchmarks.md",
      "function": null,
      "start_line": 0,
      "lines_added": [
        "# Performance Benchmarks",
        "",
        "This document provides real performance numbers for the Cortical Text Processor, measured on representative workloads.",
        "",
        "**Test Environment:**",
        "- Platform: Linux 4.4.0",
        "- Python: 3.x",
        "- Date: December 2025",
        "",
        "---",
        "",
        "## Quick Reference",
        "",
        "| Operation | Small Corpus (25 docs) | Real Codebase (151 files) |",
        "|-----------|------------------------|---------------------------|",
        "| Document processing | 0.31 ms/doc | 26.45 ms/doc |",
        "| compute_all() | 141 ms | 49.4 s |",
        "| Standard search | 0.13 ms | 1.22 ms |",
        "| Fast search | 0.06 ms | 0.66 ms |",
        "| Passage retrieval | 0.36 ms | 64.9 ms |",
        "",
        "---",
        "",
        "## Small Corpus Benchmarks (25 Documents)",
        "",
        "### Corpus Profile",
        "| Metric | Value |",
        "|--------|-------|",
        "| Documents | 25 |",
        "| Tokens (Layer 0) | 460 |",
        "| Bigrams (Layer 1) | 592 |",
        "| Concepts (Layer 2) | 31 |",
        "| L0 Connections | 3,323 |",
        "",
        "### Document Processing",
        "",
        "| Metric | Time |",
        "|--------|------|",
        "| Total (25 docs) | 7.8 ms |",
        "| Average per document | 0.31 ms |",
        "| Min per document | 0.22 ms |",
        "| Max per document | 0.58 ms |",
        "",
        "### Compute Phases",
        "",
        "Individual phase timings reveal where processing time is spent:",
        "",
        "| Phase | Time (ms) | % of Total |",
        "|-------|-----------|------------|",
        "| bigram_connections | 106.9 | 68.6% |",
        "| concept_clusters | 14.8 | 9.5% |",
        "| pagerank | 13.1 | 8.4% |",
        "| activation_propagation | 12.4 | 8.0% |",
        "| graph_embeddings | 4.7 | 3.0% |",
        "| doc_connections | 3.5 | 2.2% |",
        "| tfidf | 0.4 | 0.2% |",
        "| **TOTAL** | **155.8** | **100%** |",
        "",
        "Full `compute_all()` pipeline: **140.9 ms**",
        "",
        "### Query Operations",
        "",
        "| Operation | Avg (ms) | Min (ms) | Max (ms) |",
        "|-----------|----------|----------|----------|",
        "| Standard search | 0.13 | 0.06 | 0.25 |",
        "| Fast search | 0.06 | 0.05 | 0.08 |",
        "| Query expansion | 0.05 | 0.03 | 0.07 |",
        "| Passage retrieval | 0.36 | 0.23 | 0.62 |",
        "",
        "**Fast search speedup: 2.0x** over standard search",
        "",
        "### Persistence",
        "",
        "| Operation | Time | Size |",
        "|-----------|------|------|",
        "| Save | 137.1 ms | 1.33 MB |",
        "| Load | 45.4 ms | - |",
        "",
        "---",
        "",
        "## Real Codebase Benchmarks (151 Python Files)",
        "",
        "Benchmarked using the actual `cortical/`, `scripts/`, and `tests/` directories.",
        "",
        "### Corpus Profile",
        "| Metric | Value |",
        "|--------|-------|",
        "| Files | 151 |",
        "| Characters | 2,949,713 |",
        "| Lines | 83,272 |",
        "| Tokens (Layer 0) | 11,557 |",
        "| Bigrams (Layer 1) | 84,978 |",
        "| Concepts (Layer 2) | 54 |",
        "| L0 Connections | 388,178 |",
        "",
        "### Processing Times",
        "",
        "| Operation | Time |",
        "|-----------|------|",
        "| Document processing (total) | 3,993.8 ms |",
        "| Per-document average | 26.45 ms |",
        "| compute_all() | 49,437.6 ms (~49 s) |",
        "",
        "### Query Performance",
        "",
        "| Operation | Average Time |",
        "|-----------|--------------|",
        "| Standard search | 1.22 ms |",
        "| Fast search | 0.66 ms |",
        "| Passage retrieval | 64.94 ms |",
        "| Intent search | 0.14 ms |",
        "",
        "**Fast search speedup: 1.8x** over standard search",
        "",
        "### Persistence",
        "",
        "| Operation | Time | Size |",
        "|-----------|------|------|",
        "| Save | 21.9 s | 212.35 MB |",
        "| Load | 16.7 s | - |",
        "",
        "---",
        "",
        "## Scaling Characteristics",
        "",
        "How performance scales with corpus size:",
        "",
        "| Documents | Tokens | Process (ms) | Compute (ms) | Query (ms) |",
        "|-----------|--------|--------------|--------------|------------|",
        "| 10 | 36 | 11.9 | 4.5 | 0.04 |",
        "| 25 | 36 | 26.6 | 5.2 | 0.05 |",
        "| 50 | 36 | 53.3 | 7.8 | 0.07 |",
        "| 100 | 36 | 109.0 | 17.3 | 0.13 |",
        "| 200 | 36 | 215.3 | 44.9 | 0.22 |",
        "",
        "**Observations:**",
        "- Document processing scales linearly (O(n))",
        "- Query time scales sub-linearly due to indexed lookups",
        "- Compute time scales slightly super-linearly due to connection building",
        "",
        "---",
        "",
        "## Performance Thresholds",
        "",
        "These thresholds are used in CI to catch performance regressions:",
        "",
        "| Operation | Threshold | Notes |",
        "|-----------|-----------|-------|",
        "| compute_all() (25 docs) | 5,000 ms | Generous for CI variability |",
        "| propagate_activation | 1,000 ms | Per-phase limit |",
        "| compute_importance | 1,000 ms | PageRank phase |",
        "| compute_tfidf | 1,000 ms | TF-IDF phase |",
        "| compute_bigram_connections | 2,000 ms | Most expensive phase |",
        "| build_concept_clusters | 2,000 ms | Louvain clustering |",
        "| compute_graph_embeddings | 2,000 ms | Embedding phase |",
        "| Single query | 200 ms | Interactive use |",
        "| Query expansion | 100 ms | Per expansion |",
        "| Passage retrieval | 500 ms | Including chunking |",
        "",
        "---",
        "",
        "## Bottleneck Analysis",
        "",
        "### Primary Bottleneck: Bigram Connections",
        "",
        "On small corpora, `compute_bigram_connections` dominates at **68.6%** of compute time. This is due to O(n¬≤) complexity when building co-occurrence connections.",
        "",
        "**Mitigation parameters:**",
        "```python",
        "CorticalConfig(",
        "    max_bigrams_per_term=100,   # Limits per-term connections",
        "    max_bigrams_per_doc=500,    # Limits per-document processing",
        ")",
        "```",
        "",
        "### Secondary Bottleneck: Semantic Extraction",
        "",
        "On larger corpora, semantic extraction can become expensive due to similarity computation across all term pairs.",
        "",
        "**Mitigation parameters:**",
        "```python",
        "CorticalConfig(",
        "    max_similarity_pairs=100000,  # Cap total similarity computations",
        "    min_context_keys=3,           # Require minimum context overlap",
        ")",
        "```",
        "",
        "### Lessons Learned",
        "",
        "From profiling sessions (documented in `samples/performance_profiling_process.txt`):",
        "",
        "1. **Profile before optimizing** - The obvious bottleneck (Louvain clustering) was actually fast (2.2s); the real culprits were bigram connections and semantics",
        "2. **O(n¬≤) patterns explode** - Common terms like \"self\" creating millions of pairs",
        "3. **Parameter limits are essential** - Trading completeness for tractability",
        "",
        "---",
        "",
        "## Running Benchmarks",
        "",
        "### Quick Performance Check",
        "```bash",
        "# Run performance tests (without coverage)",
        "python -m pytest tests/performance/ -v --no-cov",
        "```",
        "",
        "### Profile Full Analysis",
        "```bash",
        "# Profile all compute phases",
        "python scripts/profile_full_analysis.py",
        "",
        "# Profile specific phase",
        "python scripts/profile_full_analysis.py --phase louvain",
        "python scripts/profile_full_analysis.py --phase semantics",
        "python scripts/profile_full_analysis.py --phase bigram",
        "",
        "# With custom timeout",
        "python scripts/profile_full_analysis.py --timeout 60",
        "```",
        "",
        "### Custom Benchmarks",
        "",
        "```python",
        "from cortical import CorticalTextProcessor",
        "import time",
        "",
        "processor = CorticalTextProcessor(enable_metrics=True)",
        "",
        "# Process documents",
        "for doc_id, content in documents.items():",
        "    processor.process_document(doc_id, content)",
        "",
        "# Run compute phases",
        "processor.compute_all(verbose=True)  # Shows phase timings",
        "",
        "# Get metrics summary",
        "print(processor.get_metrics_summary())",
        "```",
        "",
        "---",
        "",
        "## Optimizing for Your Use Case",
        "",
        "### High-Throughput Document Processing",
        "",
        "```python",
        "# Use batch processing",
        "processor.add_documents_batch(doc_dict)  # More efficient than individual adds",
        "",
        "# Skip expensive phases if not needed",
        "processor.compute_tfidf()  # Just TF-IDF",
        "processor.compute_importance()  # Just PageRank",
        "# Skip: bigram_connections, concept_clusters, semantics",
        "```",
        "",
        "### Low-Latency Search",
        "",
        "```python",
        "# Use fast search for interactive queries",
        "results = processor.fast_find_documents(query, top_n=10)",
        "",
        "# Pre-build search index for repeated queries",
        "index = processor.build_search_index()",
        "results = processor.search_with_index(query, index)",
        "",
        "# Cache query expansions",
        "expanded = processor.expand_query_cached(query)",
        "```",
        "",
        "### Memory-Constrained Environments",
        "",
        "```python",
        "# Use streaming document processing",
        "for doc_id, content in large_corpus:",
        "    processor.add_document_incremental(doc_id, content, recompute='none')",
        "",
        "# Compute in batches",
        "processor.compute_tfidf()  # Lightweight",
        "processor.compute_importance()  # Moderate",
        "# Defer expensive operations",
        "```",
        "",
        "### Git-Friendly Collaborative Indexing",
        "",
        "```bash",
        "# Use chunk-based storage for team workflows",
        "python scripts/index_codebase.py --incremental --use-chunks",
        "",
        "# Periodic compaction",
        "python scripts/index_codebase.py --compact --use-chunks",
        "```",
        "",
        "---",
        "",
        "## Historical Performance Fixes",
        "",
        "| Date | Issue | Before | After | Fix |",
        "|------|-------|--------|-------|-----|",
        "| 2025-12-11 | bigram_connections timeout | 20.85s timeout | 10.79s | `max_bigrams_per_term=100` |",
        "| 2025-12-11 | semantics timeout | 30.05s timeout | 5.56s | `max_similarity_pairs=100000` |",
        "| 2025-12-11 | louvain (not a bottleneck) | 2.2s | 2.2s | No change needed |",
        "",
        "---",
        "",
        "## Notes",
        "",
        "- All timings measured without coverage instrumentation (coverage adds ~10x overhead)",
        "- Timings will vary based on hardware, Python version, and corpus characteristics",
        "- Query performance depends heavily on corpus vocabulary and connection density",
        "- Persistence times are I/O bound and vary with storage medium"
      ],
      "lines_removed": [],
      "context_before": [],
      "context_after": [],
      "change_type": "add"
    },
    {
      "file": "docs/knowledge-transfer-bm25-optimization.md",
      "function": null,
      "start_line": 0,
      "lines_added": [
        "# Knowledge Transfer: BM25 Implementation & Performance Optimization",
        "",
        "**Date:** 2025-12-15",
        "**Author:** Claude (AI Assistant)",
        "**Branch:** `claude/explore-tfidf-alternatives-FKYpq`",
        "**Status:** Ready for PR",
        "",
        "---",
        "",
        "## Executive Summary",
        "",
        "This document captures the complete knowledge transfer for the BM25 scoring algorithm implementation and performance optimizations made to the Cortical Text Processor. The changes improve `compute_all()` performance by **34.5%** while adding a new hybrid search algorithm (GB-BM25).",
        "",
        "---",
        "",
        "## Table of Contents",
        "",
        "1. [Background & Motivation](#background--motivation)",
        "2. [BM25 Implementation](#bm25-implementation)",
        "3. [Performance Optimizations](#performance-optimizations)",
        "4. [Graph-Boosted Search (GB-BM25)](#graph-boosted-search-gb-bm25)",
        "5. [Code Locations](#code-locations)",
        "6. [Configuration Reference](#configuration-reference)",
        "7. [Testing Strategy](#testing-strategy)",
        "8. [Performance Benchmarks](#performance-benchmarks)",
        "9. [Trade-offs & Limitations](#trade-offs--limitations)",
        "10. [Future Work](#future-work)",
        "11. [Troubleshooting Guide](#troubleshooting-guide)",
        "",
        "---",
        "",
        "## Background & Motivation",
        "",
        "### Why Replace TF-IDF?",
        "",
        "TF-IDF has limitations for code search:",
        "",
        "1. **No term frequency saturation**: TF-IDF keeps increasing linearly with term frequency, over-weighting repeated terms",
        "2. **No document length normalization**: Long files get unfairly boosted",
        "3. **Single document IDF issue**: `log(N/df)` returns 0 when a term appears in only one document",
        "",
        "### Why BM25?",
        "",
        "BM25 (Best Match 25) addresses these issues:",
        "",
        "1. **Term frequency saturation** via `k1` parameter: Diminishing returns for repeated terms",
        "2. **Document length normalization** via `b` parameter: Adjusts scores based on document length",
        "3. **Better IDF formula**: `log((N - df + 0.5) / (df + 0.5) + 1)` never returns 0",
        "",
        "### Research Process",
        "",
        "Alternatives considered:",
        "- **BM25** (selected) - Best balance of effectiveness and simplicity",
        "- **BM25F** - Field-weighted variant, more complex, deferred for future",
        "- **Language Models with Dirichlet Smoothing** - More complex, less interpretable",
        "- **DFR (Divergence From Randomness)** - More parameters, harder to tune",
        "- **Pivoted Length Normalization** - Less widely adopted",
        "",
        "---",
        "",
        "## BM25 Implementation",
        "",
        "### Core Algorithm",
        "",
        "Located in `cortical/analysis.py`:",
        "",
        "```python",
        "def _bm25_core(",
        "    term_stats: Dict[str, Tuple[int, int, Dict[str, int]]],",
        "    num_docs: int,",
        "    doc_lengths: Dict[str, int],",
        "    avg_doc_length: float,",
        "    k1: float = 1.2,",
        "    b: float = 0.75",
        ") -> Dict[str, Tuple[float, Dict[str, float]]]:",
        "```",
        "",
        "**BM25 Formula:**",
        "",
        "```",
        "score(D, Q) = Œ£ IDF(qi) * (f(qi, D) * (k1 + 1)) / (f(qi, D) + k1 * (1 - b + b * |D|/avgdl))",
        "```",
        "",
        "Where:",
        "- `f(qi, D)` = frequency of term qi in document D",
        "- `|D|` = length of document D (in tokens)",
        "- `avgdl` = average document length across corpus",
        "- `k1` = term frequency saturation parameter (default 1.2)",
        "- `b` = length normalization parameter (default 0.75)",
        "",
        "**IDF Formula:**",
        "",
        "```",
        "IDF(qi) = log((N - n(qi) + 0.5) / (n(qi) + 0.5) + 1)",
        "```",
        "",
        "Where:",
        "- `N` = total number of documents",
        "- `n(qi)` = number of documents containing term qi",
        "",
        "### Document Length Tracking",
        "",
        "New fields added to processor (`cortical/processor/core.py`):",
        "",
        "```python",
        "self.doc_lengths: Dict[str, int] = {}  # doc_id -> token count",
        "self.avg_doc_length: float = 0.0       # Average across corpus",
        "```",
        "",
        "Updated in `process_document()` (`cortical/processor/documents.py`):",
        "",
        "```python",
        "self.doc_lengths[doc_id] = len(tokens)",
        "self.avg_doc_length = sum(self.doc_lengths.values()) / len(self.doc_lengths)",
        "```",
        "",
        "### Persistence",
        "",
        "Document lengths are saved/loaded with the processor state (`cortical/processor/persistence_api.py`):",
        "",
        "```python",
        "# Save",
        "metadata = {",
        "    'doc_lengths': self.doc_lengths,",
        "    'avg_doc_length': self.avg_doc_length,",
        "    ...",
        "}",
        "",
        "# Load (with backward compatibility)",
        "processor.doc_lengths = metadata.get('doc_lengths', {})",
        "processor.avg_doc_length = metadata.get('avg_doc_length', 0.0)",
        "```",
        "",
        "### Backward Compatibility",
        "",
        "- Old pickle files without `doc_lengths` are handled gracefully",
        "- `scoring_algorithm='tfidf'` still works for legacy behavior",
        "- Scores are stored in the same `col.tfidf` and `col.tfidf_per_doc` fields",
        "",
        "---",
        "",
        "## Performance Optimizations",
        "",
        "### Bottleneck Analysis",
        "",
        "Initial profiling revealed the real bottlenecks:",
        "",
        "| Phase | Before | After | Reduction |",
        "|-------|--------|-------|-----------|",
        "| `compute_bigram_connections` | 6,067ms | 3,055ms | 50% |",
        "| `extract_corpus_semantics` | 2,448ms | ~2,400ms | ~2% |",
        "| `compute_tfidf` (BM25) | 8.5ms | 6.8ms | 20% |",
        "| **Total `compute_all()`** | **7,546ms** | **4,946ms** | **34.5%** |",
        "",
        "**Key insight**: BM25 itself was already fast. The real bottlenecks were in bigram connections and semantic extraction.",
        "",
        "### Optimization 1: Inverted Index for Co-occurrence",
        "",
        "**Problem**: Original code used O(n¬≤) sparse matrix multiplication.",
        "",
        "**Solution**: Replace with O(n) inverted index approach.",
        "",
        "**Before** (`cortical/analysis.py`):",
        "```python",
        "# O(n¬≤) matrix multiplication",
        "doc_term_matrix = SparseMatrix(len(doc_to_row), len(bigrams))",
        "cooccur_matrix = doc_term_matrix.multiply_transpose()  # SLOW!",
        "```",
        "",
        "**After**:",
        "```python",
        "# O(n) inverted index",
        "doc_to_bigrams: Dict[str, List[Minicolumn]] = defaultdict(list)",
        "for bigram in bigrams:",
        "    for doc_id in bigram.document_ids:",
        "        doc_to_bigrams[doc_id].append(bigram)",
        "",
        "# Process each document's pairs directly",
        "for doc_id, doc_bigrams in doc_to_bigrams.items():",
        "    for i, b1 in enumerate(doc_bigrams):",
        "        for b2 in doc_bigrams[i+1:]:",
        "            # Connect pair",
        "```",
        "",
        "### Optimization 2: Importance-Based Filtering",
        "",
        "**Problem**: Too many low-value connections computed.",
        "",
        "**Solution**: Filter to important bigrams only (TF-IDF ‚â• 25th percentile).",
        "",
        "```python",
        "# Compute importance threshold",
        "tfidf_values = [b.tfidf for b in bigrams if b.tfidf > 0]",
        "importance_threshold = sorted(tfidf_values)[len(tfidf_values) // 4]",
        "",
        "# Filter to important bigrams",
        "important_bigrams = [b for b in doc_bigrams if b.tfidf >= importance_threshold]",
        "```",
        "",
        "**Impact**: Reduces pair count quadratically (filtering 75% of bigrams reduces pairs by ~94%).",
        "",
        "### Optimization 3: Early Termination",
        "",
        "**Problem**: Bigrams at connection limit still being processed.",
        "",
        "**Solution**: Skip bigrams that have reached `max_connections_per_bigram`.",
        "",
        "```python",
        "for i, b1 in enumerate(important_bigrams):",
        "    if connection_counts[b1.id] >= max_connections_per_bigram:",
        "        continue  # Skip - already at limit",
        "```",
        "",
        "### Optimization 4: Semantic Similarity Term Limiting",
        "",
        "**Problem**: O(n¬≤) similarity computation for all terms.",
        "",
        "**Solution**: Limit to top N terms by TF-IDF importance.",
        "",
        "```python",
        "# Sort by importance and limit",
        "filtered_terms.sort(key=lambda t: tfidf_scores.get(t, 0), reverse=True)",
        "max_terms = int(math.sqrt(max_similarity_pairs * 2))",
        "filtered_terms = filtered_terms[:max_terms]",
        "```",
        "",
        "---",
        "",
        "## Graph-Boosted Search (GB-BM25)",
        "",
        "### Concept",
        "",
        "A hybrid scoring algorithm combining BM25 with graph signals for improved code search.",
        "",
        "### Location",
        "",
        "`cortical/query/search.py:graph_boosted_search()`",
        "",
        "### Algorithm",
        "",
        "**Phase 1: Base BM25 Scoring**",
        "```python",
        "for term, term_weight in query_terms.items():",
        "    col = layer0.get_minicolumn(term)",
        "    if col:",
        "        for doc_id in col.document_ids:",
        "            tfidf = col.tfidf_per_doc.get(doc_id, col.tfidf)",
        "            doc_scores[doc_id] += tfidf * term_weight",
        "```",
        "",
        "**Phase 2: PageRank Boost**",
        "```python",
        "term_pagerank = getattr(col, 'pagerank', 0.0) or 0.0",
        "doc_pagerank_sum[doc_id] += term_pagerank * term_weight",
        "```",
        "",
        "**Phase 3: Proximity Boost**",
        "```python",
        "# Check if query terms are connected in the graph",
        "conn_weight = col1.lateral_connections.get(col2.id, 0.0)",
        "if conn_weight > 0:",
        "    for doc_id in col1.document_ids & col2.document_ids:",
        "        proximity_scores[doc_id] += conn_weight",
        "```",
        "",
        "**Phase 4: Coverage Boost**",
        "```python",
        "coverage = len(doc_term_matches[doc_id]) / num_query_terms",
        "coverage_mult = 0.5 + coverage  # Range: 0.5 to 1.5",
        "```",
        "",
        "**Final Score Combination**:",
        "```python",
        "combined = (",
        "    (1 - pagerank_weight - proximity_weight) * norm_base +",
        "    pagerank_weight * norm_pagerank +",
        "    proximity_weight * norm_proximity",
        ")",
        "final_score = combined * coverage_mult * max_base_score",
        "```",
        "",
        "### Usage",
        "",
        "```python",
        "# Basic usage",
        "results = processor.graph_boosted_search(\"query\")",
        "",
        "# With custom weights",
        "results = processor.graph_boosted_search(",
        "    \"query\",",
        "    pagerank_weight=0.3,   # Higher = more PageRank influence",
        "    proximity_weight=0.2   # Higher = more proximity influence",
        ")",
        "```",
        "",
        "### When to Use",
        "",
        "| Scenario | Recommended Method |",
        "|----------|-------------------|",
        "| General search | `find_documents_for_query()` |",
        "| Speed-critical | `fast_find_documents()` |",
        "| Code search with importance | `graph_boosted_search()` |",
        "| Repeated queries | `search_with_index()` |",
        "",
        "---",
        "",
        "## Code Locations",
        "",
        "### Core Implementation",
        "",
        "| File | Purpose |",
        "|------|---------|",
        "| `cortical/config.py` | BM25 parameters: `scoring_algorithm`, `bm25_k1`, `bm25_b` |",
        "| `cortical/analysis.py:_bm25_core()` | Pure BM25 algorithm |",
        "| `cortical/analysis.py:compute_bm25()` | BM25 wrapper for layers |",
        "| `cortical/analysis.py:compute_bigram_connections()` | Optimized connections |",
        "| `cortical/processor/core.py` | `doc_lengths`, `avg_doc_length` fields |",
        "| `cortical/processor/documents.py` | Document length tracking |",
        "| `cortical/processor/compute.py:compute_tfidf()` | Algorithm dispatch |",
        "| `cortical/processor/persistence_api.py` | Save/load doc_lengths |",
        "| `cortical/query/search.py:graph_boosted_search()` | GB-BM25 algorithm |",
        "| `cortical/processor/query_api.py` | Processor API wrapper |",
        "| `cortical/semantics.py` | Optimized similarity extraction |",
        "",
        "### Tests",
        "",
        "| File | Coverage |",
        "|------|----------|",
        "| `tests/unit/test_query_search.py` | `graph_boosted_search()` tests |",
        "| `tests/test_edge_cases.py` | Algorithm-aware scoring tests |",
        "",
        "### Documentation",
        "",
        "| File | Content |",
        "|------|---------|",
        "| `CLAUDE.md` | Scoring Algorithms section |",
        "| `docs/knowledge-transfer-bm25-optimization.md` | This document |",
        "| `benchmarks/BASELINE_SUMMARY.md` | Performance comparison |",
        "",
        "---",
        "",
        "## Configuration Reference",
        "",
        "### CorticalConfig Parameters",
        "",
        "```python",
        "from cortical.config import CorticalConfig",
        "",
        "config = CorticalConfig(",
        "    # Scoring algorithm selection",
        "    scoring_algorithm='bm25',  # 'bm25' (default) or 'tfidf'",
        "",
        "    # BM25 parameters",
        "    bm25_k1=1.2,  # Term frequency saturation (0.0-3.0)",
        "                  # Higher = more weight to term frequency",
        "                  # Lower = faster saturation",
        "",
        "    bm25_b=0.75,  # Length normalization (0.0-1.0)",
        "                  # 1.0 = full normalization",
        "                  # 0.0 = no normalization (treat all docs equally)",
        ")",
        "```",
        "",
        "### Recommended Settings",
        "",
        "| Use Case | k1 | b | Notes |",
        "|----------|-----|---|-------|",
        "| General code search | 1.2 | 0.75 | Default, balanced |",
        "| Short documents | 1.5 | 0.5 | Less length penalty |",
        "| Long documents | 1.0 | 0.9 | More length penalty |",
        "| Exact matching focus | 0.5 | 0.75 | Quick saturation |",
        "",
        "### Graph-Boosted Search Parameters",
        "",
        "```python",
        "results = processor.graph_boosted_search(",
        "    query,",
        "    top_n=5,                 # Number of results",
        "    pagerank_weight=0.3,     # 0-1, importance boost weight",
        "    proximity_weight=0.2,    # 0-1, connection boost weight",
        "    use_expansion=True       # Query expansion enabled",
        ")",
        "```",
        "",
        "---",
        "",
        "## Testing Strategy",
        "",
        "### Unit Tests Added",
        "",
        "1. **`test_basic_search`**: Verifies ranking with multiple terms",
        "2. **`test_empty_query`**: Empty query returns empty results",
        "3. **`test_no_matching_terms`**: Unknown terms return empty results",
        "4. **`test_pagerank_boost`**: High-PageRank terms boost documents",
        "5. **`test_respects_top_n`**: Result count limited correctly",
        "",
        "### Verification Commands",
        "",
        "```bash",
        "# Quick smoke test",
        "python -c \"",
        "from cortical import CorticalTextProcessor",
        "from cortical.config import CorticalConfig",
        "config = CorticalConfig(scoring_algorithm='bm25')",
        "p = CorticalTextProcessor(config=config)",
        "p.process_document('doc1', 'Test content')",
        "p.compute_all(verbose=False)",
        "results = p.graph_boosted_search('test')",
        "print(f'Results: {len(results)}')",
        "\"",
        "",
        "# Run unit tests (requires pytest)",
        "python -m pytest tests/unit/test_query_search.py -v -k \"graph_boosted\"",
        "",
        "# Run full test suite",
        "python -m unittest discover -s tests -v",
        "```",
        "",
        "---",
        "",
        "## Performance Benchmarks",
        "",
        "### Test Corpus",
        "",
        "- 43 Python files from `cortical/` directory",
        "- ~715KB total text",
        "- 4,238 unique tokens",
        "- 27,829 bigrams",
        "",
        "### Timing Results (5-run average)",
        "",
        "| Metric | Before | After | Change |",
        "|--------|--------|-------|--------|",
        "| `compute_all()` | 7,546ms | 4,946ms | -34.5% |",
        "| `compute_bigram_connections()` | 6,067ms | 3,055ms | -49.6% |",
        "| `compute_tfidf()` | 8.5ms | 6.8ms | -20.0% |",
        "| `compute_importance()` | 670ms | 626ms | -6.6% |",
        "",
        "### Search Latency",
        "",
        "| Method | Latency (avg) |",
        "|--------|---------------|",
        "| `fast_find_documents()` | 0.14ms |",
        "| `find_documents_for_query()` | 70ms* |",
        "| `graph_boosted_search()` | 74ms* |",
        "",
        "*Includes query expansion overhead",
        "",
        "### Memory Impact",
        "",
        "No significant memory increase. `doc_lengths` adds ~1KB per 1000 documents.",
        "",
        "---",
        "",
        "## Trade-offs & Limitations",
        "",
        "### What Was Traded Off",
        "",
        "1. **Importance Filtering**: Only bigrams with TF-IDF ‚â• 25th percentile get co-occurrence connections",
        "   - **Impact**: Low - connections between unimportant terms rarely help search",
        "   - **Mitigation**: Component and chain connections still computed for all bigrams",
        "",
        "2. **Similarity Term Limit**: Only top ~447 terms (by TF-IDF) considered for SimilarTo relations",
        "   - **Impact**: Low - important terms still get similarity relations",
        "   - **Mitigation**: Configurable via `max_similarity_pairs` parameter",
        "",
        "### Known Limitations",
        "",
        "1. **No field weighting**: BM25F not implemented (function names vs body treated equally)",
        "2. **Static parameters**: k1 and b are fixed at index time",
        "3. **No query-time tuning**: Same parameters used for all queries",
        "",
        "### Edge Cases",
        "",
        "1. **Single document corpus**: BM25 IDF formula returns small positive value (unlike TF-IDF which returns 0)",
        "2. **Empty documents**: Handled gracefully, excluded from length average",
        "3. **Very long documents**: May be penalized heavily with default b=0.75",
        "",
        "---",
        "",
        "## Future Work",
        "",
        "### Potential Improvements",
        "",
        "1. **BM25F Implementation**: Field-weighted scoring for code (function names, docstrings, body)",
        "2. **Query-time Parameter Tuning**: Adjust k1/b based on query characteristics",
        "3. **Numpy Acceleration**: Use numpy for vectorized BM25 computation",
        "4. **PageRank Optimization**: Currently 626ms, could be improved with sparse matrix",
        "",
        "### Deferred Optimizations",
        "",
        "1. **Parallel bigram processing**: Use multiprocessing for large corpora",
        "2. **Incremental BM25 updates**: Avoid full recomputation on document add",
        "3. **LSH for similarity**: Locality Sensitive Hashing for O(n) similarity",
        "",
        "### Related Tasks Created",
        "",
        "- 16 code coverage improvement tasks in `tasks/` directory",
        "- See `tasks/2025-12-15_05-23-36_ceac.json`",
        "",
        "---",
        "",
        "## Troubleshooting Guide",
        "",
        "### Common Issues",
        "",
        "**Q: BM25 scores seem wrong for single-document corpus**",
        "A: This is expected. BM25's IDF formula returns positive values even for df=N. Use `scoring_algorithm='tfidf'` if you need traditional behavior.",
        "",
        "**Q: Semantic relations are empty**",
        "A: Ensure `compute_all()` completes successfully. Check that documents have sufficient co-occurring terms (minimum 2 co-occurrences by default).",
        "",
        "**Q: Search results changed after upgrade**",
        "A: BM25 is now the default. Set `scoring_algorithm='tfidf'` in config to restore old behavior.",
        "",
        "**Q: `doc_lengths` missing after load**",
        "A: Old pickle files don't have this field. The processor will recompute lengths on first `compute_tfidf()` call.",
        "",
        "### Debug Commands",
        "",
        "```python",
        "# Check scoring algorithm",
        "print(processor.config.scoring_algorithm)",
        "",
        "# Check document lengths",
        "print(f\"Doc lengths: {len(processor.doc_lengths)}\")",
        "print(f\"Avg length: {processor.avg_doc_length}\")",
        "",
        "# Check BM25 scores",
        "from cortical.layers import CorticalLayer",
        "layer0 = processor.layers[CorticalLayer.TOKENS]",
        "col = layer0.get_minicolumn(\"some_term\")",
        "print(f\"Global TF-IDF/BM25: {col.tfidf}\")",
        "print(f\"Per-doc scores: {col.tfidf_per_doc}\")",
        "",
        "# Check connections",
        "from cortical.layers import CorticalLayer",
        "layer1 = processor.layers[CorticalLayer.BIGRAMS]",
        "print(f\"Bigrams: {layer1.column_count()}\")",
        "total_conns = sum(len(c.lateral_connections) for c in layer1.minicolumns.values())",
        "print(f\"Total connections: {total_conns}\")",
        "```",
        "",
        "---",
        "",
        "## Appendix: Commit History",
        "",
        "| Commit | Message |",
        "|--------|---------|",
        "| `924ae02` | feat: Add comprehensive scoring algorithm benchmark suite |",
        "| `0a52858` | feat: Implement BM25 scoring algorithm as default |",
        "| `d0732b4` | chore: Add 16 code coverage improvement tasks |",
        "| `fcce0c2` | feat: Optimize compute_all and add Graph-Boosted search (GB-BM25) |",
        "| `63064c7` | docs: Add BM25/GB-BM25 documentation and tests |",
        "",
        "---",
        "",
        "*Document generated for knowledge transfer. For questions, refer to CLAUDE.md or the source code documentation.*"
      ],
      "lines_removed": [],
      "context_before": [],
      "context_after": [],
      "change_type": "add"
    },
    {
      "file": "examples/demo_pattern_detection.py",
      "function": null,
      "start_line": 0,
      "lines_added": [
        "\"\"\"",
        "Pattern Detection Demo",
        "======================",
        "",
        "Demonstrates the code pattern detection capabilities of the",
        "Cortical Text Processor.",
        "\"\"\"",
        "",
        "from cortical.processor import CorticalTextProcessor",
        "from cortical.patterns import (",
        "    detect_patterns_in_text,",
        "    format_pattern_report,",
        "    list_all_patterns,",
        "    list_all_categories,",
        ")",
        "",
        "",
        "def main():",
        "    print(\"=\" * 70)",
        "    print(\"Code Pattern Detection Demo\")",
        "    print(\"=\" * 70)",
        "",
        "    # Sample code files",
        "    sample_files = {",
        "        'singleton.py': \"\"\"",
        "class DatabaseConnection:",
        "    _instance = None",
        "",
        "    def __new__(cls):",
        "        if cls._instance is None:",
        "            cls._instance = super().__new__(cls)",
        "        return cls._instance",
        "",
        "    def connect(self):",
        "        print(\"Connected to database\")",
        "\"\"\",",
        "        'async_handler.py': \"\"\"",
        "import asyncio",
        "from typing import List",
        "",
        "async def fetch_users() -> List[dict]:",
        "    try:",
        "        async with aiohttp.ClientSession() as session:",
        "            async for user in get_users(session):",
        "                yield user",
        "    except Exception as e:",
        "        raise FetchError(f\"Failed to fetch users: {e}\")",
        "\"\"\",",
        "        'factory.py': \"\"\"",
        "from dataclasses import dataclass",
        "",
        "@dataclass",
        "class User:",
        "    name: str",
        "    email: str",
        "",
        "    @property",
        "    def display_name(self):",
        "        return f\"{self.name} <{self.email}>\"",
        "",
        "class UserFactory:",
        "    @staticmethod",
        "    def create_user(name, email):",
        "        return User(name=name, email=email)",
        "",
        "    @staticmethod",
        "    def create_admin(name, email):",
        "        user = User(name=name, email=email)",
        "        user.is_admin = True",
        "        return user",
        "\"\"\",",
        "        'test_features.py': \"\"\"",
        "import pytest",
        "from unittest.mock import Mock, patch",
        "",
        "class TestUserFeatures:",
        "    def setUp(self):",
        "        self.user = User(\"test\")",
        "",
        "    def test_login(self):",
        "        assert self.user.login(\"password\")",
        "",
        "    @pytest.mark.skip",
        "    def test_logout(self):",
        "        assert self.user.logout()",
        "",
        "    @patch('module.authenticate')",
        "    def test_with_mock(self, mock_auth):",
        "        mock_auth.return_value = True",
        "        assert self.user.verify()",
        "\"\"\"",
        "    }",
        "",
        "    # Create processor and add documents",
        "    processor = CorticalTextProcessor()",
        "    print(\"\\n1. Adding sample code files...\")",
        "    for filename, code in sample_files.items():",
        "        processor.process_document(filename, code)",
        "        print(f\"   ‚úì {filename}\")",
        "",
        "    # List available patterns",
        "    print(f\"\\n2. Available pattern types ({len(list_all_patterns())} patterns):\")",
        "    categories = list_all_categories()",
        "    for category in categories[:5]:  # Show first 5 categories",
        "        print(f\"   - {category}\")",
        "    print(f\"   ... and {len(categories) - 5} more categories\")",
        "",
        "    # Detect patterns in each file",
        "    print(\"\\n3. Detecting patterns in each file...\")",
        "    for filename in sample_files.keys():",
        "        patterns = processor.detect_patterns(filename)",
        "        if patterns:",
        "            print(f\"\\n   {filename}:\")",
        "            for pattern_name in sorted(patterns.keys()):",
        "                lines = patterns[pattern_name]",
        "                print(f\"     - {pattern_name}: {len(lines)} occurrence(s)\")",
        "",
        "    # Detailed report for one file",
        "    print(\"\\n\" + \"=\" * 70)",
        "    print(\"4. Detailed pattern report for 'async_handler.py':\")",
        "    print(\"=\" * 70)",
        "    report = processor.format_pattern_report('async_handler.py', show_lines=True)",
        "    print(report)",
        "",
        "    # Corpus-wide statistics",
        "    print(\"=\" * 70)",
        "    print(\"5. Corpus-wide pattern statistics:\")",
        "    print(\"=\" * 70)",
        "    stats = processor.get_corpus_pattern_statistics()",
        "    print(f\"Total documents analyzed: {stats['total_documents']}\")",
        "    print(f\"Unique patterns found: {stats['patterns_found']}\")",
        "    print(f\"Most common pattern: {stats['most_common_pattern']}\")",
        "",
        "    print(\"\\nTop patterns by occurrence:\")",
        "    sorted_patterns = sorted(",
        "        stats['pattern_occurrences'].items(),",
        "        key=lambda x: -x[1]",
        "    )",
        "    for pattern, count in sorted_patterns[:10]:",
        "        doc_count = stats['pattern_document_counts'][pattern]",
        "        print(f\"  {pattern}: {count} occurrences in {doc_count} file(s)\")",
        "",
        "    # Search for specific pattern types",
        "    print(\"\\n\" + \"=\" * 70)",
        "    print(\"6. Finding all files with specific patterns:\")",
        "    print(\"=\" * 70)",
        "",
        "    patterns_to_find = ['singleton', 'factory', 'async_await', 'dataclass']",
        "    for pattern_name in patterns_to_find:",
        "        corpus_patterns = processor.detect_patterns_in_corpus(patterns=[pattern_name])",
        "        files_with_pattern = [",
        "            doc_id for doc_id, patterns in corpus_patterns.items()",
        "            if pattern_name in patterns",
        "        ]",
        "        if files_with_pattern:",
        "            print(f\"{pattern_name}:\")",
        "            for filename in files_with_pattern:",
        "                print(f\"  ‚úì {filename}\")",
        "        else:",
        "            print(f\"{pattern_name}: Not found\")",
        "",
        "    print(\"\\n\" + \"=\" * 70)",
        "    print(\"Demo complete!\")",
        "    print(\"=\" * 70)",
        "",
        "",
        "if __name__ == '__main__':",
        "    main()"
      ],
      "lines_removed": [],
      "context_before": [],
      "context_after": [],
      "change_type": "add"
    },
    {
      "file": "examples/observability_demo.py",
      "function": null,
      "start_line": 0,
      "lines_added": [
        "#!/usr/bin/env python3",
        "\"\"\"",
        "Observability Demo",
        "==================",
        "",
        "Demonstrates the observability features of the Cortical Text Processor:",
        "- Timing metrics for operations",
        "- Cache hit/miss tracking",
        "- Custom metric recording",
        "- Metrics summary generation",
        "",
        "Run this script to see how metrics collection works.",
        "\"\"\"",
        "",
        "from cortical import CorticalTextProcessor",
        "",
        "",
        "def main():",
        "    print(\"=\" * 80)",
        "    print(\"Cortical Text Processor - Observability Demo\")",
        "    print(\"=\" * 80)",
        "",
        "    # Create processor with metrics enabled",
        "    print(\"\\n1. Creating processor with metrics enabled...\")",
        "    processor = CorticalTextProcessor(enable_metrics=True)",
        "",
        "    # Process some documents",
        "    print(\"\\n2. Processing documents...\")",
        "    processor.process_document(",
        "        \"neural_nets\",",
        "        \"Neural networks are computational models inspired by biological neural networks. \"",
        "        \"They consist of layers of interconnected nodes that process information.\"",
        "    )",
        "    processor.process_document(",
        "        \"machine_learning\",",
        "        \"Machine learning is a branch of artificial intelligence that focuses on building \"",
        "        \"systems that can learn from data. It includes supervised and unsupervised learning.\"",
        "    )",
        "    processor.process_document(",
        "        \"deep_learning\",",
        "        \"Deep learning uses neural networks with multiple layers to learn hierarchical \"",
        "        \"representations of data. It has achieved remarkable success in image and speech recognition.\"",
        "    )",
        "",
        "    # Compute analysis",
        "    print(\"\\n3. Running compute_all()...\")",
        "    processor.compute_all(verbose=False)",
        "",
        "    # Perform some queries",
        "    print(\"\\n4. Performing queries...\")",
        "    processor.find_documents_for_query(\"neural networks\")",
        "    processor.find_documents_for_query(\"machine learning algorithms\")",
        "",
        "    # Use cached queries to demonstrate cache metrics",
        "    print(\"\\n5. Testing query cache (first call = miss, second = hit)...\")",
        "    processor.expand_query_cached(\"neural\")  # Cache miss",
        "    processor.expand_query_cached(\"neural\")  # Cache hit",
        "    processor.expand_query_cached(\"learning\")  # Cache miss",
        "    processor.expand_query_cached(\"learning\")  # Cache hit",
        "",
        "    # Record custom metrics",
        "    print(\"\\n6. Recording custom metrics...\")",
        "    processor.record_metric(\"api_calls\", 10)",
        "    processor.record_metric(\"api_calls\", 5)",
        "    processor.record_metric(\"users_active\", 3)",
        "",
        "    # Display metrics summary",
        "    print(\"\\n\" + \"=\" * 80)",
        "    print(\"METRICS SUMMARY\")",
        "    print(\"=\" * 80)",
        "    print(processor.get_metrics_summary())",
        "",
        "    # Get detailed metrics programmatically",
        "    print(\"\\n\" + \"=\" * 80)",
        "    print(\"DETAILED METRICS (Programmatic Access)\")",
        "    print(\"=\" * 80)",
        "    metrics = processor.get_metrics()",
        "",
        "    if \"compute_all\" in metrics:",
        "        stats = metrics[\"compute_all\"]",
        "        print(f\"\\ncompute_all:\")",
        "        print(f\"  Executed: {stats['count']} time(s)\")",
        "        print(f\"  Average: {stats['avg_ms']:.2f}ms\")",
        "        print(f\"  Min: {stats['min_ms']:.2f}ms\")",
        "        print(f\"  Max: {stats['max_ms']:.2f}ms\")",
        "",
        "    if \"find_documents_for_query\" in metrics:",
        "        stats = metrics[\"find_documents_for_query\"]",
        "        print(f\"\\nfind_documents_for_query:\")",
        "        print(f\"  Executed: {stats['count']} time(s)\")",
        "        print(f\"  Average: {stats['avg_ms']:.2f}ms\")",
        "",
        "    if \"query_cache_hits\" in metrics:",
        "        hits = metrics[\"query_cache_hits\"][\"count\"]",
        "        misses = metrics[\"query_cache_misses\"][\"count\"]",
        "        total = hits + misses",
        "        hit_rate = (hits / total * 100) if total > 0 else 0",
        "        print(f\"\\nQuery Cache Performance:\")",
        "        print(f\"  Hits: {hits}\")",
        "        print(f\"  Misses: {misses}\")",
        "        print(f\"  Hit Rate: {hit_rate:.1f}%\")",
        "",
        "    # Demonstrate disabling metrics",
        "    print(\"\\n\" + \"=\" * 80)",
        "    print(\"DISABLING METRICS\")",
        "    print(\"=\" * 80)",
        "    processor.disable_metrics()",
        "    print(\"Metrics disabled. Processing more documents (not timed)...\")",
        "    processor.process_document(\"new_doc\", \"This won't be timed.\")",
        "",
        "    # Re-enable and show metrics haven't changed",
        "    processor.enable_metrics()",
        "    metrics_after = processor.get_metrics()",
        "    print(f\"Operations still in metrics: {len(metrics_after)}\")",
        "    print(\"(Metrics from before disable were preserved)\")",
        "",
        "    # Demonstrate reset",
        "    print(\"\\n\" + \"=\" * 80)",
        "    print(\"RESETTING METRICS\")",
        "    print(\"=\" * 80)",
        "    processor.reset_metrics()",
        "    metrics_after_reset = processor.get_metrics()",
        "    print(f\"Operations after reset: {len(metrics_after_reset)}\")",
        "    print(\"(All metrics cleared)\")",
        "",
        "    print(\"\\n\" + \"=\" * 80)",
        "    print(\"Demo complete!\")",
        "    print(\"=\" * 80)",
        "",
        "",
        "if __name__ == \"__main__\":",
        "    main()"
      ],
      "lines_removed": [],
      "context_before": [],
      "context_after": [],
      "change_type": "add"
    },
    {
      "file": "examples/repl_demo.py",
      "function": null,
      "start_line": 0,
      "lines_added": [
        "#!/usr/bin/env python3",
        "\"\"\"",
        "Cortical REPL Demo",
        "==================",
        "",
        "This script demonstrates the interactive REPL for the Cortical Text Processor.",
        "",
        "The REPL provides a command-line interface for all processor operations with:",
        "- Tab completion",
        "- Command history (via readline)",
        "- Built-in help system",
        "- All processor operations accessible",
        "",
        "Run this demo:",
        "    python examples/repl_demo.py",
        "",
        "Or start the REPL manually:",
        "    python scripts/repl.py corpus_dev.pkl",
        "\"\"\"",
        "",
        "import sys",
        "import os",
        "from pathlib import Path",
        "",
        "# Add parent to path",
        "sys.path.insert(0, str(Path(__file__).parent.parent))",
        "",
        "from cortical.processor import CorticalTextProcessor",
        "",
        "",
        "def create_sample_corpus():",
        "    \"\"\"Create a sample corpus for the demo.\"\"\"",
        "    print(\"Creating sample corpus...\")",
        "",
        "    processor = CorticalTextProcessor(enable_metrics=True)",
        "",
        "    # Add some sample documents",
        "    processor.process_document(",
        "        \"neural_networks.py\",",
        "        \"\"\"",
        "        class NeuralNetwork:",
        "            def __init__(self, layers):",
        "                self.layers = layers",
        "                self.weights = []",
        "",
        "            def train(self, data):",
        "                # Train the network using backpropagation",
        "                for epoch in range(100):",
        "                    self.forward_pass(data)",
        "                    self.backward_pass()",
        "",
        "            def predict(self, input):",
        "                return self.forward_pass(input)",
        "        \"\"\"",
        "    )",
        "",
        "    processor.process_document(",
        "        \"pagerank.py\",",
        "        \"\"\"",
        "        def compute_pagerank(graph, damping=0.85, iterations=100):",
        "            # PageRank algorithm implementation",
        "            n = len(graph)",
        "            ranks = [1.0 / n] * n",
        "",
        "            for _ in range(iterations):",
        "                new_ranks = []",
        "                for node in range(n):",
        "                    rank = (1 - damping) / n",
        "                    for neighbor in graph[node]:",
        "                        rank += damping * ranks[neighbor]",
        "                    new_ranks.append(rank)",
        "                ranks = new_ranks",
        "",
        "            return ranks",
        "        \"\"\"",
        "    )",
        "",
        "    processor.process_document(",
        "        \"README.md\",",
        "        \"\"\"",
        "        # Machine Learning Library",
        "",
        "        This library provides implementations of common ML algorithms:",
        "",
        "        ## Neural Networks",
        "        - Feed-forward networks",
        "        - Backpropagation training",
        "        - Multiple activation functions",
        "",
        "        ## Graph Algorithms",
        "        - PageRank for importance ranking",
        "        - Community detection",
        "        - Graph embedding",
        "        \"\"\"",
        "    )",
        "",
        "    # Compute all analyses",
        "    processor.compute_all()",
        "",
        "    # Save corpus",
        "    corpus_file = \"demo_corpus.pkl\"",
        "    processor.save(corpus_file)",
        "    print(f\"‚úì Created {corpus_file}\")",
        "",
        "    return corpus_file",
        "",
        "",
        "def print_demo_commands():",
        "    \"\"\"Print example REPL commands.\"\"\"",
        "    print(\"\\n\" + \"=\"*70)",
        "    print(\"REPL DEMO - Example Commands\")",
        "    print(\"=\"*70)",
        "    print(\"\"\"",
        "The REPL supports the following commands:",
        "",
        "1. BASIC COMMANDS",
        "   >>> stats                        # Show corpus statistics",
        "   >>> search \"neural network\"      # Search documents",
        "   >>> expand \"neural\"              # Show query expansion",
        "   >>> concepts 10                  # List top 10 concept clusters",
        "",
        "2. ADVANCED SEARCH",
        "   >>> docs \"what is pagerank\"      # Search with documentation boost",
        "   >>> code \"train model\"           # Code-aware search (synonyms)",
        "   >>> passages \"how does it work\"  # Find relevant passages (RAG)",
        "   >>> intent \"where do we train\"   # Intent-based search",
        "",
        "3. CODE ANALYSIS",
        "   >>> patterns neural_networks.py  # Detect code patterns",
        "   >>> fingerprint \"neural net\"     # Get semantic fingerprint",
        "   >>> similar pagerank.py:10       # Find similar code",
        "",
        "4. INTROSPECTION",
        "   >>> metrics                      # Show performance metrics",
        "   >>> relations 10                 # Show semantic relations",
        "   >>> stale                        # Show stale computations",
        "",
        "5. COMPUTATION",
        "   >>> compute                      # Compute all analyses",
        "   >>> compute pagerank             # Compute specific analysis",
        "   >>> compute concepts             # Build concept clusters",
        "",
        "6. PERSISTENCE",
        "   >>> save my_corpus.pkl           # Save corpus",
        "   >>> export corpus_state json     # Export to JSON",
        "   >>> load another.pkl             # Load different corpus",
        "",
        "7. HELP SYSTEM",
        "   >>> help                         # List all commands",
        "   >>> help search                  # Help for specific command",
        "   >>> quit                         # Exit REPL",
        "",
        "Tab completion works for commands and file paths!",
        "Command history is saved (use up/down arrows).",
        "\"\"\")",
        "    print(\"=\"*70)",
        "",
        "",
        "def main():",
        "    \"\"\"Run the demo.\"\"\"",
        "    print(__doc__)",
        "",
        "    # Check if demo corpus exists",
        "    if not os.path.exists(\"demo_corpus.pkl\"):",
        "        print(\"\\nDemo corpus not found. Creating one...\")",
        "        corpus_file = create_sample_corpus()",
        "    else:",
        "        corpus_file = \"demo_corpus.pkl\"",
        "        print(f\"\\nUsing existing {corpus_file}\")",
        "",
        "    # Print example commands",
        "    print_demo_commands()",
        "",
        "    # Instructions to start REPL",
        "    print(\"\\nTo start the REPL with the demo corpus, run:\")",
        "    print(f\"    python scripts/repl.py {corpus_file}\")",
        "    print(\"\\nOr without a corpus:\")",
        "    print(\"    python scripts/repl.py\")",
        "    print(\"\\nThen use 'load <file>' to load a corpus.\")",
        "",
        "",
        "if __name__ == '__main__':",
        "    main()"
      ],
      "lines_removed": [],
      "context_before": [],
      "context_after": [],
      "change_type": "add"
    },
    {
      "file": "samples/customer_service/README.md",
      "function": null,
      "start_line": 1,
      "lines_added": [
        "# Customer Service Sample Corpus",
        "",
        "## Overview",
        "",
        "This directory contains realistic customer service documents designed to demonstrate the Cortical Text Processor's capabilities in a non-technical domain. The corpus includes FAQs, troubleshooting guides, policy documents, and response templates that showcase natural language understanding, semantic relationships, and query expansion features.",
        "",
        "## Contents",
        "",
        "### New Markdown Documents (8 files)",
        "",
        "**FAQ Documents:**",
        "- **faq-billing.md** - Billing, payments, invoices, subscriptions, and financial questions",
        "- **faq-shipping.md** - Shipping methods, delivery, tracking, and international orders",
        "",
        "**Troubleshooting Guides:**",
        "- **troubleshoot-login.md** - Account access, password issues, two-factor authentication",
        "- **troubleshoot-payment.md** - Payment failures, declined cards, promotional codes",
        "",
        "**Policy Documents:**",
        "- **policy-returns.md** - Return eligibility, refund process, exchange procedures",
        "- **policy-privacy.md** - Data collection, privacy rights, security measures",
        "",
        "**Response Templates:**",
        "- **template-apology.md** - Service failure apologies and customer recovery",
        "- **template-resolution.md** - Issue resolution confirmations and follow-ups",
        "",
        "### Legacy Text Documents (14 files)",
        "",
        "**FAQ Documents (4 files):**",
        "- software_product_faq.txt - CloudSync Pro cloud storage",
        "- electronics_product_faq.txt - TechGear wireless earbuds",
        "- subscription_service_faq.txt - StreamFlix entertainment service",
        "- account_management_faq.txt - Account access and management",
        "",
        "**Troubleshooting Guides (4 files):**",
        "- software_installation_troubleshooting.txt",
        "- connectivity_network_troubleshooting.txt",
        "- payment_billing_troubleshooting.txt",
        "- login_access_troubleshooting.txt",
        "",
        "**Policy Documents (3 files):**",
        "- return_refund_policy.txt",
        "- shipping_delivery_policy.txt",
        "- privacy_data_security_policy.txt",
        "",
        "**Templates and Guidelines (3 files):**",
        "- email_response_templates.txt",
        "- service_level_agreement.txt",
        "- customer_feedback_survey_guide.txt",
        "",
        "## Purpose",
        "",
        "This sample cluster demonstrates the Cortical Text Processor's ability to:",
        "",
        "1. **Cluster Related Concepts** - Group similar support topics (billing issues, shipping problems, account access)",
        "2. **Expand Queries** - Find synonyms and related terms (refund/reimbursement, cancel/terminate, issue/problem)",
        "3. **Extract Semantic Relations** - Understand relationships (refund relates to return relates to policy)",
        "4. **Retrieve Relevant Information** - Find answers to customer questions across multiple documents",
        "5. **Understand Intent** - Parse natural language queries into actionable search terms",
        "",
        "## Indexing and Searching",
        "",
        "### Quick Start",
        "",
        "```bash",
        "# Index the customer service corpus",
        "python -c \"",
        "from cortical.processor import CorticalTextProcessor",
        "import os",
        "",
        "processor = CorticalTextProcessor()",
        "",
        "# Load all customer service documents",
        "cs_dir = 'samples/customer_service'",
        "for filename in os.listdir(cs_dir):",
        "    if filename.endswith(('.md', '.txt')) and filename != 'README.md':",
        "        filepath = os.path.join(cs_dir, filename)",
        "        with open(filepath, 'r') as f:",
        "            text = f.read()",
        "        doc_id = f'cs_{filename.rsplit(\\\".\\\", 1)[0]}'  # Remove extension",
        "        processor.process_document(doc_id, text)",
        "",
        "# Compute all relationships and rankings",
        "processor.compute_all()",
        "",
        "# Save the indexed corpus",
        "processor.save('customer_service_corpus.pkl')",
        "print(f'Indexed {processor.document_count} customer service documents')",
        "\"",
        "```",
        "",
        "### Interactive Search",
        "",
        "```python",
        "from cortical.processor import CorticalTextProcessor",
        "",
        "# Load the indexed corpus",
        "processor = CorticalTextProcessor.load('customer_service_corpus.pkl')",
        "",
        "# Search for customer questions",
        "results = processor.find_documents_for_query(\"how do I get a refund\")",
        "for doc_id, score in results:",
        "    print(f\"{doc_id}: {score:.3f}\")",
        "",
        "# See query expansion",
        "expanded = processor.expand_query(\"cancel my order\")",
        "print(\"Expanded terms:\", expanded)",
        "",
        "# Find relevant passages",
        "passages = processor.find_passages_for_query(\"my package is late\", top_n=3)",
        "for passage, score, doc_id in passages:",
        "    print(f\"\\nFrom {doc_id} (score: {score:.3f}):\")",
        "    print(passage[:200] + \"...\")",
        "```",
        "",
        "## Example Queries",
        "",
        "### Billing and Payment Questions",
        "",
        "```python",
        "# These queries should return relevant billing documents",
        "queries = [",
        "    \"how do I change my payment method\",",
        "    \"I was charged twice\",",
        "    \"cancel my subscription\",",
        "    \"download my invoice\",",
        "    \"update billing address\",",
        "    \"dispute a charge\",",
        "]",
        "",
        "for query in queries:",
        "    print(f\"\\nQuery: {query}\")",
        "    results = processor.find_documents_for_query(query, top_n=3)",
        "    for doc_id, score in results:",
        "        print(f\"  {doc_id}: {score:.3f}\")",
        "```",
        "",
        "**Expected Results**: Should retrieve `faq-billing`, `policy-returns`, and `troubleshoot-payment` documents.",
        "",
        "### Shipping and Delivery Questions",
        "",
        "```python",
        "queries = [",
        "    \"where is my package\",",
        "    \"track my order\",",
        "    \"shipping costs too high\",",
        "    \"international delivery\",",
        "    \"package arrived damaged\",",
        "    \"change delivery address\",",
        "]",
        "```",
        "",
        "**Expected Results**: Should primarily retrieve `faq-shipping` and `shipping_delivery_policy` documents.",
        "",
        "### Account Access Questions",
        "",
        "```python",
        "queries = [",
        "    \"forgot my password\",",
        "    \"can't log in\",",
        "    \"account locked\",",
        "    \"enable two factor authentication\",",
        "    \"reset my password\",",
        "    \"SSO not working\",",
        "]",
        "```",
        "",
        "**Expected Results**: Should retrieve `troubleshoot-login` and `login_access_troubleshooting` documents.",
        "",
        "### Return and Refund Questions",
        "",
        "```python",
        "queries = [",
        "    \"how to return an item\",",
        "    \"get my money back\",",
        "    \"exchange for different size\",",
        "    \"return window expired\",",
        "    \"where's my refund\",",
        "    \"return shipping cost\",",
        "]",
        "```",
        "",
        "**Expected Results**: Should retrieve `policy-returns` and `return_refund_policy` documents.",
        "",
        "## Demonstrating Key Features",
        "",
        "### 1. Query Expansion",
        "",
        "The processor should identify synonyms and related terms:",
        "",
        "```python",
        "# See how the processor expands customer service terms",
        "terms_to_expand = [",
        "    \"refund\",      # Should expand to: reimbursement, money back, credit, return",
        "    \"cancel\",      # Should expand to: terminate, discontinue, end, stop",
        "    \"problem\",     # Should expand to: issue, error, trouble, difficulty",
        "    \"late\",        # Should expand to: delayed, overdue, slow, behind",
        "    \"broken\",      # Should expand to: defective, damaged, faulty, not working",
        "]",
        "",
        "for term in terms_to_expand:",
        "    expanded = processor.expand_query(term, max_expansions=5)",
        "    print(f\"\\n{term} ‚Üí\")",
        "    for exp_term, weight in sorted(expanded.items(), key=lambda x: -x[1])[:5]:",
        "        print(f\"  {exp_term}: {weight:.3f}\")",
        "```",
        "",
        "### 2. Concept Clustering",
        "",
        "View clusters of related support topics:",
        "",
        "```python",
        "# Build concept clusters",
        "processor.build_concept_clusters(resolution=1.0)",
        "",
        "# View clusters",
        "from cortical.layers import CorticalLayer",
        "concepts = processor.layers[CorticalLayer.CONCEPTS]",
        "",
        "print(f\"\\nFound {concepts.column_count()} concept clusters:\")",
        "for concept_id, minicolumn in list(concepts.minicolumns.items())[:10]:",
        "    terms = concept_id.replace('L2_', '').split('_')[:5]",
        "    print(f\"  {', '.join(terms)} ({len(minicolumn.document_ids)} docs)\")",
        "```",
        "",
        "**Expected Clusters**:",
        "- Billing/payment/subscription/invoice",
        "- Shipping/delivery/tracking/package",
        "- Return/refund/exchange/policy",
        "- Login/password/authentication/access",
        "- Support/help/contact/service",
        "",
        "### 3. Semantic Relations",
        "",
        "Extract relationships between customer service concepts:",
        "",
        "```python",
        "# Extract semantic relations",
        "processor.extract_corpus_semantics()",
        "",
        "# View key relations",
        "print(\"\\nTop semantic relations:\")",
        "for term1, relation, term2, weight in processor.semantic_relations[:20]:",
        "    print(f\"  {term1} --{relation}--> {term2} ({weight:.2f})\")",
        "```",
        "",
        "**Expected Relations**:",
        "- refund ‚Üí relates_to ‚Üí return",
        "- payment ‚Üí requires ‚Üí billing",
        "- tracking ‚Üí enables ‚Üí delivery",
        "- password ‚Üí enables ‚Üí login",
        "- policy ‚Üí governs ‚Üí return",
        "",
        "### 4. Intent Understanding",
        "",
        "Parse natural language customer questions:",
        "",
        "```python",
        "# Test intent parsing",
        "customer_questions = [",
        "    \"where do we explain our return policy\",",
        "    \"how do customers reset their password\",",
        "    \"what should I do if payment fails\",",
        "    \"can I change my shipping address\",",
        "    \"why was my account locked\",",
        "]",
        "",
        "for question in customer_questions:",
        "    intent = processor.parse_intent_query(question)",
        "    print(f\"\\nQuestion: {question}\")",
        "    print(f\"  Intent: {intent.get('intent', 'unknown')}\")",
        "    print(f\"  Subject: {intent.get('subject', 'N/A')}\")",
        "    print(f\"  Action: {intent.get('action', 'N/A')}\")",
        "```",
        "",
        "### 5. Passage Retrieval (RAG)",
        "",
        "Find specific answer passages for customer questions:",
        "",
        "```python",
        "# Retrieve relevant passages for RAG systems",
        "questions = [",
        "    \"What payment methods do you accept?\",",
        "    \"How long do refunds take?\",",
        "    \"Can I return an item after 30 days?\",",
        "    \"What if my package shows delivered but I didn't get it?\",",
        "]",
        "",
        "for question in questions:",
        "    print(f\"\\nQ: {question}\")",
        "    passages = processor.find_passages_for_query(question, top_n=2, chunk_size=200)",
        "    for passage, score, doc_id in passages:",
        "        print(f\"\\nA (from {doc_id}, score: {score:.3f}):\")",
        "        print(passage)",
        "```",
        "",
        "## Domain-Specific Vocabulary",
        "",
        "This corpus demonstrates handling of customer service terminology:",
        "",
        "### Operational Terms",
        "- **SLA** (Service Level Agreement)",
        "- **Escalation** (routing to higher support tier)",
        "- **Ticket** (support case identifier)",
        "- **Resolution** (issue fix/answer)",
        "- **Hold** (temporary account status)",
        "- **Verification** (identity confirmation)",
        "",
        "### Process Terms",
        "- **Fulfillment** (order processing and shipping)",
        "- **Restocking fee** (charge for returns)",
        "- **Chargeback** (payment dispute)",
        "- **Provisioning** (account setup)",
        "- **Reconciliation** (payment matching)",
        "",
        "### Customer Journey Terms",
        "- **Onboarding** (initial setup)",
        "- **Retention** (keeping customers)",
        "- **Churn** (customer departure)",
        "- **Conversion** (completing purchase)",
        "- **Touchpoint** (interaction point)",
        "",
        "## Cross-Document Semantic Queries",
        "",
        "Test queries that should retrieve information from multiple related documents:",
        "",
        "- **\"Security and privacy protection\"** ‚Üí privacy_data_security_policy, policy-privacy, troubleshoot-login (2FA)",
        "- **\"Delivery problems and solutions\"** ‚Üí faq-shipping, shipping_delivery_policy, template-resolution",
        "- **\"Account access issues\"** ‚Üí troubleshoot-login, login_access_troubleshooting, account_management_faq",
        "- **\"Payment and billing concerns\"** ‚Üí faq-billing, payment_billing_troubleshooting, policy-returns",
        "",
        "## Integration Examples",
        "",
        "### Chatbot Integration",
        "",
        "```python",
        "class CustomerServiceChatbot:",
        "    def __init__(self, corpus_path):",
        "        self.processor = CorticalTextProcessor.load(corpus_path)",
        "",
        "    def answer_question(self, question):",
        "        \"\"\"Find relevant passages to answer customer question.\"\"\"",
        "        passages = self.processor.find_passages_for_query(",
        "            question,",
        "            top_n=3,",
        "            chunk_size=300",
        "        )",
        "",
        "        if not passages:",
        "            return \"I couldn't find information about that. Please contact support.\"",
        "",
        "        # Return most relevant passage",
        "        best_passage, score, doc_id = passages[0]",
        "",
        "        if score < 0.3:",
        "            return \"I'm not sure about that. Let me connect you with a specialist.\"",
        "",
        "        return best_passage",
        "",
        "    def suggest_related_articles(self, query):",
        "        \"\"\"Suggest helpful articles based on query.\"\"\"",
        "        docs = self.processor.find_documents_for_query(query, top_n=5)",
        "        return [doc_id.replace('cs_', '').replace('-', ' ').title()",
        "                for doc_id, score in docs if score > 0.2]",
        "",
        "# Usage",
        "bot = CustomerServiceChatbot('customer_service_corpus.pkl')",
        "answer = bot.answer_question(\"How do I get a refund?\")",
        "print(answer)",
        "",
        "related = bot.suggest_related_articles(\"shipping problems\")",
        "print(\"Related articles:\", related)",
        "```",
        "",
        "### Support Ticket Classification",
        "",
        "```python",
        "def classify_ticket(ticket_text, processor):",
        "    \"\"\"Classify support ticket into category.\"\"\"",
        "    # Find most relevant documents",
        "    results = processor.find_documents_for_query(ticket_text, top_n=3)",
        "",
        "    if not results:",
        "        return \"general\"",
        "",
        "    top_doc, score = results[0]",
        "",
        "    # Map document to category",
        "    categories = {",
        "        'billing': ['faq-billing', 'payment'],",
        "        'shipping': ['faq-shipping', 'delivery'],",
        "        'returns': ['policy-returns', 'refund'],",
        "        'account': ['troubleshoot-login', 'login'],",
        "        'privacy': ['policy-privacy', 'privacy'],",
        "    }",
        "",
        "    for category, patterns in categories.items():",
        "        if any(pattern in top_doc for pattern in patterns):",
        "            return category",
        "",
        "    return \"general\"",
        "",
        "# Test classification",
        "tickets = [",
        "    \"My payment was declined and I don't know why\",",
        "    \"Package hasn't arrived and it's been 2 weeks\",",
        "    \"Need to return an item but lost the receipt\",",
        "    \"Can't log into my account, forgot password\",",
        "]",
        "",
        "for ticket in tickets:",
        "    category = classify_ticket(ticket, processor)",
        "    print(f\"{category.upper()}: {ticket}\")",
        "```",
        "",
        "## Performance Benchmarks",
        "",
        "Expected performance on typical hardware (reference):",
        "",
        "- **Indexing**: ~2-4 seconds for all 22 documents",
        "- **Query Search**: <50ms for simple queries",
        "- **Passage Retrieval**: <100ms with chunking",
        "- **Query Expansion**: <10ms",
        "- **Concept Clustering**: ~2-5 seconds (one-time)",
        "",
        "## Use Cases",
        "",
        "This corpus is suitable for demonstrating:",
        "",
        "- **Customer support automation** - Chatbots, virtual assistants",
        "- **Knowledge base search** - Help centers, FAQ search",
        "- **Ticket routing** - Automatic categorization and assignment",
        "- **Answer suggestion** - Support agent assistance tools",
        "- **Content recommendation** - Related article suggestions",
        "- **Self-service portals** - Customer account management",
        "- **Training data** - For customer service ML models",
        "",
        "## Contributing",
        "",
        "To add more customer service documents:",
        "",
        "1. **Follow naming convention**: `category-topic.md` or `descriptive_name.txt`",
        "2. **Use realistic language**: Authentic customer service tone and terminology",
        "3. **Include variety**: Different question types, solutions, and scenarios",
        "4. **Cross-reference**: Link related topics naturally in content",
        "5. **Test searchability**: Verify new docs are retrieved for relevant queries",
        "",
        "## Statistics",
        "",
        "- **Total documents**: 22 (8 markdown + 14 text)",
        "- **Document types**: FAQs, troubleshooting, policies, templates",
        "- **Coverage**: Billing, shipping, returns, privacy, authentication, technical support",
        "- **Use cases**: Search, classification, chatbots, RAG, recommendations",
        "",
        "---",
        "",
        "**Questions or suggestions?** This corpus is designed to showcase natural language processing capabilities beyond code search. Feedback on search quality, relevance ranking, and additional use cases is welcome."
      ],
      "lines_removed": [
        "# Customer Service Document Cluster",
        "",
        "This directory contains 14 customer service documents designed for semantic search testing.",
        "",
        "## Document Categories",
        "",
        "### FAQ Documents (4 files, 2,274 words)",
        "- **software_product_faq.txt** - CloudSync Pro cloud storage software",
        "- **electronics_product_faq.txt** - TechGear wireless earbuds  ",
        "- **subscription_service_faq.txt** - StreamFlix entertainment service",
        "- **account_management_faq.txt** - Account access and user management",
        "",
        "### Troubleshooting Guides (4 files, 4,228 words)",
        "- **software_installation_troubleshooting.txt** - Installation errors and setup",
        "- **connectivity_network_troubleshooting.txt** - Network and connection issues",
        "- **payment_billing_troubleshooting.txt** - Payment processing and billing",
        "- **login_access_troubleshooting.txt** - Authentication and account access",
        "",
        "### Policy Documents (3 files, 4,804 words)",
        "- **return_refund_policy.txt** - Return procedures and refund policies",
        "- **shipping_delivery_policy.txt** - Shipping methods and delivery",
        "- **privacy_data_security_policy.txt** - Data privacy and security practices",
        "",
        "### Templates and Guidelines (3 files, 4,337 words)",
        "- **email_response_templates.txt** - Standard customer service email templates",
        "- **service_level_agreement.txt** - SLA commitments and metrics",
        "- **customer_feedback_survey_guide.txt** - Survey design and feedback collection",
        "",
        "## Total Content",
        "- **14 documents**",
        "- **15,643 words**",
        "- **Average: 1,117 words per document**",
        "",
        "## Key Themes Covered",
        "",
        "### Product Support",
        "- Software installation and configuration",
        "- Hardware setup and troubleshooting",
        "- Feature explanations and how-to guides",
        "- System requirements and compatibility",
        "",
        "### Technical Issues",
        "- Network connectivity problems",
        "- Authentication and login errors",
        "- Payment processing failures",
        "- Device pairing and synchronization",
        "",
        "### Customer Policies",
        "- Return eligibility and procedures",
        "- Refund processing timelines",
        "- Shipping methods and costs",
        "- Privacy and data protection",
        "",
        "### Service Operations",
        "- Response time commitments",
        "- Escalation procedures",
        "- Support channel availability",
        "- Performance metrics",
        "",
        "### Communication",
        "- Email response templates",
        "- Complaint resolution approaches",
        "- Feedback collection methods",
        "- Survey best practices",
        "",
        "## Suggested Test Queries",
        "",
        "### Product-Specific Queries",
        "- \"How do I pair wireless earbuds with my phone?\"",
        "- \"Cloud storage encryption security\"",
        "- \"Streaming service device limits\"",
        "- \"Two-factor authentication setup\"",
        "",
        "### Problem-Solving Queries",
        "- \"Installation fails with permission error\"",
        "- \"Cannot connect to service\"",
        "- \"Payment declined troubleshooting\"",
        "- \"Forgot password reset\"",
        "",
        "### Policy Information Queries",
        "- \"Return policy for opened electronics\"",
        "- \"International shipping costs\"",
        "- \"Data privacy GDPR compliance\"",
        "- \"Refund processing time\"",
        "",
        "### Process and Procedure Queries",
        "- \"How to escalate support ticket\"",
        "- \"SLA response time commitments\"",
        "- \"Customer satisfaction survey best practices\"",
        "- \"Email template for order confirmation\"",
        "",
        "### Cross-Document Semantic Queries",
        "- \"Security and privacy protection\" (should find privacy policy, 2FA, encryption)",
        "- \"Delivery problems and solutions\" (should find shipping policy, tracking, delays)",
        "- \"Account access issues\" (should find login troubleshooting, password reset, 2FA)",
        "- \"Payment and billing concerns\" (should find billing troubleshooting, refund policy, SLA)",
        "",
        "## Testing Value",
        "",
        "These documents provide:",
        "- **Vocabulary diversity** - Multiple product types (software, hardware, services)",
        "- **Semantic overlap** - Concepts appear across different contexts",
        "- **Question-answer patterns** - FAQ format tests retrieval matching",
        "- **Procedural knowledge** - Step-by-step troubleshooting sequences",
        "- **Policy complexity** - Nuanced rules and conditions",
        "- **Customer intent variety** - Different goals (learn, fix, understand policy)"
      ],
      "context_before": [],
      "context_after": [],
      "change_type": "modify"
    },
    {
      "file": "samples/customer_service/faq-billing.md",
      "function": null,
      "start_line": 0,
      "lines_added": [
        "# Billing and Payment Frequently Asked Questions",
        "",
        "## Understanding Your Invoice",
        "",
        "**Q: How do I access my invoice?**",
        "",
        "You can view and download your invoice from your account dashboard. Navigate to Billing > Invoices to see all past statements. Invoices are generated automatically on your billing cycle date and sent via email.",
        "",
        "**Q: What payment methods do you accept?**",
        "",
        "We accept all major credit cards (Visa, MasterCard, American Express, Discover), debit cards, PayPal, and bank transfers for enterprise accounts. Digital wallet payments (Apple Pay, Google Pay) are also supported through our mobile app.",
        "",
        "## Charges and Fees",
        "",
        "**Q: Why was I charged twice?**",
        "",
        "Double charges typically occur when a payment fails initially and is retried. If you see duplicate charges, please contact our billing department immediately. We'll investigate and issue a refund within 3-5 business days if the charge was erroneous.",
        "",
        "**Q: Can I get a refund for unused service?**",
        "",
        "Yes, we offer prorated refunds for annual subscriptions canceled before renewal. Monthly subscriptions are not eligible for partial refunds, but you'll retain access until the end of your billing period. See our refund policy for complete details.",
        "",
        "**Q: What are these additional fees on my bill?**",
        "",
        "Additional fees may include:",
        "- Late payment penalties (applied after 15 days past due)",
        "- Service restoration fees (if account was suspended)",
        "- Premium support surcharges",
        "- International transaction fees",
        "- Tax adjustments based on your location",
        "",
        "## Billing Disputes and Corrections",
        "",
        "**Q: I don't recognize a charge. What should I do?**",
        "",
        "First, check if the charge description matches our company name or our payment processor. Sometimes charges appear under different names. If you still don't recognize it, contact our fraud prevention team within 60 days to dispute the transaction.",
        "",
        "**Q: How do I update my billing information?**",
        "",
        "To update your payment method, credit card details, or billing address:",
        "1. Log into your account",
        "2. Go to Settings > Payment Methods",
        "3. Click \"Add New Payment Method\" or edit existing ones",
        "4. Save changes and set a default payment method",
        "",
        "Changes take effect immediately for future charges.",
        "",
        "## Subscription Management",
        "",
        "**Q: How do I cancel my subscription?**",
        "",
        "You can cancel anytime from your account settings. Go to Subscriptions > Manage Plan > Cancel Subscription. You'll be asked to confirm and provide optional feedback. Your access continues until the end of your current billing period.",
        "",
        "**Q: Will I be charged after canceling?**",
        "",
        "No automatic charges will occur after cancellation. However, any outstanding balance must be paid. If you cancel during a free trial, you won't be charged at all.",
        "",
        "**Q: Can I pause my subscription instead of canceling?**",
        "",
        "Enterprise and professional plans can be paused for up to 90 days per year. During the pause, you won't be billed, but you also won't have access to services. Contact your account manager to arrange a subscription pause.",
        "",
        "## Technical Billing Issues",
        "",
        "**Q: My payment failed. What now?**",
        "",
        "Payment failures happen for several reasons:",
        "- Insufficient funds",
        "- Expired credit card",
        "- Bank security blocks",
        "- Incorrect billing information",
        "",
        "Update your payment method and retry. If problems persist after 3 attempts, contact your bank. We'll hold your account for 7 days before suspension.",
        "",
        "**Q: How do I request a receipt or statement?**",
        "",
        "All receipts are automatically emailed after successful payment. You can also download them from Billing > Receipts. For tax purposes, we can provide annual statements or custom date-range reports upon request.",
        "",
        "## Enterprise and Volume Billing",
        "",
        "**Q: Do you offer volume discounts?**",
        "",
        "Yes, enterprise customers with 50+ users qualify for volume pricing. Contact our sales team for custom quotes. Educational institutions and non-profits may also qualify for special discounted rates.",
        "",
        "**Q: Can I pay annually instead of monthly?**",
        "",
        "Absolutely. Annual billing provides a 15% discount compared to monthly plans. You can switch to annual billing at any time, and we'll credit any remaining monthly subscription balance toward your annual payment.",
        "",
        "**Q: We need separate invoices for different departments. Is this possible?**",
        "",
        "Enterprise accounts can split billing across cost centers or departments. Contact your account manager to set up multi-entity billing with separate invoices, payment methods, and usage tracking."
      ],
      "lines_removed": [],
      "context_before": [],
      "context_after": [],
      "change_type": "add"
    },
    {
      "file": "samples/customer_service/faq-shipping.md",
      "function": null,
      "start_line": 0,
      "lines_added": [
        "# Shipping and Delivery Frequently Asked Questions",
        "",
        "## Shipping Options and Timeframes",
        "",
        "**Q: What shipping methods are available?**",
        "",
        "We offer multiple shipping options to meet your needs:",
        "- **Standard Shipping**: 5-7 business days (free on orders over $50)",
        "- **Express Shipping**: 2-3 business days ($12.99)",
        "- **Overnight Delivery**: Next business day by 5pm ($24.99)",
        "- **International Shipping**: 7-21 days depending on destination",
        "",
        "Expedited options must be selected before 2pm EST for same-day processing.",
        "",
        "**Q: How can I track my package?**",
        "",
        "Once your order ships, you'll receive a tracking number via email. Click the tracking link or enter the number on our website's Order Status page. Tracking updates every 4-6 hours. For real-time updates, use the carrier's tracking portal directly.",
        "",
        "**Q: Can I change my shipping address after ordering?**",
        "",
        "If your order hasn't shipped yet, contact us immediately to modify the address. Once the package is in transit, you'll need to work directly with the carrier to redirect delivery. Some carriers charge fees for address changes during transit.",
        "",
        "## Delivery Problems",
        "",
        "**Q: My package shows delivered, but I didn't receive it**",
        "",
        "First, check:",
        "- All entrances to your home (front/back door, garage)",
        "- With neighbors who may have accepted delivery",
        "- Inside your mailbox or parcel locker",
        "- Building reception desk or concierge",
        "",
        "If you still can't locate it after 24 hours, file a missing package claim. We'll investigate with the carrier and either replace your order or issue a refund.",
        "",
        "**Q: My delivery is delayed. What can I do?**",
        "",
        "Delays happen due to weather, carrier capacity, or customs (for international orders). Check the tracking for updates. If your package is more than 3 days past the estimated delivery date, contact us for assistance. We can expedite a replacement or offer a shipping refund.",
        "",
        "**Q: The package arrived damaged**",
        "",
        "We apologize for damaged deliveries. Please:",
        "1. Take photos of the package exterior and damaged contents",
        "2. Keep all packaging materials",
        "3. Contact us within 48 hours with photos and order number",
        "4. We'll arrange replacement or refund immediately",
        "",
        "Damaged items don't need to be returned unless specifically requested.",
        "",
        "## International Shipping",
        "",
        "**Q: Do you ship internationally?**",
        "",
        "Yes, we ship to over 150 countries. International shipping rates vary by destination and package weight. Customers are responsible for any customs duties, import taxes, or brokerage fees imposed by their country.",
        "",
        "**Q: Why is my international package held in customs?**",
        "",
        "Customs holds packages for inspection or when documentation is incomplete. You may need to:",
        "- Provide additional identification",
        "- Pay import duties or taxes",
        "- Clarify the contents or value",
        "",
        "Contact your local customs office with the tracking number for specific requirements. We can provide commercial invoices or declarations if needed.",
        "",
        "**Q: How are international shipping costs calculated?**",
        "",
        "International rates depend on:",
        "- Package weight and dimensions",
        "- Destination country",
        "- Shipping speed selected",
        "- Declared value for insurance",
        "",
        "Use our shipping calculator at checkout for exact costs. Some countries have restrictions on certain products.",
        "",
        "## Returns and Exchanges Shipping",
        "",
        "**Q: Who pays for return shipping?**",
        "",
        "For defective or incorrect items, we provide a prepaid return label at no cost. For other returns (change of mind, wrong size), customers pay return shipping unless you have a premium membership, which includes free return shipping.",
        "",
        "**Q: How do I return an item?**",
        "",
        "1. Initiate a return request in your account",
        "2. Print the return label (or request one via email)",
        "3. Package the item securely in original packaging if possible",
        "4. Drop off at any carrier location or schedule pickup",
        "5. Track your return using the provided tracking number",
        "",
        "Refunds are processed within 5 business days of receiving the return.",
        "",
        "**Q: Can I exchange an item instead of returning it?**",
        "",
        "Yes, exchanges are processed as a return plus a new order. Return the original item using our return process, and place a new order for the replacement. This ensures you get the new item faster than waiting for the return to process first.",
        "",
        "## Shipping Costs and Fees",
        "",
        "**Q: Why is my shipping cost so high?**",
        "",
        "Shipping costs reflect:",
        "- Package weight and size (oversized items cost more)",
        "- Distance from our warehouse",
        "- Selected shipping speed",
        "- Special handling requirements (fragile, refrigerated, etc.)",
        "",
        "Consider standard shipping for lower costs, or add items to qualify for free shipping threshold.",
        "",
        "**Q: Can I combine multiple orders to save on shipping?**",
        "",
        "If you placed multiple orders on the same day and they haven't shipped yet, contact us to combine them. Once orders enter fulfillment, they can't be merged. Consider using our shopping cart's \"Save for Later\" feature to accumulate items before checkout.",
        "",
        "**Q: Do you offer free shipping?**",
        "",
        "Yes, we offer free standard shipping on:",
        "- Orders over $50 within the continental US",
        "- All orders for premium members",
        "- Promotional periods (check our website for current offers)",
        "",
        "Free shipping doesn't apply to expedited delivery, Alaska, Hawaii, or international orders.",
        "",
        "## Special Circumstances",
        "",
        "**Q: I need delivery by a specific date. Can you guarantee it?**",
        "",
        "While we can't guarantee specific delivery dates due to carrier variables, express and overnight shipping have high on-time rates (95%+). Order well in advance for critical dates. For large or custom orders, contact our concierge team for special delivery arrangements.",
        "",
        "**Q: Can someone else receive my package?**",
        "",
        "Yes, packages can be delivered to anyone at the shipping address. For high-value items, signature confirmation may be required. You can add delivery instructions like \"Leave with neighbor\" or request hold at carrier facility for pickup.",
        "",
        "**Q: What if I'm not home during delivery?**",
        "",
        "Most carriers leave packages in a safe location if signature isn't required. You can:",
        "- Provide delivery instructions in your account settings",
        "- Authorize release without signature (carrier-dependent)",
        "- Request hold for pickup at a carrier facility",
        "- Use carrier's app to select alternative delivery dates",
        "",
        "Check your tracking information for carrier-specific options."
      ],
      "lines_removed": [],
      "context_before": [],
      "context_after": [],
      "change_type": "add"
    },
    {
      "file": "samples/customer_service/policy-privacy.md",
      "function": null,
      "start_line": 0,
      "lines_added": [
        "# Privacy Policy and Data Protection",
        "",
        "## Our Commitment to Your Privacy",
        "",
        "We take your privacy seriously. This policy explains what information we collect, how we use it, how we protect it, and your rights regarding your personal data.",
        "",
        "**Last Updated**: December 2025",
        "**Effective Date**: December 1, 2025",
        "",
        "## Information We Collect",
        "",
        "### Information You Provide",
        "",
        "**Account Information**:",
        "- Name and contact details (email, phone, mailing address)",
        "- Account credentials (username, password)",
        "- Payment information (processed by secure third-party payment processors)",
        "- Billing and shipping addresses",
        "- Communication preferences",
        "",
        "**Purchase Information**:",
        "- Order history and transaction details",
        "- Product preferences and wishlists",
        "- Returns and exchanges",
        "- Customer service interactions",
        "",
        "**Optional Information**:",
        "- Profile photo and biography",
        "- Birthday (for special offers)",
        "- Product reviews and ratings",
        "- Survey responses and feedback",
        "",
        "### Information We Collect Automatically",
        "",
        "**Usage Data**:",
        "- Pages visited and time spent",
        "- Click patterns and navigation paths",
        "- Search queries and filters used",
        "- Device information (browser, OS, screen resolution)",
        "- IP address and approximate location",
        "- Referring websites and exit pages",
        "",
        "**Cookies and Tracking Technologies**:",
        "- Session cookies (required for functionality)",
        "- Persistent cookies (remember preferences)",
        "- Analytics cookies (understand usage patterns)",
        "- Advertising cookies (personalized recommendations)",
        "",
        "**Mobile App Data**:",
        "- Device identifiers (advertising ID, device ID)",
        "- App usage statistics and crash reports",
        "- Push notification tokens",
        "- Location data (if you grant permission)",
        "",
        "### Information from Third Parties",
        "",
        "**Social Media Integration**:",
        "- Public profile information when you connect social accounts",
        "- Friends list (only if you authorize sharing)",
        "- Interests and preferences from social profiles",
        "",
        "**Data Partners**:",
        "- Credit reporting agencies (fraud prevention)",
        "- Marketing partners (demographic data)",
        "- Address verification services",
        "- Public databases and records",
        "",
        "## How We Use Your Information",
        "",
        "### Primary Uses",
        "",
        "**Order Fulfillment**:",
        "- Process and ship your orders",
        "- Send order confirmations and shipping updates",
        "- Handle returns, exchanges, and refunds",
        "- Provide customer support",
        "",
        "**Account Management**:",
        "- Create and maintain your account",
        "- Authenticate your identity",
        "- Remember your preferences and settings",
        "- Manage subscriptions and memberships",
        "",
        "**Communication**:",
        "- Respond to your inquiries",
        "- Send transactional emails (order updates, password resets)",
        "- Provide customer service",
        "- Notify you of policy changes or service updates",
        "",
        "**Personalization**:",
        "- Recommend products based on your history",
        "- Customize your shopping experience",
        "- Remember items in your cart and wishlist",
        "- Suggest relevant content and offers",
        "",
        "**Marketing** (with your consent):",
        "- Send promotional emails and newsletters",
        "- Display personalized advertisements",
        "- Notify you of sales and special offers",
        "- Invite you to participate in surveys or contests",
        "",
        "### Secondary Uses",
        "",
        "**Business Operations**:",
        "- Analyze trends and customer behavior",
        "- Improve our products and services",
        "- Develop new features and offerings",
        "- Test and optimize website performance",
        "- Train customer service representatives",
        "",
        "**Legal and Security**:",
        "- Prevent fraud and abuse",
        "- Enforce our terms of service",
        "- Comply with legal obligations",
        "- Protect our rights and property",
        "- Respond to legal requests and court orders",
        "",
        "**Research and Analytics**:",
        "- Understand shopping patterns and preferences",
        "- Conduct market research",
        "- Generate aggregate statistics (anonymized)",
        "- Benchmark performance metrics",
        "",
        "## Information Sharing and Disclosure",
        "",
        "### Service Providers",
        "",
        "We share data with trusted third parties who help us operate our business:",
        "",
        "**Essential Services**:",
        "- Payment processors (credit card, PayPal, etc.)",
        "- Shipping and fulfillment partners",
        "- Cloud hosting providers",
        "- Email service providers",
        "- Customer service platforms",
        "",
        "**Marketing and Analytics**:",
        "- Email marketing platforms",
        "- Analytics providers (Google Analytics, etc.)",
        "- Advertising networks",
        "- Social media platforms",
        "- Survey and feedback tools",
        "",
        "**Security and Compliance**:",
        "- Fraud detection services",
        "- Identity verification providers",
        "- Security monitoring services",
        "- Legal and compliance consultants",
        "",
        "**Contract Terms**: All service providers are bound by contracts requiring them to protect your data and use it only for specified purposes.",
        "",
        "### Business Transfers",
        "",
        "In the event of a merger, acquisition, or sale of assets, your information may be transferred to the acquiring entity. You'll be notified of any such change in ownership or control.",
        "",
        "### Legal Requirements",
        "",
        "We may disclose information when legally required:",
        "- In response to subpoenas or court orders",
        "- To comply with legal processes",
        "- To protect our rights or property",
        "- To prevent fraud or investigate security issues",
        "- To protect public safety or comply with law enforcement",
        "",
        "### With Your Consent",
        "",
        "We may share information in other circumstances with your explicit consent, such as:",
        "- Sharing reviews with product manufacturers",
        "- Participating in partner programs",
        "- Public testimonials or case studies",
        "",
        "### No Sale of Personal Data",
        "",
        "**Important**: We do not sell your personal information to third parties for their marketing purposes.",
        "",
        "## Your Privacy Rights and Choices",
        "",
        "### Access and Correction",
        "",
        "**Right to Access**:",
        "- Request a copy of your personal data",
        "- Download your account information",
        "- Review what data we have collected",
        "",
        "**Right to Correction**:",
        "- Update inaccurate information",
        "- Complete incomplete records",
        "- Edit account details anytime",
        "",
        "**How to Access**: Log into your account > Settings > Privacy > Download My Data",
        "",
        "### Data Deletion",
        "",
        "**Right to Deletion** (\"Right to Be Forgotten\"):",
        "- Request deletion of your personal data",
        "- Close your account permanently",
        "- Remove specific information",
        "",
        "**Limitations**:",
        "- We may retain some data for legal compliance (tax records, fraud prevention)",
        "- Anonymized data may be retained for analytics",
        "- Backup copies may persist for 90 days",
        "",
        "**How to Delete**: Account Settings > Delete Account or contact privacy@example.com",
        "",
        "### Marketing Preferences",
        "",
        "**Opt-Out Options**:",
        "",
        "**Email Marketing**:",
        "- Click \"Unsubscribe\" in any marketing email",
        "- Update preferences at Account > Email Preferences",
        "- Optionally unsubscribe from all promotional emails",
        "",
        "**SMS/Text Messages**:",
        "- Reply \"STOP\" to any text message",
        "- Manage preferences at Account > Notification Settings",
        "",
        "**Push Notifications**:",
        "- Disable in mobile app settings",
        "- Manage at device level (iOS/Android settings)",
        "",
        "**Personalized Ads**:",
        "- Opt out via Digital Advertising Alliance: www.aboutads.info",
        "- Use browser privacy settings to block tracking cookies",
        "- Enable \"Do Not Track\" in browser (we honor this signal)",
        "",
        "**Note**: You'll still receive transactional emails (order confirmations, password resets) even if you opt out of marketing.",
        "",
        "### Cookie Management",
        "",
        "**Cookie Controls**:",
        "- Essential cookies: Required for site functionality (cannot be disabled)",
        "- Analytics cookies: Can be disabled via Cookie Preferences",
        "- Advertising cookies: Can be disabled via Cookie Preferences or browser settings",
        "",
        "**Browser Settings**:",
        "- Clear cookies: Browser Settings > Privacy > Clear Data",
        "- Block cookies: Browser Settings > Privacy > Cookies",
        "- Note: Disabling cookies may limit site functionality",
        "",
        "### Regional Rights",
        "",
        "**California Residents (CCPA)**:",
        "- Right to know what data is collected",
        "- Right to deletion",
        "- Right to opt-out of data sales (we don't sell data)",
        "- Right to non-discrimination",
        "",
        "**European Residents (GDPR)**:",
        "- Right to access, rectify, and erase data",
        "- Right to data portability",
        "- Right to restrict or object to processing",
        "- Right to withdraw consent",
        "- Right to lodge a complaint with supervisory authority",
        "",
        "**To Exercise Rights**: Contact privacy@example.com or use our Privacy Request Portal",
        "",
        "## Data Security",
        "",
        "### Security Measures",
        "",
        "**Technical Safeguards**:",
        "- 256-bit SSL/TLS encryption for data in transit",
        "- AES-256 encryption for data at rest",
        "- Secure authentication and access controls",
        "- Regular security audits and penetration testing",
        "- Intrusion detection and prevention systems",
        "",
        "**Organizational Safeguards**:",
        "- Employee training on data protection",
        "- Strict access controls (need-to-know basis)",
        "- Background checks for employees with data access",
        "- Confidentiality agreements with all personnel",
        "- Incident response and breach notification procedures",
        "",
        "**Payment Security**:",
        "- PCI DSS Level 1 compliance",
        "- Tokenization (we don't store full card numbers)",
        "- Secure payment gateways",
        "- Fraud detection and prevention",
        "",
        "### Data Retention",
        "",
        "**Retention Periods**:",
        "- Account data: Retained while account is active + 3 years after closure",
        "- Transaction records: 7 years (tax and legal requirements)",
        "- Marketing data: Until you opt-out or request deletion",
        "- Analytics data: Anonymized after 26 months",
        "- Security logs: 1 year",
        "",
        "**Automatic Deletion**:",
        "- Inactive accounts (no login for 3 years) are deleted",
        "- Abandoned carts purged after 90 days",
        "- Temporary data (session cookies) deleted immediately upon session end",
        "",
        "## Children's Privacy",
        "",
        "**Age Requirement**: Our services are not intended for children under 13 (or 16 in some jurisdictions).",
        "",
        "**Policy**:",
        "- We do not knowingly collect data from children",
        "- If we discover child data, we delete it immediately",
        "- Parents can request deletion of child's data: privacy@example.com",
        "",
        "**Parental Controls**: If you believe your child has provided us information, contact us immediately for removal.",
        "",
        "## International Data Transfers",
        "",
        "### Cross-Border Transfers",
        "",
        "**Data Location**: Your information may be transferred to and processed in countries other than your own, including the United States.",
        "",
        "**Protection Mechanisms**:",
        "- Standard Contractual Clauses (EU-approved)",
        "- Privacy Shield certification (where applicable)",
        "- Adequate protection requirements",
        "- Your consent where required",
        "",
        "**Your Rights**: Even when data is processed abroad, you retain all privacy rights described in this policy.",
        "",
        "## Third-Party Links and Services",
        "",
        "**External Websites**: Our site may link to third-party websites. This privacy policy does not apply to those sites. Review their privacy policies before providing information.",
        "",
        "**Social Media**: Interactions with social media features (Like, Share buttons) are governed by the privacy policies of those platforms.",
        "",
        "**Plugins and Widgets**: Third-party plugins may collect data directly. We don't control their data practices.",
        "",
        "## Changes to This Policy",
        "",
        "**Updates**: We may update this privacy policy periodically to reflect:",
        "- Changes in our practices",
        "- New legal requirements",
        "- New features or services",
        "- Customer feedback",
        "",
        "**Notification**:",
        "- Material changes: Email notification 30 days before effective date",
        "- Minor changes: Posted on website with updated \"Last Updated\" date",
        "- Continued use of services constitutes acceptance of changes",
        "",
        "**Policy History**: Previous versions available at www.example.com/privacy-archive",
        "",
        "## Contact Us",
        "",
        "### Privacy Questions",
        "",
        "**Privacy Team**:",
        "- Email: privacy@example.com",
        "- Phone: 1-800-PRIVACY (1-800-774-8229)",
        "- Mail: Privacy Officer, 123 Main Street, Suite 100, City, State 12345",
        "",
        "**Response Time**: We respond to privacy inquiries within 5 business days.",
        "",
        "### Data Protection Officer",
        "",
        "**EU/UK Residents**:",
        "- Email: dpo@example.com",
        "- Address: Data Protection Officer, [EU Office Address]",
        "",
        "### Privacy Request Portal",
        "",
        "For formal requests regarding your data:",
        "- Access requests: www.example.com/privacy/access",
        "- Deletion requests: www.example.com/privacy/delete",
        "- Opt-out requests: www.example.com/privacy/opt-out",
        "",
        "**Verification**: For security, we may ask you to verify your identity before fulfilling requests.",
        "",
        "---",
        "",
        "*This privacy policy is governed by the laws of [Jurisdiction]. For complete terms of service, visit www.example.com/terms.*"
      ],
      "lines_removed": [],
      "context_before": [],
      "context_after": [],
      "change_type": "add"
    },
    {
      "file": "samples/customer_service/policy-returns.md",
      "function": null,
      "start_line": 0,
      "lines_added": [
        "# Return and Refund Policy",
        "",
        "## Return Eligibility",
        "",
        "### What Can Be Returned",
        "",
        "We want you to be completely satisfied with your purchase. You may return most items within **30 days of delivery** for a full refund or exchange.",
        "",
        "**Eligible for Return**:",
        "- Unused items in original packaging",
        "- Products with defects or manufacturing issues",
        "- Incorrect items shipped by error",
        "- Damaged items received",
        "- Items not matching description",
        "",
        "**Non-Returnable Items**:",
        "- Personalized or custom-made products",
        "- Perishable goods (food, flowers, etc.)",
        "- Digital products or software (once downloaded)",
        "- Intimate apparel and health/safety items (unless defective)",
        "- Clearance or final sale items (marked \"All Sales Final\")",
        "- Gift cards and store credit",
        "",
        "### Time Limits for Returns",
        "",
        "- **Standard Return Window**: 30 days from delivery date",
        "- **Extended Holiday Returns**: Items purchased Nov 1 - Dec 24 can be returned until Jan 31",
        "- **Defective Items**: Can be returned within 1 year of purchase",
        "- **Premium Members**: Extended 60-day return window on all eligible items",
        "",
        "**Late Returns**: Items returned after the deadline may be refused or subject to a 25% restocking fee at our discretion.",
        "",
        "## Return Process",
        "",
        "### How to Initiate a Return",
        "",
        "**Method 1: Online Return Portal** (Fastest)",
        "1. Log into your account at www.example.com",
        "2. Go to Orders > View Order History",
        "3. Select the order containing the item to return",
        "4. Click \"Return Item\" next to the product",
        "5. Select reason for return from dropdown menu",
        "6. Choose refund method (original payment or store credit)",
        "7. Print prepaid return label or request email delivery",
        "",
        "**Method 2: Customer Service**",
        "- Call: 1-800-RETURNS (1-800-738-8767)",
        "- Email: returns@example.com with order number",
        "- Live Chat: Available Mon-Fri 9am-9pm EST",
        "",
        "**Method 3: In-Store Returns** (if applicable)",
        "- Bring item with original receipt or order confirmation",
        "- Present ID for purchases over $50",
        "- Receive instant refund to original payment method",
        "",
        "### Packaging Your Return",
        "",
        "**Proper Packaging Ensures Faster Processing**:",
        "1. Include all original accessories, manuals, and packaging if possible",
        "2. Remove or cover old shipping labels",
        "3. Place return label on outside of package",
        "4. Seal box securely with packing tape",
        "5. Keep tracking number for your records",
        "",
        "**Important**: We cannot refund items damaged during return shipping due to inadequate packaging.",
        "",
        "### Shipping Your Return",
        "",
        "**Free Returns**:",
        "- Defective or damaged products (we cover all costs)",
        "- Our error (wrong item sent)",
        "- Premium membership holders (free returns on all eligible items)",
        "",
        "**Customer-Paid Returns** ($6.99 standard rate):",
        "- Change of mind",
        "- Ordered wrong size/color",
        "- No longer needed",
        "",
        "**Return Shipping Options**:",
        "1. Use our prepaid return label (fee deducted from refund if applicable)",
        "2. Ship via your preferred carrier (save receipt for tracking)",
        "3. Drop off at any partner retail location (free for premium members)",
        "",
        "**Return Tracking**: Always use a tracked shipping method. We're not responsible for returns lost in transit without tracking.",
        "",
        "## Refunds and Processing",
        "",
        "### Refund Methods",
        "",
        "**Original Payment Method** (Default)",
        "- Credit/debit card refunds: 5-7 business days after we receive return",
        "- PayPal refunds: 3-5 business days",
        "- Bank transfers: 7-10 business days",
        "- Gift card purchases: Refunded as store credit",
        "",
        "**Store Credit** (Instant)",
        "- 10% bonus credit when choosing store credit option",
        "- Never expires",
        "- Can be combined with promotional offers",
        "- Transferable to other accounts",
        "",
        "**Exchange**",
        "- Processed as a return + new order",
        "- Original item must be returned first",
        "- New item ships immediately upon return initiation",
        "- Price difference charged or refunded accordingly",
        "",
        "### Refund Timeline",
        "",
        "**Standard Processing**:",
        "1. Return delivered to warehouse: 1-2 business days for tracking update",
        "2. Return inspected: 2-3 business days",
        "3. Refund processed: Same day as approval",
        "4. Funds available in account: 5-7 business days (bank dependent)",
        "",
        "**Total Time**: Approximately 7-14 business days from return shipment to funds in account.",
        "",
        "**Expedited Refund**: Premium members receive refund approval within 24 hours of return delivery and can request advance store credit.",
        "",
        "### Partial Refunds",
        "",
        "You may receive a partial refund in these situations:",
        "",
        "**Restocking Fees** (25% of item price):",
        "- Electronics returned after 15 days",
        "- Items returned without original packaging",
        "- Items showing signs of use or wear",
        "- Special order items",
        "",
        "**Return Shipping Deduction** ($6.99):",
        "- Non-defective returns when customer chooses our return label",
        "- Waived for premium members and defective items",
        "",
        "**Missing Components** (prorated):",
        "- Incomplete returns (missing accessories, parts, manuals)",
        "- Deduction based on cost to replace missing components",
        "",
        "**Damage** (assessed):",
        "- Items damaged during customer possession",
        "- Reduced value due to condition",
        "",
        "You'll be notified via email if any deductions apply before final refund processing.",
        "",
        "## Exchanges",
        "",
        "### Same-Item Exchange",
        "",
        "**For Different Size/Color**:",
        "- Return original item using standard process",
        "- Place new order immediately (don't wait for refund)",
        "- Note in return reason: \"Exchange for [size/color]\"",
        "- We'll match any price changes in your favor",
        "",
        "**Faster Exchange Service** (Premium Members):",
        "- New item ships immediately upon exchange request",
        "- Original item must be returned within 14 days",
        "- No charge unless original item not returned",
        "",
        "### Defective Item Replacement",
        "",
        "**Our Commitment**: If you receive a defective product, we'll make it right.",
        "",
        "**Replacement Process**:",
        "1. Contact customer service within 48 hours of receiving defective item",
        "2. Describe defect and provide photos if requested",
        "3. Receive prepaid return label via email",
        "4. Replacement ships same day we receive return",
        "5. Option for advance replacement (ships before return received)",
        "",
        "**Advance Replacement**:",
        "- Available for defective items",
        "- May require temporary authorization hold on credit card",
        "- Hold removed when defective item received",
        "- Saves time waiting for return to process",
        "",
        "## Special Circumstances",
        "",
        "### Damaged in Shipping",
        "",
        "**File Claim Immediately**:",
        "- Take photos of damaged package exterior and contents",
        "- Keep all packaging materials",
        "- Report damage within 48 hours of delivery",
        "- We'll arrange replacement or refund without requiring return",
        "",
        "**Carrier Responsibility**: For visibly damaged packages, note damage with delivery driver or refuse delivery.",
        "",
        "### Wrong Item Received",
        "",
        "**Our Error - We Fix It Fast**:",
        "1. Keep incorrect item temporarily (don't return yet)",
        "2. Contact us immediately with order number",
        "3. We'll send correct item with prepaid return label for wrong item",
        "4. No cost to you - we cover all shipping",
        "",
        "**Return Timeline**: Return wrong item within 30 days of receiving correct item.",
        "",
        "### Missing Items",
        "",
        "**If Part of Your Order Is Missing**:",
        "1. Check all packaging carefully (items may be in packaging material)",
        "2. Contact us within 7 days of delivery",
        "3. We'll investigate shipment and shipping weight",
        "4. Reship missing items or refund at your preference",
        "",
        "**Proof of Missing Item**: We may ask for package photos or weight from shipping label.",
        "",
        "### Change of Mind Before Shipping",
        "",
        "**Order Cancellation**:",
        "- Cancel anytime before shipment for full refund",
        "- Once shipped, standard return policy applies",
        "- Cancellation processed within 24 hours",
        "- Refund to original payment method in 3-5 business days",
        "",
        "**Modify Order**: Changes may be possible if order hasn't entered fulfillment (typically 2-hour window).",
        "",
        "## International Returns",
        "",
        "### Returns from Outside the US",
        "",
        "**Policy for International Customers**:",
        "- Same 30-day return window applies",
        "- Customer responsible for return shipping costs",
        "- Customs duties/taxes are non-refundable",
        "- Use tracked international shipping method",
        "- Allow 3-4 weeks for international return processing",
        "",
        "**Return Address**: Ship to designated international returns facility (provided via email, not US warehouse).",
        "",
        "**Refund Method**: Original payment method minus original shipping charges.",
        "",
        "### Import Duties and Taxes",
        "",
        "**Non-Refundable Fees**:",
        "- Customs duties",
        "- Import taxes",
        "- Brokerage fees",
        "- International shipping costs",
        "",
        "**Refund Amount**: Product cost only, excluding all shipping and import fees.",
        "",
        "## Warranty and Guarantees",
        "",
        "### Product Warranties",
        "",
        "**Manufacturer Warranty**:",
        "- Contact manufacturer directly for warranty claims",
        "- Warranty period varies by product (typically 1-5 years)",
        "- Keep proof of purchase for warranty claims",
        "- We can facilitate warranty claims if needed",
        "",
        "**Our Satisfaction Guarantee**:",
        "- 30-day money-back guarantee on most items",
        "- Free replacement for defective items within 1 year",
        "- Price match guarantee (30 days post-purchase)",
        "",
        "### Extended Protection Plans",
        "",
        "**Optional Coverage**:",
        "- Accidental damage protection",
        "- Extended warranty beyond manufacturer coverage",
        "- No-hassle replacement service",
        "- Available at checkout for eligible items",
        "",
        "## Questions About Returns",
        "",
        "**Need Help?**",
        "- Returns FAQ: www.example.com/returns-faq",
        "- Return Status Check: www.example.com/track-return",
        "- Customer Service: returns@example.com or 1-800-RETURNS",
        "- Live Chat: Available Mon-Fri 9am-9pm EST",
        "",
        "**Track Your Return**:",
        "Log into your account > Orders > Return Status to see:",
        "- Return received date",
        "- Inspection status",
        "- Refund processing status",
        "- Expected refund date",
        "",
        "**Premium Support**: Enterprise and premium members have dedicated returns support with 2-hour response SLA.",
        "",
        "---",
        "",
        "*This return policy is subject to change. Current version effective December 2025. For complete terms and conditions, visit www.example.com/terms.*"
      ],
      "lines_removed": [],
      "context_before": [],
      "context_after": [],
      "change_type": "add"
    },
    {
      "file": "samples/customer_service/template-apology.md",
      "function": null,
      "start_line": 0,
      "lines_added": [
        "# Customer Apology Response Templates",
        "",
        "## Service Failure Apologies",
        "",
        "### Template 1: Delayed Delivery",
        "",
        "**Subject**: Our Apologies for Your Delayed Order - [Order #12345]",
        "",
        "Dear [Customer Name],",
        "",
        "I sincerely apologize for the delay in delivering your order #[12345]. I understand how frustrating it is when a package doesn't arrive as expected, especially when you're counting on it.",
        "",
        "**What Happened**:",
        "[Brief, honest explanation: carrier delays, weather, warehouse issue, etc.]",
        "",
        "**What We're Doing**:",
        "- Your package is currently [location/status] and is expected to arrive by [date]",
        "- I've escalated your shipment to priority status",
        "- You'll receive tracking updates every 4 hours until delivery",
        "",
        "**Making It Right**:",
        "To apologize for this inconvenience, I've applied a [X%] discount to your account for your next purchase, and we're refunding your shipping charges.",
        "",
        "If your package doesn't arrive by [date], please contact me directly at [email] and I'll arrange for immediate replacement or a full refund‚Äîwhichever you prefer.",
        "",
        "Thank you for your patience and for giving us the opportunity to make this right.",
        "",
        "Warm regards,",
        "[Your Name]",
        "Customer Experience Team",
        "[Direct Contact Information]",
        "",
        "---",
        "",
        "### Template 2: Product Quality Issue",
        "",
        "**Subject**: We're Sorry - Your Experience Didn't Meet Our Standards",
        "",
        "Dear [Customer Name],",
        "",
        "I'm truly sorry to hear that [product name] didn't meet your expectations. We take pride in quality, and it's disappointing when we fall short.",
        "",
        "**Your Feedback**:",
        "You mentioned that [specific issue: defect, damage, not as described]. This is not acceptable, and I want to make it right immediately.",
        "",
        "**Immediate Resolution**:",
        "I've processed a replacement order that will ship today via [expedited method]. You should receive it by [date]. There's absolutely no charge for the replacement or shipping.",
        "",
        "For the defective item:",
        "- Keep it, donate it, or dispose of it‚Äîno need to return",
        "- Or, if you prefer, use the enclosed prepaid label to return it at no cost",
        "",
        "**What We're Changing**:",
        "I've shared your feedback with our quality team. We're reviewing [specific aspect: manufacturing process, packaging, product description] to prevent this from happening to other customers.",
        "",
        "**Your Account**:",
        "As an apology, I've added [store credit amount / loyalty points / discount code] to your account. You've been a valued customer since [date], and we appreciate your business.",
        "",
        "Please don't hesitate to contact me personally at [email] if you have any concerns about the replacement or if there's anything else I can do.",
        "",
        "Sincerely,",
        "[Your Name]",
        "Customer Care Manager",
        "[Direct Contact Information]",
        "",
        "---",
        "",
        "### Template 3: Wrong Item Shipped",
        "",
        "**Subject**: Our Mistake - Wrong Item Sent for Order #[12345]",
        "",
        "Dear [Customer Name],",
        "",
        "I'm reaching out to personally apologize. We sent you [wrong item] instead of [correct item] for order #[12345]. This was our error, and I'm sorry for the inconvenience.",
        "",
        "**Here's How We're Fixing It**:",
        "",
        "**Immediate Action**:",
        "- The correct item ([correct item]) is being shipped today via overnight delivery",
        "- You'll receive it by [date/time]",
        "- No additional charge",
        "",
        "**The Wrong Item**:",
        "- Please keep it as our apology gift, or",
        "- Use the prepaid return label (enclosed) if you'd prefer to return it",
        "- Absolutely no rush‚Äîyou have 60 days to return if you choose",
        "",
        "**Compensation**:",
        "In addition to expedited shipping of the correct item, I've:",
        "- Refunded your original shipping charges",
        "- Applied a [X%] courtesy discount to your account",
        "- Added [loyalty points/store credit] as an apology",
        "",
        "**Why This Happened**:",
        "[Brief explanation if relevant: warehouse reorganization, similar SKUs, etc.]. We're implementing additional quality checks to prevent this error.",
        "",
        "I know your time is valuable, and these extra steps shouldn't have been necessary. Thank you for your understanding and patience.",
        "",
        "If you have any questions or concerns, please email me directly at [email] or call my direct line at [phone].",
        "",
        "My sincere apologies,",
        "[Your Name]",
        "Senior Customer Service Specialist",
        "[Direct Contact Information]",
        "",
        "---",
        "",
        "## Technical and Access Issues",
        "",
        "### Template 4: Website/System Outage",
        "",
        "**Subject**: Apology for Service Interruption - We're Back Online",
        "",
        "Dear [Customer Name],",
        "",
        "I want to personally apologize for the service disruption you experienced on [date]. Our website and systems were unavailable from [time] to [time], and I understand this may have prevented you from [placing an order, accessing your account, etc.].",
        "",
        "**What Happened**:",
        "[Brief, transparent explanation: server issues, maintenance overrun, DDoS attack, etc.]",
        "",
        "**Impact on You**:",
        "I see that you attempted to [specific action] during the outage. [Acknowledge specific impact if known from logs]",
        "",
        "**Making Amends**:",
        "- All systems are now fully operational",
        "- We've implemented [specific improvement] to prevent recurrence",
        "- To apologize for the inconvenience, we're offering [compensation: discount, free shipping, extended trial, etc.]",
        "",
        "**If You Need Assistance**:",
        "If you were in the middle of an order or transaction:",
        "- Your cart has been saved and is ready when you are",
        "- Any pending orders have been processed with expedited shipping at no charge",
        "- Contact me at [email] if you need any help completing your transaction",
        "",
        "We value your business and patience. If there's anything I can do to help, please don't hesitate to reach out.",
        "",
        "Best regards,",
        "[Your Name]",
        "Customer Support Lead",
        "[Direct Contact Information]",
        "",
        "---",
        "",
        "### Template 5: Billing Error",
        "",
        "**Subject**: Billing Correction and Our Apologies - Account #[123456]",
        "",
        "Dear [Customer Name],",
        "",
        "I'm writing to apologize for a billing error on your account. On [date], you were [overcharged/charged incorrectly/double-billed] for [amount].",
        "",
        "**The Error**:",
        "[Specific explanation: system glitch, processing error, etc.]",
        "",
        "**Correction Applied**:",
        "- Full refund of [amount] has been processed to your [original payment method]",
        "- Funds will appear in your account within [timeframe]",
        "- Confirmation number: [number]",
        "- All late fees or penalties have been waived",
        "",
        "**Verification**:",
        "I've personally reviewed your account to ensure:",
        "- No other billing errors exist",
        "- Your payment information is correct",
        "- All charges going forward are accurate",
        "- You're on the optimal plan for your usage",
        "",
        "**Your Account Standing**:",
        "Please note that this error has not affected your account status, credit, or service in any way. Everything is in perfect standing.",
        "",
        "**Our Apology**:",
        "To apologize for this error and any concern it caused:",
        "- [Next month's service fee waived / account credit / loyalty bonus]",
        "- Priority support access for the next 90 days",
        "- Direct line to our billing supervisor if you have any questions: [phone]",
        "",
        "I sincerely apologize for any inconvenience or worry this may have caused. If you have any questions about this correction or your account, please contact me directly.",
        "",
        "Respectfully,",
        "[Your Name]",
        "Billing Resolution Specialist",
        "[Direct Contact Information]",
        "",
        "---",
        "",
        "## Customer Service Failures",
        "",
        "### Template 6: Poor Service Experience",
        "",
        "**Subject**: My Personal Apology for Your Recent Experience",
        "",
        "Dear [Customer Name],",
        "",
        "I was troubled to learn about your recent experience with our customer service team. You deserved better, and I'm sorry we didn't meet that expectation.",
        "",
        "**What You Experienced**:",
        "[Acknowledge specific issues: long wait time, unhelpful representative, rude behavior, lack of resolution, etc.]",
        "",
        "**This Is Not Who We Are**:",
        "The service you received doesn't reflect our values or standards. Our team should be [helpful, courteous, knowledgeable, responsive], and I'm disappointed that wasn't your experience.",
        "",
        "**What I'm Doing**:",
        "1. **Immediate Resolution**: I've personally reviewed your case and [specific resolution]",
        "2. **Team Training**: Your feedback has been shared with our service team and their manager for coaching",
        "3. **Process Improvement**: We're reviewing our [specific process] to ensure better outcomes",
        "",
        "**My Commitment**:",
        "Going forward, you have:",
        "- My direct contact information: [email] and [phone]",
        "- Priority support access (your calls/emails go to the front of the queue)",
        "- A dedicated account representative: [name, contact info]",
        "",
        "**Our Appreciation**:",
        "Thank you for bringing this to our attention. Feedback like yours helps us improve. As a token of our apology, [specific compensation].",
        "",
        "You've been a customer since [date], and your business means a lot to us. I hope you'll give us another opportunity to demonstrate the level of service you deserve.",
        "",
        "Sincerely,",
        "[Your Name]",
        "[Senior Title: Manager, Director, VP of Customer Experience]",
        "[Direct Contact Information]",
        "",
        "---",
        "",
        "### Template 7: Repeated Issues",
        "",
        "**Subject**: Enough Is Enough - Our Apology and Commitment to You",
        "",
        "Dear [Customer Name],",
        "",
        "I need to apologize. You've experienced [number] issues with us in [timeframe]:",
        "1. [First issue]",
        "2. [Second issue]",
        "3. [Recent issue]",
        "",
        "This is unacceptable. One problem is a mistake; multiple problems indicate a systemic issue that we need to fix.",
        "",
        "**I Hear You**:",
        "I've read through all your previous tickets and correspondence. You've been more patient than we deserve. Each time you've had to contact us, reach out again, or work around our problems represents a failure on our part.",
        "",
        "**What's Actually Changing**:",
        "Not just lip service‚Äîhere's what's happening:",
        "",
        "**For You Personally**:",
        "- I'm your single point of contact going forward: [email], [phone]",
        "- All your concerns will be escalated automatically",
        "- [Premium support level] access for the next [timeframe]",
        "- I'll personally review your account monthly to ensure everything is working perfectly",
        "",
        "**Systematically**:",
        "- Your case has been reviewed by our executive team",
        "- We've identified the root cause: [specific issue]",
        "- We're implementing [specific solution] by [date]",
        "- I'll update you on progress every [timeframe]",
        "",
        "**Making Amends**:",
        "Words aren't enough. Here's what we're doing:",
        "- [Significant compensation: multiple months free, substantial credit, upgrade, etc.]",
        "- Guaranteed [specific service level/response time]",
        "- Personal accountability from me",
        "",
        "**Your Decision**:",
        "I hope you'll stay with us and let us prove we can do better. But I understand if this has been too frustrating. If you choose to leave:",
        "- No cancellation fees or penalties",
        "- Full refund of [recent charges]",
        "- Assistance with transition to another provider",
        "- No questions asked",
        "",
        "You deserved better from the beginning. I'm committed to ensuring you get it going forward.",
        "",
        "My sincere apologies,",
        "[Your Name]",
        "[Senior Executive Title]",
        "[Direct Contact Information]",
        "[LinkedIn Profile / Corporate Bio]",
        "",
        "---",
        "",
        "## Usage Guidelines",
        "",
        "### When to Use These Templates",
        "",
        "**Use Templates When**:",
        "- Customer experienced objective service failure",
        "- Error was clearly our fault",
        "- Customer expressed dissatisfaction",
        "- We need to rebuild trust",
        "- Issue requires escalation or special handling",
        "",
        "**Customize for**:",
        "- Severity of issue",
        "- Customer's tone and emotional state",
        "- Customer's history and value",
        "- Specific circumstances",
        "- Company policies and capabilities",
        "",
        "### Tone and Language Principles",
        "",
        "**Do**:",
        "- Use first person (\"I\" not \"we\" when apologizing)",
        "- Be specific about what went wrong",
        "- Take ownership without excuses",
        "- Explain what you're doing to fix it",
        "- Offer meaningful compensation",
        "- Thank them for patience/feedback",
        "- Provide direct contact information",
        "",
        "**Don't**:",
        "- Use passive voice or deflect blame",
        "- Make excuses or over-explain",
        "- Use corporate jargon or template language obviously",
        "- Make promises you can't keep",
        "- Minimize the customer's frustration",
        "- Rush to compensation without acknowledging impact",
        "- Send generic apologies for specific problems",
        "",
        "### Compensation Guidelines",
        "",
        "**Match Compensation to Impact**:",
        "- Minor inconvenience: Small discount or loyalty points",
        "- Moderate issue: Shipping refund, account credit",
        "- Significant problem: Service credit, upgrade, substantial discount",
        "- Major failure: Multiple months free, significant account credit, premium benefits",
        "- Repeated issues: Executive-level compensation and guarantees",
        "",
        "**Always Include**:",
        "- Specific dollar/percentage amount",
        "- How and when it will be applied",
        "- Any conditions or expiration",
        "- How they can verify it was applied",
        "",
        "### Follow-Up Protocol",
        "",
        "**After Sending Apology**:",
        "1. Monitor for customer response within 24 hours",
        "2. Follow up if no response after 48 hours (ensure they received it)",
        "3. Verify compensation was applied",
        "4. Check in 1 week later to ensure resolution is satisfactory",
        "5. Flag account for extra care on next interaction",
        "",
        "**Escalation Criteria**:",
        "If customer is still unsatisfied after apology:",
        "- Escalate to supervisor/manager",
        "- Increase compensation offer",
        "- Provide additional direct contact options",
        "- Consider phone call instead of email",
        "- Involve executive team if necessary",
        "",
        "---",
        "",
        "*These templates should be personalized for each situation. The most effective apologies are genuine, specific, and demonstrate real accountability.*"
      ],
      "lines_removed": [],
      "context_before": [],
      "context_after": [],
      "change_type": "add"
    },
    {
      "file": "samples/customer_service/template-resolution.md",
      "function": null,
      "start_line": 0,
      "lines_added": [
        "# Customer Issue Resolution Templates",
        "",
        "## Order and Shipping Resolutions",
        "",
        "### Template 1: Refund Approved",
        "",
        "**Subject**: Your Refund Has Been Approved - Order #[12345]",
        "",
        "Dear [Customer Name],",
        "",
        "Great news! I've approved your refund request for order #[12345].",
        "",
        "**Refund Details**:",
        "- **Amount**: $[XX.XX]",
        "- **Method**: [Original payment method / Store credit]",
        "- **Processing Date**: [Date]",
        "- **Expected in Account**: [Timeframe] (typically 5-7 business days)",
        "- **Confirmation Number**: [Number]",
        "",
        "**What Was Refunded**:",
        "- [Item 1]: $[XX.XX]",
        "- [Item 2]: $[XX.XX]",
        "- Shipping charges: $[XX.XX]",
        "- Tax: $[XX.XX]",
        "- **Total**: $[XX.XX]",
        "",
        "**Tracking Your Refund**:",
        "You can track this refund in your account under Orders > Refunds. You'll also receive an email confirmation when the funds are deposited.",
        "",
        "**For Your Records**:",
        "- Original order date: [Date]",
        "- Refund request date: [Date]",
        "- Refund approval date: [Date]",
        "",
        "If you have any questions about this refund, or if you don't see it in your account within [timeframe], please contact me directly at [email].",
        "",
        "Thank you for your business, and we hope to serve you again soon.",
        "",
        "Best regards,",
        "[Your Name]",
        "Customer Service Team",
        "[Contact Information]",
        "",
        "---",
        "",
        "### Template 2: Replacement Order Shipped",
        "",
        "**Subject**: Your Replacement Is On The Way - Order #[12345]",
        "",
        "Dear [Customer Name],",
        "",
        "Your replacement order has been processed and shipped! I wanted to make sure you have all the tracking information.",
        "",
        "**Replacement Order Details**:",
        "- **New Order Number**: #[67890]",
        "- **Items**: [List of items]",
        "- **Shipping Method**: [Method] (upgraded at no charge)",
        "- **Tracking Number**: [Number]",
        "- **Carrier**: [Carrier name with tracking link]",
        "- **Expected Delivery**: [Date]",
        "",
        "**Original Issue**:",
        "This replacement is for your original order #[12345] where you reported [issue: damaged item, wrong item, defective product].",
        "",
        "**The Original Item**:",
        "[Choose appropriate option:]",
        "- No return necessary - please keep, donate, or dispose of the original item",
        "- Use the enclosed prepaid return label to send back at your convenience (no rush)",
        "- We'll schedule a pickup on [date] if that works for you",
        "",
        "**What's Different**:",
        "To ensure this doesn't happen again, this replacement has been:",
        "- Personally inspected by our quality team",
        "- Packed with extra protective material",
        "- Shipped via upgraded carrier service",
        "",
        "**We're Monitoring**:",
        "I've added delivery tracking alerts to your replacement. If anything goes wrong, I'll be notified immediately and will reach out to you proactively.",
        "",
        "**Your Account**:",
        "As an apology for the original issue, I've also [applied discount/credit/loyalty points] to your account.",
        "",
        "Thank you for your patience while we made this right. If you have any questions or concerns, I'm here to help.",
        "",
        "Warm regards,",
        "[Your Name]",
        "Customer Resolution Specialist",
        "[Contact Information]",
        "",
        "---",
        "",
        "### Template 3: Issue Escalated and Resolved",
        "",
        "**Subject**: Resolution Update - We've Solved Your Issue",
        "",
        "Dear [Customer Name],",
        "",
        "I'm pleased to let you know that we've resolved the issue with your account/order. Thank you for your patience while we investigated.",
        "",
        "**The Problem**:",
        "[Brief description of the issue they reported]",
        "",
        "**What We Found**:",
        "[Clear explanation of root cause without too much technical detail]",
        "",
        "**The Solution**:",
        "Here's what we did to fix it:",
        "1. [Specific action taken]",
        "2. [Specific action taken]",
        "3. [Specific action taken]",
        "",
        "**Verification**:",
        "I've personally tested/verified that:",
        "- [Specific outcome]",
        "- [Specific outcome]",
        "- Everything is now working as expected",
        "",
        "**For You Going Forward**:",
        "- [Any actions they need to take, if any]",
        "- [Preventive measures they can use]",
        "- [Improvements we've made to prevent recurrence]",
        "",
        "**Compensation**:",
        "To apologize for this inconvenience and your time, we've:",
        "- [Specific compensation]",
        "- [Additional benefit if applicable]",
        "",
        "**Confirmation**:",
        "Can you please confirm that everything is working properly on your end? Just reply to this email or call me at [phone] if you notice anything still not right.",
        "",
        "If everything looks good, no response needed‚Äîbut I wanted to make sure you're all set.",
        "",
        "Thank you for bringing this to our attention and for being such a valued customer.",
        "",
        "Best regards,",
        "[Your Name]",
        "[Title]",
        "[Contact Information]",
        "",
        "---",
        "",
        "## Account and Access Resolutions",
        "",
        "### Template 4: Account Access Restored",
        "",
        "**Subject**: Your Account Is Now Accessible - Welcome Back!",
        "",
        "Dear [Customer Name],",
        "",
        "Good news! I've successfully restored access to your account. You can now log in using your email address and the password you just reset.",
        "",
        "**What Happened**:",
        "[Brief explanation: temporary lock due to failed login attempts, payment issue resolved, verification completed, etc.]",
        "",
        "**Account Status**:",
        "- **Status**: Active and fully functional",
        "- **Access Level**: [Full access / Specific permissions]",
        "- **Services Available**: All features restored",
        "- **Outstanding Issues**: None",
        "",
        "**Security Recommendation**:",
        "To keep your account secure going forward:",
        "- Enable two-factor authentication (Account > Security Settings)",
        "- Use a strong, unique password",
        "- Never share login credentials",
        "- Review account activity regularly",
        "",
        "**Quick Security Setup**:",
        "I can help you set up two-factor authentication right now if you'd like extra security. Just reply to this email and I'll walk you through it (takes about 2 minutes).",
        "",
        "**Verification**:",
        "I've confirmed that:",
        "- All your previous data and settings are intact",
        "- Your payment method is current (if applicable)",
        "- There are no restrictions on your account",
        "- You can access all features and services",
        "",
        "If you have any trouble logging in or notice anything unusual, please contact me immediately at [email] or [phone].",
        "",
        "Welcome back!",
        "",
        "Best regards,",
        "[Your Name]",
        "Account Support Specialist",
        "[Contact Information]",
        "",
        "---",
        "",
        "### Template 5: Billing Dispute Resolved",
        "",
        "**Subject**: Billing Issue Resolved - Adjustment Applied to Your Account",
        "",
        "Dear [Customer Name],",
        "",
        "I've completed the review of your billing inquiry, and you were absolutely right. I've made the necessary corrections to your account.",
        "",
        "**The Issue**:",
        "You were charged [amount] on [date] for [description], which you disputed because [reason].",
        "",
        "**Our Findings**:",
        "After reviewing your account and transaction history, I confirmed that:",
        "- [Specific finding supporting their claim]",
        "- [Additional relevant details]",
        "",
        "**Resolution**:",
        "Here's what I've done to correct this:",
        "",
        "**Immediate Actions**:",
        "- Reversed the charge of $[XX.XX]",
        "- Applied credit of $[XX.XX] to your account",
        "- Waived [any fees/penalties]",
        "- Adjusted your billing date to [date] if applicable",
        "",
        "**Financial Details**:",
        "- **Original Charge**: $[XX.XX] on [date]",
        "- **Credit Applied**: $[XX.XX] on [date]",
        "- **Net Adjustment**: $[XX.XX] in your favor",
        "- **Confirmation Number**: [Number]",
        "",
        "**Refund Timeline** (if applicable):",
        "- Credit card refunds: 5-7 business days",
        "- Bank transfers: 7-10 business days",
        "- Account credit: Available immediately",
        "",
        "**Going Forward**:",
        "To prevent this from happening again:",
        "- [Specific change made to billing process]",
        "- [Additional preventive measure]",
        "- I've added notes to your account for special attention on future billing",
        "",
        "**Verification**:",
        "You can verify these changes immediately by:",
        "- Logging into your account > Billing > Transaction History",
        "- Checking your next billing statement on [date]",
        "- Contacting me anytime at [email]",
        "",
        "Thank you for bringing this to our attention. Your diligence helps us improve our billing accuracy for all customers.",
        "",
        "If you have any questions about these adjustments or your next bill, please don't hesitate to reach out.",
        "",
        "Sincerely,",
        "[Your Name]",
        "Billing Resolution Team",
        "[Contact Information]",
        "",
        "---",
        "",
        "## Technical Issue Resolutions",
        "",
        "### Template 6: Technical Problem Fixed",
        "",
        "**Subject**: Technical Issue Resolved - Everything Should Be Working Now",
        "",
        "Dear [Customer Name],",
        "",
        "Great news! The technical issue you reported has been resolved. I wanted to let you know what was wrong and what we did to fix it.",
        "",
        "**The Problem You Reported**:",
        "[Description of issue: page errors, features not working, slow performance, etc.]",
        "",
        "**What We Found**:",
        "Our technical team investigated and discovered:",
        "- [Root cause in plain language]",
        "- [Why it was affecting your account/experience]",
        "- [How long it had been occurring]",
        "",
        "**The Fix**:",
        "Here's what our engineers did:",
        "1. [Specific technical action in understandable terms]",
        "2. [Specific technical action in understandable terms]",
        "3. [Testing and verification performed]",
        "",
        "**What You'll Notice**:",
        "- [Specific improvement]",
        "- [Specific improvement]",
        "- [Any changes to your workflow, if applicable]",
        "",
        "**Testing Confirmation**:",
        "I've personally tested the functionality using your account (with permission) and verified:",
        "- ‚úì [Feature] is working correctly",
        "- ‚úì [Performance] has improved to normal levels",
        "- ‚úì [Error] no longer occurs",
        "- ‚úì All your data and settings are intact",
        "",
        "**What You Need To Do** (if anything):",
        "[Choose one:]",
        "- Nothing! Everything should work normally now.",
        "- Please [specific action: clear cache, log out and back in, etc.]",
        "- The next time you [perform action], you'll see the improvements",
        "",
        "**Preventing Future Issues**:",
        "We've also implemented:",
        "- [Monitoring to detect similar issues early]",
        "- [Process improvement to prevent recurrence]",
        "- [Additional testing in our development process]",
        "",
        "**Your Feedback Matters**:",
        "Thank you for reporting this. Your feedback led to improvements that will benefit all our users.",
        "",
        "**Verification**:",
        "Can you please test [specific feature/action] when you have a moment and confirm it's working well for you? Just reply to this email with your experience.",
        "",
        "If you encounter any problems or notice anything unexpected, please contact me immediately at [email] or [phone].",
        "",
        "Thank you for your patience while we resolved this!",
        "",
        "Best regards,",
        "[Your Name]",
        "Technical Support Team",
        "[Contact Information]",
        "",
        "---",
        "",
        "## Product and Service Resolutions",
        "",
        "### Template 7: Custom Solution Implemented",
        "",
        "**Subject**: Special Solution Created for Your Needs",
        "",
        "Dear [Customer Name],",
        "",
        "I have great news! After reviewing your request and discussing it with our team, we've created a custom solution that should meet your needs perfectly.",
        "",
        "**Your Request**:",
        "You needed [description of unique requirement or special circumstance].",
        "",
        "**The Challenge**:",
        "Our standard offerings don't typically include [specific need], which is why you couldn't find it on our website or through our regular support channels.",
        "",
        "**Custom Solution**:",
        "Here's what we've set up specifically for you:",
        "",
        "**What It Includes**:",
        "- [Specific feature or service]",
        "- [Specific feature or service]",
        "- [Specific feature or service]",
        "",
        "**How It Works**:",
        "1. [Step or component]",
        "2. [Step or component]",
        "3. [Step or component]",
        "",
        "**Pricing**:",
        "[Choose appropriate:]",
        "- No additional charge - we've added this to your current plan",
        "- Special pricing of $[XX] (normally $[XX]) given your circumstances",
        "- [Custom pricing structure]",
        "",
        "**Implementation**:",
        "- **Setup Date**: [Date]",
        "- **Available For Use**: [Date]",
        "- **Training/Onboarding**: I'll schedule a call to walk you through everything",
        "- **Documentation**: Attached / Will be sent separately",
        "",
        "**Support**:",
        "Because this is a custom solution:",
        "- You have my direct contact information: [email], [phone]",
        "- Priority response time: [timeframe]",
        "- Dedicated support team member: [name, contact]",
        "",
        "**Trial Period**:",
        "Let's try this for [timeframe]. If it's not working perfectly for you, we'll adjust it or find an alternative. No commitment required during the trial.",
        "",
        "**Next Steps**:",
        "1. Review the attached details about your custom solution",
        "2. Reply with any questions or adjustment requests",
        "3. I'll schedule an implementation call at your convenience",
        "4. We'll go live on [date]",
        "",
        "**Our Commitment**:",
        "We're committed to making this work for you. If anything needs adjusting, we'll refine it until it's right.",
        "",
        "Thank you for helping us expand our offerings. Your unique needs pushed us to innovate, and other customers may benefit from this solution in the future.",
        "",
        "Questions? Ideas? Concerns? I'm here and ready to help.",
        "",
        "Warm regards,",
        "[Your Name]",
        "[Title - Solutions Specialist, Account Manager, etc.]",
        "[Contact Information]",
        "",
        "---",
        "",
        "### Template 8: Exception Approved",
        "",
        "**Subject**: Exception Granted - We're Making It Work for You",
        "",
        "Dear [Customer Name],",
        "",
        "I'm pleased to let you know that I've approved your exception request. We're going to make this work for you.",
        "",
        "**Your Situation**:",
        "You requested [exception to policy: late return, billing adjustment, service modification, etc.] because [reason provided].",
        "",
        "**Standard Policy**:",
        "Normally, our policy states [standard policy], which is why our system/team initially [couldn't process request, denied request, etc.].",
        "",
        "**Why We're Approving This**:",
        "After reviewing your account history and situation:",
        "- You've been a valued customer since [date]",
        "- [Specific positive account history: payment history, loyalty, etc.]",
        "- Your circumstances are [unique situation that warrants exception]",
        "- This is a reasonable request given [specific rationale]",
        "",
        "**What We're Doing**:",
        "- [Specific exception granted]",
        "- [Additional accommodation if applicable]",
        "- [Any special terms or conditions]",
        "",
        "**Details**:",
        "- **Effective Date**: [Date]",
        "- **Valid Until**: [Date or ongoing]",
        "- **Confirmation Number**: [Number]",
        "- **Special Instructions**: [Any actions needed]",
        "",
        "**One-Time or Ongoing**:",
        "[Choose appropriate:]",
        "- This is a one-time exception for this specific situation",
        "- This exception is now part of your account terms going forward",
        "- This exception is valid for [timeframe]",
        "",
        "**Documentation**:",
        "I've noted this exception on your account so that:",
        "- You don't have to re-explain in the future",
        "- Any team member can see the approved exception",
        "- It will be honored by all departments",
        "",
        "**Your Responsibility** (if any):",
        "[If there are conditions:]",
        "- [Specific requirement]",
        "- [Specific requirement]",
        "",
        "**If No Conditions**:",
        "No action needed on your part - we've handled everything.",
        "",
        "**Appreciation**:",
        "Thank you for your understanding and patience while we reviewed your request. We value your business and wanted to find a way to accommodate your needs.",
        "",
        "If you have any questions about this exception or how it works, please contact me directly.",
        "",
        "Best regards,",
        "[Your Name]",
        "[Title]",
        "[Contact Information]",
        "",
        "---",
        "",
        "## Proactive Resolution Follow-Up",
        "",
        "### Template 9: Resolution Follow-Up Check",
        "",
        "**Subject**: Checking In - Is Everything Working Well?",
        "",
        "Dear [Customer Name],",
        "",
        "I wanted to follow up on the resolution we implemented [timeframe] ago for [issue].",
        "",
        "**What We Fixed**:",
        "- [Brief reminder of issue]",
        "- [Brief reminder of solution]",
        "",
        "**Quick Check-In**:",
        "Could you spare 30 seconds to let me know how things are going?",
        "",
        "1. Is [specific aspect] working smoothly?",
        "2. Have you encountered any related issues?",
        "3. Is there anything else we can improve?",
        "",
        "**No Response Needed If**:",
        "If everything is working perfectly, no need to reply‚ÄîI just wanted to make sure you're all set.",
        "",
        "**If There Are Issues**:",
        "Please let me know immediately:",
        "- Email: [email]",
        "- Phone: [phone]",
        "- Response time: [timeframe]",
        "",
        "Thank you for your patience during the resolution process. We appreciate your business and want to ensure you're completely satisfied.",
        "",
        "Best regards,",
        "[Your Name]",
        "Customer Success Team",
        "[Contact Information]",
        "",
        "---",
        "",
        "## Usage Guidelines",
        "",
        "### When to Send Resolution Confirmations",
        "",
        "**Always Send When**:",
        "- Issue is fully resolved",
        "- Refund or credit is processed",
        "- Replacement is shipped",
        "- Account access is restored",
        "- Technical problem is fixed",
        "- Exception is granted",
        "",
        "**Send Within**:",
        "- Critical issues: Immediately upon resolution",
        "- Standard issues: Same business day",
        "- Non-urgent: Within 24 hours",
        "",
        "### Structure of Effective Resolution Messages",
        "",
        "**Essential Elements**:",
        "1. Clear statement that issue is resolved",
        "2. Specific details of what was done",
        "3. Confirmation numbers/tracking information",
        "4. Timeline expectations (when they'll see changes)",
        "5. Any required actions from customer",
        "6. Contact information for follow-up",
        "",
        "**Tone**:",
        "- Positive and confident",
        "- Specific and detailed",
        "- Professional but warm",
        "- Proactive about preventing future issues",
        "",
        "### Follow-Up Protocol",
        "",
        "**Timing**:",
        "- **Technical fixes**: Follow up in 24-48 hours",
        "- **Refunds**: Follow up when funds should be available",
        "- **Replacements**: Follow up after delivery date",
        "- **Account changes**: Follow up in 1 week",
        "- **Complex resolutions**: Follow up in 3-7 days",
        "",
        "**Method**:",
        "- Simple resolution: Email follow-up",
        "- Complex issues: Phone call or email (customer preference)",
        "- VIP customers: Personal call from manager",
        "- Repeated issues: Escalate follow-up to senior staff",
        "",
        "### Documentation Requirements",
        "",
        "**Always Document**:",
        "- Resolution details and timeline",
        "- Confirmation/tracking numbers",
        "- Compensation provided",
        "- Customer acknowledgment",
        "- Follow-up scheduled",
        "",
        "**Account Notes Should Include**:",
        "- Date and time of resolution",
        "- Specific actions taken",
        "- Who approved (for exceptions)",
        "- Related ticket/case numbers",
        "- Follow-up status",
        "",
        "---",
        "",
        "*These templates should be customized based on specific circumstances, customer tone, and company policies. The goal is clear communication and confirmed resolution.*"
      ],
      "lines_removed": [],
      "context_before": [],
      "context_after": [],
      "change_type": "add"
    },
    {
      "file": "samples/customer_service/troubleshoot-login.md",
      "function": null,
      "start_line": 0,
      "lines_added": [
        "# Login and Account Access Troubleshooting Guide",
        "",
        "## Cannot Sign In - Common Issues",
        "",
        "### Forgot Password",
        "",
        "**Problem**: You can't remember your password.",
        "",
        "**Solution**:",
        "1. Click \"Forgot Password\" on the login page",
        "2. Enter your registered email address",
        "3. Check your inbox for password reset link (valid for 24 hours)",
        "4. Check spam/junk folder if email doesn't arrive within 5 minutes",
        "5. Click the link and create a new strong password",
        "6. Confirm the new password and sign in",
        "",
        "**Note**: For security, password reset links expire after 24 hours and can only be used once.",
        "",
        "### Email Not Recognized",
        "",
        "**Problem**: System says your email address isn't registered.",
        "",
        "**Troubleshooting**:",
        "- Verify you're using the correct email address",
        "- Check if you might have registered with a different email",
        "- Try alternative email addresses you commonly use",
        "- Look for welcome or confirmation emails from us",
        "- Contact support if you're certain you have an account",
        "",
        "Common causes:",
        "- Typos in email address",
        "- Multiple accounts with different emails",
        "- Account registered by another team member (enterprise)",
        "- Account deleted due to inactivity (after 3 years)",
        "",
        "### Incorrect Password",
        "",
        "**Problem**: \"Password incorrect\" error when signing in.",
        "",
        "**Troubleshooting**:",
        "1. Double-check caps lock is off (passwords are case-sensitive)",
        "2. Ensure you're typing the complete password",
        "3. Try copying and pasting from a password manager",
        "4. Look for special characters that might be mistyped",
        "5. Reset your password if still unable to login after 3 attempts",
        "",
        "**Security Note**: After 5 failed login attempts, your account is temporarily locked for 30 minutes to prevent unauthorized access.",
        "",
        "## Account Locked or Suspended",
        "",
        "### Temporary Account Lock",
        "",
        "**Problem**: \"Account temporarily locked\" message.",
        "",
        "**Explanation**: This security feature activates after multiple failed login attempts.",
        "",
        "**Resolution**:",
        "- Wait 30 minutes and try again",
        "- Use the \"Forgot Password\" link to reset immediately",
        "- Contact support if you suspect unauthorized access",
        "- Enable two-factor authentication after regaining access",
        "",
        "### Account Suspended",
        "",
        "**Problem**: \"Account suspended\" or \"Account disabled\" error.",
        "",
        "**Common Reasons**:",
        "- Payment failure or outstanding balance",
        "- Violation of terms of service",
        "- Security concern or suspicious activity",
        "- Inactivity (no login for 18+ months)",
        "- Request from account owner or administrator",
        "",
        "**Resolution**:",
        "1. Check email for suspension notice with details",
        "2. Contact support team with your account details",
        "3. Resolve any outstanding issues (payment, verification, etc.)",
        "4. Request account reactivation if eligible",
        "",
        "**Processing Time**: Account reactivation typically takes 1-2 business days after issue resolution.",
        "",
        "## Two-Factor Authentication Issues",
        "",
        "### Lost or Changed Phone",
        "",
        "**Problem**: Can't receive 2FA codes on your device.",
        "",
        "**Solutions**:",
        "1. Use backup codes provided during 2FA setup",
        "2. Click \"Try another way\" on 2FA prompt",
        "3. Receive code via backup email if configured",
        "4. Contact support to temporarily disable 2FA (requires identity verification)",
        "",
        "**Prevention**: Always save backup codes when enabling 2FA and keep them in a secure location.",
        "",
        "### 2FA Code Not Working",
        "",
        "**Problem**: Authentication code is rejected.",
        "",
        "**Troubleshooting**:",
        "- Ensure device time is synchronized correctly (critical for TOTP apps)",
        "- Use the most recent code (codes expire every 30 seconds)",
        "- Check you're entering the code for the correct account",
        "- Verify authenticator app is set up for correct service",
        "- Request a new code via SMS or email if available",
        "",
        "**Time Sync Issue**: If using an authenticator app, go to app settings and manually sync time. Out-of-sync clocks cause code mismatches.",
        "",
        "### Can't Set Up 2FA",
        "",
        "**Problem**: Error when trying to enable two-factor authentication.",
        "",
        "**Checklist**:",
        "- Phone number is in correct format (include country code)",
        "- Phone number is not already registered to another account",
        "- You have cell service or wifi for receiving codes",
        "- Authenticator app is updated to latest version",
        "- QR code scanner is functioning properly",
        "",
        "**Alternative**: If QR scanning fails, use manual entry with the provided secret key.",
        "",
        "## Browser and Technical Issues",
        "",
        "### Page Won't Load",
        "",
        "**Problem**: Login page shows errors or won't load.",
        "",
        "**Quick Fixes**:",
        "1. Clear browser cache and cookies",
        "2. Try a different browser (Chrome, Firefox, Safari, Edge)",
        "3. Disable browser extensions temporarily",
        "4. Check internet connection",
        "5. Try incognito/private browsing mode",
        "6. Restart your browser",
        "",
        "**Still Not Working**: Check our status page at status.example.com for any ongoing service disruptions.",
        "",
        "### Cookies or JavaScript Disabled",
        "",
        "**Problem**: \"Please enable cookies\" or \"JavaScript required\" message.",
        "",
        "**Resolution**:",
        "",
        "For Chrome:",
        "1. Settings > Privacy and Security > Cookies",
        "2. Enable \"Allow all cookies\" or add our site to exceptions",
        "3. Settings > Privacy and Security > Site Settings > JavaScript",
        "4. Ensure JavaScript is \"Allowed\"",
        "",
        "For Firefox:",
        "1. Preferences > Privacy & Security",
        "2. Set \"Custom\" under Enhanced Tracking Protection",
        "3. Uncheck \"Cookies\" or add exception for our site",
        "4. Ensure JavaScript is enabled in about:config",
        "",
        "### Redirect Loop or Infinite Loading",
        "",
        "**Problem**: Login page keeps redirecting or loading indefinitely.",
        "",
        "**Fixes**:",
        "1. Clear all browser cookies for our domain",
        "2. Close all browser tabs/windows completely",
        "3. Restart browser",
        "4. Update browser to latest version",
        "5. Try different network (switch from WiFi to cellular or vice versa)",
        "",
        "**Advanced**: Check if corporate firewall or VPN is interfering with authentication.",
        "",
        "## Enterprise and SSO Login",
        "",
        "### Single Sign-On Not Working",
        "",
        "**Problem**: SSO redirect fails or doesn't recognize your credentials.",
        "",
        "**Troubleshooting**:",
        "- Verify you're using the correct SSO login URL (ask your IT admin)",
        "- Ensure you're logged into your organization's identity provider",
        "- Check if SSO session expired (try logging into other SSO apps)",
        "- Confirm your email domain matches SSO configuration",
        "- Contact your IT administrator for SSO troubleshooting",
        "",
        "**Common SSO Issues**:",
        "- User not provisioned in identity provider",
        "- Email address mismatch between systems",
        "- Expired certificates or metadata",
        "- Firewall blocking authentication endpoints",
        "",
        "### Cannot Access Team Account",
        "",
        "**Problem**: Can't log into your organization's account.",
        "",
        "**Checklist**:",
        "- Verify invitation email was accepted",
        "- Check with account administrator about access permissions",
        "- Ensure you're using work email, not personal email",
        "- Confirm account administrator added you to the team",
        "- Check if your role has login permissions (some roles are API-only)",
        "",
        "**Getting Help**: Contact your organization's account administrator first, as they control team access.",
        "",
        "## Mobile App Login Issues",
        "",
        "### App Won't Accept Credentials",
        "",
        "**Problem**: Login works on web but not in mobile app.",
        "",
        "**Solutions**:",
        "1. Verify you're using the official app (check app store)",
        "2. Update app to latest version",
        "3. Clear app cache (Settings > Storage > Clear Cache)",
        "4. Uninstall and reinstall the app",
        "5. Try web browser on mobile device to isolate issue",
        "6. Check if app needs specific permissions (contacts, notifications)",
        "",
        "### Biometric Login Failed",
        "",
        "**Problem**: Fingerprint or Face ID authentication not working.",
        "",
        "**Troubleshooting**:",
        "- Ensure biometric authentication is enabled in phone settings",
        "- Re-register biometric credentials in app settings",
        "- Verify your device supports the biometric method",
        "- Check device biometrics work in other apps",
        "- Fall back to password login and reconfigure biometrics",
        "",
        "## Getting Additional Help",
        "",
        "If you've tried these troubleshooting steps and still can't access your account:",
        "",
        "**Contact Support**:",
        "- Email: support@example.com (response within 24 hours)",
        "- Live Chat: Available Mon-Fri 9am-5pm EST",
        "- Phone: 1-800-SUPPORT (1-800-787-7678)",
        "",
        "**Include in Your Request**:",
        "- Email address or username",
        "- Description of the problem",
        "- Error messages (screenshot if possible)",
        "- Steps you've already tried",
        "- Browser and operating system version",
        "",
        "**Priority Support**: Enterprise customers can escalate login issues through their dedicated account manager for faster resolution (SLA: 4-hour response time)."
      ],
      "lines_removed": [],
      "context_before": [],
      "context_after": [],
      "change_type": "add"
    },
    {
      "file": "samples/customer_service/troubleshoot-payment.md",
      "function": null,
      "start_line": 0,
      "lines_added": [
        "# Payment Processing Troubleshooting Guide",
        "",
        "## Payment Declined or Failed",
        "",
        "### Credit Card Declined",
        "",
        "**Problem**: Your credit card payment is rejected at checkout.",
        "",
        "**Common Reasons and Solutions**:",
        "",
        "1. **Insufficient Funds**",
        "   - Check account balance includes available credit",
        "   - Pay down balance and retry",
        "   - Use alternative payment method",
        "",
        "2. **Incorrect Card Information**",
        "   - Verify card number is entered correctly (no spaces)",
        "   - Check expiration date (MM/YY format)",
        "   - Confirm CVV/CVC security code (3-4 digits on back)",
        "   - Ensure billing address matches card on file with bank",
        "",
        "3. **Expired Card**",
        "   - Check expiration date on physical card",
        "   - Contact card issuer for replacement",
        "   - Update payment method with new card details",
        "",
        "4. **Card Security Block**",
        "   - Bank may flag transaction as potentially fraudulent",
        "   - Contact your bank to authorize the charge",
        "   - Inform bank it's a legitimate purchase",
        "   - Retry payment after bank authorization",
        "",
        "5. **Daily Transaction Limit Reached**",
        "   - Many cards have daily spending limits",
        "   - Wait 24 hours or contact bank to increase limit",
        "   - Split payment across multiple cards if supported",
        "",
        "### Bank Transfer or ACH Failed",
        "",
        "**Problem**: Direct bank payment doesn't process.",
        "",
        "**Troubleshooting**:",
        "- Verify account and routing numbers are correct",
        "- Ensure sufficient funds in account",
        "- Check if account allows ACH debits",
        "- Confirm account is active and not frozen",
        "- Allow 3-5 business days for ACH processing",
        "",
        "**Common ACH Errors**:",
        "- R01: Insufficient funds",
        "- R02: Account closed",
        "- R03: Invalid account number",
        "- R04: Invalid account type",
        "- R10: Account holder deceased",
        "",
        "Contact your bank if error code persists after verification.",
        "",
        "### PayPal or Digital Wallet Issues",
        "",
        "**Problem**: PayPal, Apple Pay, or Google Pay transaction fails.",
        "",
        "**Solutions**:",
        "",
        "**PayPal**:",
        "1. Verify PayPal account is active and verified",
        "2. Check PayPal balance or linked funding source",
        "3. Remove and re-add payment method in PayPal",
        "4. Clear PayPal authorization and reconnect",
        "5. Contact PayPal support for account-specific issues",
        "",
        "**Apple Pay**:",
        "1. Ensure card is active in Apple Wallet",
        "2. Verify device supports Apple Pay (iPhone 6+, Watch Series 1+)",
        "3. Check Face ID/Touch ID is enabled",
        "4. Update iOS to latest version",
        "5. Remove and re-add card to wallet",
        "",
        "**Google Pay**:",
        "1. Confirm card is added to Google Pay",
        "2. Check NFC is enabled on Android device",
        "3. Ensure screen lock is configured",
        "4. Update Google Pay app",
        "5. Verify merchant accepts Google Pay",
        "",
        "## Payment Processing Errors",
        "",
        "### \"Payment Gateway Error\" or \"Processing Failed\"",
        "",
        "**Problem**: Generic payment error message appears.",
        "",
        "**Immediate Actions**:",
        "1. Wait 5 minutes and retry (temporary server issues)",
        "2. Use a different payment method",
        "3. Try a different browser or device",
        "4. Disable browser extensions (ad blockers, privacy tools)",
        "5. Clear browser cookies and cache",
        "",
        "**If Error Persists**:",
        "- Check our status page for system outages",
        "- Try alternative checkout flow (guest checkout vs. signed-in)",
        "- Contact support with exact error message and timestamp",
        "",
        "### \"Payment Already Processed\" Warning",
        "",
        "**Problem**: Multiple payment attempts may have succeeded.",
        "",
        "**Important**: Do not retry payment multiple times immediately.",
        "",
        "**What to Do**:",
        "1. Check email for payment confirmation",
        "2. Review your bank/card statement",
        "3. Log into account to verify order status",
        "4. If duplicate charges appear, contact support immediately",
        "5. Allow 3-5 business days for duplicate charges to reverse automatically",
        "",
        "**Prevention**: Wait at least 2 minutes between payment retry attempts.",
        "",
        "### Currency Conversion Issues",
        "",
        "**Problem**: Unexpected currency or conversion rate applied.",
        "",
        "**Understanding Currency Processing**:",
        "- Charges appear in your local currency or merchant currency",
        "- Conversion rates fluctuate based on market conditions",
        "- Some banks charge foreign transaction fees (1-3%)",
        "- Display currency may differ from settlement currency",
        "",
        "**Solutions**:",
        "- Check if merchant supports your native currency",
        "- Consider using multi-currency credit card",
        "- Contact card issuer about conversion rates and fees",
        "- For large purchases, bank transfers may offer better rates",
        "",
        "## Promotional Code and Discount Problems",
        "",
        "### Coupon Code Not Working",
        "",
        "**Problem**: Discount code is rejected or doesn't apply.",
        "",
        "**Common Reasons**:",
        "",
        "1. **Expired Code**",
        "   - Check promotion end date",
        "   - Request updated code if available",
        "   - Sign up for notifications about new promotions",
        "",
        "2. **Minimum Purchase Not Met**",
        "   - Many codes require minimum cart value",
        "   - Add items to reach threshold",
        "   - Check code terms and conditions",
        "",
        "3. **Restricted Items**",
        "   - Some codes exclude sale items, specific brands, or categories",
        "   - Verify eligible products",
        "   - Remove excluded items and reapply code",
        "",
        "4. **First-Time Customer Only**",
        "   - Code may be limited to new accounts",
        "   - Check if you've used the code before",
        "   - Try different promotional offers",
        "",
        "5. **One Use Per Customer**",
        "   - Most codes can only be used once per account",
        "   - System blocks previously used codes",
        "   - Contact support if you believe error occurred",
        "",
        "**How to Apply Codes**:",
        "1. Add items to cart",
        "2. Proceed to checkout",
        "3. Find \"Promo Code\" or \"Discount Code\" field",
        "4. Enter code exactly as provided (case-sensitive)",
        "5. Click \"Apply\" or \"Redeem\"",
        "6. Verify discount reflects in order total",
        "",
        "### Gift Card Balance Issues",
        "",
        "**Problem**: Gift card doesn't cover purchase or shows wrong balance.",
        "",
        "**Troubleshooting**:",
        "- Check gift card balance before checkout (Account > Gift Cards)",
        "- Verify gift card is activated (physical cards need activation)",
        "- Ensure gift card hasn't expired (check terms)",
        "- Confirm you're entering the complete card number and PIN",
        "- Check if gift card is region-specific",
        "",
        "**Partial Payment with Gift Card**:",
        "If gift card doesn't cover full amount:",
        "1. Apply gift card first",
        "2. Remaining balance charged to credit card",
        "3. System prompts for second payment method automatically",
        "",
        "## Recurring Payment and Subscription Issues",
        "",
        "### Auto-Renewal Failed",
        "",
        "**Problem**: Subscription payment didn't process automatically.",
        "",
        "**Why This Happens**:",
        "- Card on file expired",
        "- Insufficient funds at renewal time",
        "- Card was canceled or reported lost",
        "- Bank declined recurring charge",
        "- Payment method removed from account",
        "",
        "**Resolution**:",
        "1. Update payment information in account settings",
        "2. Manually process payment for current period",
        "3. Verify auto-renewal is enabled",
        "4. Check email for renewal reminder notices",
        "",
        "**Grace Period**: Most subscriptions have 7-day grace period before service interruption.",
        "",
        "### Cannot Cancel Recurring Payment",
        "",
        "**Problem**: Unable to stop auto-renewal or recurring charge.",
        "",
        "**Steps to Cancel**:",
        "1. Log into account",
        "2. Navigate to Subscriptions or Billing",
        "3. Select active subscription",
        "4. Click \"Cancel Subscription\" or \"Turn Off Auto-Renewal\"",
        "5. Confirm cancellation",
        "6. Save confirmation email",
        "",
        "**If Option Not Available**:",
        "- Verify you have account administrator permissions",
        "- Check if subscription is managed by third party (iTunes, Google Play)",
        "- Contact support to cancel manually",
        "- As last resort, remove payment method from account",
        "",
        "**Note**: Canceling auto-renewal maintains access through current billing period.",
        "",
        "### Charged After Cancellation",
        "",
        "**Problem**: Payment processed despite canceling subscription.",
        "",
        "**Possible Explanations**:",
        "- Cancellation wasn't confirmed (check confirmation email)",
        "- Canceled after billing cycle cutoff (timing issue)",
        "- Separate subscription or service charged",
        "- Trial period ended and converted to paid",
        "",
        "**What to Do**:",
        "1. Verify cancellation date vs. billing date",
        "2. Check all active subscriptions",
        "3. Review cancellation confirmation",
        "4. Request refund if charge was erroneous",
        "5. Confirm all subscriptions are now canceled",
        "",
        "## Security and Fraud Concerns",
        "",
        "### Suspicious Charge Investigation",
        "",
        "**Problem**: Unrecognized charge from our company.",
        "",
        "**Verification Steps**:",
        "1. Check if family member or colleague made purchase",
        "2. Review all email accounts for order confirmations",
        "3. Check if charge description varies from company name",
        "4. Verify date matches any orders or subscriptions",
        "5. Contact support with transaction details",
        "",
        "**Reporting Fraud**:",
        "If charge is confirmed fraudulent:",
        "- Contact our fraud department immediately",
        "- File dispute with your bank/card issuer",
        "- Change account password",
        "- Review account activity for unauthorized access",
        "- Enable two-factor authentication",
        "",
        "### Payment Information Security",
        "",
        "**Problem**: Concerns about payment data security.",
        "",
        "**Our Security Measures**:",
        "- PCI DSS Level 1 compliant (highest security standard)",
        "- End-to-end encryption for all transactions",
        "- Tokenization - we don't store full card numbers",
        "- Regular security audits and penetration testing",
        "- Fraud detection and prevention systems",
        "",
        "**Your Security Best Practices**:",
        "- Never share account password",
        "- Use strong, unique passwords",
        "- Enable two-factor authentication",
        "- Monitor account for suspicious activity",
        "- Only make payments on secure networks (avoid public WiFi)",
        "- Verify URL shows https:// and padlock icon",
        "",
        "## Getting Payment Support",
        "",
        "**Before Contacting Support, Have Ready**:",
        "- Order number or transaction ID",
        "- Payment method used (last 4 digits of card)",
        "- Exact error message or screenshot",
        "- Date and time of attempted payment",
        "- Browser and device information",
        "",
        "**Contact Methods**:",
        "- Live Chat: Instant support during business hours",
        "- Email: billing@example.com (24-48 hour response)",
        "- Phone: 1-800-BILLING (1-800-245-5464)",
        "- Support Ticket: Submit through account portal",
        "",
        "**Enterprise Customers**:",
        "Contact your dedicated account manager or use priority support channel. SLA guarantees 4-hour response for payment issues affecting service access.",
        "",
        "**Escalation**:",
        "If standard support doesn't resolve your payment issue within 48 hours, request escalation to billing supervisor or dispute resolution team."
      ],
      "lines_removed": [],
      "context_before": [],
      "context_after": [],
      "change_type": "add"
    },
    {
      "file": "samples/memories/2025-12-14-search-relevance-investigation.md",
      "function": null,
      "start_line": 0,
      "lines_added": [
        "# Memory Entry: 2025-12-14 Search Relevance Investigation",
        "",
        "**Tags:** `search`, `tfidf`, `query-expansion`, `code-search`, `relevance`",
        "**Related:** [[CLAUDE.md]], [[cortical/query/expansion.py]], [[cortical/query/search.py]]",
        "",
        "## Problem Statement",
        "",
        "During dog-fooding, searching for \"security test fuzzing\" returned staleness tests instead of actual security-related code. The search seems to weight common terms like \"test\" too heavily, and query expansion pulls in unrelated terms.",
        "",
        "## Root Cause Analysis",
        "",
        "### 1. Code Stop Words Not Filtered in Query Expansion",
        "",
        "**Issue:** Ubiquitous programming tokens dominate lateral connections and query expansion.",
        "",
        "**Evidence:**",
        "- `cortical/query/expansion.py:93` - `filter_code_stop_words` defaults to `False`",
        "- `cortical/query/search.py:54-59` - `find_documents_for_query()` doesn't pass `filter_code_stop_words` to expansion",
        "- Testing shows \"def\" gets expansion weight of 1.201 (higher than original query terms!)",
        "- Common terms like \"self\", \"return\", \"def\", \"pass\" appear in almost every Python function",
        "",
        "**Impact:**",
        "```python",
        "# Query: \"security test fuzzing\"",
        "# Expansion adds:",
        "#   def: 1.201        # ‚ùå Too high! Not relevant",
        "#   staleness: 0.207  # ‚ùå Pulled in via \"test\" lateral connections",
        "#   tracked: 0.119    # ‚ùå Also from \"test\" connections",
        "```",
        "",
        "**Code Location:**",
        "- `cortical/tokenizer.py:16-25` - `CODE_EXPANSION_STOP_WORDS` defined but not used by default",
        "- `cortical/query/expansion.py:199-203` - Filtering logic exists but gated by parameter",
        "",
        "### 2. Over-Expansion of Common Terms",
        "",
        "**Issue:** Terms like \"test\" appear in many documents, creating strong lateral connections to unrelated terms.",
        "",
        "**How it happens:**",
        "1. \"test\" appears in `test_staleness.py`, `test_security.py`, `test_performance.py`, etc.",
        "2. Each file has different topic-specific terms (staleness, security, performance)",
        "3. Lateral connections link \"test\" ‚Üí \"staleness\", \"test\" ‚Üí \"security\", \"test\" ‚Üí \"performance\"",
        "4. When searching for \"security test\", expansion adds \"staleness\" and other test-related noise",
        "",
        "**Code Location:**",
        "- `cortical/query/expansion.py:150-168` - Lateral connection expansion (Method 1)",
        "- Line 164: `score = weight * neighbor.pagerank * 0.6` - doesn't account for term ubiquity",
        "",
        "**TF-IDF should help but doesn't:**",
        "- TF-IDF correctly penalizes \"test\" in individual documents",
        "- But lateral connections are based on co-occurrence count, not TF-IDF",
        "- So ubiquitous terms still get strong lateral connections",
        "",
        "### 3. Test File Penalty Not Applied in Basic Search",
        "",
        "**Issue:** Test files are penalized in `ranking.py` but not in `search.py`.",
        "",
        "**Evidence:**",
        "- `cortical/query/ranking.py:87-90` - Test file penalty of 0.8 exists",
        "- `cortical/query/search.py:25-112` - `find_documents_for_query()` doesn't use doc_type boosting",
        "- `cortical/constants.py:60-65` - `DOC_TYPE_BOOSTS` defines test penalty",
        "",
        "**Workaround exists but not used by default:**",
        "- `ranking.py:124-177` - `find_documents_with_boost()` applies penalties",
        "- But most code uses `find_documents_for_query()` directly",
        "",
        "### 4. No Security-Specific Concept Expansion",
        "",
        "**Issue:** Code concepts are defined for common operations (get/fetch/load) but not for domain-specific terms like security.",
        "",
        "**Evidence:**",
        "- `cortical/code_concepts.py:36-40` - Auth concept group exists with generic terms",
        "- Line 38: `'auth', 'authentication', 'login', 'logout', 'credentials'...`",
        "- But no 'security' concept group with terms like: fuzzing, validation, sanitize, injection, xss, csrf",
        "",
        "**Impact:**",
        "- \"security fuzzing\" doesn't expand to related security terms",
        "- \"staleness\" lateral connections get equal weight to \"fuzzing\" connections",
        "- No domain knowledge to prioritize security context",
        "",
        "## Specific Code Locations Needing Attention",
        "",
        "### High Priority",
        "",
        "1. **`cortical/query/search.py:25-112` - `find_documents_for_query()`**",
        "   - Line 54-59: Add `filter_code_stop_words=True` parameter",
        "   - Should filter ubiquitous code tokens from expansion",
        "",
        "2. **`cortical/query/expansion.py:150-168` - Lateral expansion scoring**",
        "   - Line 164: Incorporate term IDF into scoring: `score = weight * neighbor.pagerank * neighbor.tfidf * 0.6`",
        "   - Penalize ubiquitous terms that connect to everything",
        "",
        "3. **`cortical/query/search.py` - Default to test file penalty**",
        "   - Detect test files and apply 0.8 penalty by default",
        "   - Or route to `find_documents_with_boost()` instead",
        "",
        "### Medium Priority",
        "",
        "4. **`cortical/code_concepts.py:16-131` - Add security concept group**",
        "   - Add fuzzing, validation, sanitize, injection, exploit, vulnerability, etc.",
        "   - Enable domain-specific expansion",
        "",
        "5. **`cortical/tokenizer.py:158-221` - Add code-specific stop words**",
        "   - Consider adding \"def\", \"class\", \"return\" to DEFAULT_STOP_WORDS for code corpora",
        "   - Or create a `code_stop_words` set that's automatically used for code files",
        "",
        "### Low Priority",
        "",
        "6. **`cortical/analysis.py:883-924` - TF-IDF computation**",
        "   - Currently correct, but lateral connections don't use TF-IDF",
        "   - Could add IDF-weighted lateral connections in `compute_bigram_connections()`",
        "",
        "## Recommended Fixes (Prioritized)",
        "",
        "### Fix 1: Enable Code Stop Word Filtering by Default (EASY)",
        "",
        "**What:** Set `filter_code_stop_words=True` by default in code search functions.",
        "",
        "**Where:** `cortical/query/search.py:54-59`",
        "",
        "**Change:**",
        "```python",
        "# Before",
        "query_terms = get_expanded_query_terms(",
        "    query_text, layers, tokenizer,",
        "    use_expansion=use_expansion,",
        "    semantic_relations=semantic_relations,",
        "    use_semantic=use_semantic",
        ")",
        "",
        "# After",
        "query_terms = get_expanded_query_terms(",
        "    query_text, layers, tokenizer,",
        "    use_expansion=use_expansion,",
        "    semantic_relations=semantic_relations,",
        "    use_semantic=use_semantic,",
        "    filter_code_stop_words=True  # Filter def, self, return, etc.",
        ")",
        "```",
        "",
        "**Impact:** Immediate reduction in noise from ubiquitous code tokens.",
        "",
        "**Risk:** Low - filtering is already implemented and tested.",
        "",
        "### Fix 2: Weight Lateral Connections by TF-IDF (MEDIUM)",
        "",
        "**What:** Incorporate IDF into lateral expansion scoring to penalize ubiquitous terms.",
        "",
        "**Where:** `cortical/query/expansion.py:164`",
        "",
        "**Change:**",
        "```python",
        "# Before",
        "score = weight * neighbor.pagerank * 0.6",
        "",
        "# After",
        "# Penalize ubiquitous terms (low IDF)",
        "idf_factor = neighbor.tfidf / (neighbor.pagerank + 0.1)  # Normalize by pagerank",
        "score = weight * neighbor.pagerank * min(idf_factor, 1.0) * 0.6",
        "```",
        "",
        "**Impact:** Terms that appear everywhere (low TF-IDF) get lower expansion weights.",
        "",
        "**Risk:** Medium - requires testing to ensure good queries aren't hurt.",
        "",
        "### Fix 3: Apply Test File Penalty by Default (EASY)",
        "",
        "**What:** Detect test files and apply penalty in `find_documents_for_query()`.",
        "",
        "**Where:** `cortical/query/search.py:25-112`",
        "",
        "**Change:**",
        "```python",
        "# After doc_scores calculation (around line 70)",
        "for doc_id in list(doc_scores.keys()):",
        "    if doc_id.startswith('tests/') or '/test_' in doc_id or doc_id.startswith('test_'):",
        "        doc_scores[doc_id] *= 0.8  # Apply test file penalty",
        "```",
        "",
        "**Impact:** Test files naturally rank lower unless highly relevant.",
        "",
        "**Risk:** Low - penalty is already defined in constants.",
        "",
        "### Fix 4: Add Security Concept Group (EASY)",
        "",
        "**What:** Add security-related terms to code concepts for better expansion.",
        "",
        "**Where:** `cortical/code_concepts.py:16-131`",
        "",
        "**Change:**",
        "```python",
        "CODE_CONCEPT_GROUPS = {",
        "    # ... existing groups ...",
        "",
        "    # Security and safety",
        "    'security': frozenset([",
        "        'security', 'secure', 'auth', 'authentication', 'authorize',",
        "        'sanitize', 'validate', 'escape', 'injection', 'xss', 'csrf',",
        "        'fuzzing', 'fuzz', 'exploit', 'vulnerability', 'attack',",
        "        'defense', 'protect', 'encrypt', 'decrypt', 'hash', 'salt',",
        "        'permission', 'access', 'credential', 'token', 'session'",
        "    ]),",
        "}",
        "```",
        "",
        "**Impact:** \"security fuzzing\" would expand to related security terms.",
        "",
        "**Risk:** Low - additive change, doesn't affect existing queries.",
        "",
        "## Sample Queries Demonstrating the Issue",
        "",
        "### Query 1: \"security test fuzzing\"",
        "",
        "**Expected:** Security implementation files, fuzzing utilities",
        "**Actual:** Staleness tests ranked high due to \"test\" expansion to \"staleness\"",
        "",
        "**Why:**",
        "- \"test\" expands to \"staleness\", \"tracked\", \"properly\" via lateral connections",
        "- \"def\" gets added with weight 1.201 (higher than query terms!)",
        "- Test files match on many expanded terms",
        "",
        "### Query 2: \"authentication validation\"",
        "",
        "**Expected:** Auth validation code, security checks",
        "**Actual:** Works better because \"test\" not in query",
        "",
        "**Insight:** Problem is specific to queries containing common programming terms.",
        "",
        "### Query 3: \"where is PageRank computed\"",
        "",
        "**Expected:** `analysis.py` with compute_pagerank function",
        "**Actual:** Works well because \"where\" triggers implementation intent detection",
        "",
        "**Insight:** Intent detection helps, but only for certain query patterns.",
        "",
        "## Next Steps",
        "",
        "1. **Implement Fix 1** (filter code stop words) - immediate impact, low risk",
        "2. **Implement Fix 3** (test file penalty) - easy win for test file noise",
        "3. **Implement Fix 4** (security concepts) - addresses specific case",
        "4. **Test and iterate on Fix 2** (IDF-weighted expansion) - needs careful tuning",
        "5. **Run regression tests** on existing search quality benchmarks",
        "6. **Consider long-term:** Domain-specific query expansion strategies",
        "",
        "## Connections",
        "",
        "This investigation reveals a fundamental tension in code search:",
        "- Programming languages have ubiquitous tokens (\"def\", \"test\", \"return\")",
        "- These tokens appear in almost every file, creating strong lateral connections",
        "- TF-IDF correctly penalizes them in documents",
        "- But lateral connections use co-occurrence count, not TF-IDF",
        "- Result: noise dominates expansion for queries containing common terms",
        "",
        "**Related design question:** Should lateral connections be IDF-weighted during construction, not just during scoring?",
        "",
        "## Measurement",
        "",
        "To validate fixes, test these queries before/after:",
        "1. \"security test fuzzing\" - should rank security_fuzzer.py > test_staleness.py",
        "2. \"authentication validation\" - should rank auth code > test files",
        "3. \"database connection pooling\" - should rank DB code > test files",
        "4. \"error handling retry logic\" - should rank implementation > tests",
        "",
        "Success metric: Security/implementation files rank in top 3, test files rank lower unless truly relevant."
      ],
      "lines_removed": [],
      "context_before": [],
      "context_after": [],
      "change_type": "add"
    },
    {
      "file": "samples/memories/2025-12-14_20-54-35_3b3a-director-mode-session-group-tasks-orchestration.md",
      "function": null,
      "start_line": 0,
      "lines_added": [
        "# Memory Entry: 2025-12-14 Director Mode Session - Group Tasks Orchestration",
        "",
        "**Tags:** `director-mode`, `orchestration`, `memory-system`, `documentation`, `parallel-agents`",
        "**Related:** [[../decisions/adr-microseconds-task-id.md]], [[concept-hebbian-text-processing.md]]",
        "",
        "---",
        "",
        "## Context",
        "",
        "User requested Director Mode to work through task groups C ‚Üí B ‚Üí A with testing between code changes. This was a test of the director orchestration system for coordinating parallel sub-agents.",
        "",
        "## What I Learned",
        "",
        "### 1. Research-Before-Execute Pattern Works Well",
        "",
        "Spawning parallel research agents BEFORE implementation prevents wasted work:",
        "- GROUP C research revealed LEGACY-095 (processor split) was already complete",
        "- GROUP B research identified exact file locations and patterns to follow",
        "- GROUP A research found specific stale metrics and broken references",
        "",
        "**Key insight**: 5 minutes of parallel research saves 30 minutes of wrong-direction implementation.",
        "",
        "### 2. Task Completion Detection Saves Time",
        "",
        "Checking task status early is critical:",
        "- LEGACY-095 appeared pending but was actually done",
        "- The processor/ package refactor was complete with 6 mixins",
        "- WAL persistence (LEGACY-133) was correctly identified as substantial new work",
        "",
        "### 3. Parallel Agent File Isolation",
        "",
        "Successfully ran parallel implementation agents with zero conflicts:",
        "- Agent 1: `scripts/new_memory.py` (new file)",
        "- Agent 2: `scripts/index_codebase.py` + `scripts/search_codebase.py`",
        "- No overlapping modifications = no merge issues",
        "",
        "### 4. Merge-Safe Filename Pattern",
        "",
        "The timestamp + session ID pattern from task_utils works perfectly:",
        "```",
        "2025-12-14_20-54-35_3b3a-topic.md",
        "YYYY-MM-DD_HH-MM-SS_XXXX-topic.md",
        "```",
        "- Microsecond precision prevents collisions",
        "- 4-char session ID traces back to agent",
        "- Human-readable date prefix for sorting",
        "",
        "## Connections Made",
        "",
        "- **Director Mode ‚Üí Parallel Research**: Research agents identify already-done work",
        "- **Task System ‚Üí Memory System**: Same merge-safe filename pattern applied",
        "- **Documentation Audit ‚Üí Quick Wins**: Finding stale metrics is easy; fixing them is cheap",
        "",
        "## Emotional State",
        "",
        "Satisfying to see the research-first approach pay off immediately when GROUP C's major task was already complete. The parallel agent execution felt efficient.",
        "",
        "## Future Exploration",
        "",
        "- [ ] LEGACY-133: WAL + snapshot persistence (deferred - needs dedicated session)",
        "- [ ] Add unit tests for new_memory.py",
        "- [ ] Consider adding --concept flag for concept document creation",
        "- [ ] Evaluate director mode for larger multi-day features",
        "",
        "## Artifacts Created",
        "",
        "- `scripts/new_memory.py` - CLI for merge-safe memory/decision creation",
        "- `scripts/index_codebase.py` - Modified to index memories/decisions",
        "- `scripts/search_codebase.py` - Added MEM/ADR/CON labels",
        "- `README.md` - Updated metrics, added sections",
        "- `CLAUDE.md` - Fixed package references",
        "- Commit: `d647b53` on `claude/implement-director-mode-NKbiu`",
        "",
        "---",
        "",
        "*Committed to memory at: 2025-12-14T20:54:35Z*"
      ],
      "lines_removed": [],
      "context_before": [],
      "context_after": [],
      "change_type": "add"
    },
    {
      "file": "samples/memories/2025-12-14_20-55-23_632e-session-knowledge-transfer-director-mode-orchestra.md",
      "function": null,
      "start_line": 0,
      "lines_added": [
        "# Session Knowledge Transfer: 2025-12-14 Director Mode Orchestration",
        "",
        "**Date:** 2025-12-14",
        "**Session:** Director Mode testing with GROUP C ‚Üí B ‚Üí A task orchestration",
        "**Branch:** `claude/implement-director-mode-NKbiu`",
        "**Commit:** `d647b53`",
        "",
        "---",
        "",
        "## Summary",
        "",
        "Successfully executed Director Mode to orchestrate parallel sub-agents through three task groups (Architecture ‚Üí Memory System ‚Üí Documentation). Research-first approach prevented wasted work by identifying that GROUP C's major task (processor split) was already complete. Delivered 5 file changes including a new CLI tool for merge-safe memory creation.",
        "",
        "## What Was Accomplished",
        "",
        "### Completed Tasks",
        "",
        "| Task ID | Title | What Was Done |",
        "|---------|-------|---------------|",
        "| T-6aa8-002 | Memory document templates and CLI | Created `scripts/new_memory.py` with merge-safe filenames |",
        "| T-6aa8-003 | Index memories in semantic search | Modified `index_codebase.py` to include samples/memories/ and samples/decisions/ |",
        "| T-6aa8-008 | Merge-safe filenames | Integrated timestamp+session ID pattern into memory CLI |",
        "| T-6aa8-009 | Update README.md overview | Updated metrics, added Text-as-Memories and Contributing sections |",
        "| T-6aa8-010 | Audit markdown staleness | Fixed CLAUDE.md package references, test file refs |",
        "",
        "### Code Changes",
        "",
        "**New Files:**",
        "- `scripts/new_memory.py` (200 lines) - CLI for merge-safe memory/decision creation",
        "  - `generate_memory_filename()` - Creates `YYYY-MM-DD_HH-MM-SS_XXXX-topic.md` pattern",
        "  - `create_memory_template()` / `create_decision_template()` - Generates markdown",
        "  - Supports `--decision`, `--tags`, `--dry-run` flags",
        "",
        "**Modified Files:**",
        "- `scripts/index_codebase.py`",
        "  - `get_doc_files()`: Added `samples/memories/*.md` and `samples/decisions/*.md`",
        "  - `get_doc_type()`: Added detection for 'memory', 'decision', 'concept' types",
        "",
        "- `scripts/search_codebase.py`",
        "  - `get_doc_type_label()`: Added MEM, ADR, CON labels for search results",
        "",
        "- `README.md`",
        "  - Updated test count badge: 1121 ‚Üí 2941",
        "  - Updated line count: 7000 ‚Üí 19,000+",
        "  - Added \"Text-as-Memories System\" section",
        "  - Added \"Contributing\" section",
        "",
        "- `CLAUDE.md`",
        "  - Fixed `processor.py` ‚Üí `processor/` package references",
        "  - Fixed `query.py` ‚Üí `query/` package references",
        "  - Fixed `tests/test_intent_query.py` ‚Üí `tests/unit/test_query.py`",
        "",
        "### Documentation Added",
        "",
        "- Text-as-Memories section in README with CLI examples",
        "- Contributing section in README with links to quality docs",
        "- This knowledge transfer document",
        "- Session memory document",
        "",
        "## Key Decisions Made",
        "",
        "| Decision | Rationale | Alternatives Considered |",
        "|----------|-----------|------------------------|",
        "| Skip WAL implementation | Substantial feature (~200+ lines), needs dedicated session | Implement basic version |",
        "| Use existing task_utils for session IDs | Proven pattern, no new code needed | Create separate memory_utils |",
        "| MEM/ADR/CON as short labels | Fits in terminal output, recognizable | Full words (MEMORY, DECISION) |",
        "| Update README metrics manually | Accurate count matters, badges are public-facing | Leave approximate counts |",
        "",
        "## Problems Encountered & Solutions",
        "",
        "### Problem 1: pytest Not Available",
        "**Symptom:** `python -m pytest` returned \"No module named pytest\"",
        "**Root Cause:** Test environment doesn't have pytest installed",
        "**Solution:** Used `python -c` for inline verification tests, ran showcase.py",
        "**Lesson:** Always have a fallback verification approach that doesn't require test frameworks",
        "",
        "### Problem 2: GROUP C Task Already Complete",
        "**Symptom:** LEGACY-095 (split processor.py) showed as pending",
        "**Root Cause:** Task list status not updated after completion",
        "**Solution:** Research agent discovered processor/ package already exists with 6 mixins",
        "**Lesson:** Always research before implementing - check actual codebase state, not just task status",
        "",
        "## Technical Insights",
        "",
        "### Director Mode Patterns That Worked",
        "",
        "1. **Research Batch ‚Üí Implementation Batch**: Spawn 2-3 research agents in parallel, synthesize findings, then spawn implementation agents",
        "",
        "2. **File Isolation for Parallelism**: Assign non-overlapping files to parallel agents:",
        "   ```",
        "   Agent 1: scripts/new_memory.py (new)",
        "   Agent 2: scripts/index_codebase.py, scripts/search_codebase.py",
        "   ```",
        "",
        "3. **Verification Between Phases**: Run quick integration tests after each batch:",
        "   ```python",
        "   from scripts.new_memory import generate_memory_filename",
        "   from scripts.index_codebase import get_doc_type",
        "   ```",
        "",
        "### Merge-Safe Filename Pattern",
        "",
        "The timestamp + session ID approach works perfectly:",
        "```",
        "2025-12-14_20-55-23_632e-topic.md",
        "‚îÇ          ‚îÇ        ‚îÇ    ‚îî‚îÄ‚îÄ kebab-case topic",
        "‚îÇ          ‚îÇ        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 4-char session ID (from task_utils)",
        "‚îÇ          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ HH-MM-SS timestamp",
        "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ YYYY-MM-DD date",
        "```",
        "",
        "**Collision probability**: ~0% (65 billion unique IDs per second)",
        "",
        "## Context for Next Session",
        "",
        "### Current State",
        "",
        "**Working:**",
        "- Memory CLI tool creates merge-safe filenames",
        "- Index includes memories/decisions in search",
        "- Search shows MEM/ADR/CON type labels",
        "- README has accurate metrics and new sections",
        "- CLAUDE.md references correct package paths",
        "",
        "**In Progress:**",
        "- This knowledge transfer (committing now)",
        "",
        "**Deferred:**",
        "- LEGACY-133: WAL + snapshot persistence (needs dedicated session)",
        "- Unit tests for new_memory.py",
        "",
        "### Suggested Next Steps",
        "",
        "1. **Add unit tests for new_memory.py** - Test filename generation, template creation",
        "2. **Implement LEGACY-133 (WAL)** - Start with operation logging, then recovery",
        "3. **Add --concept flag** to new_memory.py for concept document creation",
        "4. **Consider CI integration** - Auto-create memory from completed tasks",
        "",
        "### Files to Review",
        "",
        "| File | Purpose | Entry Point |",
        "|------|---------|-------------|",
        "| `scripts/new_memory.py` | Memory CLI | `main()` at bottom |",
        "| `scripts/index_codebase.py:1316-1383` | Memory indexing | `get_doc_files()`, `get_doc_type()` |",
        "| `scripts/search_codebase.py:47-63` | Type labels | `get_doc_type_label()` |",
        "| `.claude/commands/director.md` | Director Mode prompt | Full document |",
        "",
        "## Connections to Existing Knowledge",
        "",
        "- Related memory: [[2025-12-14_20-54-35_3b3a-director-mode-session-group-tasks-orchestration.md]]",
        "- Related decision: [[../decisions/adr-microseconds-task-id.md]]",
        "- Concept: [[concept-hebbian-text-processing.md]]",
        "- Documentation: [[../../docs/text-as-memories.md]]",
        "",
        "## Tags",
        "",
        "`knowledge-transfer`, `director-mode`, `handoff`, `memory-system`, `documentation`, `parallel-agents`, `orchestration`",
        "",
        "---",
        "",
        "*Transfer prepared: 2025-12-14T20:55:23Z*",
        "*Next agent: Review files listed above, check git log for context*"
      ],
      "lines_removed": [],
      "context_before": [],
      "context_after": [],
      "change_type": "add"
    },
    {
      "file": "scripts/README_suggest_consolidation.md",
      "function": null,
      "start_line": 0,
      "lines_added": [
        "# Memory Consolidation Suggestions",
        "",
        "The `suggest_consolidation.py` script analyzes memory documents and suggests consolidation opportunities.",
        "",
        "## Features",
        "",
        "1. **Cluster Analysis**: Groups similar memories using semantic similarity and suggests creating concept documents",
        "2. **High Overlap Detection**: Finds memory pairs with significant term overlap that could be merged",
        "3. **Old Memory Tracking**: Identifies unconsolidated memories that are aging and should be reviewed",
        "4. **Topic Extraction**: Automatically suggests concept names based on key terms from clusters",
        "",
        "## Usage",
        "",
        "### Basic Usage",
        "",
        "```bash",
        "# Default analysis (corpus_dev.pkl)",
        "python scripts/suggest_consolidation.py",
        "",
        "# Specify corpus file",
        "python scripts/suggest_consolidation.py --corpus my_corpus.pkl",
        "",
        "# Verbose output with details",
        "python scripts/suggest_consolidation.py --verbose",
        "```",
        "",
        "### Advanced Options",
        "",
        "```bash",
        "# Higher similarity threshold (more strict)",
        "python scripts/suggest_consolidation.py --threshold 0.7",
        "",
        "# Require at least 3 memories per cluster",
        "python scripts/suggest_consolidation.py --min-cluster 3",
        "",
        "# Only flag memories older than 60 days",
        "python scripts/suggest_consolidation.py --min-age-days 60",
        "",
        "# Adjust clustering resolution (higher = more clusters)",
        "python scripts/suggest_consolidation.py --resolution 1.5",
        "",
        "# JSON output for programmatic use",
        "python scripts/suggest_consolidation.py --output json",
        "```",
        "",
        "### Combined Options",
        "",
        "```bash",
        "# Detailed analysis with custom thresholds",
        "python scripts/suggest_consolidation.py \\",
        "  --threshold 0.6 \\",
        "  --min-cluster 2 \\",
        "  --min-age-days 45 \\",
        "  --verbose",
        "```",
        "",
        "## Output Format",
        "",
        "### Text Output (Default)",
        "",
        "The script outputs three types of suggestions:",
        "",
        "1. **Cluster Suggestions**: Groups of related memories that should be consolidated",
        "   ```",
        "   [1] These 3 memories discuss 'security-testing-fuzzing'.",
        "       Consider creating samples/memories/concept-security-testing-fuzzing.md",
        "   ```",
        "",
        "2. **High Overlap Pairs**: Memory pairs with significant similarity",
        "   ```",
        "   [1] memory-1.md and memory-2.md have 78.5% overlap (shared: security, fuzzing, validation).",
        "       Consider merging?",
        "   ```",
        "",
        "3. **Old Memories**: Unconsolidated memories past the age threshold",
        "   ```",
        "   [1] 2025-10-15-old-topic.md is 60 days old.",
        "       Consider consolidating into a concept document?",
        "   ```",
        "",
        "### JSON Output",
        "",
        "```bash",
        "python scripts/suggest_consolidation.py --output json",
        "```",
        "",
        "Returns structured JSON with:",
        "- `clusters`: Array of cluster suggestions with topics and document lists",
        "- `similar_pairs`: Array of high-overlap pairs with similarity scores",
        "- `old_memories`: Array of old memory entries with ages",
        "- `stats`: Summary statistics",
        "",
        "Example:",
        "```json",
        "{",
        "  \"clusters\": [",
        "    {",
        "      \"cluster_id\": 0,",
        "      \"document_count\": 3,",
        "      \"documents\": [\"samples/memories/2025-12-01-topic.md\", ...],",
        "      \"suggested_concept\": \"security-testing-fuzzing\",",
        "      \"topics\": [[\"security\", 0.85], [\"testing\", 0.67], ...],",
        "      \"message\": \"These 3 memories discuss ...\"",
        "    }",
        "  ],",
        "  \"similar_pairs\": [...],",
        "  \"old_memories\": [...],",
        "  \"stats\": {",
        "    \"total_memories\": 15,",
        "    \"total_concepts\": 3,",
        "    \"analyzed_memories\": 12",
        "  }",
        "}",
        "```",
        "",
        "## Algorithm Details",
        "",
        "### Clustering",
        "",
        "The script uses fingerprint-based similarity clustering:",
        "1. Computes semantic fingerprints for all memory documents",
        "2. Calculates pairwise similarity using term overlap",
        "3. Builds a similarity graph with threshold-based edges",
        "4. Finds connected components (clusters) using depth-first search",
        "",
        "The `--resolution` parameter adjusts the similarity threshold:",
        "- `resolution = 1.0`: threshold = 0.3 (default)",
        "- `resolution = 2.0`: threshold = 0.6 (stricter, more clusters)",
        "- `resolution = 0.5`: threshold = 0.15 (looser, fewer clusters)",
        "",
        "### Topic Extraction",
        "",
        "For each cluster, the script:",
        "1. Aggregates term weights across all documents",
        "2. Weights by document PageRank importance",
        "3. Considers global term importance",
        "4. Extracts top 5 terms as representative topics",
        "5. Suggests concept name as hyphenated combination of top 3 terms",
        "",
        "### Similarity Calculation",
        "",
        "Uses the processor's fingerprint comparison:",
        "- Extracts top 20 terms from each document",
        "- Computes cosine similarity between fingerprints",
        "- Includes shared term analysis",
        "- Considers both term weights and overlap",
        "",
        "## Integration with Workflow",
        "",
        "### Typical Workflow",
        "",
        "1. **Regularly run analysis**:",
        "   ```bash",
        "   python scripts/suggest_consolidation.py --min-age-days 30",
        "   ```",
        "",
        "2. **Review cluster suggestions**: Create concept documents for major topics",
        "",
        "3. **Merge high-overlap pairs**: Consolidate redundant memories",
        "",
        "4. **Archive old memories**: Integrate learnings into concept docs",
        "",
        "### Creating Concept Documents",
        "",
        "When the script suggests creating a concept document:",
        "",
        "```bash",
        "# Script output:",
        "# [1] These 3 memories discuss 'security-testing-fuzzing'.",
        "#     Consider creating samples/memories/concept-security-testing-fuzzing.md",
        "",
        "# Create the concept document",
        "cat > samples/memories/concept-security-testing-fuzzing.md << 'EOF'",
        "# Concept: Security Testing and Fuzzing",
        "",
        "**Tags:** `security`, `testing`, `fuzzing`",
        "**Related:** [[2025-12-01-topic.md]], [[2025-12-05-topic.md]]",
        "",
        "## Overview",
        "",
        "Consolidated learnings from multiple sessions on security testing...",
        "",
        "## Key Insights",
        "",
        "1. **Fuzzing finds edge cases**: Property-based testing...",
        "2. **Validation is critical**: NaN and infinity...",
        "",
        "## Patterns",
        "",
        "- Always validate numeric inputs for NaN/inf",
        "- Use Hypothesis for property-based testing",
        "- Test with extreme values",
        "EOF",
        "```",
        "",
        "## Command Reference",
        "",
        "| Option | Short | Type | Default | Description |",
        "|--------|-------|------|---------|-------------|",
        "| `--corpus` | `-c` | string | `corpus_dev.pkl` | Path to corpus file |",
        "| `--threshold` | `-t` | float | `0.5` | Min similarity for pair suggestions (0.0-1.0) |",
        "| `--min-cluster` | | int | `2` | Min memories per cluster |",
        "| `--min-age-days` | | int | `30` | Min age for old memory warnings |",
        "| `--resolution` | | float | `1.0` | Clustering resolution (higher = more clusters) |",
        "| `--output` | `-o` | choice | `text` | Output format: `text` or `json` |",
        "| `--verbose` | `-v` | flag | `false` | Detailed output with document lists |",
        "",
        "## Examples",
        "",
        "### Find duplicate content",
        "",
        "```bash",
        "# High threshold to find near-duplicates",
        "python scripts/suggest_consolidation.py --threshold 0.8",
        "```",
        "",
        "### Review all memories quarterly",
        "",
        "```bash",
        "# Find memories older than 90 days",
        "python scripts/suggest_consolidation.py --min-age-days 90",
        "```",
        "",
        "### Generate concept document candidates",
        "",
        "```bash",
        "# Loose clustering to find broad topic groups",
        "python scripts/suggest_consolidation.py --resolution 0.5 --min-cluster 3",
        "```",
        "",
        "### Export for automation",
        "",
        "```bash",
        "# JSON output for scripting",
        "python scripts/suggest_consolidation.py --output json > suggestions.json",
        "",
        "# Process with jq",
        "cat suggestions.json | jq '.clusters[] | .suggested_concept'",
        "```",
        "",
        "## Testing",
        "",
        "Unit tests are in `tests/unit/test_suggest_consolidation.py`:",
        "",
        "```bash",
        "# Run tests",
        "python -m unittest tests.unit.test_suggest_consolidation -v",
        "",
        "# Or with pytest",
        "pytest tests/unit/test_suggest_consolidation.py -v",
        "```",
        "",
        "Tests cover:",
        "- Date parsing for various formats",
        "- Memory age calculation",
        "- Concept document detection",
        "- Suggestion generation",
        "- Edge cases (empty corpus, single memory, etc.)",
        "",
        "## Limitations",
        "",
        "- **Small corpus only**: Designed for personal memory management (10-100 memories)",
        "- **No automatic merging**: Suggestions must be manually reviewed and actioned",
        "- **Static analysis**: Does not consider semantic relationships or context",
        "- **Filename-based dating**: Relies on consistent filename format",
        "",
        "## Future Enhancements",
        "",
        "Potential improvements (see task system):",
        "- Interactive mode to act on suggestions",
        "- Automatic concept document generation",
        "- Timeline visualization of memory topics",
        "- Semantic relation analysis between memories",
        "- Cross-reference to decision records (ADRs)"
      ],
      "lines_removed": [],
      "context_before": [],
      "context_after": [],
      "change_type": "add"
    },
    {
      "file": "scripts/benchmark_scoring.py",
      "function": null,
      "start_line": 0,
      "lines_added": [
        "#!/usr/bin/env python3",
        "\"\"\"",
        "Benchmark Scoring Algorithms (TF-IDF vs BM25)",
        "=============================================",
        "",
        "Comprehensive benchmark suite for comparing document scoring algorithms.",
        "Run this BEFORE and AFTER implementing BM25 to measure impact.",
        "",
        "Usage:",
        "    # Run full benchmark suite",
        "    python scripts/benchmark_scoring.py",
        "",
        "    # Run specific benchmark",
        "    python scripts/benchmark_scoring.py --benchmark compute",
        "    python scripts/benchmark_scoring.py --benchmark search",
        "    python scripts/benchmark_scoring.py --benchmark relevance",
        "",
        "    # Save results for comparison",
        "    python scripts/benchmark_scoring.py --output baseline_tfidf.json",
        "",
        "    # Compare two benchmark runs",
        "    python scripts/benchmark_scoring.py --compare baseline_tfidf.json after_bm25.json",
        "",
        "Benchmarks:",
        "    1. COMPUTE: Time to compute scores for varying corpus sizes",
        "    2. SEARCH: Query latency and throughput",
        "    3. RELEVANCE: Search quality using known-relevant queries",
        "    4. MEMORY: Memory footprint of score storage",
        "    5. SCALING: How performance changes with corpus growth",
        "\"\"\"",
        "",
        "import argparse",
        "import json",
        "import sys",
        "import time",
        "import gc",
        "import statistics",
        "from pathlib import Path",
        "from typing import Dict, List, Any, Tuple, Optional",
        "from dataclasses import dataclass, asdict",
        "from datetime import datetime",
        "",
        "# Add parent directory to path",
        "sys.path.insert(0, str(Path(__file__).parent.parent))",
        "",
        "from cortical.processor import CorticalTextProcessor",
        "from cortical.tokenizer import Tokenizer",
        "from cortical.layers import CorticalLayer",
        "",
        "",
        "# ============================================================================",
        "# BENCHMARK DATA STRUCTURES",
        "# ============================================================================",
        "",
        "@dataclass",
        "class BenchmarkResult:",
        "    \"\"\"Result from a single benchmark run.\"\"\"",
        "    name: str",
        "    algorithm: str  # 'tfidf' or 'bm25'",
        "    timestamp: str",
        "    corpus_size: int",
        "    vocabulary_size: int",
        "    metrics: Dict[str, Any]",
        "",
        "    def to_dict(self) -> dict:",
        "        return asdict(self)",
        "",
        "",
        "@dataclass",
        "class BenchmarkSuite:",
        "    \"\"\"Collection of benchmark results.\"\"\"",
        "    version: str = \"1.0\"",
        "    algorithm: str = \"tfidf\"  # Current algorithm being benchmarked",
        "    timestamp: str = \"\"",
        "    system_info: Dict[str, Any] = None",
        "    results: List[Dict] = None",
        "",
        "    def __post_init__(self):",
        "        if self.timestamp == \"\":",
        "            self.timestamp = datetime.now().isoformat()",
        "        if self.system_info is None:",
        "            self.system_info = get_system_info()",
        "        if self.results is None:",
        "            self.results = []",
        "",
        "    def add_result(self, result: BenchmarkResult):",
        "        self.results.append(result.to_dict())",
        "",
        "    def to_dict(self) -> dict:",
        "        return {",
        "            'version': self.version,",
        "            'algorithm': self.algorithm,",
        "            'timestamp': self.timestamp,",
        "            'system_info': self.system_info,",
        "            'results': self.results",
        "        }",
        "",
        "    def save(self, path: str):",
        "        with open(path, 'w') as f:",
        "            json.dump(self.to_dict(), f, indent=2)",
        "        print(f\"Results saved to {path}\")",
        "",
        "    @classmethod",
        "    def load(cls, path: str) -> 'BenchmarkSuite':",
        "        with open(path) as f:",
        "            data = json.load(f)",
        "        suite = cls(",
        "            version=data['version'],",
        "            algorithm=data['algorithm'],",
        "            timestamp=data['timestamp'],",
        "            system_info=data['system_info'],",
        "            results=data['results']",
        "        )",
        "        return suite",
        "",
        "",
        "def get_system_info() -> Dict[str, Any]:",
        "    \"\"\"Collect system information for benchmark context.\"\"\"",
        "    import platform",
        "    return {",
        "        'python_version': platform.python_version(),",
        "        'platform': platform.platform(),",
        "        'processor': platform.processor(),",
        "    }",
        "",
        "",
        "# ============================================================================",
        "# TEST CORPUS GENERATORS",
        "# ============================================================================",
        "",
        "def generate_synthetic_corpus(n_docs: int, avg_length: int = 200) -> Dict[str, str]:",
        "    \"\"\"",
        "    Generate synthetic documents for benchmarking.",
        "",
        "    Uses deterministic content for reproducible benchmarks.",
        "    \"\"\"",
        "    import hashlib",
        "",
        "    # Domain vocabulary for realistic term distributions",
        "    domains = {",
        "        'ml': ['neural', 'network', 'learning', 'model', 'training', 'gradient',",
        "               'loss', 'optimization', 'batch', 'epoch', 'layer', 'activation',",
        "               'weights', 'bias', 'backpropagation', 'forward', 'inference'],",
        "        'db': ['database', 'query', 'index', 'table', 'row', 'column', 'join',",
        "               'transaction', 'commit', 'rollback', 'lock', 'cache', 'buffer',",
        "               'storage', 'retrieval', 'schema', 'normalization'],",
        "        'sys': ['process', 'thread', 'memory', 'allocation', 'kernel', 'system',",
        "                'file', 'socket', 'network', 'protocol', 'buffer', 'stream',",
        "                'handler', 'callback', 'event', 'scheduler', 'queue'],",
        "        'web': ['request', 'response', 'server', 'client', 'http', 'api',",
        "                'endpoint', 'route', 'middleware', 'session', 'cookie',",
        "                'authentication', 'authorization', 'token', 'header'],",
        "    }",
        "",
        "    all_terms = []",
        "    for terms in domains.values():",
        "        all_terms.extend(terms)",
        "",
        "    docs = {}",
        "    for i in range(n_docs):",
        "        # Deterministic seed based on doc index",
        "        seed = int(hashlib.md5(f\"doc_{i}\".encode()).hexdigest()[:8], 16)",
        "",
        "        # Select primary domain for this doc",
        "        domain_idx = seed % len(domains)",
        "        domain = list(domains.keys())[domain_idx]",
        "        domain_terms = domains[domain]",
        "",
        "        # Generate document content",
        "        words = []",
        "        word_count = avg_length + (seed % 100) - 50  # Vary length",
        "",
        "        for j in range(word_count):",
        "            term_seed = (seed + j * 31) % 1000",
        "            if term_seed < 600:  # 60% domain terms",
        "                term_idx = (seed + j) % len(domain_terms)",
        "                words.append(domain_terms[term_idx])",
        "            else:  # 40% cross-domain terms",
        "                term_idx = (seed + j * 17) % len(all_terms)",
        "                words.append(all_terms[term_idx])",
        "",
        "        doc_id = f\"synthetic/doc_{i:04d}.txt\"",
        "        docs[doc_id] = ' '.join(words)",
        "",
        "    return docs",
        "",
        "",
        "def load_real_corpus() -> Optional[Dict[str, str]]:",
        "    \"\"\"Load real corpus if available.\"\"\"",
        "    corpus_path = Path(\"corpus_dev.pkl\")",
        "    if corpus_path.exists():",
        "        try:",
        "            processor = CorticalTextProcessor.load(str(corpus_path))",
        "            return processor.documents",
        "        except Exception as e:",
        "            print(f\"Warning: Could not load corpus: {e}\")",
        "    return None",
        "",
        "",
        "# ============================================================================",
        "# RELEVANCE TEST QUERIES",
        "# ============================================================================",
        "",
        "# Queries with expected relevant documents (for synthetic corpus)",
        "RELEVANCE_QUERIES = [",
        "    {",
        "        'query': 'neural network training',",
        "        'domain': 'ml',",
        "        'expected_terms': ['neural', 'network', 'training', 'learning', 'model'],",
        "    },",
        "    {",
        "        'query': 'database query optimization',",
        "        'domain': 'db',",
        "        'expected_terms': ['database', 'query', 'index', 'cache', 'retrieval'],",
        "    },",
        "    {",
        "        'query': 'process memory management',",
        "        'domain': 'sys',",
        "        'expected_terms': ['process', 'memory', 'allocation', 'buffer', 'kernel'],",
        "    },",
        "    {",
        "        'query': 'api authentication',",
        "        'domain': 'web',",
        "        'expected_terms': ['api', 'authentication', 'token', 'request', 'session'],",
        "    },",
        "]",
        "",
        "",
        "# ============================================================================",
        "# BENCHMARK IMPLEMENTATIONS",
        "# ============================================================================",
        "",
        "def benchmark_compute(suite: BenchmarkSuite, corpus_sizes: List[int] = None):",
        "    \"\"\"",
        "    Benchmark: Score computation time.",
        "",
        "    Measures time to compute TF-IDF/BM25 scores for varying corpus sizes.",
        "    \"\"\"",
        "    print(\"\\n\" + \"=\" * 60)",
        "    print(\"BENCHMARK: Score Computation Time\")",
        "    print(\"=\" * 60)",
        "",
        "    if corpus_sizes is None:",
        "        corpus_sizes = [25, 50, 100, 200]",
        "",
        "    tokenizer = Tokenizer(filter_code_noise=True)",
        "",
        "    for n_docs in corpus_sizes:",
        "        print(f\"\\nCorpus size: {n_docs} documents\")",
        "",
        "        # Generate corpus",
        "        docs = generate_synthetic_corpus(n_docs)",
        "",
        "        # Create processor and load documents",
        "        processor = CorticalTextProcessor(tokenizer=tokenizer)",
        "        for doc_id, content in docs.items():",
        "            processor.process_document(doc_id, content)",
        "",
        "        layer0 = processor.layers.get(CorticalLayer.TOKENS)",
        "        vocab_size = layer0.column_count() if layer0 else 0",
        "",
        "        # Warm up",
        "        processor.compute_tfidf(verbose=False)",
        "",
        "        # Benchmark TF-IDF computation (multiple runs for stability)",
        "        times = []",
        "        for _ in range(5):",
        "            # Reset TF-IDF scores",
        "            for col in layer0.minicolumns.values():",
        "                col.tfidf = 0.0",
        "                col.tfidf_per_doc = {}",
        "",
        "            gc.collect()",
        "            start = time.perf_counter()",
        "            processor.compute_tfidf(verbose=False)",
        "            elapsed = time.perf_counter() - start",
        "            times.append(elapsed)",
        "",
        "        metrics = {",
        "            'corpus_size': n_docs,",
        "            'vocabulary_size': vocab_size,",
        "            'mean_time_ms': statistics.mean(times) * 1000,",
        "            'std_time_ms': statistics.stdev(times) * 1000 if len(times) > 1 else 0,",
        "            'min_time_ms': min(times) * 1000,",
        "            'max_time_ms': max(times) * 1000,",
        "            'time_per_doc_ms': (statistics.mean(times) * 1000) / n_docs,",
        "            'time_per_term_us': (statistics.mean(times) * 1_000_000) / vocab_size if vocab_size else 0,",
        "        }",
        "",
        "        print(f\"  Vocabulary: {vocab_size} terms\")",
        "        print(f\"  Mean time: {metrics['mean_time_ms']:.2f}ms (+/- {metrics['std_time_ms']:.2f}ms)\")",
        "        print(f\"  Per-doc: {metrics['time_per_doc_ms']:.3f}ms\")",
        "        print(f\"  Per-term: {metrics['time_per_term_us']:.2f}us\")",
        "",
        "        result = BenchmarkResult(",
        "            name='compute_scores',",
        "            algorithm=suite.algorithm,",
        "            timestamp=datetime.now().isoformat(),",
        "            corpus_size=n_docs,",
        "            vocabulary_size=vocab_size,",
        "            metrics=metrics",
        "        )",
        "        suite.add_result(result)",
        "",
        "        del processor",
        "        gc.collect()",
        "",
        "",
        "def benchmark_search(suite: BenchmarkSuite, n_docs: int = 100):",
        "    \"\"\"",
        "    Benchmark: Search query latency and throughput.",
        "",
        "    Measures time to execute search queries using computed scores.",
        "    \"\"\"",
        "    print(\"\\n\" + \"=\" * 60)",
        "    print(\"BENCHMARK: Search Query Performance\")",
        "    print(\"=\" * 60)",
        "",
        "    # Setup corpus",
        "    tokenizer = Tokenizer(filter_code_noise=True)",
        "    processor = CorticalTextProcessor(tokenizer=tokenizer)",
        "",
        "    docs = generate_synthetic_corpus(n_docs)",
        "    for doc_id, content in docs.items():",
        "        processor.process_document(doc_id, content)",
        "    processor.compute_all(verbose=False)",
        "",
        "    layer0 = processor.layers.get(CorticalLayer.TOKENS)",
        "    vocab_size = layer0.column_count() if layer0 else 0",
        "",
        "    # Test queries",
        "    queries = [q['query'] for q in RELEVANCE_QUERIES]",
        "    queries.extend([",
        "        'learning optimization',",
        "        'cache buffer',",
        "        'request handler',",
        "        'network protocol',",
        "    ])",
        "",
        "    # Warm up",
        "    for q in queries[:2]:",
        "        processor.find_documents_for_query(q, top_n=5)",
        "",
        "    # Benchmark queries",
        "    print(f\"\\nCorpus: {n_docs} docs, {vocab_size} terms\")",
        "    print(f\"Running {len(queries)} queries...\")",
        "",
        "    query_times = []",
        "    for query in queries:",
        "        times = []",
        "        for _ in range(10):",
        "            start = time.perf_counter()",
        "            results = processor.find_documents_for_query(query, top_n=5)",
        "            elapsed = time.perf_counter() - start",
        "            times.append(elapsed)",
        "",
        "        avg_time = statistics.mean(times)",
        "        query_times.append(avg_time)",
        "",
        "    metrics = {",
        "        'corpus_size': n_docs,",
        "        'vocabulary_size': vocab_size,",
        "        'num_queries': len(queries),",
        "        'mean_latency_ms': statistics.mean(query_times) * 1000,",
        "        'median_latency_ms': statistics.median(query_times) * 1000,",
        "        'p95_latency_ms': sorted(query_times)[int(len(query_times) * 0.95)] * 1000,",
        "        'max_latency_ms': max(query_times) * 1000,",
        "        'min_latency_ms': min(query_times) * 1000,",
        "        'throughput_qps': 1.0 / statistics.mean(query_times) if query_times else 0,",
        "    }",
        "",
        "    print(f\"  Mean latency: {metrics['mean_latency_ms']:.2f}ms\")",
        "    print(f\"  P95 latency: {metrics['p95_latency_ms']:.2f}ms\")",
        "    print(f\"  Throughput: {metrics['throughput_qps']:.1f} queries/sec\")",
        "",
        "    result = BenchmarkResult(",
        "        name='search_latency',",
        "        algorithm=suite.algorithm,",
        "        timestamp=datetime.now().isoformat(),",
        "        corpus_size=n_docs,",
        "        vocabulary_size=vocab_size,",
        "        metrics=metrics",
        "    )",
        "    suite.add_result(result)",
        "",
        "",
        "def benchmark_relevance(suite: BenchmarkSuite, n_docs: int = 100):",
        "    \"\"\"",
        "    Benchmark: Search result relevance quality.",
        "",
        "    Measures how well the scoring algorithm ranks relevant documents.",
        "    Uses domain-based relevance (docs from same domain should rank higher).",
        "    \"\"\"",
        "    print(\"\\n\" + \"=\" * 60)",
        "    print(\"BENCHMARK: Search Relevance Quality\")",
        "    print(\"=\" * 60)",
        "",
        "    # Setup corpus with domain tracking",
        "    tokenizer = Tokenizer(filter_code_noise=True)",
        "    processor = CorticalTextProcessor(tokenizer=tokenizer)",
        "",
        "    docs = generate_synthetic_corpus(n_docs)",
        "    for doc_id, content in docs.items():",
        "        processor.process_document(doc_id, content)",
        "    processor.compute_all(verbose=False)",
        "",
        "    # Determine document domains (based on generation algorithm)",
        "    import hashlib",
        "    domains = ['ml', 'db', 'sys', 'web']",
        "    doc_domains = {}",
        "    for i in range(n_docs):",
        "        seed = int(hashlib.md5(f\"doc_{i}\".encode()).hexdigest()[:8], 16)",
        "        domain_idx = seed % len(domains)",
        "        doc_id = f\"synthetic/doc_{i:04d}.txt\"",
        "        doc_domains[doc_id] = domains[domain_idx]",
        "",
        "    # Run relevance tests",
        "    print(f\"\\nCorpus: {n_docs} docs\")",
        "",
        "    relevance_scores = []",
        "",
        "    for test in RELEVANCE_QUERIES:",
        "        query = test['query']",
        "        expected_domain = test['domain']",
        "        expected_terms = test['expected_terms']",
        "",
        "        # Get search results",
        "        results = processor.find_documents_for_query(query, top_n=10)",
        "",
        "        # Calculate precision@k (docs from expected domain in top k)",
        "        precisions = {}",
        "        for k in [1, 3, 5, 10]:",
        "            top_k = results[:k]",
        "            relevant = sum(1 for doc_id, _ in top_k",
        "                         if doc_domains.get(doc_id) == expected_domain)",
        "            precisions[f'p@{k}'] = relevant / k if k <= len(results) else 0",
        "",
        "        # Calculate MRR (mean reciprocal rank of first relevant doc)",
        "        mrr = 0.0",
        "        for rank, (doc_id, _) in enumerate(results, 1):",
        "            if doc_domains.get(doc_id) == expected_domain:",
        "                mrr = 1.0 / rank",
        "                break",
        "",
        "        # Check if expected terms appear in expanded query",
        "        expanded = processor.expand_query(query, max_expansions=10)",
        "        term_recall = sum(1 for t in expected_terms if t in expanded) / len(expected_terms)",
        "",
        "        relevance_scores.append({",
        "            'query': query,",
        "            'domain': expected_domain,",
        "            'p@1': precisions['p@1'],",
        "            'p@3': precisions['p@3'],",
        "            'p@5': precisions['p@5'],",
        "            'mrr': mrr,",
        "            'term_recall': term_recall,",
        "        })",
        "",
        "        print(f\"  '{query}': P@3={precisions['p@3']:.2f}, MRR={mrr:.2f}, TermRecall={term_recall:.2f}\")",
        "",
        "    # Aggregate metrics",
        "    metrics = {",
        "        'corpus_size': n_docs,",
        "        'num_queries': len(relevance_scores),",
        "        'mean_p@1': statistics.mean(r['p@1'] for r in relevance_scores),",
        "        'mean_p@3': statistics.mean(r['p@3'] for r in relevance_scores),",
        "        'mean_p@5': statistics.mean(r['p@5'] for r in relevance_scores),",
        "        'mean_mrr': statistics.mean(r['mrr'] for r in relevance_scores),",
        "        'mean_term_recall': statistics.mean(r['term_recall'] for r in relevance_scores),",
        "        'per_query': relevance_scores,",
        "    }",
        "",
        "    print(f\"\\n  AGGREGATE:\")",
        "    print(f\"    Mean P@3: {metrics['mean_p@3']:.3f}\")",
        "    print(f\"    Mean MRR: {metrics['mean_mrr']:.3f}\")",
        "    print(f\"    Mean Term Recall: {metrics['mean_term_recall']:.3f}\")",
        "",
        "    result = BenchmarkResult(",
        "        name='search_relevance',",
        "        algorithm=suite.algorithm,",
        "        timestamp=datetime.now().isoformat(),",
        "        corpus_size=n_docs,",
        "        vocabulary_size=processor.layers[CorticalLayer.TOKENS].column_count(),",
        "        metrics=metrics",
        "    )",
        "    suite.add_result(result)",
        "",
        "",
        "def benchmark_memory(suite: BenchmarkSuite, corpus_sizes: List[int] = None):",
        "    \"\"\"",
        "    Benchmark: Memory footprint of score storage.",
        "",
        "    Measures memory used by TF-IDF/BM25 data structures.",
        "    \"\"\"",
        "    print(\"\\n\" + \"=\" * 60)",
        "    print(\"BENCHMARK: Memory Footprint\")",
        "    print(\"=\" * 60)",
        "",
        "    if corpus_sizes is None:",
        "        corpus_sizes = [25, 50, 100, 200]",
        "",
        "    import tracemalloc",
        "",
        "    tokenizer = Tokenizer(filter_code_noise=True)",
        "",
        "    for n_docs in corpus_sizes:",
        "        print(f\"\\nCorpus size: {n_docs} documents\")",
        "",
        "        # Generate corpus",
        "        docs = generate_synthetic_corpus(n_docs)",
        "",
        "        gc.collect()",
        "        tracemalloc.start()",
        "",
        "        # Create processor and load documents",
        "        processor = CorticalTextProcessor(tokenizer=tokenizer)",
        "        for doc_id, content in docs.items():",
        "            processor.process_document(doc_id, content)",
        "",
        "        # Snapshot before computing scores",
        "        before_compute = tracemalloc.take_snapshot()",
        "",
        "        # Compute scores",
        "        processor.compute_tfidf(verbose=False)",
        "",
        "        # Snapshot after computing scores",
        "        after_compute = tracemalloc.take_snapshot()",
        "",
        "        tracemalloc.stop()",
        "",
        "        # Calculate memory difference",
        "        diff = after_compute.compare_to(before_compute, 'lineno')",
        "        score_memory = sum(stat.size_diff for stat in diff if stat.size_diff > 0)",
        "",
        "        layer0 = processor.layers.get(CorticalLayer.TOKENS)",
        "        vocab_size = layer0.column_count() if layer0 else 0",
        "",
        "        # Estimate per-doc TF-IDF dict size",
        "        total_tfidf_entries = sum(",
        "            len(col.tfidf_per_doc)",
        "            for col in layer0.minicolumns.values()",
        "        )",
        "",
        "        metrics = {",
        "            'corpus_size': n_docs,",
        "            'vocabulary_size': vocab_size,",
        "            'score_memory_bytes': score_memory,",
        "            'score_memory_kb': score_memory / 1024,",
        "            'total_tfidf_entries': total_tfidf_entries,",
        "            'bytes_per_entry': score_memory / total_tfidf_entries if total_tfidf_entries else 0,",
        "            'bytes_per_term': score_memory / vocab_size if vocab_size else 0,",
        "        }",
        "",
        "        print(f\"  Vocabulary: {vocab_size} terms\")",
        "        print(f\"  TF-IDF entries: {total_tfidf_entries}\")",
        "        print(f\"  Score memory: {metrics['score_memory_kb']:.1f} KB\")",
        "        print(f\"  Per entry: {metrics['bytes_per_entry']:.1f} bytes\")",
        "",
        "        result = BenchmarkResult(",
        "            name='memory_footprint',",
        "            algorithm=suite.algorithm,",
        "            timestamp=datetime.now().isoformat(),",
        "            corpus_size=n_docs,",
        "            vocabulary_size=vocab_size,",
        "            metrics=metrics",
        "        )",
        "        suite.add_result(result)",
        "",
        "        del processor",
        "        gc.collect()",
        "",
        "",
        "def benchmark_scaling(suite: BenchmarkSuite):",
        "    \"\"\"",
        "    Benchmark: Scaling behavior analysis.",
        "",
        "    Measures how compute time scales with corpus size to detect O(n^2) issues.",
        "    \"\"\"",
        "    print(\"\\n\" + \"=\" * 60)",
        "    print(\"BENCHMARK: Scaling Behavior\")",
        "    print(\"=\" * 60)",
        "",
        "    corpus_sizes = [10, 25, 50, 100, 150, 200]",
        "    tokenizer = Tokenizer(filter_code_noise=True)",
        "",
        "    timings = []",
        "",
        "    for n_docs in corpus_sizes:",
        "        docs = generate_synthetic_corpus(n_docs)",
        "",
        "        processor = CorticalTextProcessor(tokenizer=tokenizer)",
        "        for doc_id, content in docs.items():",
        "            processor.process_document(doc_id, content)",
        "",
        "        layer0 = processor.layers.get(CorticalLayer.TOKENS)",
        "        vocab_size = layer0.column_count() if layer0 else 0",
        "",
        "        # Time score computation",
        "        gc.collect()",
        "        times = []",
        "        for _ in range(3):",
        "            # Reset scores",
        "            for col in layer0.minicolumns.values():",
        "                col.tfidf = 0.0",
        "                col.tfidf_per_doc = {}",
        "",
        "            start = time.perf_counter()",
        "            processor.compute_tfidf(verbose=False)",
        "            elapsed = time.perf_counter() - start",
        "            times.append(elapsed)",
        "",
        "        avg_time = statistics.mean(times)",
        "        timings.append({",
        "            'n_docs': n_docs,",
        "            'vocab_size': vocab_size,",
        "            'time_ms': avg_time * 1000,",
        "        })",
        "",
        "        print(f\"  {n_docs} docs, {vocab_size} terms: {avg_time*1000:.2f}ms\")",
        "",
        "        del processor",
        "        gc.collect()",
        "",
        "    # Analyze scaling behavior",
        "    # Linear: time ~ n, Quadratic: time ~ n^2",
        "    # Fit log-log slope to estimate complexity",
        "    import math",
        "",
        "    if len(timings) >= 3:",
        "        log_n = [math.log(t['n_docs']) for t in timings]",
        "        log_t = [math.log(t['time_ms']) for t in timings]",
        "",
        "        # Simple linear regression on log-log plot",
        "        n = len(log_n)",
        "        sum_x = sum(log_n)",
        "        sum_y = sum(log_t)",
        "        sum_xy = sum(x*y for x, y in zip(log_n, log_t))",
        "        sum_xx = sum(x*x for x in log_n)",
        "",
        "        slope = (n * sum_xy - sum_x * sum_y) / (n * sum_xx - sum_x * sum_x)",
        "",
        "        complexity = \"O(n)\" if slope < 1.3 else \"O(n log n)\" if slope < 1.7 else \"O(n^2)\"",
        "",
        "        print(f\"\\n  Scaling exponent: {slope:.2f}\")",
        "        print(f\"  Estimated complexity: {complexity}\")",
        "    else:",
        "        slope = 0",
        "        complexity = \"Unknown (need more data points)\"",
        "",
        "    metrics = {",
        "        'data_points': timings,",
        "        'scaling_exponent': slope,",
        "        'estimated_complexity': complexity,",
        "    }",
        "",
        "    result = BenchmarkResult(",
        "        name='scaling_behavior',",
        "        algorithm=suite.algorithm,",
        "        timestamp=datetime.now().isoformat(),",
        "        corpus_size=max(t['n_docs'] for t in timings),",
        "        vocabulary_size=max(t['vocab_size'] for t in timings),",
        "        metrics=metrics",
        "    )",
        "    suite.add_result(result)",
        "",
        "",
        "def benchmark_real_corpus(suite: BenchmarkSuite):",
        "    \"\"\"",
        "    Benchmark: Performance on real corpus (if available).",
        "",
        "    Uses the actual indexed codebase for realistic measurements.",
        "    \"\"\"",
        "    print(\"\\n\" + \"=\" * 60)",
        "    print(\"BENCHMARK: Real Corpus Performance\")",
        "    print(\"=\" * 60)",
        "",
        "    # Try to load real corpus",
        "    corpus_path = Path(\"corpus_dev.pkl\")",
        "    if not corpus_path.exists():",
        "        print(\"  Skipping: corpus_dev.pkl not found\")",
        "        print(\"  Run: python scripts/index_codebase.py first\")",
        "        return",
        "",
        "    try:",
        "        processor = CorticalTextProcessor.load(str(corpus_path))",
        "    except Exception as e:",
        "        print(f\"  Skipping: Could not load corpus: {e}\")",
        "        return",
        "",
        "    n_docs = len(processor.documents)",
        "    layer0 = processor.layers.get(CorticalLayer.TOKENS)",
        "    vocab_size = layer0.column_count() if layer0 else 0",
        "",
        "    print(f\"  Corpus: {n_docs} documents, {vocab_size} terms\")",
        "",
        "    # Test queries relevant to this codebase",
        "    codebase_queries = [",
        "        \"pagerank algorithm\",",
        "        \"tfidf computation\",",
        "        \"lateral connections\",",
        "        \"query expansion\",",
        "        \"document search\",",
        "        \"minicolumn layer\",",
        "        \"semantic relations\",",
        "        \"louvain clustering\",",
        "    ]",
        "",
        "    # Benchmark TF-IDF computation",
        "    print(\"\\n  TF-IDF Computation:\")",
        "    times = []",
        "    for _ in range(3):",
        "        # Reset scores",
        "        for col in layer0.minicolumns.values():",
        "            col.tfidf = 0.0",
        "            col.tfidf_per_doc = {}",
        "",
        "        gc.collect()",
        "        start = time.perf_counter()",
        "        processor.compute_tfidf(verbose=False)",
        "        elapsed = time.perf_counter() - start",
        "        times.append(elapsed)",
        "",
        "    compute_time = statistics.mean(times)",
        "    print(f\"    Time: {compute_time*1000:.2f}ms\")",
        "",
        "    # Benchmark search queries",
        "    print(\"\\n  Search Queries:\")",
        "    query_times = []",
        "    for query in codebase_queries:",
        "        times = []",
        "        for _ in range(5):",
        "            start = time.perf_counter()",
        "            results = processor.find_documents_for_query(query, top_n=5)",
        "            elapsed = time.perf_counter() - start",
        "            times.append(elapsed)",
        "",
        "        avg_time = statistics.mean(times)",
        "        query_times.append(avg_time)",
        "        print(f\"    '{query}': {avg_time*1000:.2f}ms, {len(results)} results\")",
        "",
        "    metrics = {",
        "        'corpus_size': n_docs,",
        "        'vocabulary_size': vocab_size,",
        "        'compute_time_ms': compute_time * 1000,",
        "        'mean_query_time_ms': statistics.mean(query_times) * 1000,",
        "        'max_query_time_ms': max(query_times) * 1000,",
        "        'queries_tested': len(codebase_queries),",
        "    }",
        "",
        "    result = BenchmarkResult(",
        "        name='real_corpus',",
        "        algorithm=suite.algorithm,",
        "        timestamp=datetime.now().isoformat(),",
        "        corpus_size=n_docs,",
        "        vocabulary_size=vocab_size,",
        "        metrics=metrics",
        "    )",
        "    suite.add_result(result)",
        "",
        "",
        "# ============================================================================",
        "# COMPARISON TOOLS",
        "# ============================================================================",
        "",
        "def compare_results(before_path: str, after_path: str):",
        "    \"\"\"Compare two benchmark runs and report improvements/regressions.\"\"\"",
        "    print(\"\\n\" + \"=\" * 60)",
        "    print(\"BENCHMARK COMPARISON\")",
        "    print(\"=\" * 60)",
        "",
        "    before = BenchmarkSuite.load(before_path)",
        "    after = BenchmarkSuite.load(after_path)",
        "",
        "    print(f\"\\nBefore: {before.algorithm} ({before.timestamp})\")",
        "    print(f\"After:  {after.algorithm} ({after.timestamp})\")",
        "",
        "    # Group results by benchmark name",
        "    before_by_name = {}",
        "    for r in before.results:",
        "        key = (r['name'], r['corpus_size'])",
        "        before_by_name[key] = r",
        "",
        "    after_by_name = {}",
        "    for r in after.results:",
        "        key = (r['name'], r['corpus_size'])",
        "        after_by_name[key] = r",
        "",
        "    print(\"\\n\" + \"-\" * 60)",
        "    print(f\"{'Benchmark':<30} {'Before':>12} {'After':>12} {'Change':>12}\")",
        "    print(\"-\" * 60)",
        "",
        "    # Compare common benchmarks",
        "    for key in sorted(before_by_name.keys()):",
        "        if key not in after_by_name:",
        "            continue",
        "",
        "        b = before_by_name[key]['metrics']",
        "        a = after_by_name[key]['metrics']",
        "        name = f\"{key[0]} (n={key[1]})\"",
        "",
        "        # Compare key metrics",
        "        if 'mean_time_ms' in b:",
        "            b_val = b['mean_time_ms']",
        "            a_val = a['mean_time_ms']",
        "            change = ((a_val - b_val) / b_val) * 100 if b_val else 0",
        "            indicator = \"faster\" if change < 0 else \"SLOWER\"",
        "            print(f\"{name:<30} {b_val:>10.2f}ms {a_val:>10.2f}ms {change:>+10.1f}% {indicator}\")",
        "",
        "        if 'mean_latency_ms' in b:",
        "            b_val = b['mean_latency_ms']",
        "            a_val = a['mean_latency_ms']",
        "            change = ((a_val - b_val) / b_val) * 100 if b_val else 0",
        "            indicator = \"faster\" if change < 0 else \"SLOWER\"",
        "            print(f\"{name:<30} {b_val:>10.2f}ms {a_val:>10.2f}ms {change:>+10.1f}% {indicator}\")",
        "",
        "        if 'mean_p@3' in b:",
        "            b_val = b['mean_p@3']",
        "            a_val = a['mean_p@3']",
        "            change = ((a_val - b_val) / b_val) * 100 if b_val else 0",
        "            indicator = \"BETTER\" if change > 0 else \"worse\"",
        "            print(f\"{name:<30} {b_val:>10.3f}   {a_val:>10.3f}   {change:>+10.1f}% {indicator}\")",
        "",
        "    print(\"-\" * 60)",
        "",
        "",
        "# ============================================================================",
        "# MAIN",
        "# ============================================================================",
        "",
        "def run_all_benchmarks(output_path: Optional[str] = None, algorithm: str = None):",
        "    \"\"\"Run all benchmarks and optionally save results.\"\"\"",
        "    # Detect algorithm from config if not specified",
        "    if algorithm is None:",
        "        from cortical.config import CorticalConfig",
        "        config = CorticalConfig()",
        "        algorithm = config.scoring_algorithm",
        "",
        "    suite = BenchmarkSuite(algorithm=algorithm)",
        "",
        "    print(\"\\n\" + \"=\" * 60)",
        "    print(\"SCORING ALGORITHM BENCHMARK SUITE\")",
        "    print(\"=\" * 60)",
        "    print(f\"Algorithm: {suite.algorithm}\")",
        "    print(f\"Timestamp: {suite.timestamp}\")",
        "    print(f\"Python: {suite.system_info['python_version']}\")",
        "",
        "    # Run benchmarks",
        "    benchmark_compute(suite)",
        "    benchmark_search(suite)",
        "    benchmark_relevance(suite)",
        "    benchmark_memory(suite)",
        "    benchmark_scaling(suite)",
        "    benchmark_real_corpus(suite)",
        "",
        "    # Summary",
        "    print(\"\\n\" + \"=\" * 60)",
        "    print(\"BENCHMARK SUMMARY\")",
        "    print(\"=\" * 60)",
        "",
        "    for r in suite.results:",
        "        print(f\"\\n{r['name']} (n={r['corpus_size']}):\")",
        "        for key, value in r['metrics'].items():",
        "            if key == 'per_query' or key == 'data_points':",
        "                continue",
        "            if isinstance(value, float):",
        "                print(f\"  {key}: {value:.3f}\")",
        "            else:",
        "                print(f\"  {key}: {value}\")",
        "",
        "    # Save if requested",
        "    if output_path:",
        "        suite.save(output_path)",
        "",
        "    return suite",
        "",
        "",
        "def main():",
        "    parser = argparse.ArgumentParser(",
        "        description=\"Benchmark scoring algorithms (TF-IDF vs BM25)\",",
        "        formatter_class=argparse.RawDescriptionHelpFormatter,",
        "        epilog=__doc__",
        "    )",
        "    parser.add_argument('--benchmark', choices=['all', 'compute', 'search', 'relevance',",
        "                                                  'memory', 'scaling', 'real'],",
        "                       default='all', help='Benchmark to run')",
        "    parser.add_argument('--output', '-o', help='Save results to JSON file')",
        "    parser.add_argument('--compare', nargs=2, metavar=('BEFORE', 'AFTER'),",
        "                       help='Compare two benchmark result files')",
        "    parser.add_argument('--corpus-sizes', type=int, nargs='+', default=[25, 50, 100, 200],",
        "                       help='Corpus sizes to test')",
        "    parser.add_argument('--algorithm', choices=['tfidf', 'bm25'],",
        "                       help='Algorithm to benchmark (default: from config)')",
        "",
        "    args = parser.parse_args()",
        "",
        "    if args.compare:",
        "        compare_results(args.compare[0], args.compare[1])",
        "        return",
        "",
        "    # Detect algorithm from config if not specified",
        "    algorithm = args.algorithm",
        "    if algorithm is None:",
        "        from cortical.config import CorticalConfig",
        "        config = CorticalConfig()",
        "        algorithm = config.scoring_algorithm",
        "",
        "    if args.benchmark == 'all':",
        "        run_all_benchmarks(args.output, algorithm=algorithm)",
        "    else:",
        "        suite = BenchmarkSuite(algorithm=algorithm)",
        "",
        "        if args.benchmark == 'compute':",
        "            benchmark_compute(suite, args.corpus_sizes)",
        "        elif args.benchmark == 'search':",
        "            benchmark_search(suite)",
        "        elif args.benchmark == 'relevance':",
        "            benchmark_relevance(suite)",
        "        elif args.benchmark == 'memory':",
        "            benchmark_memory(suite)",
        "        elif args.benchmark == 'scaling':",
        "            benchmark_scaling(suite)",
        "        elif args.benchmark == 'real':",
        "            benchmark_real_corpus(suite)",
        "",
        "        if args.output:",
        "            suite.save(args.output)",
        "",
        "",
        "if __name__ == '__main__':",
        "    main()"
      ],
      "lines_removed": [],
      "context_before": [],
      "context_after": [],
      "change_type": "add"
    },
    {
      "file": "scripts/index_codebase.py",
      "function": "def get_doc_files(base_path: Path) -> list:",
      "start_line": 1322,
      "lines_added": [
        "    # Memory documents in samples/memories/",
        "    memories_dir = base_path / 'samples' / 'memories'",
        "    if memories_dir.exists():",
        "        for md_file in memories_dir.glob('*.md'):",
        "            files.append(md_file)",
        "",
        "    # Decision records in samples/decisions/",
        "    decisions_dir = base_path / 'samples' / 'decisions'",
        "    if decisions_dir.exists():",
        "        for md_file in decisions_dir.glob('*.md'):",
        "            files.append(md_file)",
        ""
      ],
      "lines_removed": [],
      "context_before": [
        "        doc_path = base_path / doc",
        "        if doc_path.exists():",
        "            files.append(doc_path)",
        "",
        "    # Intelligence documentation in docs/",
        "    docs_dir = base_path / 'docs'",
        "    if docs_dir.exists():",
        "        for md_file in docs_dir.glob('*.md'):",
        "            files.append(md_file)",
        ""
      ],
      "context_after": [
        "    return files",
        "",
        "",
        "def create_doc_id(file_path: Path, base_path: Path) -> str:",
        "    \"\"\"Create a document ID from file path.\"\"\"",
        "    rel_path = file_path.relative_to(base_path)",
        "    return str(rel_path)",
        "",
        "",
        "def extract_markdown_headings(content: str) -> List[str]:"
      ],
      "change_type": "add"
    },
    {
      "file": "scripts/index_codebase.py",
      "function": "def extract_markdown_headings(content: str) -> List[str]:",
      "start_line": 1344,
      "lines_added": [
        "        One of: 'code', 'test', 'docs', 'root_docs', 'memory', 'decision', 'concept'",
        "    elif doc_id.startswith('samples/memories/'):",
        "        # Check if it's a concept doc",
        "        filename = doc_id.split('/')[-1]",
        "        if filename.startswith('concept-'):",
        "            return 'concept'",
        "        return 'memory'",
        "    elif doc_id.startswith('samples/decisions/'):",
        "        return 'decision'"
      ],
      "lines_removed": [
        "        One of: 'code', 'test', 'docs', 'root_docs'"
      ],
      "context_before": [
        "    # Match ## and ### headings (skip # as it's usually the title)",
        "    headings = re.findall(r'^##+ (.+)$', content, re.MULTILINE)",
        "    return headings",
        "",
        "",
        "def get_doc_type(doc_id: str) -> str:",
        "    \"\"\"",
        "    Determine document type from document ID.",
        "",
        "    Returns:"
      ],
      "context_after": [
        "    \"\"\"",
        "    if doc_id.startswith('tests/'):",
        "        return 'test'",
        "    elif doc_id.startswith('docs/'):",
        "        return 'docs'",
        "    elif doc_id.endswith('.md'):",
        "        return 'root_docs'",
        "    else:",
        "        return 'code'",
        "",
        "",
        "def _extract_file_metadata(",
        "    doc_id: str,"
      ],
      "change_type": "modify"
    },
    {
      "file": "scripts/new_memory.py",
      "function": null,
      "start_line": 0,
      "lines_added": [
        "#!/usr/bin/env python3",
        "\"\"\"",
        "Quick memory and decision record creation from command line.",
        "",
        "Usage:",
        "    # Create a memory entry (interactive prompts)",
        "    python scripts/new_memory.py",
        "",
        "    # Create with title",
        "    python scripts/new_memory.py \"dogfooding session insights\"",
        "",
        "    # Create with tags",
        "    python scripts/new_memory.py \"fuzzing discoveries\" --tags \"security,testing,fuzzing\"",
        "",
        "    # Create a decision record",
        "    python scripts/new_memory.py \"use microseconds in task IDs\" --decision",
        "",
        "    # Dry-run to preview",
        "    python scripts/new_memory.py \"test topic\" --dry-run",
        "",
        "Examples:",
        "    $ python scripts/new_memory.py \"learned about NaN validation\" --tags \"testing,validation\"",
        "    Created: samples/memories/2025-12-14_14-30-52_a1b2-nan-validation.md",
        "",
        "    $ python scripts/new_memory.py \"add microseconds to timestamps\" --decision",
        "    Created: samples/decisions/2025-12-14_14-31-15_c3d4-microseconds-timestamps.md",
        "\"\"\"",
        "",
        "import argparse",
        "import os",
        "import sys",
        "import subprocess",
        "from datetime import datetime",
        "from pathlib import Path",
        "",
        "# Add scripts to path",
        "sys.path.insert(0, str(Path(__file__).parent))",
        "",
        "from task_utils import generate_session_id",
        "",
        "",
        "# Directories for memories and decisions",
        "MEMORIES_DIR = Path(\"samples/memories\")",
        "DECISIONS_DIR = Path(\"samples/decisions\")",
        "",
        "",
        "def get_git_author() -> str:",
        "    \"\"\"Get git author name from config.\"\"\"",
        "    try:",
        "        result = subprocess.run(",
        "            [\"git\", \"config\", \"user.name\"],",
        "            capture_output=True,",
        "            text=True,",
        "            timeout=2",
        "        )",
        "        if result.returncode == 0:",
        "            return result.stdout.strip()",
        "    except (subprocess.TimeoutExpired, FileNotFoundError):",
        "        pass",
        "    return \"Unknown\"",
        "",
        "",
        "def slugify(text: str) -> str:",
        "    \"\"\"Convert text to URL-friendly slug.\"\"\"",
        "    # Simple slugification: lowercase, replace spaces with hyphens",
        "    slug = text.lower().strip()",
        "    slug = slug.replace(\" \", \"-\")",
        "    # Remove non-alphanumeric except hyphens",
        "    slug = \"\".join(c for c in slug if c.isalnum() or c == \"-\")",
        "    # Remove duplicate hyphens",
        "    while \"--\" in slug:",
        "        slug = slug.replace(\"--\", \"-\")",
        "    # Truncate to reasonable length",
        "    return slug[:50]",
        "",
        "",
        "def generate_memory_filename(title: str, is_decision: bool = False) -> str:",
        "    \"\"\"",
        "    Generate merge-safe filename with timestamp and session ID.",
        "",
        "    Format: YYYY-MM-DD_HH-MM-SS_XXXX-topic.md",
        "",
        "    Args:",
        "        title: Topic or title of the memory/decision",
        "        is_decision: If True, generates a decision record filename",
        "",
        "    Returns:",
        "        Filename string",
        "    \"\"\"",
        "    now = datetime.now()",
        "    date_str = now.strftime(\"%Y-%m-%d\")",
        "    time_str = now.strftime(\"%H-%M-%S\")",
        "    session_id = generate_session_id()",
        "    slug = slugify(title)",
        "",
        "    return f\"{date_str}_{time_str}_{session_id}-{slug}.md\"",
        "",
        "",
        "def create_memory_template(title: str, tags: str = \"\", author: str = \"\") -> str:",
        "    \"\"\"",
        "    Create a memory entry template.",
        "",
        "    Args:",
        "        title: Memory title/topic",
        "        tags: Comma-separated tags",
        "        author: Git author name",
        "",
        "    Returns:",
        "        Markdown template string",
        "    \"\"\"",
        "    now = datetime.now()",
        "    date_str = now.strftime(\"%Y-%m-%d\")",
        "    timestamp = now.strftime(\"%Y-%m-%dT%H:%M:%SZ\")",
        "",
        "    # Format tags",
        "    tag_list = \"\"",
        "    if tags:",
        "        tag_items = [f\"`{t.strip()}`\" for t in tags.split(\",\")]",
        "        tag_list = \", \".join(tag_items)",
        "",
        "    template = f\"\"\"# Memory Entry: {date_str} {title.title()}",
        "",
        "**Tags:** {tag_list}",
        "**Related:** [[link-to-related-docs.md]]",
        "",
        "---",
        "",
        "## Context",
        "",
        "What prompted this memory entry?",
        "",
        "## What I Learned",
        "",
        "### 1. Key Insight",
        "",
        "Describe what you learned or discovered.",
        "",
        "### 2. Additional Findings",
        "",
        "Any other important learnings?",
        "",
        "## Connections Made",
        "",
        "- **Concept A ‚Üí Concept B**: How are they related?",
        "- **Pattern ‚Üí Implementation**: What patterns emerged?",
        "",
        "## Emotional State",
        "",
        "How did this work feel? What was satisfying or challenging?",
        "",
        "## Future Exploration",
        "",
        "- [ ] Follow-up item 1",
        "- [ ] Follow-up item 2",
        "",
        "## Artifacts Created",
        "",
        "- Files, tasks, or other outputs from this session",
        "",
        "---",
        "",
        "*Committed to memory at: {timestamp}*",
        "\"\"\"",
        "    return template",
        "",
        "",
        "def create_decision_template(title: str, tags: str = \"\", author: str = \"\") -> str:",
        "    \"\"\"",
        "    Create an ADR (Architecture Decision Record) template.",
        "",
        "    Args:",
        "        title: Decision title",
        "        tags: Comma-separated tags",
        "        author: Git author name",
        "",
        "    Returns:",
        "        Markdown template string",
        "    \"\"\"",
        "    now = datetime.now()",
        "    date_str = now.strftime(\"%Y-%m-%d\")",
        "",
        "    # Format tags",
        "    tag_list = \"\"",
        "    if tags:",
        "        tag_items = [f\"`{t.strip()}`\" for t in tags.split(\",\")]",
        "        tag_list = \", \".join(tag_items)",
        "",
        "    # Find next ADR number (simple approach - count existing files)",
        "    try:",
        "        existing = list(DECISIONS_DIR.glob(\"adr-*.md\"))",
        "        numbers = []",
        "        for f in existing:",
        "            parts = f.stem.split(\"-\")",
        "            if len(parts) >= 2 and parts[0] == \"adr\" and parts[1].isdigit():",
        "                numbers.append(int(parts[1]))",
        "        next_num = max(numbers) + 1 if numbers else 1",
        "    except:",
        "        next_num = 1",
        "",
        "    adr_id = f\"ADR-{next_num:03d}\"",
        "",
        "    template = f\"\"\"# {adr_id}: {title.title()}",
        "",
        "**Status:** Proposed",
        "**Date:** {date_str}",
        "**Deciders:** Development team",
        "**Tags:** {tag_list}",
        "",
        "---",
        "",
        "## Context and Problem Statement",
        "",
        "What is the problem we're trying to solve? What factors are influencing this decision?",
        "",
        "## Decision Drivers",
        "",
        "1. **Factor 1**: Description",
        "2. **Factor 2**: Description",
        "3. **Factor 3**: Description",
        "",
        "## Considered Options",
        "",
        "### Option 1: [Name]",
        "",
        "**Pros:**",
        "- Advantage 1",
        "- Advantage 2",
        "",
        "**Cons:**",
        "- Disadvantage 1",
        "- Disadvantage 2",
        "",
        "### Option 2: [Name]",
        "",
        "**Pros:**",
        "- Advantage 1",
        "",
        "**Cons:**",
        "- Disadvantage 1",
        "",
        "## Decision Outcome",
        "",
        "**Chosen Option:** Option X - [Name]",
        "",
        "**Rationale:**",
        "Explain why this option was chosen.",
        "",
        "## Implementation",
        "",
        "```python",
        "# Code example if applicable",
        "```",
        "",
        "## Consequences",
        "",
        "### Positive",
        "- Benefit 1",
        "- Benefit 2",
        "",
        "### Negative",
        "- Trade-off 1",
        "- Trade-off 2",
        "",
        "### Neutral",
        "- Other effects",
        "",
        "## Validation",
        "",
        "How will we verify this decision was correct?",
        "",
        "## Related Decisions",
        "",
        "- Link to related ADRs or documentation",
        "",
        "---",
        "",
        "*Decision recorded on: {date_str}*",
        "\"\"\"",
        "    return template",
        "",
        "",
        "def create_memory(",
        "    title: str,",
        "    tags: str = \"\",",
        "    is_decision: bool = False,",
        "    dry_run: bool = False",
        ") -> Path:",
        "    \"\"\"",
        "    Create a memory entry or decision record.",
        "",
        "    Args:",
        "        title: Title/topic of the memory",
        "        tags: Comma-separated tags",
        "        is_decision: If True, creates a decision record",
        "        dry_run: If True, only shows what would be created",
        "",
        "    Returns:",
        "        Path to created file (or would-be path in dry-run)",
        "    \"\"\"",
        "    # Determine directory and filename",
        "    target_dir = DECISIONS_DIR if is_decision else MEMORIES_DIR",
        "    filename = generate_memory_filename(title, is_decision)",
        "    filepath = target_dir / filename",
        "",
        "    # Get git author",
        "    author = get_git_author()",
        "",
        "    # Create template",
        "    if is_decision:",
        "        content = create_decision_template(title, tags, author)",
        "    else:",
        "        content = create_memory_template(title, tags, author)",
        "",
        "    if dry_run:",
        "        print(\"=== DRY RUN ===\")",
        "        print(f\"Would create: {filepath}\")",
        "        print(f\"\\nContent preview:\\n\")",
        "        print(content[:500] + \"...\" if len(content) > 500 else content)",
        "        return filepath",
        "",
        "    # Create directory if needed",
        "    target_dir.mkdir(parents=True, exist_ok=True)",
        "",
        "    # Write file",
        "    with open(filepath, \"w\") as f:",
        "        f.write(content)",
        "",
        "    return filepath",
        "",
        "",
        "def main():",
        "    parser = argparse.ArgumentParser(",
        "        description=\"Create merge-safe memory entries and decision records\",",
        "        formatter_class=argparse.RawDescriptionHelpFormatter,",
        "        epilog=__doc__",
        "    )",
        "",
        "    parser.add_argument(",
        "        \"title\",",
        "        nargs=\"?\",",
        "        help=\"Memory topic or decision title\"",
        "    )",
        "    parser.add_argument(",
        "        \"-d\", \"--decision\",",
        "        action=\"store_true\",",
        "        help=\"Create a decision record (ADR) instead of memory entry\"",
        "    )",
        "    parser.add_argument(",
        "        \"-t\", \"--tags\",",
        "        default=\"\",",
        "        help=\"Comma-separated tags (e.g., 'security,testing,fuzzing')\"",
        "    )",
        "    parser.add_argument(",
        "        \"--dry-run\",",
        "        action=\"store_true\",",
        "        help=\"Show what would be created without writing file\"",
        "    )",
        "",
        "    args = parser.parse_args()",
        "",
        "    # Ensure directories exist",
        "    MEMORIES_DIR.mkdir(parents=True, exist_ok=True)",
        "    DECISIONS_DIR.mkdir(parents=True, exist_ok=True)",
        "",
        "    if args.title:",
        "        filepath = create_memory(",
        "            title=args.title,",
        "            tags=args.tags,",
        "            is_decision=args.decision,",
        "            dry_run=args.dry_run",
        "        )",
        "",
        "        if not args.dry_run:",
        "            doc_type = \"Decision record\" if args.decision else \"Memory entry\"",
        "            print(f\"Created {doc_type}:\")",
        "            print(f\"  {filepath}\")",
        "            print(f\"\\nEdit with: $EDITOR {filepath}\")",
        "    else:",
        "        # Interactive mode",
        "        doc_type = \"decision record\" if args.decision else \"memory entry\"",
        "        print(f\"Create a new {doc_type} (Ctrl+C to cancel)\\n\")",
        "",
        "        title = input(\"Title/topic: \").strip()",
        "        if not title:",
        "            print(\"Title is required\")",
        "            return",
        "",
        "        tags = input(\"Tags (comma-separated, optional): \").strip()",
        "",
        "        filepath = create_memory(",
        "            title=title,",
        "            tags=tags,",
        "            is_decision=args.decision,",
        "            dry_run=args.dry_run",
        "        )",
        "",
        "        if not args.dry_run:",
        "            print(f\"\\nCreated {doc_type}:\")",
        "            print(f\"  {filepath}\")",
        "            print(f\"\\nEdit with: $EDITOR {filepath}\")",
        "",
        "",
        "if __name__ == \"__main__\":",
        "    main()"
      ],
      "lines_removed": [],
      "context_before": [],
      "context_after": [],
      "change_type": "add"
    },
    {
      "file": "scripts/repl.py",
      "function": null,
      "start_line": 0,
      "lines_added": [
        "#!/usr/bin/env python3",
        "\"\"\"",
        "Cortical Text Processor REPL",
        "=============================",
        "",
        "Interactive Read-Eval-Print Loop for the Cortical Text Processor.",
        "",
        "Usage:",
        "    python scripts/repl.py [corpus_file]",
        "    python scripts/repl.py corpus_dev.pkl",
        "",
        "Features:",
        "    - Tab completion for commands",
        "    - Command history via readline",
        "    - Built-in help system",
        "    - All processor operations accessible",
        "",
        "Commands:",
        "    load <file>              Load a corpus file",
        "    search <query>           Search documents",
        "    expand <term>            Show query expansion",
        "    stats                    Show corpus statistics",
        "    concepts [n]             List top n concept clusters (default: 10)",
        "    fingerprint <text>       Get semantic fingerprint",
        "    patterns <doc_id>        Show code patterns in document",
        "    metrics                  Show observability metrics",
        "    similar <file:line>      Find similar code to reference",
        "    docs <query>             Search with documentation boost",
        "    code <query>             Search with code-aware expansion",
        "    intent <query>           Parse and search by intent",
        "    passages <query>         Find relevant passages (RAG)",
        "    relations [n]            Show semantic relations (default: 10)",
        "    stale                    Show stale computations",
        "    compute [type]           Compute all or specific type (tfidf, pagerank, etc.)",
        "    save <file>              Save corpus to file",
        "    export <file> [format]   Export corpus (json, csv, txt)",
        "    clear                    Clear metrics",
        "    reset                    Reset metrics collection",
        "    help [command]           Show help for command(s)",
        "    quit                     Exit REPL",
        "",
        "Example session:",
        "    >>> load corpus_dev.pkl",
        "    Loaded 125 documents",
        "    >>> search \"pagerank algorithm\"",
        "    [1] cortical/analysis.py:45 (score: 0.850)",
        "    >>> expand \"neural\"",
        "    neural: 1.000, network: 0.650, neuron: 0.450...",
        "    >>> metrics",
        "    Operation          Count    Avg (ms)    Min (ms)    Max (ms)",
        "    >>> quit",
        "\"\"\"",
        "",
        "import cmd",
        "import sys",
        "import os",
        "import shlex",
        "from pathlib import Path",
        "from typing import Optional, Dict, Any, List",
        "",
        "# Add parent directory to path",
        "sys.path.insert(0, str(Path(__file__).parent.parent))",
        "",
        "from cortical.processor import CorticalTextProcessor",
        "from cortical.layers import CorticalLayer",
        "",
        "# Try to import readline for history/completion",
        "try:",
        "    import readline",
        "    READLINE_AVAILABLE = True",
        "except ImportError:",
        "    READLINE_AVAILABLE = False",
        "",
        "",
        "class CorticalREPL(cmd.Cmd):",
        "    \"\"\"Interactive REPL for Cortical Text Processor.\"\"\"",
        "",
        "    intro = \"\"\"",
        "‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó",
        "‚ïë         Cortical Text Processor REPL v1.0                      ‚ïë",
        "‚ïë         Type 'help' for commands, 'quit' to exit               ‚ïë",
        "‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù",
        "\"\"\"",
        "    prompt = '>>> '",
        "",
        "    def __init__(self, corpus_file: Optional[str] = None):",
        "        \"\"\"",
        "        Initialize REPL.",
        "",
        "        Args:",
        "            corpus_file: Optional corpus file to load on startup",
        "        \"\"\"",
        "        super().__init__()",
        "        self.processor: Optional[CorticalTextProcessor] = None",
        "        self.corpus_file: Optional[str] = None",
        "",
        "        # Enable metrics by default for observability",
        "        if corpus_file:",
        "            try:",
        "                self.do_load(corpus_file)",
        "            except Exception as e:",
        "                print(f\"Warning: Could not load {corpus_file}: {e}\")",
        "                print(\"Use 'load <file>' to load a corpus.\\n\")",
        "",
        "    # =========================================================================",
        "    # CORPUS MANAGEMENT COMMANDS",
        "    # =========================================================================",
        "",
        "    def do_load(self, arg: str) -> None:",
        "        \"\"\"",
        "        Load a corpus file.",
        "",
        "        Usage: load <file>",
        "",
        "        Example:",
        "            >>> load corpus_dev.pkl",
        "            Loaded 125 documents",
        "        \"\"\"",
        "        if not arg.strip():",
        "            print(\"Error: Please specify a file to load\")",
        "            print(\"Usage: load <file>\")",
        "            return",
        "",
        "        file_path = arg.strip()",
        "        if not os.path.exists(file_path):",
        "            print(f\"Error: File not found: {file_path}\")",
        "            return",
        "",
        "        try:",
        "            print(f\"Loading corpus from {file_path}...\")",
        "            self.processor = CorticalTextProcessor.load(file_path)",
        "            # Enable metrics after loading",
        "            self.processor.enable_metrics()",
        "            self.corpus_file = file_path",
        "            print(f\"‚úì Loaded {len(self.processor.documents)} documents\")",
        "",
        "            # Show quick stats",
        "            layer0 = self.processor.layers[CorticalLayer.TOKENS]",
        "            layer1 = self.processor.layers[CorticalLayer.BIGRAMS]",
        "            layer2 = self.processor.layers[CorticalLayer.CONCEPTS]",
        "            print(f\"  Tokens: {layer0.column_count()}, \"",
        "                  f\"Bigrams: {layer1.column_count()}, \"",
        "                  f\"Concepts: {layer2.column_count()}\")",
        "        except Exception as e:",
        "            print(f\"Error loading corpus: {e}\")",
        "",
        "    def do_save(self, arg: str) -> None:",
        "        \"\"\"",
        "        Save corpus to file.",
        "",
        "        Usage: save <file>",
        "",
        "        Example:",
        "            >>> save my_corpus.pkl",
        "            Saved to my_corpus.pkl",
        "        \"\"\"",
        "        if not self._require_processor():",
        "            return",
        "",
        "        if not arg.strip():",
        "            print(\"Error: Please specify a file to save to\")",
        "            print(\"Usage: save <file>\")",
        "            return",
        "",
        "        file_path = arg.strip()",
        "        try:",
        "            self.processor.save(file_path)",
        "            print(f\"‚úì Saved to {file_path}\")",
        "        except Exception as e:",
        "            print(f\"Error saving corpus: {e}\")",
        "",
        "    def do_export(self, arg: str) -> None:",
        "        \"\"\"",
        "        Export corpus to various formats.",
        "",
        "        Usage: export <dir> [type]",
        "        Types: json (default), graph, embeddings, relations",
        "",
        "        Example:",
        "            >>> export corpus_state        # Export full state to JSON",
        "            >>> export graph.json graph    # Export graph only",
        "        \"\"\"",
        "        if not self._require_processor():",
        "            return",
        "",
        "        parts = arg.strip().split()",
        "        if not parts:",
        "            print(\"Error: Please specify a path to export to\")",
        "            print(\"Usage: export <dir> [type]\")",
        "            return",
        "",
        "        path = parts[0]",
        "        export_type = parts[1] if len(parts) > 1 else 'json'",
        "",
        "        if export_type not in ['json', 'graph', 'embeddings', 'relations']:",
        "            print(f\"Error: Unknown export type '{export_type}'\")",
        "            print(\"Use: json, graph, embeddings, relations\")",
        "            return",
        "",
        "        try:",
        "            if export_type == 'json':",
        "                # Export full state to JSON directory",
        "                self.processor.save_json(path, verbose=True)",
        "                print(f\"‚úì Exported full state to {path}/\")",
        "            elif export_type == 'graph':",
        "                # Export graph structure",
        "                self.processor.export_graph(path)",
        "                print(f\"‚úì Exported graph to {path}\")",
        "            else:",
        "                print(f\"Error: Export type '{export_type}' not yet implemented\")",
        "                print(\"Currently supported: json, graph\")",
        "        except Exception as e:",
        "            print(f\"Error exporting corpus: {e}\")",
        "",
        "    # =========================================================================",
        "    # SEARCH COMMANDS",
        "    # =========================================================================",
        "",
        "    def do_search(self, arg: str) -> None:",
        "        \"\"\"",
        "        Search documents for a query.",
        "",
        "        Usage: search <query>",
        "",
        "        Example:",
        "            >>> search \"pagerank algorithm\"",
        "            [1] cortical/analysis.py (score: 0.850)",
        "            [2] docs/architecture.md (score: 0.720)",
        "        \"\"\"",
        "        if not self._require_processor():",
        "            return",
        "",
        "        query = arg.strip()",
        "        if not query:",
        "            print(\"Error: Please provide a search query\")",
        "            return",
        "",
        "        try:",
        "            results = self.processor.find_documents_for_query(query, top_n=10)",
        "            if not results:",
        "                print(\"No results found.\")",
        "                return",
        "",
        "            print(f\"\\n{'='*70}\")",
        "            print(f\"Results for: {query}\")",
        "            print(f\"{'='*70}\\n\")",
        "",
        "            for i, (doc_id, score) in enumerate(results, 1):",
        "                print(f\"[{i}] {doc_id}\")",
        "                print(f\"    Score: {score:.3f}\\n\")",
        "        except Exception as e:",
        "            print(f\"Error searching: {e}\")",
        "",
        "    def do_docs(self, arg: str) -> None:",
        "        \"\"\"",
        "        Search with documentation boost.",
        "",
        "        Usage: docs <query>",
        "",
        "        Example:",
        "            >>> docs \"what is pagerank\"",
        "            [1] docs/architecture.md (score: 1.200)",
        "        \"\"\"",
        "        if not self._require_processor():",
        "            return",
        "",
        "        query = arg.strip()",
        "        if not query:",
        "            print(\"Error: Please provide a search query\")",
        "            return",
        "",
        "        try:",
        "            results = self.processor.find_documents_with_boost(",
        "                query, top_n=10, prefer_docs=True",
        "            )",
        "            if not results:",
        "                print(\"No results found.\")",
        "                return",
        "",
        "            print(f\"\\n{'='*70}\")",
        "            print(f\"Results (docs boosted): {query}\")",
        "            print(f\"{'='*70}\\n\")",
        "",
        "            for i, (doc_id, score) in enumerate(results, 1):",
        "                print(f\"[{i}] {doc_id}\")",
        "                print(f\"    Score: {score:.3f}\\n\")",
        "        except Exception as e:",
        "            print(f\"Error searching: {e}\")",
        "",
        "    def do_code(self, arg: str) -> None:",
        "        \"\"\"",
        "        Search with code-aware expansion.",
        "",
        "        Usage: code <query>",
        "",
        "        Example:",
        "            >>> code \"fetch data\"",
        "            Expands to: fetch, get, load, retrieve, read...",
        "        \"\"\"",
        "        if not self._require_processor():",
        "            return",
        "",
        "        query = arg.strip()",
        "        if not query:",
        "            print(\"Error: Please provide a search query\")",
        "            return",
        "",
        "        try:",
        "            # Show expansion first",
        "            expanded = self.processor.expand_query_for_code(query)",
        "            print(\"\\nCode-aware expansion:\")",
        "            for term, weight in sorted(expanded.items(), key=lambda x: -x[1])[:8]:",
        "                print(f\"  {term}: {weight:.3f}\")",
        "",
        "            # Then search",
        "            results = self.processor.find_documents_for_query(query, top_n=10)",
        "            if not results:",
        "                print(\"\\nNo results found.\")",
        "                return",
        "",
        "            print(f\"\\n{'='*70}\")",
        "            print(f\"Results: {query}\")",
        "            print(f\"{'='*70}\\n\")",
        "",
        "            for i, (doc_id, score) in enumerate(results, 1):",
        "                print(f\"[{i}] {doc_id}\")",
        "                print(f\"    Score: {score:.3f}\\n\")",
        "        except Exception as e:",
        "            print(f\"Error searching: {e}\")",
        "",
        "    def do_passages(self, arg: str) -> None:",
        "        \"\"\"",
        "        Find relevant passages for RAG systems.",
        "",
        "        Usage: passages <query>",
        "",
        "        Example:",
        "            >>> passages \"how does pagerank work\"",
        "            [1] cortical/analysis.py:45-65",
        "                PageRank implementation...",
        "        \"\"\"",
        "        if not self._require_processor():",
        "            return",
        "",
        "        query = arg.strip()",
        "        if not query:",
        "            print(\"Error: Please provide a search query\")",
        "            return",
        "",
        "        try:",
        "            results = self.processor.find_passages_for_query(query, top_n=5)",
        "            if not results:",
        "                print(\"No passages found.\")",
        "                return",
        "",
        "            print(f\"\\n{'='*70}\")",
        "            print(f\"Passages for: {query}\")",
        "            print(f\"{'='*70}\\n\")",
        "",
        "            for i, (passage, doc_id, start, end, score) in enumerate(results, 1):",
        "                # Find approximate line numbers",
        "                doc_content = self.processor.documents.get(doc_id, '')",
        "                line_start = doc_content[:start].count('\\n') + 1",
        "                line_end = doc_content[:end].count('\\n') + 1",
        "",
        "                print(f\"[{i}] {doc_id}:{line_start}-{line_end}\")",
        "                print(f\"    Score: {score:.3f}\")",
        "                print(f\"    {'-'*60}\")",
        "                # Show first 5 lines",
        "                lines = passage.split('\\n')[:5]",
        "                for line in lines:",
        "                    if len(line) > 70:",
        "                        line = line[:67] + '...'",
        "                    print(f\"    {line}\")",
        "                if len(passage.split('\\n')) > 5:",
        "                    print(f\"    ... ({len(passage.split(chr(10))) - 5} more lines)\")",
        "                print()",
        "        except Exception as e:",
        "            print(f\"Error finding passages: {e}\")",
        "",
        "    def do_intent(self, arg: str) -> None:",
        "        \"\"\"",
        "        Parse query intent and search.",
        "",
        "        Usage: intent <query>",
        "",
        "        Example:",
        "            >>> intent \"where do we handle authentication\"",
        "            Intent: location, Action: handle, Subject: authentication",
        "        \"\"\"",
        "        if not self._require_processor():",
        "            return",
        "",
        "        query = arg.strip()",
        "        if not query:",
        "            print(\"Error: Please provide a query\")",
        "            return",
        "",
        "        try:",
        "            # Parse intent",
        "            parsed = self.processor.parse_intent_query(query)",
        "            print(f\"\\nParsed intent:\")",
        "            print(f\"  Intent: {parsed.get('intent', 'unknown')}\")",
        "            print(f\"  Action: {parsed.get('action', 'N/A')}\")",
        "            print(f\"  Subject: {parsed.get('subject', 'N/A')}\")",
        "            if parsed.get('modifiers'):",
        "                print(f\"  Modifiers: {', '.join(parsed['modifiers'])}\")",
        "",
        "            # Search by intent",
        "            results = self.processor.search_by_intent(query, top_n=5)",
        "            if not results:",
        "                print(\"\\nNo results found.\")",
        "                return",
        "",
        "            print(f\"\\n{'='*70}\")",
        "            print(f\"Results:\")",
        "            print(f\"{'='*70}\\n\")",
        "",
        "            for i, (doc_id, score) in enumerate(results, 1):",
        "                print(f\"[{i}] {doc_id}\")",
        "                print(f\"    Score: {score:.3f}\\n\")",
        "        except Exception as e:",
        "            print(f\"Error with intent search: {e}\")",
        "",
        "    def do_similar(self, arg: str) -> None:",
        "        \"\"\"",
        "        Find code similar to a file:line reference.",
        "",
        "        Usage: similar <file:line>",
        "",
        "        Example:",
        "            >>> similar cortical/processor.py:100",
        "            [1] cortical/analysis.py:250 (85% similar)",
        "        \"\"\"",
        "        if not self._require_processor():",
        "            return",
        "",
        "        target = arg.strip()",
        "        if not target:",
        "            print(\"Error: Please provide file:line reference\")",
        "            print(\"Usage: similar <file:line>\")",
        "            return",
        "",
        "        try:",
        "            # Parse file:line",
        "            if ':' not in target:",
        "                print(\"Error: Use format file:line (e.g., processor.py:100)\")",
        "                return",
        "",
        "            parts = target.split(':')",
        "            file_path = parts[0]",
        "            try:",
        "                line_num = int(parts[1]) if len(parts) > 1 else 1",
        "            except ValueError:",
        "                line_num = 1",
        "",
        "            # Get content from document",
        "            doc_content = self.processor.documents.get(file_path, '')",
        "            if not doc_content:",
        "                # Try to find matching document",
        "                for doc_id in self.processor.documents:",
        "                    if doc_id.endswith(file_path) or file_path in doc_id:",
        "                        doc_content = self.processor.documents[doc_id]",
        "                        file_path = doc_id",
        "                        break",
        "",
        "            if not doc_content:",
        "                print(f\"Error: Document not found: {file_path}\")",
        "                return",
        "",
        "            # Extract passage around line",
        "            lines = doc_content.split('\\n')",
        "            start_line = max(0, line_num - 1)",
        "            end_line = min(len(lines), start_line + 20)",
        "            target_text = '\\n'.join(lines[start_line:end_line])",
        "",
        "            if not target_text.strip():",
        "                print(\"Error: No content at specified line\")",
        "                return",
        "",
        "            # Get fingerprint",
        "            target_fp = self.processor.get_fingerprint(target_text, top_n=20)",
        "",
        "            # Compare against all documents",
        "            results = []",
        "            for doc_id, content in self.processor.documents.items():",
        "                if doc_id == file_path:",
        "                    continue  # Skip source document",
        "",
        "                # Chunk and compare",
        "                chunk_size = 400",
        "                for start in range(0, len(content), chunk_size // 2):",
        "                    end = min(start + chunk_size, len(content))",
        "                    chunk = content[start:end]",
        "",
        "                    if len(chunk.strip()) < 50:",
        "                        continue",
        "",
        "                    chunk_fp = self.processor.get_fingerprint(chunk, top_n=20)",
        "                    comparison = self.processor.compare_fingerprints(target_fp, chunk_fp)",
        "",
        "                    similarity = comparison.get('overall_similarity', 0)",
        "                    if similarity > 0.1:",
        "                        chunk_line = content[:start].count('\\n') + 1",
        "                        results.append({",
        "                            'doc_id': doc_id,",
        "                            'line': chunk_line,",
        "                            'similarity': similarity,",
        "                            'shared': list(comparison.get('shared_terms', []))[:5]",
        "                        })",
        "",
        "            # Sort and display",
        "            results.sort(key=lambda x: x['similarity'], reverse=True)",
        "            results = results[:10]",
        "",
        "            if not results:",
        "                print(\"No similar code found.\")",
        "                return",
        "",
        "            print(f\"\\n{'='*70}\")",
        "            print(f\"Code similar to: {target}\")",
        "            print(f\"{'='*70}\\n\")",
        "",
        "            for i, result in enumerate(results, 1):",
        "                print(f\"[{i}] {result['doc_id']}:{result['line']}\")",
        "                print(f\"    Similarity: {result['similarity']:.1%}\")",
        "                if result.get('shared'):",
        "                    print(f\"    Shared: {', '.join(result['shared'])}\")",
        "                print()",
        "",
        "        except Exception as e:",
        "            print(f\"Error finding similar code: {e}\")",
        "",
        "    # =========================================================================",
        "    # QUERY EXPANSION & ANALYSIS",
        "    # =========================================================================",
        "",
        "    def do_expand(self, arg: str) -> None:",
        "        \"\"\"",
        "        Show query expansion for a term.",
        "",
        "        Usage: expand <term>",
        "",
        "        Example:",
        "            >>> expand \"neural\"",
        "            neural: 1.000, network: 0.650, neuron: 0.450...",
        "        \"\"\"",
        "        if not self._require_processor():",
        "            return",
        "",
        "        term = arg.strip()",
        "        if not term:",
        "            print(\"Error: Please provide a term to expand\")",
        "            return",
        "",
        "        try:",
        "            expanded = self.processor.expand_query(term, max_expansions=15)",
        "            if not expanded:",
        "                print(f\"No expansions found for: {term}\")",
        "                return",
        "",
        "            print(f\"\\nQuery expansion for '{term}':\")",
        "            print(f\"{'‚îÄ'*50}\")",
        "            for t, weight in sorted(expanded.items(), key=lambda x: -x[1])[:15]:",
        "                bar = '‚ñà' * int(weight * 20)",
        "                print(f\"  {t:.<30} {weight:.3f} {bar}\")",
        "        except Exception as e:",
        "            print(f\"Error expanding query: {e}\")",
        "",
        "    def do_fingerprint(self, arg: str) -> None:",
        "        \"\"\"",
        "        Get semantic fingerprint of text.",
        "",
        "        Usage: fingerprint <text>",
        "",
        "        Example:",
        "            >>> fingerprint \"neural networks process data\"",
        "            Top terms: neural, network, process, data...",
        "        \"\"\"",
        "        if not self._require_processor():",
        "            return",
        "",
        "        text = arg.strip()",
        "        if not text:",
        "            print(\"Error: Please provide text to fingerprint\")",
        "            return",
        "",
        "        try:",
        "            fp = self.processor.get_fingerprint(text, top_n=20)",
        "            explanation = self.processor.explain_fingerprint(fp, top_n=10)",
        "",
        "            print(f\"\\nFingerprint:\")",
        "            print(f\"{'‚îÄ'*50}\")",
        "            print(f\"Term count: {fp.get('term_count', 0)}\")",
        "",
        "            if explanation.get('top_terms'):",
        "                print(f\"\\nTop terms:\")",
        "                for term, weight in explanation['top_terms']:",
        "                    print(f\"  {term}: {weight:.3f}\")",
        "",
        "            if explanation.get('concepts'):",
        "                print(f\"\\nConcepts: {', '.join(explanation['concepts'][:5])}\")",
        "",
        "            if explanation.get('bigrams'):",
        "                print(f\"\\nBigrams: {', '.join(explanation['bigrams'][:5])}\")",
        "",
        "        except Exception as e:",
        "            print(f\"Error computing fingerprint: {e}\")",
        "",
        "    # =========================================================================",
        "    # INTROSPECTION COMMANDS",
        "    # =========================================================================",
        "",
        "    def do_stats(self, arg: str) -> None:",
        "        \"\"\"",
        "        Show corpus statistics.",
        "",
        "        Usage: stats",
        "",
        "        Example:",
        "            >>> stats",
        "            Documents: 125",
        "            Tokens: 5420",
        "            Bigrams: 8930",
        "            Concepts: 34",
        "        \"\"\"",
        "        if not self._require_processor():",
        "            return",
        "",
        "        try:",
        "            summary = self.processor.get_corpus_summary()",
        "            print(f\"\\nCorpus Statistics:\")",
        "            print(f\"{'‚ïê'*50}\")",
        "            print(f\"  Documents:     {summary.get('document_count', 0):,}\")",
        "            print(f\"  Tokens:        {summary.get('token_count', 0):,}\")",
        "            print(f\"  Bigrams:       {summary.get('bigram_count', 0):,}\")",
        "            print(f\"  Concepts:      {summary.get('concept_count', 0):,}\")",
        "            print(f\"  Relations:     {len(self.processor.semantic_relations):,}\")",
        "",
        "            # Stale computations",
        "            stale = self.processor.get_stale_computations()",
        "            if stale:",
        "                print(f\"\\n  Stale:         {', '.join(sorted(stale))}\")",
        "            else:",
        "                print(f\"\\n  All computations up-to-date\")",
        "",
        "        except Exception as e:",
        "            print(f\"Error getting stats: {e}\")",
        "",
        "    def do_concepts(self, arg: str) -> None:",
        "        \"\"\"",
        "        List concept clusters.",
        "",
        "        Usage: concepts [n]",
        "        Default: n=10",
        "",
        "        Example:",
        "            >>> concepts 5",
        "            [1] neural network deep learning...",
        "            [2] algorithm computation analysis...",
        "        \"\"\"",
        "        if not self._require_processor():",
        "            return",
        "",
        "        try:",
        "            n = int(arg.strip()) if arg.strip() else 10",
        "        except ValueError:",
        "            print(\"Error: Please provide a valid number\")",
        "            return",
        "",
        "        try:",
        "            layer2 = self.processor.layers[CorticalLayer.CONCEPTS]",
        "            concepts = sorted(",
        "                layer2.minicolumns.values(),",
        "                key=lambda c: c.pagerank if hasattr(c, 'pagerank') else 0,",
        "                reverse=True",
        "            )[:n]",
        "",
        "            print(f\"\\nTop {n} Concept Clusters:\")",
        "            print(f\"{'‚ïê'*70}\")",
        "",
        "            for i, concept in enumerate(concepts, 1):",
        "                content = concept.content[:60]",
        "                if len(concept.content) > 60:",
        "                    content += '...'",
        "                pr = getattr(concept, 'pagerank', 0)",
        "                print(f\"[{i}] {content}\")",
        "                print(f\"    PageRank: {pr:.4f}, Docs: {len(concept.document_ids)}\\n\")",
        "",
        "        except Exception as e:",
        "            print(f\"Error listing concepts: {e}\")",
        "",
        "    def do_relations(self, arg: str) -> None:",
        "        \"\"\"",
        "        Show semantic relations.",
        "",
        "        Usage: relations [n]",
        "        Default: n=10",
        "",
        "        Example:",
        "            >>> relations 5",
        "            network --is_a--> system (0.85)",
        "            algorithm --uses--> data (0.72)",
        "        \"\"\"",
        "        if not self._require_processor():",
        "            return",
        "",
        "        try:",
        "            n = int(arg.strip()) if arg.strip() else 10",
        "        except ValueError:",
        "            print(\"Error: Please provide a valid number\")",
        "            return",
        "",
        "        try:",
        "            relations = self.processor.semantic_relations[:n]",
        "            if not relations:",
        "                print(\"No semantic relations found.\")",
        "                print(\"Run 'compute semantics' first.\")",
        "                return",
        "",
        "            print(f\"\\nTop {n} Semantic Relations:\")",
        "            print(f\"{'‚ïê'*70}\")",
        "",
        "            for i, (term1, rel, term2, weight) in enumerate(relations, 1):",
        "                print(f\"[{i}] {term1} --{rel}--> {term2}\")",
        "                print(f\"    Weight: {weight:.3f}\\n\")",
        "",
        "        except Exception as e:",
        "            print(f\"Error showing relations: {e}\")",
        "",
        "    def do_patterns(self, arg: str) -> None:",
        "        \"\"\"",
        "        Show code patterns in a document.",
        "",
        "        Usage: patterns <doc_id>",
        "",
        "        Example:",
        "            >>> patterns cortical/processor.py",
        "            Decorator: 15 occurrences",
        "            Context Manager: 8 occurrences",
        "        \"\"\"",
        "        if not self._require_processor():",
        "            return",
        "",
        "        doc_id = arg.strip()",
        "        if not doc_id:",
        "            print(\"Error: Please provide a document ID\")",
        "            return",
        "",
        "        try:",
        "            patterns = self.processor.detect_patterns(doc_id)",
        "            if not patterns:",
        "                print(f\"No patterns found in: {doc_id}\")",
        "                return",
        "",
        "            print(f\"\\nCode Patterns in {doc_id}:\")",
        "            print(f\"{'‚ïê'*70}\")",
        "",
        "            # Group by category",
        "            from collections import defaultdict",
        "            by_category = defaultdict(list)",
        "",
        "            # Get pattern definitions for categories",
        "            from cortical.patterns import PATTERN_DEFINITIONS",
        "",
        "            for pattern_name, occurrences in patterns.items():",
        "                if not occurrences:",
        "                    continue",
        "                category = PATTERN_DEFINITIONS.get(pattern_name, ('', '', 'other'))[2]",
        "                by_category[category].append((pattern_name, len(occurrences)))",
        "",
        "            # Display by category",
        "            for category in sorted(by_category.keys()):",
        "                print(f\"\\n{category.upper()}:\")",
        "                for pattern_name, count in sorted(by_category[category], key=lambda x: -x[1]):",
        "                    print(f\"  {pattern_name:.<40} {count:>3} occurrences\")",
        "",
        "        except Exception as e:",
        "            print(f\"Error detecting patterns: {e}\")",
        "",
        "    def do_metrics(self, arg: str) -> None:",
        "        \"\"\"",
        "        Show observability metrics.",
        "",
        "        Usage: metrics",
        "",
        "        Example:",
        "            >>> metrics",
        "            Operation          Count    Avg (ms)    Min (ms)    Max (ms)",
        "            compute_all            1      125.30       125.30      125.30",
        "        \"\"\"",
        "        if not self._require_processor():",
        "            return",
        "",
        "        try:",
        "            summary = self.processor.get_metrics_summary()",
        "            if not summary or summary.strip() == \"No metrics collected yet.\":",
        "                print(\"\\nNo metrics collected yet.\")",
        "                print(\"Metrics are collected as you use the processor.\")",
        "                return",
        "",
        "            print(f\"\\n{summary}\")",
        "        except Exception as e:",
        "            print(f\"Error getting metrics: {e}\")",
        "",
        "    def do_stale(self, arg: str) -> None:",
        "        \"\"\"",
        "        Show stale computations.",
        "",
        "        Usage: stale",
        "",
        "        Example:",
        "            >>> stale",
        "            Stale: pagerank, concepts",
        "        \"\"\"",
        "        if not self._require_processor():",
        "            return",
        "",
        "        try:",
        "            stale = self.processor.get_stale_computations()",
        "            if not stale:",
        "                print(\"All computations are up-to-date.\")",
        "            else:",
        "                print(f\"\\nStale computations: {', '.join(sorted(stale))}\")",
        "                print(\"Use 'compute' to update them.\")",
        "        except Exception as e:",
        "            print(f\"Error checking staleness: {e}\")",
        "",
        "    # =========================================================================",
        "    # COMPUTATION COMMANDS",
        "    # =========================================================================",
        "",
        "    def do_compute(self, arg: str) -> None:",
        "        \"\"\"",
        "        Run computations.",
        "",
        "        Usage: compute [type]",
        "        Types: tfidf, pagerank, concepts, semantics, all (default)",
        "",
        "        Example:",
        "            >>> compute",
        "            Computing all...",
        "            >>> compute pagerank",
        "            Computing PageRank...",
        "        \"\"\"",
        "        if not self._require_processor():",
        "            return",
        "",
        "        comp_type = arg.strip().lower() or 'all'",
        "",
        "        try:",
        "            if comp_type == 'all':",
        "                print(\"Computing all...\")",
        "                self.processor.compute_all()",
        "                print(\"‚úì Done\")",
        "            elif comp_type == 'tfidf':",
        "                print(\"Computing TF-IDF...\")",
        "                self.processor.compute_tfidf()",
        "                print(\"‚úì Done\")",
        "            elif comp_type == 'pagerank':",
        "                print(\"Computing PageRank...\")",
        "                self.processor.compute_importance()",
        "                print(\"‚úì Done\")",
        "            elif comp_type == 'concepts':",
        "                print(\"Computing concepts...\")",
        "                self.processor.build_concept_clusters()",
        "                print(\"‚úì Done\")",
        "            elif comp_type == 'semantics':",
        "                print(\"Computing semantic relations...\")",
        "                self.processor.extract_corpus_semantics()",
        "                print(\"‚úì Done\")",
        "            elif comp_type == 'embeddings':",
        "                print(\"Computing embeddings...\")",
        "                self.processor.compute_graph_embeddings()",
        "                print(\"‚úì Done\")",
        "            else:",
        "                print(f\"Error: Unknown computation type: {comp_type}\")",
        "                print(\"Use: tfidf, pagerank, concepts, semantics, embeddings, all\")",
        "",
        "        except Exception as e:",
        "            print(f\"Error computing: {e}\")",
        "",
        "    # =========================================================================",
        "    # UTILITY COMMANDS",
        "    # =========================================================================",
        "",
        "    def do_clear(self, arg: str) -> None:",
        "        \"\"\"",
        "        Clear metrics.",
        "",
        "        Usage: clear",
        "",
        "        Example:",
        "            >>> clear",
        "            Metrics cleared.",
        "        \"\"\"",
        "        if not self._require_processor():",
        "            return",
        "",
        "        try:",
        "            self.processor.reset_metrics()",
        "            print(\"‚úì Metrics cleared\")",
        "        except Exception as e:",
        "            print(f\"Error clearing metrics: {e}\")",
        "",
        "    def do_reset(self, arg: str) -> None:",
        "        \"\"\"",
        "        Reset metrics collection.",
        "",
        "        Usage: reset",
        "",
        "        Example:",
        "            >>> reset",
        "            Metrics reset.",
        "        \"\"\"",
        "        if not self._require_processor():",
        "            return",
        "",
        "        try:",
        "            self.processor.reset_metrics()",
        "            self.processor.enable_metrics()",
        "            print(\"‚úì Metrics reset and re-enabled\")",
        "        except Exception as e:",
        "            print(f\"Error resetting metrics: {e}\")",
        "",
        "    def do_quit(self, arg: str) -> bool:",
        "        \"\"\"",
        "        Exit the REPL.",
        "",
        "        Usage: quit",
        "",
        "        Example:",
        "            >>> quit",
        "            Goodbye!",
        "        \"\"\"",
        "        print(\"\\nGoodbye!\")",
        "        return True",
        "",
        "    def do_exit(self, arg: str) -> bool:",
        "        \"\"\"Alias for quit.\"\"\"",
        "        return self.do_quit(arg)",
        "",
        "    def do_EOF(self, arg: str) -> bool:",
        "        \"\"\"Handle Ctrl+D.\"\"\"",
        "        print()  # New line after ^D",
        "        return self.do_quit(arg)",
        "",
        "    # =========================================================================",
        "    # COMPLETION SUPPORT",
        "    # =========================================================================",
        "",
        "    def completedefault(self, text: str, line: str, begidx: int, endidx: int) -> List[str]:",
        "        \"\"\"",
        "        Provide completion for document IDs in commands that accept them.",
        "        \"\"\"",
        "        if not self.processor:",
        "            return []",
        "",
        "        # Commands that take doc_id as argument",
        "        doc_commands = ['patterns', 'similar']",
        "",
        "        # Get the command",
        "        parts = line.split()",
        "        if not parts:",
        "            return []",
        "",
        "        cmd = parts[0]",
        "",
        "        # If command takes doc_id, complete with document IDs",
        "        if cmd in doc_commands and len(parts) >= 1:",
        "            docs = list(self.processor.documents.keys())",
        "            return [d for d in docs if d.startswith(text)]",
        "",
        "        return []",
        "",
        "    def complete_load(self, text: str, line: str, begidx: int, endidx: int) -> List[str]:",
        "        \"\"\"Complete file paths for load command.\"\"\"",
        "        # Simple file completion - just list .pkl files in current dir",
        "        import glob",
        "        matches = glob.glob(text + '*.pkl')",
        "        return matches",
        "",
        "    def complete_save(self, text: str, line: str, begidx: int, endidx: int) -> List[str]:",
        "        \"\"\"Complete file paths for save command.\"\"\"",
        "        import glob",
        "        matches = glob.glob(text + '*.pkl')",
        "        return matches",
        "",
        "    def complete_export(self, text: str, line: str, begidx: int, endidx: int) -> List[str]:",
        "        \"\"\"Complete types for export command.\"\"\"",
        "        parts = line.split()",
        "        if len(parts) == 3 or (len(parts) == 2 and not line.endswith(' ')):",
        "            # Completing export type",
        "            types = ['json', 'graph', 'embeddings', 'relations']",
        "            return [t for t in types if t.startswith(text)]",
        "        return []",
        "",
        "    def complete_compute(self, text: str, line: str, begidx: int, endidx: int) -> List[str]:",
        "        \"\"\"Complete computation types.\"\"\"",
        "        types = ['all', 'tfidf', 'pagerank', 'concepts', 'semantics', 'embeddings']",
        "        return [t for t in types if t.startswith(text)]",
        "",
        "    # =========================================================================",
        "    # HELPER METHODS",
        "    # =========================================================================",
        "",
        "    def _require_processor(self) -> bool:",
        "        \"\"\"Check if processor is loaded, print error if not.\"\"\"",
        "        if not self.processor:",
        "            print(\"Error: No corpus loaded. Use 'load <file>' first.\")",
        "            return False",
        "        return True",
        "",
        "    def emptyline(self) -> bool:",
        "        \"\"\"Do nothing on empty line (override default repeat behavior).\"\"\"",
        "        return False",
        "",
        "    def default(self, line: str) -> None:",
        "        \"\"\"Handle unknown commands.\"\"\"",
        "        print(f\"Unknown command: {line.split()[0] if line else ''}\")",
        "        print(\"Type 'help' for available commands.\")",
        "",
        "",
        "def main():",
        "    \"\"\"Main entry point.\"\"\"",
        "    import argparse",
        "",
        "    parser = argparse.ArgumentParser(",
        "        description='Cortical Text Processor REPL',",
        "        epilog=\"\"\"",
        "Examples:",
        "  %(prog)s                       # Start REPL without corpus",
        "  %(prog)s corpus_dev.pkl        # Start with corpus loaded",
        "  %(prog)s my_corpus.pkl         # Start with custom corpus",
        "        \"\"\"",
        "    )",
        "    parser.add_argument('corpus', nargs='?', help='Corpus file to load (optional)')",
        "    args = parser.parse_args()",
        "",
        "    # Create and run REPL",
        "    repl = CorticalREPL(corpus_file=args.corpus)",
        "    try:",
        "        repl.cmdloop()",
        "    except KeyboardInterrupt:",
        "        print(\"\\n\\nGoodbye!\")",
        "        sys.exit(0)",
        "",
        "",
        "if __name__ == '__main__':",
        "    main()"
      ],
      "lines_removed": [],
      "context_before": [],
      "context_after": [],
      "change_type": "add"
    },
    {
      "file": "scripts/resolve_wiki_links.py",
      "function": null,
      "start_line": 0,
      "lines_added": [
        "#!/usr/bin/env python3",
        "\"\"\"Wiki-link cross-reference resolution for memory documents.\"\"\"",
        "",
        "import re",
        "import sys",
        "import json",
        "import argparse",
        "from pathlib import Path",
        "from typing import List, Optional, Tuple, Dict",
        "",
        "",
        "def extract_wiki_links(content: str) -> List[str]:",
        "    \"\"\"Parse [[link]] patterns from markdown content.\"\"\"",
        "    return re.findall(r'\\[\\[([^\\]]+)\\]\\]', content)",
        "",
        "",
        "def resolve_link(link: str, source_file: str, search_dirs: List[str]) -> Optional[str]:",
        "    \"\"\"Resolve wiki-link to file path (exact, fuzzy, or date-based match).\"\"\"",
        "    source_dir = Path(source_file).resolve().parent",
        "",
        "    # Try exact path match (relative to source file)",
        "    candidate = source_dir / link",
        "    if candidate.exists() and candidate.is_file():",
        "        return str(candidate.resolve())",
        "",
        "    # Try fuzzy filename match in search directories",
        "    link_name = Path(link).name",
        "    for search_dir in search_dirs:",
        "        search_path = Path(search_dir)",
        "        if search_path.exists():",
        "            for file_path in search_path.rglob('*.md'):",
        "                if file_path.name == link_name:",
        "                    return str(file_path.resolve())",
        "",
        "    # Try date-based match (YYYY-MM-DD)",
        "    if re.match(r'^\\d{4}-\\d{2}-\\d{2}$', link):",
        "        for search_dir in search_dirs:",
        "            search_path = Path(search_dir)",
        "            if search_path.exists():",
        "                for file_path in search_path.rglob('*.md'):",
        "                    if link in file_path.name:",
        "                        return str(file_path.resolve())",
        "",
        "    return None",
        "",
        "",
        "def find_backlinks(target_file: str, search_dirs: List[str]) -> List[Tuple[str, int]]:",
        "    \"\"\"Find all files that link to the target file.\"\"\"",
        "    target_path = Path(target_file).resolve()",
        "    target_name = target_path.name",
        "    backlinks = []",
        "",
        "    for search_dir in search_dirs:",
        "        search_path = Path(search_dir)",
        "        if not search_path.exists():",
        "            continue",
        "        for file_path in search_path.rglob('*.md'):",
        "            if file_path.resolve() == target_path:",
        "                continue",
        "            try:",
        "                with open(file_path, 'r', encoding='utf-8') as f:",
        "                    for line_num, line in enumerate(f, start=1):",
        "                        for link in extract_wiki_links(line):",
        "                            resolved = resolve_link(link, str(file_path), search_dirs)",
        "                            if (resolved and Path(resolved) == target_path) or Path(link).name == target_name:",
        "                                backlinks.append((str(file_path.resolve()), line_num))",
        "            except (IOError, UnicodeDecodeError):",
        "                continue",
        "",
        "    return backlinks",
        "",
        "",
        "def generate_link_report(file_path: str, search_dirs: List[str]) -> Dict:",
        "    \"\"\"Generate a report of all wiki-links in a file.\"\"\"",
        "    file_path_obj = Path(file_path)",
        "    if not file_path_obj.exists():",
        "        return {'error': f'File not found: {file_path}'}",
        "",
        "    try:",
        "        with open(file_path_obj, 'r', encoding='utf-8') as f:",
        "            content = f.read()",
        "    except (IOError, UnicodeDecodeError) as e:",
        "        return {'error': f'Error reading file: {e}'}",
        "",
        "    links = extract_wiki_links(content)",
        "    resolved, broken = {}, []",
        "    for link in links:",
        "        target = resolve_link(link, file_path, search_dirs)",
        "        (resolved.__setitem__(link, target) if target else broken.append(link))",
        "",
        "    return {'file': str(file_path_obj.resolve()), 'links': links, 'resolved': resolved, 'broken': broken}",
        "",
        "",
        "def main():",
        "    \"\"\"CLI for wiki-link resolution.\"\"\"",
        "    parser = argparse.ArgumentParser(description='Parse and resolve wiki-style links in markdown files')",
        "    parser.add_argument('file', nargs='?', help='File to analyze')",
        "    parser.add_argument('--backlinks', action='store_true', help='Show files that link to the specified file')",
        "    parser.add_argument('--check', metavar='DIR', help='Check all links in directory')",
        "    parser.add_argument('--json', action='store_true', help='Output as JSON')",
        "    parser.add_argument('--search-dirs', nargs='+', default=['samples/memories', 'samples/decisions', 'docs'],",
        "                        help='Directories to search for link targets')",
        "    args = parser.parse_args()",
        "",
        "    if args.check:",
        "        check_dir = Path(args.check)",
        "        if not check_dir.exists():",
        "            print(f\"Error: Directory not found: {args.check}\", file=sys.stderr)",
        "            return 1",
        "        results = {str(fp): r for fp in check_dir.rglob('*.md')",
        "                   if (r := generate_link_report(str(fp), args.search_dirs)).get('broken')}",
        "        if args.json:",
        "            print(json.dumps(results, indent=2))",
        "        else:",
        "            print(f\"‚úì All links in {args.check} are valid\" if not results else",
        "                  f\"Broken links found in {args.check}:\")",
        "            for file_path, report in results.items():",
        "                print(f\"\\n{file_path}:\")",
        "                for broken in report['broken']:",
        "                    print(f\"  ‚úó [[{broken}]] ‚Üí NOT FOUND\")",
        "        return 0",
        "",
        "    if not args.file:",
        "        parser.print_help()",
        "        return 1",
        "",
        "    if args.backlinks:",
        "        backlinks = find_backlinks(args.file, args.search_dirs)",
        "        if args.json:",
        "            print(json.dumps({'target': args.file, 'backlinks': [{'file': f, 'line': ln} for f, ln in backlinks]}, indent=2))",
        "        else:",
        "            print(f\"Backlinks to {args.file}:\")",
        "            print(\"  (none)\" if not backlinks else '\\n'.join(f\"  - {f}:{ln}\" for f, ln in backlinks))",
        "    else:",
        "        report = generate_link_report(args.file, args.search_dirs)",
        "        if args.json:",
        "            print(json.dumps(report, indent=2))",
        "        else:",
        "            if 'error' in report:",
        "                print(f\"Error: {report['error']}\", file=sys.stderr)",
        "                return 1",
        "            print(f\"Links in {report['file']}:\")",
        "            print(\"  (none)\" if not report['links'] else '\\n'.join(",
        "                f\"  ‚úì [[{link}]] ‚Üí {report['resolved'][link]}\" if link in report['resolved']",
        "                else f\"  ‚úó [[{link}]] ‚Üí NOT FOUND\" for link in report['links']))",
        "    return 0",
        "",
        "",
        "if __name__ == '__main__':",
        "    sys.exit(main())"
      ],
      "lines_removed": [],
      "context_before": [],
      "context_after": [],
      "change_type": "add"
    },
    {
      "file": "scripts/search_codebase.py",
      "function": "def format_passage(passage: str, max_width: int = 80) -> str:",
      "start_line": 39,
      "lines_added": [
        "    if doc_id.startswith('samples/memories/'):",
        "        # Check if it's a concept doc",
        "        filename = doc_id.split('/')[-1]",
        "        if filename.startswith('concept-'):",
        "            return 'CON'",
        "        return 'MEM'",
        "    elif doc_id.startswith('samples/decisions/'):",
        "        return 'ADR'",
        "    elif doc_id.endswith('.md'):"
      ],
      "lines_removed": [
        "    if doc_id.endswith('.md'):"
      ],
      "context_before": [
        "        if len(line) > max_width:",
        "            line = line[:max_width - 3] + '...'",
        "        formatted.append(line)",
        "    if len(lines) > 10:",
        "        formatted.append(f'  ... ({len(lines) - 10} more lines)')",
        "    return '\\n'.join(formatted)",
        "",
        "",
        "def get_doc_type_label(doc_id: str) -> str:",
        "    \"\"\"Get a display label for document type.\"\"\""
      ],
      "context_after": [
        "        if doc_id.startswith('docs/'):",
        "            return 'DOCS'",
        "        return 'DOC'",
        "    elif doc_id.startswith('tests/'):",
        "        return 'TEST'",
        "    return 'CODE'",
        "",
        "",
        "def find_similar_code(",
        "    processor: CorticalTextProcessor,"
      ],
      "change_type": "modify"
    },
    {
      "file": "scripts/session_handoff.py",
      "function": null,
      "start_line": 0,
      "lines_added": [
        "#!/usr/bin/env python3",
        "\"\"\"",
        "Generate session handoff documents for knowledge transfer.",
        "",
        "Creates automatic handoff documents when ending a coding session, capturing:",
        "- Git status and branch information",
        "- Recently completed tasks",
        "- Uncommitted changes",
        "- Suggested next steps",
        "",
        "Usage:",
        "    # Generate handoff for current session",
        "    python scripts/session_handoff.py",
        "",
        "    # Preview without creating",
        "    python scripts/session_handoff.py --dry-run",
        "",
        "    # Custom output location",
        "    python scripts/session_handoff.py --output samples/memories/handoff.md",
        "",
        "Example:",
        "    $ python scripts/session_handoff.py",
        "    Created session handoff: samples/memories/session-handoff-2025-12-14_14-30-52_a1b2.md",
        "\"\"\"",
        "",
        "import argparse",
        "import os",
        "import subprocess",
        "import sys",
        "from datetime import datetime, timedelta",
        "from pathlib import Path",
        "from typing import Dict, List, Optional, Tuple, Any",
        "",
        "# Add scripts to path",
        "sys.path.insert(0, str(Path(__file__).parent))",
        "",
        "from task_utils import load_all_tasks, Task, generate_session_id",
        "",
        "",
        "# Default output directory",
        "MEMORIES_DIR = Path(\"samples/memories\")",
        "",
        "",
        "def gather_session_context() -> Dict[str, Any]:",
        "    \"\"\"",
        "    Gather current session context from git and system.",
        "",
        "    Returns:",
        "        Dictionary with:",
        "        - branch: Current git branch name",
        "        - status_summary: Git status summary",
        "        - uncommitted_files: List of modified/staged files",
        "        - recent_commits: List of (hash, message) tuples for last 5 commits",
        "        - background_processes: Optional list of running processes",
        "    \"\"\"",
        "    context = {",
        "        'branch': None,",
        "        'status_summary': '',",
        "        'uncommitted_files': [],",
        "        'recent_commits': [],",
        "        'background_processes': []",
        "    }",
        "",
        "    # Get current branch",
        "    try:",
        "        result = subprocess.run(",
        "            [\"git\", \"rev-parse\", \"--abbrev-ref\", \"HEAD\"],",
        "            capture_output=True,",
        "            text=True,",
        "            timeout=2",
        "        )",
        "        if result.returncode == 0:",
        "            context['branch'] = result.stdout.strip()",
        "    except (subprocess.TimeoutExpired, FileNotFoundError):",
        "        pass",
        "",
        "    # Get git status",
        "    try:",
        "        result = subprocess.run(",
        "            [\"git\", \"status\", \"--short\"],",
        "            capture_output=True,",
        "            text=True,",
        "            timeout=2",
        "        )",
        "        if result.returncode == 0:",
        "            status_lines = result.stdout.strip().split('\\n')",
        "            context['uncommitted_files'] = [",
        "                line.strip() for line in status_lines if line.strip()",
        "            ]",
        "",
        "            # Create summary",
        "            if context['uncommitted_files']:",
        "                modified = sum(1 for line in context['uncommitted_files'] if line.startswith('M'))",
        "                added = sum(1 for line in context['uncommitted_files'] if line.startswith('A'))",
        "                deleted = sum(1 for line in context['uncommitted_files'] if line.startswith('D'))",
        "                untracked = sum(1 for line in context['uncommitted_files'] if line.startswith('??'))",
        "",
        "                parts = []",
        "                if modified:",
        "                    parts.append(f\"{modified} modified\")",
        "                if added:",
        "                    parts.append(f\"{added} added\")",
        "                if deleted:",
        "                    parts.append(f\"{deleted} deleted\")",
        "                if untracked:",
        "                    parts.append(f\"{untracked} untracked\")",
        "",
        "                context['status_summary'] = ', '.join(parts) if parts else 'clean'",
        "            else:",
        "                context['status_summary'] = 'clean'",
        "    except (subprocess.TimeoutExpired, FileNotFoundError):",
        "        context['status_summary'] = 'unknown'",
        "",
        "    # Get recent commits (last 5)",
        "    try:",
        "        result = subprocess.run(",
        "            [\"git\", \"log\", \"--pretty=format:%h|%s\", \"-n\", \"5\"],",
        "            capture_output=True,",
        "            text=True,",
        "            timeout=2",
        "        )",
        "        if result.returncode == 0:",
        "            for line in result.stdout.strip().split('\\n'):",
        "                if '|' in line:",
        "                    commit_hash, message = line.split('|', 1)",
        "                    context['recent_commits'].append((commit_hash, message))",
        "    except (subprocess.TimeoutExpired, FileNotFoundError):",
        "        pass",
        "",
        "    return context",
        "",
        "",
        "def gather_completed_tasks(tasks_dir: str = \"tasks\") -> List[Task]:",
        "    \"\"\"",
        "    Gather tasks completed today from task session files.",
        "",
        "    Args:",
        "        tasks_dir: Directory containing task session files",
        "",
        "    Returns:",
        "        List of Task objects completed today, sorted by completion time",
        "    \"\"\"",
        "    all_tasks = load_all_tasks(tasks_dir)",
        "",
        "    # Get today's date range",
        "    today = datetime.now().date()",
        "    today_start = datetime.combine(today, datetime.min.time())",
        "    today_end = datetime.combine(today, datetime.max.time())",
        "",
        "    # Filter to completed tasks from today",
        "    completed_today = []",
        "    for task in all_tasks:",
        "        if task.status == 'completed' and task.completed_at:",
        "            try:",
        "                completed_time = datetime.fromisoformat(task.completed_at)",
        "                if today_start <= completed_time <= today_end:",
        "                    completed_today.append(task)",
        "            except (ValueError, TypeError):",
        "                # Skip tasks with invalid completion dates",
        "                continue",
        "",
        "    # Sort by completion time",
        "    completed_today.sort(key=lambda t: t.completed_at or '')",
        "",
        "    return completed_today",
        "",
        "",
        "def generate_handoff_document(",
        "    context: Dict[str, Any],",
        "    completed_tasks: List[Task],",
        "    title: str = \"Session Handoff\"",
        ") -> str:",
        "    \"\"\"",
        "    Generate a handoff document from session context and completed tasks.",
        "",
        "    Args:",
        "        context: Session context from gather_session_context()",
        "        completed_tasks: List of completed tasks from gather_completed_tasks()",
        "        title: Document title (default: \"Session Handoff\")",
        "",
        "    Returns:",
        "        Markdown formatted handoff document",
        "    \"\"\"",
        "    now = datetime.now()",
        "    date_str = now.strftime(\"%Y-%m-%d\")",
        "    timestamp = now.strftime(\"%Y-%m-%dT%H:%M:%SZ\")",
        "",
        "    lines = [",
        "        f\"# {title}: {date_str}\",",
        "        \"\",",
        "        f\"**Date:** {date_str}\",",
        "        f\"**Time:** {timestamp}\",",
        "        f\"**Branch:** {context['branch'] or 'unknown'}\",",
        "        \"\",",
        "        \"---\",",
        "        \"\",",
        "        \"## Summary\",",
        "        \"\"",
        "    ]",
        "",
        "    # Generate summary",
        "    num_tasks = len(completed_tasks)",
        "    if num_tasks > 0:",
        "        lines.append(",
        "            f\"Completed {num_tasks} task{'s' if num_tasks != 1 else ''} this session. \"",
        "            f\"Repository state: {context['status_summary']}.\"",
        "        )",
        "    else:",
        "        lines.append(",
        "            f\"Session focused on exploration and investigation. \"",
        "            f\"Repository state: {context['status_summary']}.\"",
        "        )",
        "",
        "    lines.extend([",
        "        \"\",",
        "        \"## Completed This Session\",",
        "        \"\"",
        "    ])",
        "",
        "    if completed_tasks:",
        "        for task in completed_tasks:",
        "            lines.append(f\"### {task.id}: {task.title}\")",
        "            if task.description:",
        "                lines.append(f\"{task.description}\")",
        "",
        "            # Handle retrospective (must be a dict)",
        "            if task.retrospective and isinstance(task.retrospective, dict):",
        "                if task.retrospective.get('notes'):",
        "                    lines.append(f\"**Notes:** {task.retrospective['notes']}\")",
        "                if task.retrospective.get('files_touched'):",
        "                    files = task.retrospective['files_touched']",
        "                    if files:",
        "                        lines.append(\"**Files modified:**\")",
        "                        for file in files:",
        "                            lines.append(f\"- `{file}`\")",
        "            lines.append(\"\")",
        "    else:",
        "        lines.append(\"*No tasks completed this session*\")",
        "        lines.append(\"\")",
        "",
        "    lines.extend([",
        "        \"## Current State\",",
        "        \"\",",
        "        f\"**Git Status:** {context['status_summary']}\",",
        "        \"\"",
        "    ])",
        "",
        "    if context['uncommitted_files']:",
        "        lines.append(\"**Uncommitted Changes:**\")",
        "        for file_status in context['uncommitted_files']:",
        "            lines.append(f\"- `{file_status}`\")",
        "        lines.append(\"\")",
        "",
        "    if context['recent_commits']:",
        "        lines.extend([",
        "            \"**Recent Commits:**\",",
        "            \"\"",
        "        ])",
        "        for commit_hash, message in context['recent_commits']:",
        "            lines.append(f\"- `{commit_hash}` {message}\")",
        "        lines.append(\"\")",
        "",
        "    lines.extend([",
        "        \"## Suggested Next Steps\",",
        "        \"\"",
        "    ])",
        "",
        "    # Generate suggested next steps based on context",
        "    next_steps = []",
        "",
        "    # Check for uncommitted changes",
        "    if context['uncommitted_files']:",
        "        modified_count = sum(1 for f in context['uncommitted_files'] if f.startswith('M'))",
        "        if modified_count > 0:",
        "            next_steps.append(\"Review and commit uncommitted changes\")",
        "",
        "    # Check for pending tasks",
        "    all_tasks = load_all_tasks(\"tasks\")",
        "    pending = [t for t in all_tasks if t.status == 'pending']",
        "    in_progress = [t for t in all_tasks if t.status == 'in_progress']",
        "",
        "    if in_progress:",
        "        for task in in_progress[:3]:  # Show first 3",
        "            next_steps.append(f\"Continue: {task.title} ({task.id})\")",
        "",
        "    if pending:",
        "        high_priority = [t for t in pending if t.priority == 'high']",
        "        if high_priority:",
        "            for task in high_priority[:2]:  # Show first 2 high priority",
        "                next_steps.append(f\"Start: {task.title} ({task.id})\")",
        "        elif pending:",
        "            next_steps.append(f\"Start next pending task ({len(pending)} available)\")",
        "",
        "    # Add test and documentation reminders",
        "    if completed_tasks:",
        "        next_steps.append(\"Run full test suite to verify changes\")",
        "        next_steps.append(\"Update documentation if needed\")",
        "",
        "    if next_steps:",
        "        for i, step in enumerate(next_steps, 1):",
        "            lines.append(f\"{i}. {step}\")",
        "    else:",
        "        lines.append(\"*Review pending tasks in `tasks/` directory*\")",
        "",
        "    lines.extend([",
        "        \"\",",
        "        \"## Files Modified\",",
        "        \"\"",
        "    ])",
        "",
        "    # Collect all modified files from tasks and git status",
        "    all_files = set()",
        "",
        "    for task in completed_tasks:",
        "        if task.retrospective and isinstance(task.retrospective, dict):",
        "            if task.retrospective.get('files_touched'):",
        "                all_files.update(task.retrospective['files_touched'])",
        "",
        "    # Parse git status files",
        "    for file_status in context['uncommitted_files']:",
        "        # Format: \"XX filename\" where XX is status code",
        "        parts = file_status.split(maxsplit=1)",
        "        if len(parts) == 2:",
        "            all_files.add(parts[1])",
        "",
        "    if all_files:",
        "        for file in sorted(all_files):",
        "            lines.append(f\"- `{file}`\")",
        "    else:",
        "        lines.append(\"*No files modified this session*\")",
        "",
        "    lines.extend([",
        "        \"\",",
        "        \"---\",",
        "        \"\",",
        "        f\"*Session handoff generated at: {timestamp}*\"",
        "    ])",
        "",
        "    return '\\n'.join(lines)",
        "",
        "",
        "def generate_handoff_filename() -> str:",
        "    \"\"\"",
        "    Generate merge-safe handoff filename.",
        "",
        "    Returns:",
        "        Filename in format: session-handoff-YYYY-MM-DD_HH-MM-SS_XXXX.md",
        "    \"\"\"",
        "    now = datetime.now()",
        "    date_str = now.strftime(\"%Y-%m-%d\")",
        "    time_str = now.strftime(\"%H-%M-%S\")",
        "    session_id = generate_session_id()",
        "",
        "    return f\"session-handoff-{date_str}_{time_str}_{session_id}.md\"",
        "",
        "",
        "def main():",
        "    parser = argparse.ArgumentParser(",
        "        description=\"Generate session handoff documents for knowledge transfer\",",
        "        formatter_class=argparse.RawDescriptionHelpFormatter,",
        "        epilog=__doc__",
        "    )",
        "",
        "    parser.add_argument(",
        "        \"--dry-run\",",
        "        action=\"store_true\",",
        "        help=\"Preview handoff document without creating file\"",
        "    )",
        "    parser.add_argument(",
        "        \"--output\",",
        "        type=Path,",
        "        help=\"Custom output file path (default: auto-generated in samples/memories/)\"",
        "    )",
        "    parser.add_argument(",
        "        \"--title\",",
        "        default=\"Session Handoff\",",
        "        help=\"Document title (default: 'Session Handoff')\"",
        "    )",
        "    parser.add_argument(",
        "        \"--tasks-dir\",",
        "        default=\"tasks\",",
        "        help=\"Directory containing task files (default: tasks/)\"",
        "    )",
        "",
        "    args = parser.parse_args()",
        "",
        "    # Gather session information",
        "    print(\"Gathering session context...\")",
        "    context = gather_session_context()",
        "",
        "    print(\"Loading completed tasks...\")",
        "    completed_tasks = gather_completed_tasks(args.tasks_dir)",
        "",
        "    # Generate document",
        "    print(\"Generating handoff document...\")",
        "    document = generate_handoff_document(context, completed_tasks, args.title)",
        "",
        "    # Determine output path",
        "    if args.output:",
        "        output_path = args.output",
        "    else:",
        "        MEMORIES_DIR.mkdir(parents=True, exist_ok=True)",
        "        filename = generate_handoff_filename()",
        "        output_path = MEMORIES_DIR / filename",
        "",
        "    if args.dry_run:",
        "        print(\"\\n=== DRY RUN ===\")",
        "        print(f\"Would create: {output_path}\")",
        "        print(f\"\\nDocument preview:\\n\")",
        "        print(document)",
        "        return",
        "",
        "    # Write file",
        "    output_path.parent.mkdir(parents=True, exist_ok=True)",
        "    with open(output_path, 'w') as f:",
        "        f.write(document)",
        "",
        "    print(f\"\\nCreated session handoff:\")",
        "    print(f\"  {output_path}\")",
        "    print(f\"\\nNext steps:\")",
        "    print(f\"  1. Review: $EDITOR {output_path}\")",
        "    print(f\"  2. Commit: git add {output_path} && git commit -m 'memory: session handoff'\")",
        "    print(f\"  3. Re-index: python scripts/index_codebase.py --incremental\")",
        "",
        "",
        "if __name__ == \"__main__\":",
        "    main()"
      ],
      "lines_removed": [],
      "context_before": [],
      "context_after": [],
      "change_type": "add"
    },
    {
      "file": "scripts/suggest_consolidation.py",
      "function": null,
      "start_line": 0,
      "lines_added": [
        "#!/usr/bin/env python3",
        "\"\"\"",
        "Suggest Memory Consolidation Opportunities",
        "",
        "Analyzes memory documents and suggests consolidation opportunities based on:",
        "- Term overlap and semantic similarity",
        "- Repeated concepts across multiple entries",
        "- Memory age (old unconsolidated memories)",
        "- Cluster analysis (memories discussing similar topics)",
        "",
        "Usage:",
        "    python scripts/suggest_consolidation.py",
        "    python scripts/suggest_consolidation.py --threshold 0.7",
        "    python scripts/suggest_consolidation.py --min-cluster 2 --output json",
        "    python scripts/suggest_consolidation.py --min-age-days 30",
        "\"\"\"",
        "",
        "import argparse",
        "import json",
        "import os",
        "import sys",
        "from collections import defaultdict",
        "from datetime import datetime, timedelta",
        "from pathlib import Path",
        "from typing import Dict, List, Tuple, Set, Any",
        "",
        "# Add parent directory to path for imports",
        "sys.path.insert(0, str(Path(__file__).parent.parent))",
        "",
        "from cortical.processor import CorticalTextProcessor",
        "from cortical.layers import CorticalLayer",
        "",
        "",
        "def parse_memory_date(doc_id: str) -> datetime:",
        "    \"\"\"",
        "    Extract date from memory document ID.",
        "",
        "    Supports formats:",
        "    - samples/memories/2025-12-14-topic.md",
        "    - samples/memories/2025-12-14_20-54-35_3b3a-topic.md",
        "    - samples/memories/concept-*.md (returns very old date for concepts)",
        "",
        "    Args:",
        "        doc_id: Document ID path",
        "",
        "    Returns:",
        "        datetime object, or very old date if parsing fails",
        "    \"\"\"",
        "    filename = doc_id.split('/')[-1]",
        "",
        "    # Concept documents are considered \"timeless\" (very old)",
        "    if filename.startswith('concept-'):",
        "        return datetime(2000, 1, 1)",
        "",
        "    # Try timestamp format first: YYYY-MM-DD_HH-MM-SS_XXXX-topic.md",
        "    if '_' in filename:",
        "        date_part = filename.split('_')[0]",
        "        parts = date_part.split('-')",
        "        if len(parts) >= 3:",
        "            try:",
        "                year = int(parts[0])",
        "                month = int(parts[1])",
        "                day = int(parts[2])",
        "                return datetime(year, month, day)",
        "            except (ValueError, IndexError):",
        "                pass",
        "",
        "    # Extract date from YYYY-MM-DD pattern (basic format)",
        "    parts = filename.split('-')",
        "    if len(parts) >= 3:",
        "        try:",
        "            year = int(parts[0])",
        "            month = int(parts[1])",
        "            day = int(parts[2])",
        "            return datetime(year, month, day)",
        "        except (ValueError, IndexError):",
        "            pass",
        "",
        "    # Default to very old if can't parse",
        "    return datetime(2000, 1, 1)",
        "",
        "",
        "def get_memory_age_days(doc_id: str) -> int:",
        "    \"\"\"Get the age of a memory in days from today.\"\"\"",
        "    memory_date = parse_memory_date(doc_id)",
        "    today = datetime.now()",
        "    return (today - memory_date).days",
        "",
        "",
        "def is_concept_doc(doc_id: str) -> bool:",
        "    \"\"\"Check if document is a concept document.\"\"\"",
        "    filename = doc_id.split('/')[-1]",
        "    return filename.startswith('concept-')",
        "",
        "",
        "def compute_pairwise_similarity(",
        "    processor: CorticalTextProcessor,",
        "    doc_ids: List[str]",
        ") -> Dict[Tuple[str, str], float]:",
        "    \"\"\"",
        "    Compute pairwise similarity between all documents using fingerprints.",
        "",
        "    Args:",
        "        processor: CorticalTextProcessor instance",
        "        doc_ids: List of document IDs to compare",
        "",
        "    Returns:",
        "        Dictionary mapping (doc_id1, doc_id2) to similarity score",
        "    \"\"\"",
        "    similarities = {}",
        "",
        "    # Compute fingerprints for all documents",
        "    fingerprints = {}",
        "    for doc_id in doc_ids:",
        "        content = processor.documents.get(doc_id, '')",
        "        if content:",
        "            fingerprints[doc_id] = processor.get_fingerprint(content, top_n=20)",
        "",
        "    # Compute pairwise similarities",
        "    for i, doc_id1 in enumerate(doc_ids):",
        "        for doc_id2 in doc_ids[i+1:]:",
        "            if doc_id1 in fingerprints and doc_id2 in fingerprints:",
        "                fp1 = fingerprints[doc_id1]",
        "                fp2 = fingerprints[doc_id2]",
        "                comparison = processor.compare_fingerprints(fp1, fp2)",
        "                similarity = comparison.get('overall_similarity', 0.0)",
        "                similarities[(doc_id1, doc_id2)] = similarity",
        "                similarities[(doc_id2, doc_id1)] = similarity  # Symmetric",
        "",
        "    return similarities",
        "",
        "",
        "def cluster_memories(",
        "    processor: CorticalTextProcessor,",
        "    memory_ids: List[str],",
        "    min_cluster_size: int = 2,",
        "    resolution: float = 1.0",
        ") -> Dict[int, List[str]]:",
        "    \"\"\"",
        "    Cluster memory documents using similarity-based grouping.",
        "",
        "    Since we have a small number of memories, we'll use a simple",
        "    similarity-based clustering approach instead of Louvain.",
        "",
        "    Args:",
        "        processor: CorticalTextProcessor instance",
        "        memory_ids: List of memory document IDs",
        "        min_cluster_size: Minimum documents per cluster",
        "        resolution: Clustering resolution (higher = more clusters)",
        "",
        "    Returns:",
        "        Dictionary mapping cluster_id to list of document IDs",
        "    \"\"\"",
        "    if len(memory_ids) < min_cluster_size:",
        "        return {}",
        "",
        "    # Compute fingerprints for all memories",
        "    fingerprints = {}",
        "    for doc_id in memory_ids:",
        "        content = processor.documents.get(doc_id, '')",
        "        if content:",
        "            fingerprints[doc_id] = processor.get_fingerprint(content, top_n=20)",
        "",
        "    # Build similarity graph",
        "    # edges[doc1][doc2] = similarity",
        "    edges: Dict[str, Dict[str, float]] = defaultdict(dict)",
        "",
        "    for i, doc_id1 in enumerate(memory_ids):",
        "        if doc_id1 not in fingerprints:",
        "            continue",
        "",
        "        for doc_id2 in memory_ids[i+1:]:",
        "            if doc_id2 not in fingerprints:",
        "                continue",
        "",
        "            fp1 = fingerprints[doc_id1]",
        "            fp2 = fingerprints[doc_id2]",
        "            comparison = processor.compare_fingerprints(fp1, fp2)",
        "            similarity = comparison.get('overall_similarity', 0.0)",
        "",
        "            # Adjust threshold based on resolution",
        "            # Higher resolution = higher threshold = more clusters",
        "            threshold = 0.3 * resolution",
        "",
        "            if similarity >= threshold:",
        "                edges[doc_id1][doc_id2] = similarity",
        "                edges[doc_id2][doc_id1] = similarity",
        "",
        "    # Simple greedy clustering: find connected components",
        "    visited = set()",
        "    clusters = {}",
        "    cluster_id = 0",
        "",
        "    def dfs(doc_id: str, cluster: List[str]):",
        "        \"\"\"Depth-first search to find connected component.\"\"\"",
        "        if doc_id in visited:",
        "            return",
        "        visited.add(doc_id)",
        "        cluster.append(doc_id)",
        "",
        "        # Visit neighbors",
        "        for neighbor in edges.get(doc_id, {}):",
        "            if neighbor not in visited:",
        "                dfs(neighbor, cluster)",
        "",
        "    # Find all connected components",
        "    for doc_id in memory_ids:",
        "        if doc_id not in visited:",
        "            cluster = []",
        "            dfs(doc_id, cluster)",
        "",
        "            if len(cluster) >= min_cluster_size:",
        "                clusters[cluster_id] = cluster",
        "                cluster_id += 1",
        "",
        "    return clusters",
        "",
        "",
        "def extract_cluster_topics(",
        "    processor: CorticalTextProcessor,",
        "    doc_ids: List[str],",
        "    top_n: int = 5",
        ") -> List[Tuple[str, float]]:",
        "    \"\"\"",
        "    Extract top terms representing a cluster of documents.",
        "",
        "    Args:",
        "        processor: CorticalTextProcessor instance",
        "        doc_ids: List of document IDs in the cluster",
        "        top_n: Number of top terms to extract",
        "",
        "    Returns:",
        "        List of (term, score) tuples sorted by importance",
        "    \"\"\"",
        "    # Aggregate term weights across all documents in cluster",
        "    term_scores: Dict[str, float] = defaultdict(float)",
        "",
        "    layer0 = processor.layers[CorticalLayer.TOKENS]",
        "",
        "    # For each document, get its top terms",
        "    for doc_id in doc_ids:",
        "        content = processor.documents.get(doc_id, '')",
        "        if not content:",
        "            continue",
        "",
        "        fp = processor.get_fingerprint(content, top_n=20)",
        "        terms = fp.get('terms', {})",
        "",
        "        # Weight by document's PageRank in the cluster",
        "        doc_col = processor.layers[CorticalLayer.DOCUMENTS].get_by_id(f\"L3_{doc_id}\")",
        "        doc_weight = doc_col.pagerank if doc_col else 1.0",
        "",
        "        for term, weight in terms.items():",
        "            # Also consider the term's global importance",
        "            term_col = layer0.get_minicolumn(term)",
        "            term_importance = term_col.pagerank if term_col else 0.0",
        "",
        "            # Combined score: term weight in doc * doc importance * term importance",
        "            term_scores[term] += weight * doc_weight * (1 + term_importance)",
        "",
        "    # Sort by score and return top N",
        "    sorted_terms = sorted(term_scores.items(), key=lambda x: -x[1])",
        "    return sorted_terms[:top_n]",
        "",
        "",
        "def suggest_consolidations(",
        "    processor: CorticalTextProcessor,",
        "    min_overlap: float = 0.5,",
        "    min_cluster_size: int = 2,",
        "    min_age_days: int = 30,",
        "    resolution: float = 1.0,",
        "    verbose: bool = False",
        ") -> Dict[str, Any]:",
        "    \"\"\"",
        "    Analyze memories and suggest consolidation opportunities.",
        "",
        "    Args:",
        "        processor: CorticalTextProcessor instance",
        "        min_overlap: Minimum similarity for pair suggestions (0.0-1.0)",
        "        min_cluster_size: Minimum memories per cluster",
        "        min_age_days: Minimum age in days for \"old memory\" warnings",
        "        resolution: Louvain clustering resolution",
        "        verbose: Print detailed information",
        "",
        "    Returns:",
        "        Dictionary with suggestions categorized by type",
        "    \"\"\"",
        "    # Filter for memory documents (not concept docs, not decisions)",
        "    memory_ids = [",
        "        doc_id for doc_id in processor.documents.keys()",
        "        if doc_id.startswith('samples/memories/') and not is_concept_doc(doc_id)",
        "    ]",
        "",
        "    concept_ids = [",
        "        doc_id for doc_id in processor.documents.keys()",
        "        if doc_id.startswith('samples/memories/') and is_concept_doc(doc_id)",
        "    ]",
        "",
        "    if verbose:",
        "        print(f\"Found {len(memory_ids)} memory entries\")",
        "        print(f\"Found {len(concept_ids)} concept documents\")",
        "",
        "    suggestions = {",
        "        'clusters': [],",
        "        'similar_pairs': [],",
        "        'old_memories': [],",
        "        'stats': {",
        "            'total_memories': len(memory_ids),",
        "            'total_concepts': len(concept_ids),",
        "            'analyzed_memories': len(memory_ids)",
        "        }",
        "    }",
        "",
        "    if len(memory_ids) < 2:",
        "        return suggestions",
        "",
        "    # 1. Cluster analysis - find groups of related memories",
        "    if verbose:",
        "        print(\"\\nClustering memories...\")",
        "",
        "    clusters = cluster_memories(",
        "        processor,",
        "        memory_ids,",
        "        min_cluster_size=min_cluster_size,",
        "        resolution=resolution",
        "    )",
        "",
        "    for cluster_id, doc_ids in clusters.items():",
        "        # Extract topic terms for this cluster",
        "        topics = extract_cluster_topics(processor, doc_ids, top_n=5)",
        "        topic_terms = [term for term, _ in topics]",
        "",
        "        # Suggest a concept name based on top terms",
        "        concept_name = \"-\".join(topic_terms[:3])  # e.g., \"security-testing-fuzzing\"",
        "",
        "        suggestions['clusters'].append({",
        "            'cluster_id': cluster_id,",
        "            'document_count': len(doc_ids),",
        "            'documents': doc_ids,",
        "            'suggested_concept': concept_name,",
        "            'topics': topics,",
        "            'message': f\"These {len(doc_ids)} memories discuss '{concept_name}'. Consider creating samples/memories/concept-{concept_name}.md\"",
        "        })",
        "",
        "    # 2. High similarity pairs - find memories with strong overlap",
        "    if verbose:",
        "        print(\"Computing pairwise similarities...\")",
        "",
        "    similarities = compute_pairwise_similarity(processor, memory_ids)",
        "",
        "    for (doc_id1, doc_id2), similarity in similarities.items():",
        "        if similarity >= min_overlap and doc_id1 < doc_id2:  # Avoid duplicates",
        "            # Get shared terms",
        "            fp1 = processor.get_fingerprint(processor.documents[doc_id1], top_n=20)",
        "            fp2 = processor.get_fingerprint(processor.documents[doc_id2], top_n=20)",
        "            comparison = processor.compare_fingerprints(fp1, fp2)",
        "            shared = list(comparison.get('shared_terms', []))[:5]",
        "",
        "            suggestions['similar_pairs'].append({",
        "                'doc1': doc_id1,",
        "                'doc2': doc_id2,",
        "                'similarity': similarity,",
        "                'shared_terms': shared,",
        "                'message': f\"{doc_id1.split('/')[-1]} and {doc_id2.split('/')[-1]} have {similarity:.1%} overlap (shared: {', '.join(shared[:3])}). Consider merging?\"",
        "            })",
        "",
        "    # 3. Old memories - find memories that haven't been consolidated",
        "    if verbose:",
        "        print(\"Checking for old memories...\")",
        "",
        "    today = datetime.now()",
        "    for doc_id in memory_ids:",
        "        age_days = get_memory_age_days(doc_id)",
        "        if age_days >= min_age_days:",
        "            memory_date = parse_memory_date(doc_id)",
        "            suggestions['old_memories'].append({",
        "                'doc_id': doc_id,",
        "                'age_days': age_days,",
        "                'date': memory_date.strftime(\"%Y-%m-%d\"),",
        "                'message': f\"{doc_id.split('/')[-1]} is {age_days} days old. Consider consolidating into a concept document?\"",
        "            })",
        "",
        "    # Sort suggestions",
        "    suggestions['clusters'].sort(key=lambda x: x['document_count'], reverse=True)",
        "    suggestions['similar_pairs'].sort(key=lambda x: x['similarity'], reverse=True)",
        "    suggestions['old_memories'].sort(key=lambda x: x['age_days'], reverse=True)",
        "",
        "    return suggestions",
        "",
        "",
        "def format_suggestions_text(suggestions: Dict[str, Any], verbose: bool = False) -> str:",
        "    \"\"\"Format suggestions as human-readable text.\"\"\"",
        "    lines = []",
        "",
        "    lines.append(\"=\" * 70)",
        "    lines.append(\"MEMORY CONSOLIDATION SUGGESTIONS\")",
        "    lines.append(\"=\" * 70)",
        "    lines.append(\"\")",
        "",
        "    stats = suggestions['stats']",
        "    lines.append(f\"Analyzed {stats['total_memories']} memory entries\")",
        "    lines.append(f\"Found {stats['total_concepts']} existing concept documents\")",
        "    lines.append(\"\")",
        "",
        "    # Cluster suggestions",
        "    if suggestions['clusters']:",
        "        lines.append(f\"{'‚îÄ' * 70}\")",
        "        lines.append(f\"CLUSTER SUGGESTIONS ({len(suggestions['clusters'])})\")",
        "        lines.append(f\"{'‚îÄ' * 70}\")",
        "        lines.append(\"\")",
        "",
        "        for i, cluster in enumerate(suggestions['clusters'], 1):",
        "            lines.append(f\"[{i}] {cluster['message']}\")",
        "            if verbose:",
        "                lines.append(f\"    Documents ({cluster['document_count']}):\")",
        "                for doc_id in cluster['documents']:",
        "                    filename = doc_id.split('/')[-1]",
        "                    age = get_memory_age_days(doc_id)",
        "                    lines.append(f\"      - {filename} ({age} days old)\")",
        "                lines.append(f\"    Key topics: {', '.join(t for t, _ in cluster['topics'][:5])}\")",
        "            lines.append(\"\")",
        "    else:",
        "        lines.append(\"No cluster suggestions found.\")",
        "        lines.append(\"\")",
        "",
        "    # Similar pair suggestions",
        "    if suggestions['similar_pairs']:",
        "        lines.append(f\"{'‚îÄ' * 70}\")",
        "        lines.append(f\"HIGH OVERLAP PAIRS ({len(suggestions['similar_pairs'])})\")",
        "        lines.append(f\"{'‚îÄ' * 70}\")",
        "        lines.append(\"\")",
        "",
        "        for i, pair in enumerate(suggestions['similar_pairs'][:10], 1):  # Limit to top 10",
        "            lines.append(f\"[{i}] {pair['message']}\")",
        "            if verbose:",
        "                lines.append(f\"    Similarity: {pair['similarity']:.1%}\")",
        "                lines.append(f\"    Shared terms: {', '.join(pair['shared_terms'])}\")",
        "            lines.append(\"\")",
        "    else:",
        "        lines.append(\"No high-overlap pairs found.\")",
        "        lines.append(\"\")",
        "",
        "    # Old memory suggestions",
        "    if suggestions['old_memories']:",
        "        lines.append(f\"{'‚îÄ' * 70}\")",
        "        lines.append(f\"OLD MEMORIES ({len(suggestions['old_memories'])})\")",
        "        lines.append(f\"{'‚îÄ' * 70}\")",
        "        lines.append(\"\")",
        "",
        "        for i, old in enumerate(suggestions['old_memories'][:10], 1):  # Limit to top 10",
        "            lines.append(f\"[{i}] {old['message']}\")",
        "            lines.append(\"\")",
        "    else:",
        "        lines.append(\"No old memories found.\")",
        "        lines.append(\"\")",
        "",
        "    lines.append(\"=\" * 70)",
        "    lines.append(\"RECOMMENDATIONS\")",
        "    lines.append(\"=\" * 70)",
        "    lines.append(\"\")",
        "",
        "    if suggestions['clusters']:",
        "        lines.append(\"1. Review cluster suggestions and create concept documents:\")",
        "        for cluster in suggestions['clusters'][:3]:",
        "            lines.append(f\"   - Create: samples/memories/concept-{cluster['suggested_concept']}.md\")",
        "        lines.append(\"\")",
        "",
        "    if suggestions['similar_pairs']:",
        "        lines.append(\"2. Review high-overlap pairs and consider merging:\")",
        "        for pair in suggestions['similar_pairs'][:3]:",
        "            lines.append(f\"   - Compare: {pair['doc1'].split('/')[-1]} vs {pair['doc2'].split('/')[-1]}\")",
        "        lines.append(\"\")",
        "",
        "    if suggestions['old_memories']:",
        "        lines.append(\"3. Review old memories and consolidate into concepts:\")",
        "        for old in suggestions['old_memories'][:3]:",
        "            lines.append(f\"   - Review: {old['doc_id'].split('/')[-1]} ({old['age_days']} days)\")",
        "        lines.append(\"\")",
        "",
        "    return \"\\n\".join(lines)",
        "",
        "",
        "def main():",
        "    parser = argparse.ArgumentParser(",
        "        description='Suggest memory consolidation opportunities',",
        "        formatter_class=argparse.RawDescriptionHelpFormatter,",
        "        epilog=\"\"\"",
        "Examples:",
        "  %(prog)s                              # Default analysis",
        "  %(prog)s --threshold 0.7              # Higher similarity threshold",
        "  %(prog)s --min-cluster 3              # Require 3+ memories per cluster",
        "  %(prog)s --min-age-days 60            # Only flag memories older than 60 days",
        "  %(prog)s --output json                # JSON output",
        "  %(prog)s --verbose                    # Detailed output",
        "        \"\"\"",
        "    )",
        "",
        "    parser.add_argument(",
        "        '--corpus', '-c',",
        "        default='corpus_dev.pkl',",
        "        help='Corpus file path (default: corpus_dev.pkl)'",
        "    )",
        "    parser.add_argument(",
        "        '--threshold', '-t',",
        "        type=float,",
        "        default=0.5,",
        "        help='Minimum similarity for pair suggestions (0.0-1.0, default: 0.5)'",
        "    )",
        "    parser.add_argument(",
        "        '--min-cluster',",
        "        type=int,",
        "        default=2,",
        "        help='Minimum memories per cluster (default: 2)'",
        "    )",
        "    parser.add_argument(",
        "        '--min-age-days',",
        "        type=int,",
        "        default=30,",
        "        help='Minimum age in days for old memory warnings (default: 30)'",
        "    )",
        "    parser.add_argument(",
        "        '--resolution',",
        "        type=float,",
        "        default=1.0,",
        "        help='Louvain clustering resolution (default: 1.0, higher = more clusters)'",
        "    )",
        "    parser.add_argument(",
        "        '--output', '-o',",
        "        choices=['text', 'json'],",
        "        default='text',",
        "        help='Output format (default: text)'",
        "    )",
        "    parser.add_argument(",
        "        '--verbose', '-v',",
        "        action='store_true',",
        "        help='Verbose output with detailed information'",
        "    )",
        "",
        "    args = parser.parse_args()",
        "",
        "    # Validate arguments",
        "    if not 0.0 <= args.threshold <= 1.0:",
        "        parser.error(\"--threshold must be between 0.0 and 1.0\")",
        "",
        "    if args.min_cluster < 2:",
        "        parser.error(\"--min-cluster must be at least 2\")",
        "",
        "    base_path = Path(__file__).parent.parent",
        "    corpus_path = base_path / args.corpus",
        "",
        "    # Check if corpus exists",
        "    if not corpus_path.exists():",
        "        print(f\"Error: Corpus file not found: {corpus_path}\", file=sys.stderr)",
        "        print(\"Run 'python scripts/index_codebase.py' first to create it.\", file=sys.stderr)",
        "        sys.exit(1)",
        "",
        "    # Load corpus",
        "    if args.verbose or args.output == 'text':",
        "        print(f\"Loading corpus from {corpus_path}...\")",
        "",
        "    try:",
        "        processor = CorticalTextProcessor.load(str(corpus_path))",
        "    except Exception as e:",
        "        print(f\"Error loading corpus: {e}\", file=sys.stderr)",
        "        sys.exit(1)",
        "",
        "    if args.verbose or args.output == 'text':",
        "        print(f\"Loaded {len(processor.documents)} documents\")",
        "",
        "    # Ensure we have computed necessary features",
        "    if processor.is_stale(processor.COMP_PAGERANK):",
        "        if args.verbose:",
        "            print(\"Computing PageRank...\")",
        "        processor.compute_importance()",
        "",
        "    if processor.is_stale(processor.COMP_DOC_CONNECTIONS):",
        "        if args.verbose:",
        "            print(\"Computing document connections...\")",
        "        processor.compute_document_connections()",
        "",
        "    # Generate suggestions",
        "    suggestions = suggest_consolidations(",
        "        processor,",
        "        min_overlap=args.threshold,",
        "        min_cluster_size=args.min_cluster,",
        "        min_age_days=args.min_age_days,",
        "        resolution=args.resolution,",
        "        verbose=args.verbose and args.output == 'text'",
        "    )",
        "",
        "    # Output results",
        "    if args.output == 'json':",
        "        # Make suggestions JSON-serializable",
        "        json_suggestions = suggestions.copy()",
        "        for cluster in json_suggestions['clusters']:",
        "            cluster['topics'] = [[term, float(score)] for term, score in cluster['topics']]",
        "",
        "        print(json.dumps(json_suggestions, indent=2))",
        "    else:",
        "        output = format_suggestions_text(suggestions, verbose=args.verbose)",
        "        print(output)",
        "",
        "",
        "if __name__ == '__main__':",
        "    main()"
      ],
      "lines_removed": [],
      "context_before": [],
      "context_after": [],
      "change_type": "add"
    },
    {
      "file": "scripts/task_utils.py",
      "function": "Usage:",
      "start_line": 29,
      "lines_added": [
        "import sys"
      ],
      "lines_removed": [],
      "context_before": [
        "    task_id = generate_task_id()  # T-20251213-143052-a1b2",
        "",
        "    # Session-based (guaranteed unique within session)",
        "    session = TaskSession()",
        "    task1 = session.new_task_id()  # T-20251213-143052-a1b2-01",
        "    task2 = session.new_task_id()  # T-20251213-143052-a1b2-02",
        "\"\"\"",
        "",
        "import json",
        "import os"
      ],
      "context_after": [
        "import uuid",
        "from dataclasses import dataclass, field, asdict",
        "from datetime import datetime",
        "from pathlib import Path",
        "from typing import Dict, List, Optional, Any",
        "",
        "",
        "# Directory for per-session task files",
        "DEFAULT_TASKS_DIR = \"tasks\"",
        ""
      ],
      "change_type": "add"
    },
    {
      "file": "scripts/task_utils.py",
      "function": "def generate_short_task_id() -> str:",
      "start_line": 83,
      "lines_added": [
        "def slugify(text: str) -> str:",
        "    \"\"\"",
        "    Convert text to URL-friendly slug.",
        "",
        "    Args:",
        "        text: Text to convert to slug",
        "",
        "    Returns:",
        "        Slugified text (lowercase, hyphens, alphanumeric only)",
        "    \"\"\"",
        "    # Simple slugification: lowercase, replace spaces with hyphens",
        "    slug = text.lower().strip()",
        "    slug = slug.replace(\" \", \"-\")",
        "    # Remove non-alphanumeric except hyphens",
        "    slug = \"\".join(c for c in slug if c.isalnum() or c == \"-\")",
        "    # Remove duplicate hyphens",
        "    while \"--\" in slug:",
        "        slug = slug.replace(\"--\", \"-\")",
        "    # Truncate to reasonable length",
        "    return slug[:50]",
        "",
        "",
        "def generate_memory_from_task(task: dict) -> str:",
        "    \"\"\"",
        "    Generate memory entry markdown from a completed task.",
        "",
        "    Args:",
        "        task: Task dictionary with id, title, description, retrospective, etc.",
        "",
        "    Returns:",
        "        Markdown content for the memory entry",
        "    \"\"\"",
        "    now = datetime.now()",
        "    date_str = now.strftime(\"%Y-%m-%d\")",
        "",
        "    # Extract task fields",
        "    task_id = task.get('id', 'Unknown')",
        "    title = task.get('title', 'Untitled Task')",
        "    category = task.get('category', 'general')",
        "    description = task.get('description', 'No description provided')",
        "",
        "    # Extract retrospective notes",
        "    retrospective = task.get('retrospective', {})",
        "    if isinstance(retrospective, dict):",
        "        notes = retrospective.get('notes', 'No retrospective notes provided')",
        "    else:",
        "        notes = str(retrospective) if retrospective else 'No retrospective notes provided'",
        "",
        "    # Extract related files from context or retrospective",
        "    related_files = []",
        "    if 'context' in task and isinstance(task['context'], dict):",
        "        if 'files' in task['context']:",
        "            related_files.extend(task['context']['files'])",
        "    if isinstance(retrospective, dict) and 'files_touched' in retrospective:",
        "        related_files.extend(retrospective['files_touched'])",
        "",
        "    # Remove duplicates and format",
        "    related_files = list(set(related_files))",
        "    files_section = \"\\n\".join(f\"- `{f}`\" for f in related_files) if related_files else \"No files recorded\"",
        "",
        "    # Generate template",
        "    template = f\"\"\"# Task Learning: {title}",
        "",
        "**Task ID:** {task_id}",
        "**Completed:** {date_str}",
        "**Category:** {category}",
        "**Tags:** `{category}`, `task-learning`",
        "",
        "---",
        "",
        "## Task Context",
        "",
        "{description}",
        "",
        "## What Was Learned",
        "",
        "{notes}",
        "",
        "## Related Files",
        "",
        "{files_section}",
        "",
        "---",
        "",
        "*Auto-generated from task completion*",
        "\"\"\"",
        "",
        "    return template",
        "",
        "",
        "def create_memory_for_task(task: dict, output_dir: str = \"samples/memories\") -> str:",
        "    \"\"\"",
        "    Create a memory entry file from a completed task.",
        "",
        "    Args:",
        "        task: Task dictionary",
        "        output_dir: Directory to write memory file to",
        "",
        "    Returns:",
        "        Path to created memory file",
        "    \"\"\"",
        "    # Generate memory content",
        "    content = generate_memory_from_task(task)",
        "",
        "    # Generate merge-safe filename",
        "    now = datetime.now()",
        "    date_str = now.strftime(\"%Y-%m-%d\")",
        "    time_str = now.strftime(\"%H-%M-%S\")",
        "    session_id = generate_session_id()",
        "",
        "    # Use task title for slug",
        "    title = task.get('title', 'task-completion')",
        "    slug = slugify(title)",
        "",
        "    filename = f\"{date_str}_{time_str}_{session_id}-task-{slug}.md\"",
        "",
        "    # Create directory if needed",
        "    output_path = Path(output_dir)",
        "    output_path.mkdir(parents=True, exist_ok=True)",
        "",
        "    # Write file",
        "    filepath = output_path / filename",
        "    with open(filepath, 'w') as f:",
        "        f.write(content)",
        "",
        "    return str(filepath)",
        "",
        ""
      ],
      "lines_removed": [],
      "context_before": [
        "    Returns:",
        "        Task ID in format T-XXXXXXXX",
        "",
        "    Example:",
        "        >>> generate_short_task_id()",
        "        'T-a1b2c3d4'",
        "    \"\"\"",
        "    return f\"T-{uuid.uuid4().hex[:8]}\"",
        "",
        ""
      ],
      "context_after": [
        "@dataclass",
        "class Task:",
        "    \"\"\"A single task with merge-friendly ID.\"\"\"",
        "    id: str",
        "    title: str",
        "    status: str = \"pending\"  # pending, in_progress, completed, deferred",
        "    priority: str = \"medium\"  # high, medium, low",
        "    category: str = \"general\"",
        "    description: str = \"\"",
        "    depends_on: List[str] = field(default_factory=list)"
      ],
      "change_type": "add"
    },
    {
      "file": "scripts/task_utils.py",
      "function": "class TaskSession:",
      "start_line": 318,
      "lines_added": [
        "    def complete_task(",
        "        self,",
        "        task_id: str,",
        "        retrospective: Optional[str] = None,",
        "        create_memory: bool = False",
        "    ) -> Optional[str]:",
        "        \"\"\"",
        "        Mark a task as completed and optionally create a memory entry.",
        "",
        "        Args:",
        "            task_id: The task ID to complete",
        "            retrospective: Optional completion notes/learnings",
        "            create_memory: If True, create a memory entry from the task",
        "",
        "        Returns:",
        "            Path to created memory file if create_memory=True, else None",
        "",
        "        Raises:",
        "            ValueError: If task_id is not found in this session",
        "        \"\"\"",
        "        task = self.get_task(task_id)",
        "        if not task:",
        "            raise ValueError(f\"Task not found: {task_id}\")",
        "",
        "        # Mark task as complete",
        "        task.mark_complete()",
        "",
        "        # Capture retrospective if provided",
        "        if retrospective:",
        "            duration = self._calculate_duration(task.created_at)",
        "            task.retrospective = {",
        "                'notes': retrospective,",
        "                'duration_minutes': duration,",
        "                'files_touched': [],",
        "                'tests_added': 0,",
        "                'commits': [],",
        "                'captured_at': datetime.now().isoformat()",
        "            }",
        "",
        "        # Create memory if requested",
        "        memory_path = None",
        "        if create_memory and task.retrospective:",
        "            memory_path = create_memory_for_task(task.to_dict())",
        "",
        "        return memory_path",
        ""
      ],
      "lines_removed": [],
      "context_before": [
        "",
        "        return {",
        "            'total_completed': len(completed),",
        "            'avg_duration_minutes': round(avg_duration, 1),",
        "            'total_duration_minutes': total_duration,",
        "            'total_tests_added': total_tests,",
        "            'most_touched_files': file_counts.most_common(10),",
        "            'tasks_with_retrospective': [t.id for t in completed]",
        "        }",
        ""
      ],
      "context_after": [
        "    def get_filename(self) -> str:",
        "        \"\"\"Get the session filename.\"\"\"",
        "        dt = datetime.fromisoformat(self.started_at)",
        "        timestamp = dt.strftime(\"%Y-%m-%d_%H-%M-%S\")",
        "        return f\"{timestamp}_{self.session_id}.json\"",
        "",
        "    def save(self, tasks_dir: Optional[str] = None) -> Path:",
        "        \"\"\"",
        "        Save session tasks to a JSON file atomically.",
        ""
      ],
      "change_type": "add"
    },
    {
      "file": "scripts/task_utils.py",
      "function": "if __name__ == \"__main__\":",
      "start_line": 523,
      "lines_added": [
        "    # complete command",
        "    complete_parser = subparsers.add_parser(\"complete\", help=\"Complete a task\")",
        "    complete_parser.add_argument(\"task_id\", help=\"Task ID to complete\")",
        "    complete_parser.add_argument(\"--retrospective\", help=\"Completion notes/learnings\")",
        "    complete_parser.add_argument(\"--create-memory\", action=\"store_true\", help=\"Create memory entry\")",
        "    complete_parser.add_argument(\"--dir\", default=DEFAULT_TASKS_DIR, help=\"Tasks directory\")",
        ""
      ],
      "lines_removed": [],
      "context_before": [
        "    # consolidate command",
        "    cons_parser = subparsers.add_parser(\"consolidate\", help=\"Consolidate task files\")",
        "    cons_parser.add_argument(\"--dir\", default=DEFAULT_TASKS_DIR, help=\"Tasks directory\")",
        "    cons_parser.add_argument(\"--output\", help=\"Output markdown file\")",
        "",
        "    # list command",
        "    list_parser = subparsers.add_parser(\"list\", help=\"List all tasks\")",
        "    list_parser.add_argument(\"--dir\", default=DEFAULT_TASKS_DIR, help=\"Tasks directory\")",
        "    list_parser.add_argument(\"--status\", help=\"Filter by status\")",
        ""
      ],
      "context_after": [
        "    args = parser.parse_args()",
        "",
        "    if args.command == \"generate\":",
        "        if args.short:",
        "            print(generate_short_task_id())",
        "        else:",
        "            print(generate_task_id())",
        "",
        "    elif args.command == \"consolidate\":",
        "        grouped = consolidate_tasks(args.dir, args.output)"
      ],
      "change_type": "add"
    },
    {
      "file": "scripts/task_utils.py",
      "function": "if __name__ == \"__main__\":",
      "start_line": 546,
      "lines_added": [
        "    elif args.command == \"complete\":",
        "        # Find the session file containing this task",
        "        dir_path = Path(args.dir)",
        "        if not dir_path.exists():",
        "            print(f\"Error: Tasks directory not found: {args.dir}\")",
        "            sys.exit(1)",
        "",
        "        session_file = None",
        "        target_session = None",
        "",
        "        for filepath in sorted(dir_path.glob(\"*.json\")):",
        "            try:",
        "                session = TaskSession.load(filepath)",
        "                if session.get_task(args.task_id):",
        "                    session_file = filepath",
        "                    target_session = session",
        "                    break",
        "            except (json.JSONDecodeError, KeyError) as e:",
        "                print(f\"Warning: Could not load {filepath}: {e}\")",
        "                continue",
        "",
        "        if not target_session:",
        "            print(f\"Error: Could not find session containing task {args.task_id}\")",
        "            sys.exit(1)",
        "",
        "        # Complete the task",
        "        memory_path = target_session.complete_task(",
        "            args.task_id,",
        "            retrospective=args.retrospective,",
        "            create_memory=args.create_memory",
        "        )",
        "",
        "        # Save the session",
        "        target_session.save(args.dir)",
        "",
        "        print(f\"‚úì Task {args.task_id} marked as completed\")",
        "        if memory_path:",
        "            print(f\"‚úì Memory entry created: {memory_path}\")",
        ""
      ],
      "lines_removed": [],
      "context_before": [
        "            print(f\"\\nWritten to {args.output}\")",
        "",
        "    elif args.command == \"list\":",
        "        tasks = load_all_tasks(args.dir)",
        "        if args.status:",
        "            tasks = [t for t in tasks if t.status == args.status]",
        "",
        "        for task in tasks:",
        "            print(f\"[{task.status}] {task.id}: {task.title}\")",
        ""
      ],
      "context_after": [
        "    else:",
        "        parser.print_help()"
      ],
      "change_type": "add"
    },
    {
      "file": "tasks/2025-12-14_11-11-44_legacy-migration.json",
      "function": null,
      "start_line": 0,
      "lines_added": [
        "{",
        "  \"version\": 1,",
        "  \"session_id\": \"legacy-migration\",",
        "  \"started_at\": \"2025-12-14T11:11:44.783627\",",
        "  \"saved_at\": \"2025-12-14T23:21:19.750928\",",
        "  \"tasks\": [",
        "    {",
        "      \"id\": \"LEGACY-001\",",
        "      \"title\": \"Fix Per-Document TF-IDF Calculation Bug\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"bug-fix\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #1\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-10T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 1",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-002\",",
        "      \"title\": \"Add ID-to-Minicolumn Lookup Optimization\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"performance\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #2\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-10T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 2",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-003\",",
        "      \"title\": \"Fix Type Annotation Errors\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"bug-fix\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #3\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-10T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 3",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-004\",",
        "      \"title\": \"Remove Unused Import\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"cleanup\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #4\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-10T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 4",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-005\",",
        "      \"title\": \"Fix Unconditional Print in Export\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"bug-fix\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #5\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-10T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 5",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-006\",",
        "      \"title\": \"Add Missing Test Coverage\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"testing\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #6\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-10T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 6",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-007\",",
        "      \"title\": \"Document magic numbers in gaps.py\",",
        "      \"status\": \"deferred\",",
        "      \"priority\": \"low\",",
        "      \"category\": \"deferred\",",
        "      \"description\": \"Low priority, functional as-is\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": null,",
        "      \"context\": {",
        "        \"legacy_task_number\": 7",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-008\",",
        "      \"title\": \"Implement Chunk-Level Retrieval\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"rag\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #8\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-10T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 8",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-009\",",
        "      \"title\": \"Add Document Metadata Support\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"rag\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #9\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-10T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 9",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-010\",",
        "      \"title\": \"Activate Layer 2 Concept Clustering\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"rag\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #10\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-10T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 10",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-011\",",
        "      \"title\": \"Integrate Semantic Relations into Retrieval\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"rag\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #11\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-10T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 11",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-012\",",
        "      \"title\": \"Persist Full Computed State\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"rag\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #12\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-10T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 12",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-013\",",
        "      \"title\": \"Fix Remaining Type Annotation\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"bug-fix\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #13\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-10T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 13",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-014\",",
        "      \"title\": \"Optimize Spectral Embeddings Lookup\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"performance\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #14\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-10T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 14",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-015\",",
        "      \"title\": \"Add Incremental Document Indexing\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"rag\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #15\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-10T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 15",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-016\",",
        "      \"title\": \"Document Magic Numbers in Gap Detection\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"docs\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #16\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-10T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 16",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-017\",",
        "      \"title\": \"Add Multi-Stage Ranking Pipeline\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"rag\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #17\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-10T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 17",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-018\",",
        "      \"title\": \"Add Batch Query API\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"rag\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #18\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-10T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 18",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-019\",",
        "      \"title\": \"Build Cross-Layer Feedforward Connections\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"conceptnet\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #19\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-10T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 19",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-020\",",
        "      \"title\": \"Add Concept-Level Lateral Connections\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"conceptnet\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #20\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-10T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 20",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-021\",",
        "      \"title\": \"Add Bigram Lateral Connections\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"conceptnet\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #21\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-10T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 21",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-022\",",
        "      \"title\": \"Implement Relation-Weighted PageRank\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"conceptnet\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #22\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-10T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 22",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-023\",",
        "      \"title\": \"Implement Cross-Layer PageRank Propagation\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"conceptnet\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #23\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-10T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 23",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-024\",",
        "      \"title\": \"Add Typed Edge Storage\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"conceptnet\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #24\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-10T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 24",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-025\",",
        "      \"title\": \"Implement Multi-Hop Semantic Inference\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"conceptnet\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #25\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-10T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 25",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-026\",",
        "      \"title\": \"Add Relation Path Scoring\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"conceptnet\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #26\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-10T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 26",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-027\",",
        "      \"title\": \"Implement Concept Inheritance\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"conceptnet\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #27\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-10T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 27",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-028\",",
        "      \"title\": \"Add Commonsense Relation Extraction\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"conceptnet\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #28\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-10T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 28",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-029\",",
        "      \"title\": \"Visualize ConceptNet-Style Graph\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"conceptnet\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #29\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-10T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 29",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-030\",",
        "      \"title\": \"Add Analogy Completion\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"conceptnet\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #30\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-10T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 30",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-034\",",
        "      \"title\": \"Fix Bigram Separator Mismatch in Analogy\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"bug-fix\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #34\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-10T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 34",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-035\",",
        "      \"title\": \"Fix Bigram Separator Mismatch in Connections\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"bug-fix\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #35\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-10T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 35",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-037\",",
        "      \"title\": \"Create Dedicated Query Module Tests\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"testing\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #37\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-10T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 37",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-038\",",
        "      \"title\": \"Add Input Validation to Public API\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"code-quality\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #38\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-10T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 38",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-039\",",
        "      \"title\": \"Move Inline Imports to Module Top\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"code-quality\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #39\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-10T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 39",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-040\",",
        "      \"title\": \"Add Parameter Range Validation\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"code-quality\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #40\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-10T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 40",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-041\",",
        "      \"title\": \"Create Configuration Dataclass\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"architecture\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #41\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-11T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 41",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-042\",",
        "      \"title\": \"Add simple query language\",",
        "      \"status\": \"deferred\",",
        "      \"priority\": \"low\",",
        "      \"category\": \"deferred\",",
        "      \"description\": \"Nice-to-have, not blocking\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": null,",
        "      \"context\": {",
        "        \"legacy_task_number\": 42",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-043\",",
        "      \"title\": \"Optimize Chunk Scoring Performance\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"performance\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #43\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-10T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 43",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-044\",",
        "      \"title\": \"Remove deprecated feedforward_sources\",",
        "      \"status\": \"deferred\",",
        "      \"priority\": \"low\",",
        "      \"category\": \"deferred\",",
        "      \"description\": \"Cleanup, low impact\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": null,",
        "      \"context\": {",
        "        \"legacy_task_number\": 44",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-045\",",
        "      \"title\": \"Add LRU Cache for Query Results\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"performance\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #45\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-10T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 45",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-046\",",
        "      \"title\": \"Standardize return types with dataclasses\",",
        "      \"status\": \"deferred\",",
        "      \"priority\": \"low\",",
        "      \"category\": \"deferred\",",
        "      \"description\": \"Superseded by #185\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": null,",
        "      \"context\": {",
        "        \"legacy_task_number\": 46",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-047\",",
        "      \"title\": \"Dog-Food the System During Development\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"devex\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #47\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-10T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 47",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-048\",",
        "      \"title\": \"Add Code-Aware Tokenization\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"code-search\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #48\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-10T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 48",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-049\",",
        "      \"title\": \"Add Synonym/Concept Mapping for Code\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"code-search\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #49\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-10T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 49",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-050\",",
        "      \"title\": \"Add Intent-Based Query Understanding\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"code-search\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #50\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-10T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 50",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-051\",",
        "      \"title\": \"Add Fingerprint Export API\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"code-search\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #51\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-10T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 51",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-052\",",
        "      \"title\": \"Optimize Query-to-Corpus Comparison\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"performance\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #52\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-10T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 52",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-053\",",
        "      \"title\": \"Create Algorithm Intelligence Docs\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"docs\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #53\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-10T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 53",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-054\",",
        "      \"title\": \"Create Architecture Intelligence Docs\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"docs\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #54\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-10T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 54",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-055\",",
        "      \"title\": \"Create Pattern Glossary\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"docs\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #55\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-10T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 55",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-056\",",
        "      \"title\": \"Create Usage Patterns Documentation\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"docs\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #56\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-11T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 56",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-057\",",
        "      \"title\": \"Add Incremental Codebase Indexing\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"devex\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #57\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-10T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 57",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-058\",",
        "      \"title\": \"Git-Compatible Chunk-Based Indexing\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"devex\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #58\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-10T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 58",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-059\",",
        "      \"title\": \"Rename TimeoutError to Avoid Shadowing\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"code-quality\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #59\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-11T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 59",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-060\",",
        "      \"title\": \"Add Windows Compatibility for Timeout\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"code-quality\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #60\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-11T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 60",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-061\",",
        "      \"title\": \"Add Chunk Size Warning\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"code-quality\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #61\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-11T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 61",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-062\",",
        "      \"title\": \"Add Chunk Compaction Documentation\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"docs\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #62\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-11T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 62",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-063\",",
        "      \"title\": \"Improve Search Ranking for Docs\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"code-search\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #63\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-11T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 63",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-064\",",
        "      \"title\": \"Add Document Type Indicator\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"code-search\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #64\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-11T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 64",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-065\",",
        "      \"title\": \"Add Document Metadata to Chunk Indexing\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"devex\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #65\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-11T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 65",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-066\",",
        "      \"title\": \"Add Doc-Type Boosting to Passage Search\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"code-search\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #66\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-11T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 66",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-067\",",
        "      \"title\": \"Fix O(n) Lookup in Showcase\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"showcase\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #67\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-11T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 67",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-068\",",
        "      \"title\": \"Add Code-Specific Features to Showcase\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"showcase\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #68\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-11T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 68",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-069\",",
        "      \"title\": \"Add Passage-Level Search Demo\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"showcase\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #69\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-11T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 69",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-070\",",
        "      \"title\": \"Add Performance Timing to Showcase\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"showcase\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #70\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-11T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 70",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-071\",",
        "      \"title\": \"Enable Code-Aware Tokenization in Index\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"code-index\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #71\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-11T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 71",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-072\",",
        "      \"title\": \"Use Programming Query Expansion\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"code-index\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #72\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-11T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 72",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-075\",",
        "      \"title\": \"Add \\\"What Changed?\\\" semantic diff\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"low\",",
        "      \"category\": \"devex\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #75\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:34:29.103266\",",
        "      \"completed_at\": \"2025-12-14T11:34:29.103248\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 75",
        "      },",
        "      \"retrospective\": {",
        "        \"notes\": \"Implemented cortical/diff.py with compare_with(), compare_documents(), what_changed() methods\"",
        "      }",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-077\",",
        "      \"title\": \"Add Interactive \\\"Ask the Codebase\\\" Mode\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"devex\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #77\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-11T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 77",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-078\",",
        "      \"title\": \"Add code pattern detection\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"low\",",
        "      \"category\": \"devex\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #78\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T23:21:00.282637\",",
        "      \"completed_at\": \"2025-12-14T23:21:00.282637\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 78",
        "      },",
        "      \"retrospective\": {",
        "        \"notes\": \"Created cortical/patterns.py (542 lines) with 32 patterns across 9 categories + processor integration\",",
        "        \"duration_minutes\": 7161,",
        "        \"files_touched\": [],",
        "        \"tests_added\": 0,",
        "        \"commits\": [],",
        "        \"captured_at\": \"2025-12-14T23:21:00.282664\"",
        "      }",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-080\",",
        "      \"title\": \"Add \\\"Learning Mode\\\" for contributors\",",
        "      \"status\": \"pending\",",
        "      \"priority\": \"low\",",
        "      \"category\": \"devex\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #80\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": null,",
        "      \"context\": {",
        "        \"legacy_task_number\": 80",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-081\",",
        "      \"title\": \"Fix Tokenizer Underscore Identifiers\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"code-search\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #81\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-11T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 81",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-082\",",
        "      \"title\": \"Add Code Stop Words Filter\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"code-search\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #82\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-11T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 82",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-083\",",
        "      \"title\": \"Add Definition-Aware Boosting\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"code-search\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #83\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-11T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 83",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-084\",",
        "      \"title\": \"Add Direct Definition Pattern Search\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"code-search\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #84\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-11T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 84",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-085\",",
        "      \"title\": \"Improve Test vs Source File Ranking\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"code-search\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #85\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-11T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 85",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-086\",",
        "      \"title\": \"Add Semantic Chunk Boundaries for Code\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"code-search\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #86\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-11T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 86",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-087\",",
        "      \"title\": \"Add Python Code Samples and Showcase\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"showcase\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #87\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-13T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 87",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-088\",",
        "      \"title\": \"Create Package Installation Files\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"devex\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #88\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-11T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 88",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-089\",",
        "      \"title\": \"Create CONTRIBUTING.md\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"devex\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #89\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-11T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 89",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-090\",",
        "      \"title\": \"Create docs/quickstart.md\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"docs\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #90\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-11T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 90",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-091\",",
        "      \"title\": \"Create docs/README.md Index\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"docs\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #91\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-12T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 91",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-092\",",
        "      \"title\": \"Add Badges to README.md\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"devex\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #92\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-12T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 92",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-093\",",
        "      \"title\": \"Update README with Docs References\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"docs\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #93\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-12T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 93",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-094\",",
        "      \"title\": \"Split query.py into Focused Modules\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"architecture\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #94\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-12T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 94",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-095\",",
        "      \"title\": \"Split processor.py into modules\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"arch\",",
        "      \"description\": \"Correction: processor.py still 3115 lines - not split into modules\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-14T21:43:24.122320\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 95",
        "      },",
        "      \"retrospective\": \"Processor split was completed prior to this session. Verified processor/ package has 6 mixins: core.py, documents.py, compute.py, query_api.py, introspection.py, persistence_api.py\"",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-096\",",
        "      \"title\": \"Centralize Duplicate Constants\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"code-quality\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #96\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-12T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 96",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-097\",",
        "      \"title\": \"Integrate CorticalConfig into Processor\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"architecture\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #97\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-11T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 97",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-098\",",
        "      \"title\": \"Replace print() with Logging\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"code-quality\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #98\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-12T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 98",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-100\",",
        "      \"title\": \"Implement plugin/extension registry\",",
        "      \"status\": \"pending\",",
        "      \"priority\": \"low\",",
        "      \"category\": \"arch\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #100\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": null,",
        "      \"context\": {",
        "        \"legacy_task_number\": 100",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-102\",",
        "      \"title\": \"Add Tests for Edge Cases\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"testing\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #102\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-12T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 102",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-103\",",
        "      \"title\": \"Add Priority Backlog Summary\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"task-mgmt\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #103\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-11T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 103",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-104\",",
        "      \"title\": \"Create TASK_ARCHIVE.md\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"task-mgmt\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #104\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-11T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 104",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-105\",",
        "      \"title\": \"Standardize Task Format\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"task-mgmt\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #105\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-11T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 105",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-109\",",
        "      \"title\": \"Add Recently Completed Section\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"task-mgmt\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #109\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-11T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 109",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-110\",",
        "      \"title\": \"Add section markers to large files\",",
        "      \"status\": \"deferred\",",
        "      \"priority\": \"low\",",
        "      \"category\": \"deferred\",",
        "      \"description\": \"Superseded by #119 (AI metadata generator)\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": null,",
        "      \"context\": {",
        "        \"legacy_task_number\": 110",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-111\",",
        "      \"title\": \"Add \\\"See Also\\\" cross-references\",",
        "      \"status\": \"deferred\",",
        "      \"priority\": \"low\",",
        "      \"category\": \"deferred\",",
        "      \"description\": \"Superseded by #119 (AI metadata generator)\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": null,",
        "      \"context\": {",
        "        \"legacy_task_number\": 111",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-112\",",
        "      \"title\": \"Add docstring examples\",",
        "      \"status\": \"deferred\",",
        "      \"priority\": \"low\",",
        "      \"category\": \"deferred\",",
        "      \"description\": \"Superseded by #119 (AI metadata generator)\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": null,",
        "      \"context\": {",
        "        \"legacy_task_number\": 112",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-113\",",
        "      \"title\": \"Document Staleness Tracking System\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"docs\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #113\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-12T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 113",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-114\",",
        "      \"title\": \"Add Type Aliases for Complex Types\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"code-quality\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #114\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-12T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 114",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-115\",",
        "      \"title\": \"Create Component Interaction Diagram\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"docs\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #115\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-12T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 115",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-116\",",
        "      \"title\": \"Document Return Value Semantics\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"docs\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #116\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-12T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 116",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-119\",",
        "      \"title\": \"Create AI Metadata Generator Script\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"devex\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #119\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-11T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 119",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-120\",",
        "      \"title\": \"Add AI Metadata Loader to Claude Skills\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"devex\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #120\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-11T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 120",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-121\",",
        "      \"title\": \"Auto-regenerate AI Metadata on Changes\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"devex\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #121\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-11T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 121",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-122\",",
        "      \"title\": \"Investigate Concept Layer Regressions\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"research\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #122\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-11T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 122",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-123\",",
        "      \"title\": \"Replace Label Propagation with Louvain\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"algorithm\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #123\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-11T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 123",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-124\",",
        "      \"title\": \"Add Minimum Cluster Count Tests\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"testing\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #124\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-11T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 124",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-125\",",
        "      \"title\": \"Add Clustering Quality Metrics\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"algorithm\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #125\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-11T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 125",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-126\",",
        "      \"title\": \"Investigate Louvain Resolution\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"research\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #126\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-11T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 126",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-127\",",
        "      \"title\": \"Create Cluster Coverage Evaluation Script\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"devex\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #127\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-11T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 127",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-128\",",
        "      \"title\": \"Fix Definition Boost Test File Penalty\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"bug-fix\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #128\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-11T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 128",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-130\",",
        "      \"title\": \"Expand customer service sample cluster\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"low\",",
        "      \"category\": \"samples\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #130\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T23:21:19.750714\",",
        "      \"completed_at\": \"2025-12-14T23:21:19.750714\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 130",
        "      },",
        "      \"retrospective\": {",
        "        \"notes\": \"Created 8 customer service documents (~80KB) covering billing, shipping, returns, privacy, and templates\",",
        "        \"duration_minutes\": 7161,",
        "        \"files_touched\": [],",
        "        \"tests_added\": 0,",
        "        \"commits\": [],",
        "        \"captured_at\": \"2025-12-14T23:21:19.750745\"",
        "      }",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-132\",",
        "      \"title\": \"Profile Full-Analysis Bottleneck\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"performance\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #132\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-11T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 132",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-133\",",
        "      \"title\": \"Implement WAL + snapshot persistence (fault-tolerant rebuild)\",",
        "      \"status\": \"pending\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"arch\",",
        "      \"description\": \"Correction: Checkpointing added to compute_all() but full WAL not implemented\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": null,",
        "      \"context\": {",
        "        \"legacy_task_number\": 133",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-134\",",
        "      \"title\": \"Implement protobuf serialization for corpus\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"arch\",",
        "      \"description\": \"Correction: cortical/proto/ directory with schema.proto and serialization.py\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-13T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 134",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-135\",",
        "      \"title\": \"Implement chunked parallel processing for full-analysis\",",
        "      \"status\": \"pending\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"arch\",",
        "      \"description\": \"Correction: Parallel processing not implemented - processor.py still sequential\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": null,",
        "      \"context\": {",
        "        \"legacy_task_number\": 135",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-136\",",
        "      \"title\": \"Optimize Semantics O(n\\u00b2) Similarity\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"performance\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #136\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-11T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 136",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-137\",",
        "      \"title\": \"Cap Bigram Connections to Top-K\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"performance\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #137\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-12T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 137",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-138\",",
        "      \"title\": \"Sparse Matrix for Bigram Connections\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"performance\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #138\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-12T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 138",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-139\",",
        "      \"title\": \"Batch Bigram Connection Updates\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"performance\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #139\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-12T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 139",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-141\",",
        "      \"title\": \"Filter Python Keywords from Analysis\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"code-quality\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #141\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-12T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 141",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-142\",",
        "      \"title\": \"Investigate compute_all() Regression\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"performance\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #142\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-12T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 142",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-143\",",
        "      \"title\": \"Investigate Negative Silhouette Score\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"research\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #143\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-12T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 143",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-144\",",
        "      \"title\": \"Boost Exact Document Name Matches\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"search\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #144\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-12T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 144",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-145\",",
        "      \"title\": \"Improve Graph Embedding Quality\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"algorithm\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #145\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-12T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 145",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-146\",",
        "      \"title\": \"Create Behavioral Tests\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"testing\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #146\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-12T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 146",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-147\",",
        "      \"title\": \"Fix Misleading Hardcoded Values\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"bug-fix\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #147\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-12T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 147",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-150\",",
        "      \"title\": \"Create Unit Test Fixtures and Mocks\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"testing\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #150\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-12T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 150",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-153\",",
        "      \"title\": \"Refactor query/* for Unit Testability\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"testing\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #153\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-12T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 153",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-154\",",
        "      \"title\": \"Add Unit Tests for query/* (partial)\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"testing\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #154\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-12T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 154",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-157\",",
        "      \"title\": \"Add Unit Tests for semantics.py\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"testing\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #157\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-12T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 157",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-158\",",
        "      \"title\": \"Add Unit Tests for persistence.py\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"testing\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #158\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-12T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 158",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-159\",",
        "      \"title\": \"Unit Tests for tokenizer.py\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"unit-test\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #159\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-13T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 159",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-160\",",
        "      \"title\": \"Unit Tests for embeddings.py\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"unit-test\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #160\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-13T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 160",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-161\",",
        "      \"title\": \"Unit Tests for layers.py\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"unit-test\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #161\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-13T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 161",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-162\",",
        "      \"title\": \"Unit Tests for minicolumn.py\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"unit-test\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #162\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-13T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 162",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-163\",",
        "      \"title\": \"Unit Tests for fingerprint.py\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"unit-test\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #163\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-13T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 163",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-164\",",
        "      \"title\": \"Unit Tests for gaps.py\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"unit-test\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #164\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-13T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 164",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-167\",",
        "      \"title\": \"Unit Tests for chunk_index.py\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"unit-test\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #167\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-13T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 167",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-168\",",
        "      \"title\": \"Unit Tests for config.py\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"unit-test\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #168\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-13T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 168",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-169\",",
        "      \"title\": \"Unit Tests for code_concepts.py\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"unit-test\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #169\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-13T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 169",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-170\",",
        "      \"title\": \"Unit Tests for query/expansion.py\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"unit-test\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #170\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-13T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 170",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-171\",",
        "      \"title\": \"Unit Tests for query/search.py\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"unit-test\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #171\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-13T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 171",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-172\",",
        "      \"title\": \"Unit Tests for query/passages.py\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"unit-test\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #172\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-13T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 172",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-173\",",
        "      \"title\": \"Unit Tests for query/definitions.py\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"unit-test\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #173\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-13T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 173",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-174\",",
        "      \"title\": \"Unit Tests for query/analogy.py\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"unit-test\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #174\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-13T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 174",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-175\",",
        "      \"title\": \"Unit Tests for query/ranking.py\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"unit-test\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #175\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-13T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 175",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-176\",",
        "      \"title\": \"Unit Tests for analysis.py\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"unit-test\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #176\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-13T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 176",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-177\",",
        "      \"title\": \"Unit Tests for semantics.py\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"unit-test\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #177\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-13T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 177",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-178\",",
        "      \"title\": \"Unit Tests for persistence.py\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"unit-test\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #178\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-13T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 178",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-187\",",
        "      \"title\": \"Add async API support (AsyncCorticalTextProcessor)\",",
        "      \"status\": \"pending\",",
        "      \"priority\": \"low\",",
        "      \"category\": \"architecture\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #187\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": null,",
        "      \"context\": {",
        "        \"legacy_task_number\": 187",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-188\",",
        "      \"title\": \"Add streaming query results\",",
        "      \"status\": \"pending\",",
        "      \"priority\": \"low\",",
        "      \"category\": \"architecture\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #188\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": null,",
        "      \"context\": {",
        "        \"legacy_task_number\": 188",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-189\",",
        "      \"title\": \"Add observability hooks (timing, traces, metrics)\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"low\",",
        "      \"category\": \"devex\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #189\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T23:21:04.236734\",",
        "      \"completed_at\": \"2025-12-14T23:21:04.236734\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 189",
        "      },",
        "      \"retrospective\": {",
        "        \"notes\": \"Created cortical/observability.py (374 lines) with @timed decorator, MetricsCollector, TraceContext + processor integration\",",
        "        \"duration_minutes\": 7161,",
        "        \"files_touched\": [],",
        "        \"tests_added\": 0,",
        "        \"commits\": [],",
        "        \"captured_at\": \"2025-12-14T23:21:04.236764\"",
        "      }",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-190\",",
        "      \"title\": \"Create REST API wrapper (FastAPI)\",",
        "      \"status\": \"pending\",",
        "      \"priority\": \"low\",",
        "      \"category\": \"integration\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #190\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": null,",
        "      \"context\": {",
        "        \"legacy_task_number\": 190",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-191\",",
        "      \"title\": \"Add Interactive REPL mode\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"low\",",
        "      \"category\": \"devex\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #191\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T23:21:15.793340\",",
        "      \"completed_at\": \"2025-12-14T23:21:15.793340\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 191",
        "      },",
        "      \"retrospective\": {",
        "        \"notes\": \"Created scripts/repl.py (1050 lines) with full REPL, tab completion, history, and 20+ commands\",",
        "        \"duration_minutes\": 7161,",
        "        \"files_touched\": [],",
        "        \"tests_added\": 0,",
        "        \"commits\": [],",
        "        \"captured_at\": \"2025-12-14T23:21:15.793374\"",
        "      }",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-206\",",
        "      \"title\": \"Replace pkl with git-friendly JSON state storage\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"high\",",
        "      \"category\": \"arch\",",
        "      \"description\": \"Correction: cortical/state_storage.py exists - JSON state storage implemented\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-13T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 206",
        "      },",
        "      \"retrospective\": null",
        "    }",
        "  ]",
        "}"
      ],
      "lines_removed": [],
      "context_before": [],
      "context_after": [],
      "change_type": "add"
    },
    {
      "file": "tasks/2025-12-14_17-13-01_6aa8.json",
      "function": null,
      "start_line": 1,
      "lines_added": [
        "  \"saved_at\": \"2025-12-14T23:21:24.133461\",",
        "      \"status\": \"completed\",",
        "      \"updated_at\": \"2025-12-14T23:21:24.133269\",",
        "      \"completed_at\": \"2025-12-14T23:21:24.133269\",",
        "      \"retrospective\": {",
        "        \"notes\": \"Investigation complete: documented 4 root causes and prioritized fixes in samples/memories/2025-12-14-search-relevance-investigation.md\",",
        "        \"duration_minutes\": 368,",
        "        \"files_touched\": [],",
        "        \"tests_added\": 0,",
        "        \"commits\": [],",
        "        \"captured_at\": \"2025-12-14T23:21:24.133323\"",
        "      }",
        "      \"status\": \"completed\",",
        "      \"completed_at\": \"2025-12-14T20:56:22.394615\",",
        "      \"retrospective\": \"Completed in Director Mode session. See knowledge transfer: samples/memories/2025-12-14_20-55-23_632e-session-knowledge-transfer-director-mode-orchestra.md\"",
        "      \"status\": \"completed\",",
        "      \"completed_at\": \"2025-12-14T20:56:22.394615\",",
        "      \"retrospective\": \"Completed in Director Mode session. See knowledge transfer: samples/memories/2025-12-14_20-55-23_632e-session-knowledge-transfer-director-mode-orchestra.md\"",
        "      \"status\": \"completed\",",
        "      \"completed_at\": \"2025-12-14T21:37:01.725943\",",
        "      \"retrospective\": \"Added generate_memory_from_task() and create_memory_for_task() to task_utils.py\"",
        "      \"status\": \"completed\",",
        "      \"completed_at\": \"2025-12-14T21:49:19.784103\",",
        "      \"retrospective\": \"Implemented scripts/resolve_wiki_links.py with extract, resolve, backlinks, and directory check functionality\"",
        "      \"status\": \"completed\",",
        "      \"updated_at\": \"2025-12-14T23:20:56.056922\",",
        "      \"completed_at\": \"2025-12-14T23:20:56.056922\",",
        "      \"retrospective\": {",
        "        \"notes\": \"Implemented scripts/suggest_consolidation.py (605 lines) with clustering, overlap detection, and age tracking\",",
        "        \"duration_minutes\": 358,",
        "        \"files_touched\": [],",
        "        \"tests_added\": 0,",
        "        \"commits\": [],",
        "        \"captured_at\": \"2025-12-14T23:20:56.056957\"",
        "      }",
        "      \"updated_at\": null,",
        "      \"completed_at\": \"2025-12-14T21:37:01.725943\",",
        "      \"retrospective\": \"Implemented scripts/session_handoff.py with full CLI support\"",
        "      \"status\": \"completed\",",
        "      \"completed_at\": \"2025-12-14T20:56:22.394615\",",
        "      \"retrospective\": \"Completed in Director Mode session. See knowledge transfer: samples/memories/2025-12-14_20-55-23_632e-session-knowledge-transfer-director-mode-orchestra.md\"",
        "      \"updated_at\": null,",
        "      \"completed_at\": \"2025-12-14T20:56:22.394615\",",
        "      \"retrospective\": \"Completed in Director Mode session. See knowledge transfer: samples/memories/2025-12-14_20-55-23_632e-session-knowledge-transfer-director-mode-orchestra.md\"",
        "      \"updated_at\": null,",
        "      \"completed_at\": \"2025-12-14T20:56:22.394615\",",
        "      \"retrospective\": \"Completed in Director Mode session. See knowledge transfer: samples/memories/2025-12-14_20-55-23_632e-session-knowledge-transfer-director-mode-orchestra.md\"",
        "      \"status\": \"completed\",",
        "      \"completed_at\": \"2025-12-14T21:37:01.725943\",",
        "      \"retrospective\": \"Added markdown-links job to CI with .markdown-link-check.json config\""
      ],
      "lines_removed": [
        "  \"saved_at\": \"2025-12-15T11:08:59.138796\",",
        "      \"status\": \"pending\",",
        "      \"updated_at\": null,",
        "      \"completed_at\": null,",
        "      \"retrospective\": null",
        "      \"status\": \"pending\",",
        "      \"completed_at\": null,",
        "      \"retrospective\": null",
        "      \"status\": \"pending\",",
        "      \"completed_at\": null,",
        "      \"retrospective\": null",
        "      \"status\": \"pending\",",
        "      \"completed_at\": null,",
        "      \"retrospective\": null",
        "      \"status\": \"pending\",",
        "      \"completed_at\": null,",
        "      \"retrospective\": null",
        "      \"status\": \"pending\",",
        "      \"updated_at\": null,",
        "      \"completed_at\": null,",
        "      \"retrospective\": null",
        "      \"updated_at\": \"2025-12-15T11:08:51.197528\",",
        "      \"completed_at\": \"2025-12-15T11:08:51.197528\",",
        "      \"retrospective\": null",
        "      \"status\": \"pending\",",
        "      \"completed_at\": null,",
        "      \"retrospective\": null",
        "      \"updated_at\": \"2025-12-15T11:08:55.461099\",",
        "      \"completed_at\": \"2025-12-15T11:08:55.461099\",",
        "      \"retrospective\": null",
        "      \"updated_at\": \"2025-12-15T11:08:59.138683\",",
        "      \"completed_at\": \"2025-12-15T11:08:59.138683\",",
        "      \"retrospective\": null",
        "      \"status\": \"pending\",",
        "      \"completed_at\": null,",
        "      \"retrospective\": null"
      ],
      "context_before": [
        "{",
        "  \"version\": 1,",
        "  \"session_id\": \"6aa8\",",
        "  \"started_at\": \"2025-12-14T17:13:01.505357\","
      ],
      "context_after": [
        "  \"tasks\": [",
        "    {",
        "      \"id\": \"T-20251214-171301-6aa8-001\",",
        "      \"title\": \"Investigate semantic search relevance for domain-specific queries\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"arch\",",
        "      \"description\": \"During dog-fooding, searching for 'security test fuzzing' returned staleness tests instead of actual security-related code. The search seems to weight common terms like 'test' too heavily.\\n\\nInvestigation areas:\\n- Query expansion may be pulling in too many generic terms\\n- TF-IDF weighting may not properly discount common programming terms\\n- Domain-specific boosting could improve relevance for security/testing queries\\n\\nRelated: The code_concepts.py has programming synonyms but may need security-specific terms.\\n\\nDiscovered during: Dog-fooding session 2025-12-14\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"medium\",",
        "      \"created_at\": \"2025-12-14T17:13:01.505725\",",
        "      \"context\": {},",
        "    },",
        "    {",
        "      \"id\": \"T-20251214-172207-6aa8-002\",",
        "      \"title\": \"Add memory document templates and CLI\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"feature\",",
        "      \"description\": \"Create templates and CLI tooling for the text-as-memories system:\\n\\n1. Memory entry template (memories/YYYY-MM-DD-topic.md)\\n2. Decision record template (decisions/adr-NNN-title.md)\\n3. Concept consolidation template (concepts/topic.md)\\n\\nCLI commands:\\n- python scripts/new_memory.py 'What I learned today'\\n- python scripts/new_decision.py 'ADR: Choose X over Y'\\n\\nAuto-populate:\\n- Date, tags placeholder, related links section\\n- Git author info\\n- Link to recent tasks\\n\\nSee: docs/text-as-memories.md for format reference\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"medium\",",
        "      \"created_at\": \"2025-12-14T17:22:07.596921\",",
        "      \"updated_at\": null,",
        "      \"context\": {},",
        "    },",
        "    {",
        "      \"id\": \"T-20251214-172212-6aa8-003\",",
        "      \"title\": \"Index memories and decisions in semantic search\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"feature\",",
        "      \"description\": \"Extend the codebase indexer to include memory documents:\\n\\n1. Add samples/memories/ and samples/decisions/ to indexed paths\\n2. Add doc-type detection for memory vs decision vs concept docs\\n3. Apply appropriate boosting (decisions may be more authoritative)\\n4. Support [[wiki-link]] extraction for cross-references\\n\\nIntegration points:\\n- scripts/index_codebase.py: Add memory paths\\n- cortical/processor: Add memory-specific metadata\\n- scripts/search_codebase.py: Show memory type in results\\n\\nEnables: Searching across code AND institutional knowledge\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"medium\",",
        "      \"created_at\": \"2025-12-14T17:22:12.010789\",",
        "      \"updated_at\": null,",
        "      \"context\": {},",
        "    },",
        "    {",
        "      \"id\": \"T-20251214-172216-6aa8-004\",",
        "      \"title\": \"Auto-generate memory entries from completed tasks\",",
        "      \"priority\": \"low\",",
        "      \"category\": \"feature\",",
        "      \"description\": \"When a task is marked complete, offer to generate a memory entry:\\n\\n1. Extract task title, description, retrospective\\n2. Create memory document with learnings\\n3. Link to related files from task context\\n4. Add tags from task category\\n\\nIntegration:\\n- TaskSession.complete_task() could trigger this\\n- Optional flag: --create-memory\\n- Template pulls from task retrospective field\\n\\nBenefits:\\n- Captures learnings automatically\\n- Builds institutional memory from task work\\n- Creates searchable knowledge base\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"medium\",",
        "      \"created_at\": \"2025-12-14T17:22:16.074170\",",
        "      \"updated_at\": null,",
        "      \"context\": {},",
        "    },",
        "    {",
        "      \"id\": \"T-20251214-172238-6aa8-005\",",
        "      \"title\": \"Add wiki-link cross-reference resolution\",",
        "      \"priority\": \"low\",",
        "      \"category\": \"feature\",",
        "      \"description\": \"Parse and resolve [[wiki-style]] links in memory documents:\\n\\n1. Extract [[link]] patterns from markdown files\\n2. Resolve to actual file paths (fuzzy matching)\\n3. Build bidirectional link graph\\n4. Add 'backlinks' section showing what links TO a document\\n\\nUse cases:\\n- [[concepts/pagerank.md]] resolves to actual path\\n- [[2025-12-14]] finds memory entries for that date\\n- Search results show connection strength via links\\n\\nImplementation:\\n- Add link extraction to tokenizer or separate module\\n- Store links as typed_connections (relation_type='references')\\n- Query can traverse link graph for related docs\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"medium\",",
        "      \"created_at\": \"2025-12-14T17:22:38.635912\",",
        "      \"updated_at\": null,",
        "      \"context\": {},",
        "    },",
        "    {",
        "      \"id\": \"T-20251214-172243-6aa8-006\",",
        "      \"title\": \"Memory consolidation suggestions\",",
        "      \"priority\": \"low\",",
        "      \"category\": \"feature\",",
        "      \"description\": \"Analyze memories to suggest consolidation opportunities:\\n\\n1. Find memories with high term overlap (similar topics)\\n2. Identify repeated concepts across multiple entries\\n3. Suggest creating concept documents from clusters\\n4. Track 'memory age' - old unconsolidated memories\\n\\nAlgorithm:\\n- Use existing Louvain clustering on memory documents\\n- Memories in same cluster = consolidation candidates\\n- High PageRank terms across cluster = concept name\\n\\nOutput:\\n- 'These 5 memories all discuss PageRank, consider creating concepts/pagerank.md'\\n- 'Memory from 2025-12-10 has 80% overlap with 2025-12-14, merge?'\\n\\nCLI: python scripts/suggest_consolidation.py\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"medium\",",
        "      \"created_at\": \"2025-12-14T17:22:43.647861\",",
        "      \"context\": {},",
        "    },",
        "    {",
        "      \"id\": \"T-20251214-172247-6aa8-007\",",
        "      \"title\": \"Session handoff memory generator\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"feature\",",
        "      \"description\": \"Generate memory documents for agent session continuity:\\n\\nWhen ending a session, create a handoff document containing:\\n1. What was accomplished (from completed tasks)\\n2. Current state (uncommitted changes, running processes)\\n3. Blockers or issues encountered\\n4. Suggested next steps\\n5. Key context the next session needs\\n\\nIntegration:\\n- Hook into session end (or manual trigger)\\n- Pull from task retrospectives\\n- Include git status summary\\n- Link to relevant code locations\\n\\nFormat: memories/session-handoff-YYYY-MM-DD-HHMM.md\\n\\nThis enables smooth continuation across agent sessions\\nand builds institutional memory of development flow.\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"medium\",",
        "      \"created_at\": \"2025-12-14T17:22:47.634689\",",
        "      \"context\": {},",
        "    },",
        "    {",
        "      \"id\": \"T-20251214-173831-6aa8-008\",",
        "      \"title\": \"Make memory/decision filenames merge-safe\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"arch\",",
        "      \"description\": \"Apply the same merge-safe pattern from tasks to memories and decisions.\\n\\nCurrent patterns (can conflict):\\n- memories: YYYY-MM-DD-topic.md\\n- decisions: adr-NNN-title.md\\n\\nProposed patterns (merge-safe):\\n- memories: YYYY-MM-DD_HH-MM-SS_XXXX-topic.md\\n- decisions: adr-YYYYMMDD-HHMMSS-XXXX-title.md\\n\\nChanges needed:\\n1. Update memory-manager skill templates\\n2. Update /knowledge-transfer command\\n3. Update docs/text-as-memories.md examples\\n4. Add helper: scripts/new_memory.py with auto-generated safe names\\n5. Add helper: scripts/new_decision.py with auto-generated safe names\\n\\nAlternative: Use topic-hash suffix instead of timestamp\\nExample: 2025-12-14-dogfooding-a1b2.md\\n\\nThe session ID approach mirrors the proven task system design.\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"medium\",",
        "      \"created_at\": \"2025-12-14T17:38:31.813288\",",
        "      \"updated_at\": null,",
        "      \"context\": {},",
        "    },",
        "    {",
        "      \"id\": \"T-20251214-174107-6aa8-009\",",
        "      \"title\": \"Update README.md with comprehensive project overview\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"high\",",
        "      \"category\": \"docs\",",
        "      \"description\": \"The README.md needs to be updated to reflect current project state and be more engaging.\\n\\nCurrent issues:\\n- May be outdated with recent features\\n- Missing text-as-memories system\\n- Missing security features (HMAC signing, Bandit CI)\\n- Missing Claude skills and commands\\n\\nREADME should include:\\n1. Compelling intro with the 'visual cortex for text' metaphor\\n2. Quick start (5-line example)\\n3. Key features table with badges\\n4. Architecture diagram (ASCII or link to docs)\\n5. Installation instructions\\n6. Links to docs/quickstart.md for detailed guide\\n7. Security section (pickle warnings, HMAC signing)\\n8. Claude Code integration (skills, commands)\\n9. Contributing section\\n10. License\\n\\nMake it visually appealing with:\\n- Feature badges\\n- Code examples that actually run\\n- Clear navigation to detailed docs\\n- The 'neurons that fire together' quote\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"medium\",",
        "      \"created_at\": \"2025-12-14T17:41:07.348022\",",
        "      \"context\": {},",
        "    },",
        "    {",
        "      \"id\": \"T-20251214-174112-6aa8-010\",",
        "      \"title\": \"Audit markdown files for staleness\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"docs\",",
        "      \"description\": \"Review all markdown documentation for outdated content.\\n\\nFiles to audit:\\n- README.md - main project readme\\n- CLAUDE.md - development guide\\n- CONTRIBUTING.md - contribution guide\\n- docs/*.md - all documentation files\\n- samples/**/*.md - sample documents\\n\\nCheck for:\\n1. Outdated code examples (do they still run?)\\n2. Missing new features (text-as-memories, security, skills)\\n3. Broken internal links ([[wiki-style]] and markdown links)\\n4. Incorrect file paths or line numbers\\n5. Deprecated APIs still documented\\n6. Missing new configuration options\\n7. Outdated task references\\n\\nCreate a staleness report:\\n- List files with issues\\n- Categorize by severity (broken vs outdated vs minor)\\n- Link to specific lines needing updates\\n\\nConsider adding a CI check for:\\n- Broken markdown links\\n- Code blocks that don't parse\\n- References to non-existent files\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"medium\",",
        "      \"created_at\": \"2025-12-14T17:41:12.741156\",",
        "      \"context\": {},",
        "    },",
        "    {",
        "      \"id\": \"T-20251214-174116-6aa8-011\",",
        "      \"title\": \"Add markdown link checker to CI\",",
        "      \"priority\": \"low\",",
        "      \"category\": \"infra\",",
        "      \"description\": \"Add automated checking for broken links in markdown files.\\n\\nTools to consider:\\n- markdown-link-check (npm)\\n- mlc (rust-based, fast)\\n- lychee (rust-based, comprehensive)\\n\\nCI integration:\\n```yaml\\nmarkdown-lint:\\n  runs-on: ubuntu-latest\\n  steps:\\n    - uses: actions/checkout@v4\\n    - name: Check markdown links\\n      uses: gaurav-nelson/github-action-markdown-link-check@v1\\n      with:\\n        use-quiet-mode: 'yes'\\n        config-file: '.markdown-link-check.json'\\n```\\n\\nConfig file should:\\n- Ignore external URLs (or check with timeout)\\n- Check internal file references\\n- Check anchor links (#section-name)\\n- Whitelist known-good external domains\\n\\nAlso check:\\n- [[wiki-style]] links resolve to real files\\n- Code file references (cortical/foo.py:123) exist\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"medium\",",
        "      \"created_at\": \"2025-12-14T17:41:16.926225\",",
        "      \"updated_at\": null,",
        "      \"context\": {},",
        "    },",
        "    {",
        "      \"id\": \"T-20251214-174530-6aa8-012\",",
        "      \"title\": \"Enhance director orchestration with execution tracking\",",
        "      \"status\": \"pending\",",
        "      \"priority\": \"low\",",
        "      \"category\": \"feature\",",
        "      \"description\": \"Extend the director prompt with tooling support:\\n\\n1. Execution tracking file:\\n   - .claude/orchestration/current-plan.json\\n   - Track: batches, agents, status, results\\n\\n2. Verification automation:\\n   - scripts/verify_batch.py - run standard checks\\n   - Integrate with CI for parallel agent validation\\n\\n3. Replanning assistant:\\n   - Analyze failure patterns\\n   - Suggest alternative approaches\\n   - Track what was tried\\n\\n4. Metrics collection:\\n   - Time per batch\\n   - Success/failure rates\\n   - Common failure modes\\n\\n5. Integration with task system:\\n   - Auto-create tasks for each batch\\n   - Link to parent orchestration task\\n   - Capture retrospectives automatically\\n\\nSee: .claude/commands/director.md for current prompt\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"medium\","
      ],
      "change_type": "modify"
    },
    {
      "file": "tasks/2025-12-14_23-31-16_3058.json",
      "function": null,
      "start_line": 0,
      "lines_added": [
        "{",
        "  \"version\": 1,",
        "  \"session_id\": \"3058\",",
        "  \"started_at\": \"2025-12-14T23:31:16.044725\",",
        "  \"saved_at\": \"2025-12-14T23:46:35.265317\",",
        "  \"tasks\": [",
        "    {",
        "      \"id\": \"T-20251214-233116-3058-001\",",
        "      \"title\": \"Weight lateral connections by TF-IDF in query expansion\",",
        "      \"status\": \"pending\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"bugfix\",",
        "      \"description\": \"Incorporate IDF into lateral expansion scoring at cortical/query/expansion.py:164 to penalize ubiquitous terms. Currently: score = weight * neighbor.pagerank * 0.6. Proposed: Add idf_factor to penalize terms that appear everywhere. Medium risk - requires testing to ensure good queries aren't hurt.\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"medium\",",
        "      \"created_at\": \"2025-12-14T23:31:16.045127\",",
        "      \"updated_at\": null,",
        "      \"completed_at\": null,",
        "      \"context\": {},",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"T-20251214-233136-3058-002\",",
        "      \"title\": \"Enable code stop word filtering by default in search\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"high\",",
        "      \"category\": \"bugfix\",",
        "      \"description\": \"Set filter_code_stop_words=True by default in find_documents_for_query() at cortical/query/search.py:54-59. This filters ubiquitous code tokens (def, self, return) from expansion, reducing noise in code search results. Low risk - filtering logic already exists and is tested.\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"small\",",
        "      \"created_at\": \"2025-12-14T23:31:36.020301\",",
        "      \"updated_at\": \"2025-12-14T23:46:35.265106\",",
        "      \"completed_at\": \"2025-12-14T23:46:35.265106\",",
        "      \"context\": {},",
        "      \"retrospective\": {",
        "        \"notes\": \"Implemented: filter_code_stop_words=True by default in find_documents_for_query and find_passages_for_query\",",
        "        \"duration_minutes\": 15,",
        "        \"files_touched\": [],",
        "        \"tests_added\": 0,",
        "        \"commits\": [],",
        "        \"captured_at\": \"2025-12-14T23:46:35.265137\"",
        "      }",
        "    },",
        "    {",
        "      \"id\": \"T-20251214-233140-3058-003\",",
        "      \"title\": \"Apply test file penalty by default in search\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"high\",",
        "      \"category\": \"bugfix\",",
        "      \"description\": \"Detect test files and apply 0.8 penalty in find_documents_for_query() at cortical/query/search.py. Files matching tests/ or test_ pattern should be penalized. Penalty already defined in constants.py. Low risk - easy implementation.\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"small\",",
        "      \"created_at\": \"2025-12-14T23:31:40.104443\",",
        "      \"updated_at\": \"2025-12-14T23:46:35.265139\",",
        "      \"completed_at\": \"2025-12-14T23:46:35.265139\",",
        "      \"context\": {},",
        "      \"retrospective\": {",
        "        \"notes\": \"Implemented: test_file_penalty=0.8 by default in find_documents_for_query and find_passages_for_query\",",
        "        \"duration_minutes\": 15,",
        "        \"files_touched\": [],",
        "        \"tests_added\": 0,",
        "        \"commits\": [],",
        "        \"captured_at\": \"2025-12-14T23:46:35.265142\"",
        "      }",
        "    },",
        "    {",
        "      \"id\": \"T-20251214-233143-3058-004\",",
        "      \"title\": \"Add security concept group to code_concepts.py\",",
        "      \"status\": \"pending\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"feature\",",
        "      \"description\": \"Add security-related terms to CODE_CONCEPT_GROUPS in cortical/code_concepts.py. Include: security, sanitize, validate, escape, injection, xss, csrf, fuzzing, exploit, vulnerability, attack, defense, protect, encrypt, decrypt, hash, permission, credential, token. Enables better query expansion for security-related searches.\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"small\",",
        "      \"created_at\": \"2025-12-14T23:31:43.882369\",",
        "      \"updated_at\": null,",
        "      \"completed_at\": null,",
        "      \"context\": {},",
        "      \"retrospective\": null",
        "    }",
        "  ]",
        "}"
      ],
      "lines_removed": [],
      "context_before": [],
      "context_after": [],
      "change_type": "add"
    },
    {
      "file": "tasks/2025-12-15_05-23-36_ceac.json",
      "function": null,
      "start_line": 0,
      "lines_added": [
        "{",
        "  \"version\": 1,",
        "  \"session_id\": \"ceac\",",
        "  \"started_at\": \"2025-12-15T05:23:36.072062\",",
        "  \"saved_at\": \"2025-12-15T05:24:40.799225\",",
        "  \"tasks\": [",
        "    {",
        "      \"id\": \"T-20251215-052336-ceac-001\",",
        "      \"title\": \"Add tests for query/search.py to improve coverage from 26% to >80%\",",
        "      \"status\": \"pending\",",
        "      \"priority\": \"high\",",
        "      \"category\": \"testing\",",
        "      \"description\": \"\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"medium\",",
        "      \"created_at\": \"2025-12-15T05:23:36.072891\",",
        "      \"updated_at\": null,",
        "      \"completed_at\": null,",
        "      \"context\": {},",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"T-20251215-052339-ceac-002\",",
        "      \"title\": \"Add tests for query/ranking.py to improve coverage from 25% to >80%\",",
        "      \"status\": \"pending\",",
        "      \"priority\": \"high\",",
        "      \"category\": \"testing\",",
        "      \"description\": \"\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"medium\",",
        "      \"created_at\": \"2025-12-15T05:23:39.292952\",",
        "      \"updated_at\": null,",
        "      \"completed_at\": null,",
        "      \"context\": {},",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"T-20251215-052342-ceac-003\",",
        "      \"title\": \"Add tests for query/passages.py to improve coverage from 43% to >80%\",",
        "      \"status\": \"pending\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"testing\",",
        "      \"description\": \"\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"medium\",",
        "      \"created_at\": \"2025-12-15T05:23:42.361308\",",
        "      \"updated_at\": null,",
        "      \"completed_at\": null,",
        "      \"context\": {},",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"T-20251215-052345-ceac-004\",",
        "      \"title\": \"Add tests for query/definitions.py to improve coverage from 30% to >80%\",",
        "      \"status\": \"pending\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"testing\",",
        "      \"description\": \"\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"medium\",",
        "      \"created_at\": \"2025-12-15T05:23:45.335215\",",
        "      \"updated_at\": null,",
        "      \"completed_at\": null,",
        "      \"context\": {},",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"T-20251215-052354-ceac-005\",",
        "      \"title\": \"Add tests for query/chunking.py to improve coverage from 43% to >80%\",",
        "      \"status\": \"pending\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"testing\",",
        "      \"description\": \"\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"medium\",",
        "      \"created_at\": \"2025-12-15T05:23:54.641886\",",
        "      \"updated_at\": null,",
        "      \"completed_at\": null,",
        "      \"context\": {},",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"T-20251215-052357-ceac-006\",",
        "      \"title\": \"Add tests for gaps.py to improve coverage from 9% to >80%\",",
        "      \"status\": \"pending\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"testing\",",
        "      \"description\": \"\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"medium\",",
        "      \"created_at\": \"2025-12-15T05:23:57.795144\",",
        "      \"updated_at\": null,",
        "      \"completed_at\": null,",
        "      \"context\": {},",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"T-20251215-052400-ceac-007\",",
        "      \"title\": \"Add tests for embeddings.py to improve coverage from 31% to >80%\",",
        "      \"status\": \"pending\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"testing\",",
        "      \"description\": \"\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"medium\",",
        "      \"created_at\": \"2025-12-15T05:24:00.910240\",",
        "      \"updated_at\": null,",
        "      \"completed_at\": null,",
        "      \"context\": {},",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"T-20251215-052403-ceac-008\",",
        "      \"title\": \"Add tests for diff.py to improve coverage from 30% to >80%\",",
        "      \"status\": \"pending\",",
        "      \"priority\": \"low\",",
        "      \"category\": \"testing\",",
        "      \"description\": \"\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"medium\",",
        "      \"created_at\": \"2025-12-15T05:24:03.990703\",",
        "      \"updated_at\": null,",
        "      \"completed_at\": null,",
        "      \"context\": {},",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"T-20251215-052412-ceac-009\",",
        "      \"title\": \"Add tests for patterns.py to improve coverage from 32% to >80%\",",
        "      \"status\": \"pending\",",
        "      \"priority\": \"low\",",
        "      \"category\": \"testing\",",
        "      \"description\": \"\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"medium\",",
        "      \"created_at\": \"2025-12-15T05:24:12.737164\",",
        "      \"updated_at\": null,",
        "      \"completed_at\": null,",
        "      \"context\": {},",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"T-20251215-052415-ceac-010\",",
        "      \"title\": \"Add tests for fluent.py to improve coverage from 25% to >80%\",",
        "      \"status\": \"pending\",",
        "      \"priority\": \"low\",",
        "      \"category\": \"testing\",",
        "      \"description\": \"\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"medium\",",
        "      \"created_at\": \"2025-12-15T05:24:15.646917\",",
        "      \"updated_at\": null,",
        "      \"completed_at\": null,",
        "      \"context\": {},",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"T-20251215-052418-ceac-011\",",
        "      \"title\": \"Add tests for code_concepts.py to improve coverage from 54% to >80%\",",
        "      \"status\": \"pending\",",
        "      \"priority\": \"low\",",
        "      \"category\": \"testing\",",
        "      \"description\": \"\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"medium\",",
        "      \"created_at\": \"2025-12-15T05:24:18.762807\",",
        "      \"updated_at\": null,",
        "      \"completed_at\": null,",
        "      \"context\": {},",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"T-20251215-052421-ceac-012\",",
        "      \"title\": \"Add tests for query/expansion.py to improve coverage from 53% to >80%\",",
        "      \"status\": \"pending\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"testing\",",
        "      \"description\": \"\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"medium\",",
        "      \"created_at\": \"2025-12-15T05:24:21.608203\",",
        "      \"updated_at\": null,",
        "      \"completed_at\": null,",
        "      \"context\": {},",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"T-20251215-052431-ceac-013\",",
        "      \"title\": \"Add tests for analysis.py to improve coverage from 60% to >80%\",",
        "      \"status\": \"pending\",",
        "      \"priority\": \"high\",",
        "      \"category\": \"testing\",",
        "      \"description\": \"\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"medium\",",
        "      \"created_at\": \"2025-12-15T05:24:31.651297\",",
        "      \"updated_at\": null,",
        "      \"completed_at\": null,",
        "      \"context\": {},",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"T-20251215-052434-ceac-014\",",
        "      \"title\": \"Add tests for semantics.py to improve coverage from 60% to >80%\",",
        "      \"status\": \"pending\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"testing\",",
        "      \"description\": \"\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"medium\",",
        "      \"created_at\": \"2025-12-15T05:24:34.754429\",",
        "      \"updated_at\": null,",
        "      \"completed_at\": null,",
        "      \"context\": {},",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"T-20251215-052437-ceac-015\",",
        "      \"title\": \"Add tests for config.py to improve coverage from 67% to >80%\",",
        "      \"status\": \"pending\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"testing\",",
        "      \"description\": \"\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"medium\",",
        "      \"created_at\": \"2025-12-15T05:24:37.732544\",",
        "      \"updated_at\": null,",
        "      \"completed_at\": null,",
        "      \"context\": {},",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"T-20251215-052440-ceac-016\",",
        "      \"title\": \"Add tests for fingerprint.py to improve coverage from 65% to >80%\",",
        "      \"status\": \"pending\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"testing\",",
        "      \"description\": \"\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"medium\",",
        "      \"created_at\": \"2025-12-15T05:24:40.799030\",",
        "      \"updated_at\": null,",
        "      \"completed_at\": null,",
        "      \"context\": {},",
        "      \"retrospective\": null",
        "    }",
        "  ]",
        "}"
      ],
      "lines_removed": [],
      "context_before": [],
      "context_after": [],
      "change_type": "add"
    },
    {
      "file": "tasks/legacy_migration.json",
      "function": null,
      "start_line": 1,
      "lines_added": [
        "  \"saved_at\": \"2025-12-14T21:43:24.122320\","
      ],
      "lines_removed": [
        "  \"saved_at\": \"2025-12-14T11:11:44.783627\","
      ],
      "context_before": [
        "{",
        "  \"version\": 1,",
        "  \"session_id\": \"legacy-migration\",",
        "  \"started_at\": \"2025-12-14T11:11:44.783627\","
      ],
      "context_after": [
        "  \"migration_info\": {",
        "    \"source\": \"TASK_LIST.md + TASK_ARCHIVE.md\",",
        "    \"migrated_at\": \"2025-12-14T11:11:44.783627\",",
        "    \"total_tasks\": 158,",
        "    \"completed\": 138,",
        "    \"pending\": 13,",
        "    \"deferred\": 7,",
        "    \"status_corrections_applied\": [",
        "      206,",
        "      134,"
      ],
      "change_type": "modify"
    },
    {
      "file": "tasks/legacy_migration.json",
      "function": null,
      "start_line": 1480,
      "lines_added": [
        "      \"status\": \"completed\",",
        "      \"completed_at\": \"2025-12-14T21:43:24.122320\",",
        "      \"retrospective\": \"Processor split was completed prior to this session. Verified processor/ package has 6 mixins: core.py, documents.py, compute.py, query_api.py, introspection.py, persistence_api.py\""
      ],
      "lines_removed": [
        "      \"status\": \"pending\",",
        "      \"completed_at\": null,",
        "      \"retrospective\": null"
      ],
      "context_before": [
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"completed_at\": \"2025-12-12T00:00:00\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 94",
        "      },",
        "      \"retrospective\": null",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-095\",",
        "      \"title\": \"Split processor.py into modules\","
      ],
      "context_after": [
        "      \"priority\": \"medium\",",
        "      \"category\": \"arch\",",
        "      \"description\": \"Correction: processor.py still 3115 lines - not split into modules\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\",",
        "      \"created_at\": \"2025-12-10T00:00:00\",",
        "      \"updated_at\": \"2025-12-14T11:11:44.783627\",",
        "      \"context\": {",
        "        \"legacy_task_number\": 95",
        "      },",
        "    },",
        "    {",
        "      \"id\": \"LEGACY-096\",",
        "      \"title\": \"Centralize Duplicate Constants\",",
        "      \"status\": \"completed\",",
        "      \"priority\": \"medium\",",
        "      \"category\": \"code-quality\",",
        "      \"description\": \"Migrated from legacy TASK_LIST.md task #96\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"unknown\","
      ],
      "change_type": "modify"
    },
    {
      "file": "tests/test_edge_cases.py",
      "function": "class TestComputationEdgeCases(unittest.TestCase):",
      "start_line": 494,
      "lines_added": [
        "        \"\"\"Test scoring computation with single document.\"\"\"",
        "        from cortical.config import CorticalConfig",
        "",
        "        # Test with TF-IDF (IDF = log(1/1) = 0 for single doc)",
        "        config_tfidf = CorticalConfig(scoring_algorithm='tfidf')",
        "        processor_tfidf = CorticalTextProcessor(config=config_tfidf)",
        "        processor_tfidf.process_document(\"only_doc\", \"neural networks machine learning\")",
        "        processor_tfidf.compute_tfidf(verbose=False)",
        "        layer0 = processor_tfidf.get_layer(CorticalLayer.TOKENS)",
        "            # TF-IDF should be 0 for single document corpus (IDF = log(1/1) = 0)",
        "        # Test with BM25 (uses different IDF formula, won't be zero)",
        "        config_bm25 = CorticalConfig(scoring_algorithm='bm25')",
        "        processor_bm25 = CorticalTextProcessor(config=config_bm25)",
        "        processor_bm25.process_document(\"only_doc\", \"neural networks machine learning\")",
        "        processor_bm25.compute_tfidf(verbose=False)",
        "",
        "        layer0_bm25 = processor_bm25.get_layer(CorticalLayer.TOKENS)",
        "        for col in layer0_bm25:",
        "            # BM25 IDF = log((N-df+0.5)/(df+0.5)+1) > 0 even for single doc",
        "            self.assertGreater(col.tfidf, 0.0)",
        ""
      ],
      "lines_removed": [
        "        \"\"\"Test TF-IDF computation with single document.\"\"\"",
        "        processor = CorticalTextProcessor()",
        "        processor.process_document(\"only_doc\", \"neural networks machine learning\")",
        "        processor.compute_tfidf(verbose=False)",
        "        # With single document, IDF should be 0 (log(1/1) = 0)",
        "        layer0 = processor.get_layer(CorticalLayer.TOKENS)",
        "            # TF-IDF should be 0 for single document corpus"
      ],
      "context_before": [
        "    def test_compute_all_on_empty_corpus(self):",
        "        \"\"\"Test compute_all on empty processor.\"\"\"",
        "        processor = CorticalTextProcessor()",
        "        # Should handle gracefully without crashing",
        "        try:",
        "            processor.compute_all(verbose=False)",
        "        except Exception as e:",
        "            self.fail(f\"compute_all on empty corpus raised {type(e).__name__}: {e}\")",
        "",
        "    def test_compute_tfidf_single_document(self):"
      ],
      "context_after": [
        "",
        "        for col in layer0:",
        "            self.assertEqual(col.tfidf, 0.0)",
        "",
        "    def test_compute_importance_on_disconnected_graph(self):",
        "        \"\"\"Test PageRank on graph with no connections.\"\"\"",
        "        processor = CorticalTextProcessor()",
        "        # Single word documents with no shared terms",
        "        processor.process_document(\"doc1\", \"aardvark\")",
        "        processor.process_document(\"doc2\", \"zeppelin\")",
        "",
        "        # compute_importance should handle disconnected components",
        "        try:",
        "            processor.compute_importance(verbose=False)"
      ],
      "change_type": "modify"
    },
    {
      "file": "tests/unit/test_new_memory.py",
      "function": null,
      "start_line": 0,
      "lines_added": [
        "\"\"\"",
        "Unit tests for scripts/new_memory.py.",
        "",
        "Tests memory and decision record creation utilities including:",
        "- Filename generation with merge-safe timestamps",
        "- Slugification of titles",
        "- Template generation for memories and decisions",
        "- File creation and dry-run mode",
        "\"\"\"",
        "",
        "import os",
        "import sys",
        "import tempfile",
        "import unittest",
        "from datetime import datetime",
        "from pathlib import Path",
        "from unittest.mock import patch, MagicMock",
        "",
        "# Add scripts to path",
        "sys.path.insert(0, str(Path(__file__).parent.parent.parent / \"scripts\"))",
        "",
        "from new_memory import (",
        "    generate_memory_filename,",
        "    slugify,",
        "    get_git_author,",
        "    create_memory_template,",
        "    create_decision_template,",
        "    create_memory,",
        "    MEMORIES_DIR,",
        "    DECISIONS_DIR,",
        ")",
        "",
        "",
        "class TestSlugify(unittest.TestCase):",
        "    \"\"\"Tests for slugify function.\"\"\"",
        "",
        "    def test_converts_spaces_to_hyphens(self):",
        "        \"\"\"Spaces should be converted to hyphens.\"\"\"",
        "        self.assertEqual(slugify(\"hello world\"), \"hello-world\")",
        "        self.assertEqual(slugify(\"foo bar baz\"), \"foo-bar-baz\")",
        "",
        "    def test_removes_special_characters(self):",
        "        \"\"\"Special characters should be removed.\"\"\"",
        "        self.assertEqual(slugify(\"hello!world\"), \"helloworld\")",
        "        self.assertEqual(slugify(\"test@#$%case\"), \"testcase\")",
        "        self.assertEqual(slugify(\"a/b\\\\c*d?e\"), \"abcde\")",
        "",
        "    def test_lowercases_text(self):",
        "        \"\"\"Text should be lowercased.\"\"\"",
        "        self.assertEqual(slugify(\"HELLO\"), \"hello\")",
        "        self.assertEqual(slugify(\"CamelCase\"), \"camelcase\")",
        "        self.assertEqual(slugify(\"MiXeD CaSe\"), \"mixed-case\")",
        "",
        "    def test_handles_empty_string(self):",
        "        \"\"\"Empty string should return empty string.\"\"\"",
        "        self.assertEqual(slugify(\"\"), \"\")",
        "        self.assertEqual(slugify(\"   \"), \"\")",
        "",
        "    def test_removes_duplicate_hyphens(self):",
        "        \"\"\"Duplicate hyphens should be collapsed.\"\"\"",
        "        self.assertEqual(slugify(\"foo--bar\"), \"foo-bar\")",
        "        self.assertEqual(slugify(\"a   b\"), \"a-b\")",
        "        self.assertEqual(slugify(\"hello---world\"), \"hello-world\")",
        "",
        "    def test_truncates_long_strings(self):",
        "        \"\"\"Strings longer than 50 chars should be truncated.\"\"\"",
        "        long_text = \"a\" * 100",
        "        result = slugify(long_text)",
        "        self.assertEqual(len(result), 50)",
        "",
        "    def test_handles_unicode(self):",
        "        \"\"\"Unicode characters should be handled gracefully.\"\"\"",
        "        # Python's isalnum() preserves unicode letters",
        "        self.assertEqual(slugify(\"caf√©\"), \"caf√©\")",
        "        self.assertEqual(slugify(\"na√Øve\"), \"na√Øve\")",
        "        # Only non-alphanumeric symbols are removed",
        "        self.assertEqual(slugify(\"hello!‰∏ñÁïå\"), \"hello‰∏ñÁïå\")",
        "",
        "    def test_strips_leading_trailing_whitespace(self):",
        "        \"\"\"Leading/trailing whitespace should be stripped.\"\"\"",
        "        self.assertEqual(slugify(\"  hello  \"), \"hello\")",
        "        self.assertEqual(slugify(\"\\tfoo bar\\n\"), \"foo-bar\")",
        "",
        "    def test_real_world_examples(self):",
        "        \"\"\"Test real-world memory title examples.\"\"\"",
        "        self.assertEqual(",
        "            slugify(\"learned about NaN validation\"),",
        "            \"learned-about-nan-validation\"",
        "        )",
        "        self.assertEqual(",
        "            slugify(\"add microseconds to timestamps\"),",
        "            \"add-microseconds-to-timestamps\"",
        "        )",
        "        self.assertEqual(",
        "            slugify(\"Why we chose PostgreSQL\"),",
        "            \"why-we-chose-postgresql\"",
        "        )",
        "",
        "",
        "class TestGenerateMemoryFilename(unittest.TestCase):",
        "    \"\"\"Tests for generate_memory_filename function.\"\"\"",
        "",
        "    @patch('new_memory.generate_session_id')",
        "    @patch('new_memory.datetime')",
        "    def test_correct_format(self, mock_datetime, mock_session_id):",
        "        \"\"\"Filename should have format YYYY-MM-DD_HH-MM-SS_XXXX-topic.md.\"\"\"",
        "        # Mock datetime",
        "        mock_now = MagicMock()",
        "        mock_now.strftime.side_effect = lambda fmt: {",
        "            \"%Y-%m-%d\": \"2025-12-14\",",
        "            \"%H-%M-%S\": \"14-30-52\"",
        "        }[fmt]",
        "        mock_datetime.now.return_value = mock_now",
        "",
        "        # Mock session ID",
        "        mock_session_id.return_value = \"a1b2\"",
        "",
        "        result = generate_memory_filename(\"test topic\")",
        "        self.assertEqual(result, \"2025-12-14_14-30-52_a1b2-test-topic.md\")",
        "",
        "    @patch('new_memory.generate_session_id')",
        "    @patch('new_memory.datetime')",
        "    def test_handles_empty_topic(self, mock_datetime, mock_session_id):",
        "        \"\"\"Empty topic should still generate valid filename.\"\"\"",
        "        mock_now = MagicMock()",
        "        mock_now.strftime.side_effect = lambda fmt: {",
        "            \"%Y-%m-%d\": \"2025-12-14\",",
        "            \"%H-%M-%S\": \"14-30-52\"",
        "        }[fmt]",
        "        mock_datetime.now.return_value = mock_now",
        "        mock_session_id.return_value = \"a1b2\"",
        "",
        "        result = generate_memory_filename(\"\")",
        "        self.assertEqual(result, \"2025-12-14_14-30-52_a1b2-.md\")",
        "",
        "    @patch('new_memory.generate_session_id')",
        "    @patch('new_memory.datetime')",
        "    def test_handles_special_characters_in_topic(self, mock_datetime, mock_session_id):",
        "        \"\"\"Special characters in topic should be slugified.\"\"\"",
        "        mock_now = MagicMock()",
        "        mock_now.strftime.side_effect = lambda fmt: {",
        "            \"%Y-%m-%d\": \"2025-12-14\",",
        "            \"%H-%M-%S\": \"14-30-52\"",
        "        }[fmt]",
        "        mock_datetime.now.return_value = mock_now",
        "        mock_session_id.return_value = \"a1b2\"",
        "",
        "        result = generate_memory_filename(\"Test! @#$ Topic?\")",
        "        self.assertEqual(result, \"2025-12-14_14-30-52_a1b2-test-topic.md\")",
        "",
        "    @patch('new_memory.generate_session_id')",
        "    @patch('new_memory.datetime')",
        "    def test_decision_flag_ignored_in_filename(self, mock_datetime, mock_session_id):",
        "        \"\"\"is_decision parameter doesn't affect filename format.\"\"\"",
        "        mock_now = MagicMock()",
        "        mock_now.strftime.side_effect = lambda fmt: {",
        "            \"%Y-%m-%d\": \"2025-12-14\",",
        "            \"%H-%M-%S\": \"14-30-52\"",
        "        }[fmt]",
        "        mock_datetime.now.return_value = mock_now",
        "        mock_session_id.return_value = \"a1b2\"",
        "",
        "        # Decision flag doesn't change filename format",
        "        result1 = generate_memory_filename(\"test\", is_decision=False)",
        "        result2 = generate_memory_filename(\"test\", is_decision=True)",
        "        self.assertEqual(result1, result2)",
        "",
        "",
        "class TestGetGitAuthor(unittest.TestCase):",
        "    \"\"\"Tests for get_git_author function.\"\"\"",
        "",
        "    @patch('new_memory.subprocess.run')",
        "    def test_returns_author_on_success(self, mock_run):",
        "        \"\"\"Should return git user.name when command succeeds.\"\"\"",
        "        mock_result = MagicMock()",
        "        mock_result.returncode = 0",
        "        mock_result.stdout = \"John Doe\\n\"",
        "        mock_run.return_value = mock_result",
        "",
        "        result = get_git_author()",
        "        self.assertEqual(result, \"John Doe\")",
        "        mock_run.assert_called_once_with(",
        "            [\"git\", \"config\", \"user.name\"],",
        "            capture_output=True,",
        "            text=True,",
        "            timeout=2",
        "        )",
        "",
        "    @patch('new_memory.subprocess.run')",
        "    def test_returns_unknown_on_failure(self, mock_run):",
        "        \"\"\"Should return 'Unknown' when git command fails.\"\"\"",
        "        mock_result = MagicMock()",
        "        mock_result.returncode = 1",
        "        mock_run.return_value = mock_result",
        "",
        "        result = get_git_author()",
        "        self.assertEqual(result, \"Unknown\")",
        "",
        "    @patch('new_memory.subprocess.run')",
        "    def test_handles_timeout(self, mock_run):",
        "        \"\"\"Should return 'Unknown' on timeout.\"\"\"",
        "        from subprocess import TimeoutExpired",
        "        mock_run.side_effect = TimeoutExpired(\"git\", 2)",
        "",
        "        result = get_git_author()",
        "        self.assertEqual(result, \"Unknown\")",
        "",
        "    @patch('new_memory.subprocess.run')",
        "    def test_handles_file_not_found(self, mock_run):",
        "        \"\"\"Should return 'Unknown' if git not installed.\"\"\"",
        "        mock_run.side_effect = FileNotFoundError()",
        "",
        "        result = get_git_author()",
        "        self.assertEqual(result, \"Unknown\")",
        "",
        "",
        "class TestCreateMemoryTemplate(unittest.TestCase):",
        "    \"\"\"Tests for create_memory_template function.\"\"\"",
        "",
        "    @patch('new_memory.datetime')",
        "    def test_contains_required_sections(self, mock_datetime):",
        "        \"\"\"Template should contain all required memory sections.\"\"\"",
        "        mock_now = MagicMock()",
        "        mock_now.strftime.side_effect = lambda fmt: {",
        "            \"%Y-%m-%d\": \"2025-12-14\",",
        "            \"%Y-%m-%dT%H:%M:%SZ\": \"2025-12-14T14:30:52Z\"",
        "        }[fmt]",
        "        mock_datetime.now.return_value = mock_now",
        "",
        "        template = create_memory_template(\"test topic\")",
        "",
        "        # Check for required sections",
        "        self.assertIn(\"# Memory Entry:\", template)",
        "        self.assertIn(\"**Tags:**\", template)",
        "        self.assertIn(\"**Related:**\", template)",
        "        self.assertIn(\"## Context\", template)",
        "        self.assertIn(\"## What I Learned\", template)",
        "        self.assertIn(\"## Connections Made\", template)",
        "        self.assertIn(\"## Emotional State\", template)",
        "        self.assertIn(\"## Future Exploration\", template)",
        "        self.assertIn(\"## Artifacts Created\", template)",
        "",
        "    @patch('new_memory.datetime')",
        "    def test_includes_title(self, mock_datetime):",
        "        \"\"\"Template should include the provided title.\"\"\"",
        "        mock_now = MagicMock()",
        "        mock_now.strftime.side_effect = lambda fmt: {",
        "            \"%Y-%m-%d\": \"2025-12-14\",",
        "            \"%Y-%m-%dT%H:%M:%SZ\": \"2025-12-14T14:30:52Z\"",
        "        }[fmt]",
        "        mock_datetime.now.return_value = mock_now",
        "",
        "        template = create_memory_template(\"learning about pagerank\")",
        "        self.assertIn(\"Learning About Pagerank\", template)",
        "",
        "    @patch('new_memory.datetime')",
        "    def test_includes_tags_when_provided(self, mock_datetime):",
        "        \"\"\"Template should include formatted tags.\"\"\"",
        "        mock_now = MagicMock()",
        "        mock_now.strftime.side_effect = lambda fmt: {",
        "            \"%Y-%m-%d\": \"2025-12-14\",",
        "            \"%Y-%m-%dT%H:%M:%SZ\": \"2025-12-14T14:30:52Z\"",
        "        }[fmt]",
        "        mock_datetime.now.return_value = mock_now",
        "",
        "        template = create_memory_template(\"test\", tags=\"testing,validation,bugfix\")",
        "        self.assertIn(\"`testing`\", template)",
        "        self.assertIn(\"`validation`\", template)",
        "        self.assertIn(\"`bugfix`\", template)",
        "",
        "    @patch('new_memory.datetime')",
        "    def test_empty_tags_when_not_provided(self, mock_datetime):",
        "        \"\"\"Template should have empty tags section when no tags provided.\"\"\"",
        "        mock_now = MagicMock()",
        "        mock_now.strftime.side_effect = lambda fmt: {",
        "            \"%Y-%m-%d\": \"2025-12-14\",",
        "            \"%Y-%m-%dT%H:%M:%SZ\": \"2025-12-14T14:30:52Z\"",
        "        }[fmt]",
        "        mock_datetime.now.return_value = mock_now",
        "",
        "        template = create_memory_template(\"test\", tags=\"\")",
        "        # Should have Tags: line but empty",
        "        self.assertIn(\"**Tags:**\", template)",
        "        # No backtick-wrapped tags",
        "        self.assertNotIn(\"`test`\", template)",
        "",
        "    @patch('new_memory.datetime')",
        "    def test_includes_timestamp(self, mock_datetime):",
        "        \"\"\"Template should include commit timestamp.\"\"\"",
        "        mock_now = MagicMock()",
        "        mock_now.strftime.side_effect = lambda fmt: {",
        "            \"%Y-%m-%d\": \"2025-12-14\",",
        "            \"%Y-%m-%dT%H:%M:%SZ\": \"2025-12-14T14:30:52Z\"",
        "        }[fmt]",
        "        mock_datetime.now.return_value = mock_now",
        "",
        "        template = create_memory_template(\"test\")",
        "        self.assertIn(\"*Committed to memory at: 2025-12-14T14:30:52Z*\", template)",
        "",
        "    @patch('new_memory.datetime')",
        "    def test_author_parameter_not_used(self, mock_datetime):",
        "        \"\"\"Author parameter exists but is not used in template.\"\"\"",
        "        mock_now = MagicMock()",
        "        mock_now.strftime.side_effect = lambda fmt: {",
        "            \"%Y-%m-%d\": \"2025-12-14\",",
        "            \"%Y-%m-%dT%H:%M:%SZ\": \"2025-12-14T14:30:52Z\"",
        "        }[fmt]",
        "        mock_datetime.now.return_value = mock_now",
        "",
        "        # Author parameter accepted but not used",
        "        template = create_memory_template(\"test\", author=\"John Doe\")",
        "        self.assertNotIn(\"John Doe\", template)",
        "",
        "",
        "class TestCreateDecisionTemplate(unittest.TestCase):",
        "    \"\"\"Tests for create_decision_template function.\"\"\"",
        "",
        "    @patch('new_memory.datetime')",
        "    @patch('new_memory.DECISIONS_DIR')",
        "    def test_contains_adr_sections(self, mock_decisions_dir, mock_datetime):",
        "        \"\"\"Template should contain ADR sections.\"\"\"",
        "        mock_now = MagicMock()",
        "        mock_now.strftime.return_value = \"2025-12-14\"",
        "        mock_datetime.now.return_value = mock_now",
        "",
        "        # Mock no existing ADR files",
        "        mock_decisions_dir.glob.return_value = []",
        "",
        "        template = create_decision_template(\"test decision\")",
        "",
        "        # Check for ADR sections",
        "        self.assertIn(\"ADR-001:\", template)",
        "        self.assertIn(\"**Status:**\", template)",
        "        self.assertIn(\"**Date:**\", template)",
        "        self.assertIn(\"**Deciders:**\", template)",
        "        self.assertIn(\"## Context and Problem Statement\", template)",
        "        self.assertIn(\"## Decision Drivers\", template)",
        "        self.assertIn(\"## Considered Options\", template)",
        "        self.assertIn(\"## Decision Outcome\", template)",
        "        self.assertIn(\"## Implementation\", template)",
        "        self.assertIn(\"## Consequences\", template)",
        "        self.assertIn(\"## Validation\", template)",
        "        self.assertIn(\"## Related Decisions\", template)",
        "",
        "    @patch('new_memory.datetime')",
        "    @patch('new_memory.DECISIONS_DIR')",
        "    def test_adr_number_starts_at_001(self, mock_decisions_dir, mock_datetime):",
        "        \"\"\"First ADR should be numbered 001.\"\"\"",
        "        mock_now = MagicMock()",
        "        mock_now.strftime.return_value = \"2025-12-14\"",
        "        mock_datetime.now.return_value = mock_now",
        "",
        "        # No existing files",
        "        mock_decisions_dir.glob.return_value = []",
        "",
        "        template = create_decision_template(\"test\")",
        "        self.assertIn(\"# ADR-001:\", template)",
        "",
        "    @patch('new_memory.datetime')",
        "    @patch('new_memory.DECISIONS_DIR')",
        "    def test_adr_number_increments(self, mock_decisions_dir, mock_datetime):",
        "        \"\"\"ADR number should increment based on existing files.\"\"\"",
        "        mock_now = MagicMock()",
        "        mock_now.strftime.return_value = \"2025-12-14\"",
        "        mock_datetime.now.return_value = mock_now",
        "",
        "        # Mock existing ADR files",
        "        mock_file1 = MagicMock()",
        "        mock_file1.stem = \"adr-001-first-decision\"",
        "        mock_file2 = MagicMock()",
        "        mock_file2.stem = \"adr-002-second-decision\"",
        "        mock_decisions_dir.glob.return_value = [mock_file1, mock_file2]",
        "",
        "        template = create_decision_template(\"third decision\")",
        "        self.assertIn(\"# ADR-003:\", template)",
        "",
        "    @patch('new_memory.datetime')",
        "    @patch('new_memory.DECISIONS_DIR')",
        "    def test_adr_number_handles_gaps(self, mock_decisions_dir, mock_datetime):",
        "        \"\"\"ADR number should use max + 1 even with gaps.\"\"\"",
        "        mock_now = MagicMock()",
        "        mock_now.strftime.return_value = \"2025-12-14\"",
        "        mock_datetime.now.return_value = mock_now",
        "",
        "        # Mock existing ADR files with gaps",
        "        mock_file1 = MagicMock()",
        "        mock_file1.stem = \"adr-001-first\"",
        "        mock_file2 = MagicMock()",
        "        mock_file2.stem = \"adr-005-fifth\"",
        "        mock_decisions_dir.glob.return_value = [mock_file1, mock_file2]",
        "",
        "        template = create_decision_template(\"next decision\")",
        "        self.assertIn(\"# ADR-006:\", template)",
        "",
        "    @patch('new_memory.datetime')",
        "    @patch('new_memory.DECISIONS_DIR')",
        "    def test_adr_number_ignores_invalid_filenames(self, mock_decisions_dir, mock_datetime):",
        "        \"\"\"Should ignore files that don't match adr-NNN pattern.\"\"\"",
        "        mock_now = MagicMock()",
        "        mock_now.strftime.return_value = \"2025-12-14\"",
        "        mock_datetime.now.return_value = mock_now",
        "",
        "        # Mix of valid and invalid filenames",
        "        mock_file1 = MagicMock()",
        "        mock_file1.stem = \"adr-001-valid\"",
        "        mock_file2 = MagicMock()",
        "        mock_file2.stem = \"not-an-adr\"",
        "        mock_file3 = MagicMock()",
        "        mock_file3.stem = \"adr-abc-invalid\"",
        "        mock_decisions_dir.glob.return_value = [mock_file1, mock_file2, mock_file3]",
        "",
        "        template = create_decision_template(\"test\")",
        "        self.assertIn(\"# ADR-002:\", template)",
        "",
        "    @patch('new_memory.datetime')",
        "    @patch('new_memory.DECISIONS_DIR')",
        "    def test_includes_title(self, mock_decisions_dir, mock_datetime):",
        "        \"\"\"Template should include the decision title.\"\"\"",
        "        mock_now = MagicMock()",
        "        mock_now.strftime.return_value = \"2025-12-14\"",
        "        mock_datetime.now.return_value = mock_now",
        "        mock_decisions_dir.glob.return_value = []",
        "",
        "        template = create_decision_template(\"use postgresql for storage\")",
        "        self.assertIn(\"Use Postgresql For Storage\", template)",
        "",
        "    @patch('new_memory.datetime')",
        "    @patch('new_memory.DECISIONS_DIR')",
        "    def test_includes_tags_when_provided(self, mock_decisions_dir, mock_datetime):",
        "        \"\"\"Template should include formatted tags.\"\"\"",
        "        mock_now = MagicMock()",
        "        mock_now.strftime.return_value = \"2025-12-14\"",
        "        mock_datetime.now.return_value = mock_now",
        "        mock_decisions_dir.glob.return_value = []",
        "",
        "        template = create_decision_template(\"test\", tags=\"architecture,database\")",
        "        self.assertIn(\"`architecture`\", template)",
        "        self.assertIn(\"`database`\", template)",
        "",
        "    @patch('new_memory.datetime')",
        "    @patch('new_memory.DECISIONS_DIR')",
        "    def test_handles_glob_exception(self, mock_decisions_dir, mock_datetime):",
        "        \"\"\"Should handle exceptions when reading existing files.\"\"\"",
        "        mock_now = MagicMock()",
        "        mock_now.strftime.return_value = \"2025-12-14\"",
        "        mock_datetime.now.return_value = mock_now",
        "",
        "        # Simulate exception",
        "        mock_decisions_dir.glob.side_effect = Exception(\"Permission denied\")",
        "",
        "        # Should default to ADR-001",
        "        template = create_decision_template(\"test\")",
        "        self.assertIn(\"# ADR-001:\", template)",
        "",
        "",
        "class TestCreateMemory(unittest.TestCase):",
        "    \"\"\"Tests for create_memory integration function.\"\"\"",
        "",
        "    def setUp(self):",
        "        \"\"\"Create temporary directory for test files.\"\"\"",
        "        self.temp_dir = tempfile.mkdtemp()",
        "        self.original_memories_dir = MEMORIES_DIR",
        "        self.original_decisions_dir = DECISIONS_DIR",
        "",
        "    def tearDown(self):",
        "        \"\"\"Clean up temporary directory.\"\"\"",
        "        import shutil",
        "        shutil.rmtree(self.temp_dir, ignore_errors=True)",
        "",
        "    @patch('new_memory.DECISIONS_DIR', new_callable=lambda: Path(tempfile.mkdtemp()))",
        "    @patch('new_memory.MEMORIES_DIR', new_callable=lambda: Path(tempfile.mkdtemp()))",
        "    @patch('new_memory.get_git_author')",
        "    def test_dry_run_does_not_create_file(self, mock_author, mock_mem_dir, mock_dec_dir):",
        "        \"\"\"Dry-run should not create any files.\"\"\"",
        "        mock_author.return_value = \"Test User\"",
        "",
        "        # Dry-run",
        "        filepath = create_memory(\"test topic\", dry_run=True)",
        "",
        "        # File should not exist",
        "        self.assertFalse(filepath.exists())",
        "",
        "        # Clean up mocked directories",
        "        import shutil",
        "        shutil.rmtree(mock_mem_dir, ignore_errors=True)",
        "        shutil.rmtree(mock_dec_dir, ignore_errors=True)",
        "",
        "    @patch('new_memory.get_git_author')",
        "    def test_creates_memory_file(self, mock_author):",
        "        \"\"\"Should create memory file with correct name.\"\"\"",
        "        mock_author.return_value = \"Test User\"",
        "",
        "        # Create in temp directory",
        "        with patch('new_memory.MEMORIES_DIR', Path(self.temp_dir)):",
        "            filepath = create_memory(\"test topic\")",
        "",
        "            # File should exist",
        "            self.assertTrue(filepath.exists())",
        "",
        "            # Should be in memories directory",
        "            self.assertEqual(filepath.parent, Path(self.temp_dir))",
        "",
        "            # Should be markdown",
        "            self.assertTrue(filepath.name.endswith(\".md\"))",
        "",
        "            # Should contain topic in filename",
        "            self.assertIn(\"test-topic\", filepath.name)",
        "",
        "    @patch('new_memory.get_git_author')",
        "    def test_creates_decision_file(self, mock_author):",
        "        \"\"\"Should create decision file when is_decision=True.\"\"\"",
        "        mock_author.return_value = \"Test User\"",
        "",
        "        with patch('new_memory.DECISIONS_DIR', Path(self.temp_dir)):",
        "            filepath = create_memory(\"test decision\", is_decision=True)",
        "",
        "            # File should exist",
        "            self.assertTrue(filepath.exists())",
        "",
        "            # Should be markdown",
        "            self.assertTrue(filepath.name.endswith(\".md\"))",
        "",
        "    @patch('new_memory.get_git_author')",
        "    def test_file_contains_correct_content_memory(self, mock_author):",
        "        \"\"\"Memory file should contain correct content.\"\"\"",
        "        mock_author.return_value = \"Test User\"",
        "",
        "        with patch('new_memory.MEMORIES_DIR', Path(self.temp_dir)):",
        "            filepath = create_memory(\"test topic\", tags=\"testing,validation\")",
        "",
        "            # Read file",
        "            content = filepath.read_text()",
        "",
        "            # Check content",
        "            self.assertIn(\"# Memory Entry:\", content)",
        "            self.assertIn(\"`testing`\", content)",
        "            self.assertIn(\"`validation`\", content)",
        "            self.assertIn(\"## What I Learned\", content)",
        "",
        "    @patch('new_memory.get_git_author')",
        "    def test_file_contains_correct_content_decision(self, mock_author):",
        "        \"\"\"Decision file should contain ADR content.\"\"\"",
        "        mock_author.return_value = \"Test User\"",
        "",
        "        with patch('new_memory.DECISIONS_DIR', Path(self.temp_dir)):",
        "            filepath = create_memory(\"test decision\", is_decision=True)",
        "",
        "            # Read file",
        "            content = filepath.read_text()",
        "",
        "            # Check content",
        "            self.assertIn(\"# ADR-001:\", content)",
        "            self.assertIn(\"**Status:**\", content)",
        "            self.assertIn(\"## Decision Outcome\", content)",
        "",
        "    @patch('new_memory.get_git_author')",
        "    def test_creates_directory_if_missing(self, mock_author):",
        "        \"\"\"Should create target directory if it doesn't exist.\"\"\"",
        "        mock_author.return_value = \"Test User\"",
        "",
        "        # Use non-existent subdirectory",
        "        new_dir = Path(self.temp_dir) / \"new_memories\"",
        "        self.assertFalse(new_dir.exists())",
        "",
        "        with patch('new_memory.MEMORIES_DIR', new_dir):",
        "            filepath = create_memory(\"test topic\")",
        "",
        "            # Directory should now exist",
        "            self.assertTrue(new_dir.exists())",
        "            self.assertTrue(filepath.exists())",
        "",
        "    @patch('new_memory.get_git_author')",
        "    def test_handles_special_characters_in_title(self, mock_author):",
        "        \"\"\"Should handle special characters in title.\"\"\"",
        "        mock_author.return_value = \"Test User\"",
        "",
        "        with patch('new_memory.MEMORIES_DIR', Path(self.temp_dir)):",
        "            filepath = create_memory(\"Test! @#$ Topic?\")",
        "",
        "            # Should create valid filename",
        "            self.assertTrue(filepath.exists())",
        "            # Special chars should be removed",
        "            self.assertIn(\"test-topic\", filepath.name)",
        "",
        "    @patch('new_memory.get_git_author')",
        "    @patch('new_memory.datetime')",
        "    def test_dry_run_shows_preview(self, mock_datetime, mock_author):",
        "        \"\"\"Dry-run should print preview without creating file.\"\"\"",
        "        import io",
        "        from contextlib import redirect_stdout",
        "",
        "        mock_author.return_value = \"Test User\"",
        "        mock_now = MagicMock()",
        "        mock_now.strftime.side_effect = lambda fmt: {",
        "            \"%Y-%m-%d\": \"2025-12-14\",",
        "            \"%H-%M-%S\": \"14-30-52\",",
        "            \"%Y-%m-%dT%H:%M:%SZ\": \"2025-12-14T14:30:52Z\"",
        "        }.get(fmt, \"2025-12-14\")",
        "        mock_datetime.now.return_value = mock_now",
        "",
        "        with patch('new_memory.MEMORIES_DIR', Path(self.temp_dir)):",
        "            # Capture output",
        "            output = io.StringIO()",
        "            with redirect_stdout(output):",
        "                filepath = create_memory(\"test\", dry_run=True)",
        "",
        "            # Check output",
        "            output_str = output.getvalue()",
        "            self.assertIn(\"DRY RUN\", output_str)",
        "            self.assertIn(\"Would create:\", output_str)",
        "",
        "            # File should not exist",
        "            self.assertFalse(filepath.exists())",
        "",
        "",
        "class TestFilenameFormat(unittest.TestCase):",
        "    \"\"\"Integration tests for filename format consistency.\"\"\"",
        "",
        "    @patch('new_memory.generate_session_id')",
        "    @patch('new_memory.datetime')",
        "    def test_filename_uniqueness(self, mock_datetime, mock_session_id):",
        "        \"\"\"Multiple calls should generate unique filenames.\"\"\"",
        "        # First call",
        "        mock_now1 = MagicMock()",
        "        mock_now1.strftime.side_effect = lambda fmt: {",
        "            \"%Y-%m-%d\": \"2025-12-14\",",
        "            \"%H-%M-%S\": \"14-30-52\"",
        "        }[fmt]",
        "        mock_datetime.now.return_value = mock_now1",
        "        mock_session_id.return_value = \"a1b2\"",
        "",
        "        filename1 = generate_memory_filename(\"test\")",
        "",
        "        # Second call with different session ID",
        "        mock_now2 = MagicMock()",
        "        mock_now2.strftime.side_effect = lambda fmt: {",
        "            \"%Y-%m-%d\": \"2025-12-14\",",
        "            \"%H-%M-%S\": \"14-30-52\"",
        "        }[fmt]",
        "        mock_datetime.now.return_value = mock_now2",
        "        mock_session_id.return_value = \"c3d4\"",
        "",
        "        filename2 = generate_memory_filename(\"test\")",
        "",
        "        # Should be different due to session ID",
        "        self.assertNotEqual(filename1, filename2)",
        "",
        "    @patch('new_memory.generate_session_id')",
        "    @patch('new_memory.datetime')",
        "    def test_filename_parts_accessible(self, mock_datetime, mock_session_id):",
        "        \"\"\"Filename parts should be parseable.\"\"\"",
        "        mock_now = MagicMock()",
        "        mock_now.strftime.side_effect = lambda fmt: {",
        "            \"%Y-%m-%d\": \"2025-12-14\",",
        "            \"%H-%M-%S\": \"14-30-52\"",
        "        }[fmt]",
        "        mock_datetime.now.return_value = mock_now",
        "        mock_session_id.return_value = \"a1b2\"",
        "",
        "        filename = generate_memory_filename(\"test topic\")",
        "",
        "        # Remove .md extension",
        "        base = filename[:-3]",
        "",
        "        # Split parts",
        "        parts = base.split(\"_\")",
        "        self.assertEqual(len(parts), 3)",
        "",
        "        # Date part",
        "        self.assertEqual(parts[0], \"2025-12-14\")",
        "",
        "        # Time part",
        "        self.assertEqual(parts[1], \"14-30-52\")",
        "",
        "        # Session + topic part",
        "        self.assertTrue(parts[2].startswith(\"a1b2-\"))",
        "",
        "",
        "if __name__ == \"__main__\":",
        "    unittest.main()"
      ],
      "lines_removed": [],
      "context_before": [],
      "context_after": [],
      "change_type": "add"
    },
    {
      "file": "tests/unit/test_observability.py",
      "function": null,
      "start_line": 0,
      "lines_added": [
        "\"\"\"",
        "Tests for observability module.",
        "",
        "Tests timing decorators, metrics collection, and trace context functionality.",
        "\"\"\"",
        "",
        "import unittest",
        "import time",
        "from cortical import CorticalTextProcessor",
        "from cortical.observability import (",
        "    MetricsCollector,",
        "    TraceContext,",
        "    timed,",
        "    measure_time,",
        "    get_global_metrics,",
        "    enable_global_metrics,",
        "    disable_global_metrics,",
        "    reset_global_metrics",
        ")",
        "",
        "",
        "class TestMetricsCollector(unittest.TestCase):",
        "    \"\"\"Tests for MetricsCollector class.\"\"\"",
        "",
        "    def setUp(self):",
        "        self.metrics = MetricsCollector()",
        "",
        "    def test_initialization(self):",
        "        \"\"\"Test MetricsCollector initializes correctly.\"\"\"",
        "        self.assertTrue(self.metrics.enabled)",
        "        self.assertEqual(len(self.metrics.operations), 0)",
        "        self.assertEqual(len(self.metrics.traces), 0)",
        "",
        "    def test_record_timing(self):",
        "        \"\"\"Test recording timing measurements.\"\"\"",
        "        self.metrics.record_timing(\"test_op\", 100.0)",
        "        stats = self.metrics.get_operation_stats(\"test_op\")",
        "",
        "        self.assertEqual(stats['count'], 1)",
        "        self.assertEqual(stats['total_ms'], 100.0)",
        "        self.assertEqual(stats['avg_ms'], 100.0)",
        "        self.assertEqual(stats['min_ms'], 100.0)",
        "        self.assertEqual(stats['max_ms'], 100.0)",
        "",
        "    def test_record_multiple_timings(self):",
        "        \"\"\"Test recording multiple measurements for same operation.\"\"\"",
        "        self.metrics.record_timing(\"test_op\", 50.0)",
        "        self.metrics.record_timing(\"test_op\", 150.0)",
        "        self.metrics.record_timing(\"test_op\", 100.0)",
        "",
        "        stats = self.metrics.get_operation_stats(\"test_op\")",
        "        self.assertEqual(stats['count'], 3)",
        "        self.assertEqual(stats['total_ms'], 300.0)",
        "        self.assertEqual(stats['avg_ms'], 100.0)",
        "        self.assertEqual(stats['min_ms'], 50.0)",
        "        self.assertEqual(stats['max_ms'], 150.0)",
        "",
        "    def test_record_count(self):",
        "        \"\"\"Test recording count metrics.\"\"\"",
        "        self.metrics.record_count(\"cache_hits\", 5)",
        "        self.metrics.record_count(\"cache_hits\", 3)",
        "",
        "        stats = self.metrics.get_operation_stats(\"cache_hits\")",
        "        self.assertEqual(stats['count'], 8)",
        "        # Count-only metrics should not have timing stats",
        "        self.assertNotIn('total_ms', stats)",
        "",
        "    def test_enabled_disabled(self):",
        "        \"\"\"Test enabling and disabling metrics collection.\"\"\"",
        "        self.metrics.disable()",
        "        self.assertFalse(self.metrics.enabled)",
        "",
        "        # Recording while disabled should be no-op",
        "        self.metrics.record_timing(\"disabled_op\", 100.0)",
        "        self.assertEqual(len(self.metrics.operations), 0)",
        "",
        "        # Re-enable",
        "        self.metrics.enable()",
        "        self.assertTrue(self.metrics.enabled)",
        "        self.metrics.record_timing(\"enabled_op\", 50.0)",
        "        self.assertEqual(len(self.metrics.operations), 1)",
        "",
        "    def test_reset(self):",
        "        \"\"\"Test resetting metrics.\"\"\"",
        "        self.metrics.record_timing(\"op1\", 100.0)",
        "        self.metrics.record_count(\"counter\", 5)",
        "",
        "        self.assertEqual(len(self.metrics.operations), 2)",
        "",
        "        self.metrics.reset()",
        "        self.assertEqual(len(self.metrics.operations), 0)",
        "        self.assertEqual(len(self.metrics.traces), 0)",
        "",
        "    def test_trace_context(self):",
        "        \"\"\"Test trace context recording.\"\"\"",
        "        with self.metrics.trace_context(\"trace-123\"):",
        "            self.metrics.record_timing(\"op1\", 50.0, context={'arg': 'value1'})",
        "            self.metrics.record_timing(\"op2\", 75.0, context={'arg': 'value2'})",
        "",
        "        trace = self.metrics.get_trace(\"trace-123\")",
        "        self.assertEqual(len(trace), 2)",
        "        self.assertEqual(trace[0][0], \"op1\")",
        "        self.assertEqual(trace[0][1], 50.0)",
        "        self.assertEqual(trace[0][2], {'arg': 'value1'})",
        "",
        "    def test_get_all_stats(self):",
        "        \"\"\"Test getting all statistics.\"\"\"",
        "        self.metrics.record_timing(\"op1\", 100.0)",
        "        self.metrics.record_timing(\"op2\", 50.0)",
        "        self.metrics.record_count(\"counter\", 3)",
        "",
        "        all_stats = self.metrics.get_all_stats()",
        "        self.assertEqual(len(all_stats), 3)",
        "        self.assertIn(\"op1\", all_stats)",
        "        self.assertIn(\"op2\", all_stats)",
        "        self.assertIn(\"counter\", all_stats)",
        "",
        "    def test_get_summary(self):",
        "        \"\"\"Test getting human-readable summary.\"\"\"",
        "        self.metrics.record_timing(\"compute_all\", 1234.5)",
        "        self.metrics.record_timing(\"find_documents\", 56.7)",
        "        self.metrics.record_count(\"cache_hits\", 42)",
        "",
        "        summary = self.metrics.get_summary()",
        "        self.assertIn(\"Metrics Summary\", summary)",
        "        self.assertIn(\"compute_all\", summary)",
        "        self.assertIn(\"find_documents\", summary)",
        "        self.assertIn(\"cache_hits\", summary)",
        "        self.assertIn(\"42\", summary)  # Count should appear",
        "",
        "    def test_empty_summary(self):",
        "        \"\"\"Test summary when no metrics collected.\"\"\"",
        "        summary = self.metrics.get_summary()",
        "        self.assertEqual(summary, \"No metrics collected.\")",
        "",
        "",
        "class TestTraceContext(unittest.TestCase):",
        "    \"\"\"Tests for TraceContext class.\"\"\"",
        "",
        "    def test_initialization(self):",
        "        \"\"\"Test TraceContext initializes correctly.\"\"\"",
        "        trace = TraceContext(\"trace-123\", metadata={'user': 'test'})",
        "        self.assertEqual(trace.trace_id, \"trace-123\")",
        "        self.assertEqual(trace.metadata, {'user': 'test'})",
        "",
        "    def test_elapsed_time(self):",
        "        \"\"\"Test elapsed time measurement.\"\"\"",
        "        trace = TraceContext(\"trace-123\")",
        "        time.sleep(0.01)  # Sleep 10ms",
        "        elapsed = trace.elapsed_ms()",
        "        self.assertGreater(elapsed, 5.0)  # Should be > 5ms",
        "",
        "",
        "class TestTimedDecorator(unittest.TestCase):",
        "    \"\"\"Tests for @timed decorator.\"\"\"",
        "",
        "    def test_timed_decorator_with_metrics(self):",
        "        \"\"\"Test @timed decorator records metrics.\"\"\"",
        "        metrics = MetricsCollector()",
        "",
        "        class MockProcessor:",
        "            def __init__(self):",
        "                self._metrics = metrics",
        "",
        "            @timed(\"test_method\")",
        "            def test_method(self):",
        "                time.sleep(0.01)",
        "                return \"done\"",
        "",
        "        processor = MockProcessor()",
        "        result = processor.test_method()",
        "",
        "        self.assertEqual(result, \"done\")",
        "        stats = metrics.get_operation_stats(\"test_method\")",
        "        self.assertEqual(stats['count'], 1)",
        "        self.assertGreater(stats['avg_ms'], 5.0)",
        "",
        "    def test_timed_decorator_without_metrics(self):",
        "        \"\"\"Test @timed decorator when metrics disabled.\"\"\"",
        "        class MockProcessor:",
        "            def __init__(self):",
        "                self._metrics = MetricsCollector(enabled=False)",
        "",
        "            @timed(\"test_method\")",
        "            def test_method(self):",
        "                return \"done\"",
        "",
        "        processor = MockProcessor()",
        "        result = processor.test_method()",
        "",
        "        self.assertEqual(result, \"done\")",
        "        stats = processor._metrics.get_operation_stats(\"test_method\")",
        "        self.assertEqual(stats, {})",
        "",
        "    def test_timed_decorator_no_metrics_object(self):",
        "        \"\"\"Test @timed decorator when no _metrics attribute.\"\"\"",
        "        class MockProcessor:",
        "            @timed(\"test_method\")",
        "            def test_method(self):",
        "                return \"done\"",
        "",
        "        processor = MockProcessor()",
        "        result = processor.test_method()",
        "        self.assertEqual(result, \"done\")",
        "",
        "    def test_timed_with_include_args(self):",
        "        \"\"\"Test @timed decorator with include_args.\"\"\"",
        "        metrics = MetricsCollector()",
        "",
        "        class MockProcessor:",
        "            def __init__(self):",
        "                self._metrics = metrics",
        "",
        "            @timed(\"test_method\", include_args=True)",
        "            def test_method(self, arg1, kwarg1=\"default\"):",
        "                return \"done\"",
        "",
        "        processor = MockProcessor()",
        "        processor.test_method(\"value1\", kwarg1=\"value2\")",
        "",
        "        # Check that context was recorded",
        "        stats = metrics.get_operation_stats(\"test_method\")",
        "        self.assertEqual(stats['count'], 1)",
        "",
        "",
        "class TestProcessorIntegration(unittest.TestCase):",
        "    \"\"\"Integration tests with CorticalTextProcessor.\"\"\"",
        "",
        "    def test_processor_with_metrics_enabled(self):",
        "        \"\"\"Test processor with metrics enabled.\"\"\"",
        "        processor = CorticalTextProcessor(enable_metrics=True)",
        "        processor.process_document(\"doc1\", \"Neural networks process data.\")",
        "        processor.compute_all(verbose=False)",
        "",
        "        metrics = processor.get_metrics()",
        "",
        "        # Check that key operations were timed",
        "        self.assertIn(\"process_document\", metrics)",
        "        self.assertIn(\"compute_all\", metrics)",
        "",
        "        # Check process_document was called once",
        "        self.assertEqual(metrics[\"process_document\"][\"count\"], 1)",
        "        self.assertGreater(metrics[\"process_document\"][\"avg_ms\"], 0)",
        "",
        "    def test_processor_with_metrics_disabled(self):",
        "        \"\"\"Test processor with metrics disabled (default).\"\"\"",
        "        processor = CorticalTextProcessor()",
        "        processor.process_document(\"doc1\", \"Neural networks process data.\")",
        "        processor.compute_all(verbose=False)",
        "",
        "        metrics = processor.get_metrics()",
        "",
        "        # No metrics should be collected",
        "        self.assertEqual(metrics, {})",
        "",
        "    def test_processor_metrics_summary(self):",
        "        \"\"\"Test getting metrics summary.\"\"\"",
        "        processor = CorticalTextProcessor(enable_metrics=True)",
        "        processor.process_document(\"doc1\", \"Neural networks process data.\")",
        "        processor.process_document(\"doc2\", \"Machine learning algorithms.\")",
        "        processor.compute_all(verbose=False)",
        "",
        "        summary = processor.get_metrics_summary()",
        "",
        "        # Check summary contains expected operations",
        "        self.assertIn(\"process_document\", summary)",
        "        self.assertIn(\"compute_all\", summary)",
        "        self.assertIn(\"Metrics Summary\", summary)",
        "",
        "    def test_processor_reset_metrics(self):",
        "        \"\"\"Test resetting processor metrics.\"\"\"",
        "        processor = CorticalTextProcessor(enable_metrics=True)",
        "        processor.process_document(\"doc1\", \"Neural networks process data.\")",
        "",
        "        metrics_before = processor.get_metrics()",
        "        self.assertGreater(len(metrics_before), 0)",
        "",
        "        processor.reset_metrics()",
        "        metrics_after = processor.get_metrics()",
        "        self.assertEqual(len(metrics_after), 0)",
        "",
        "    def test_processor_enable_disable_metrics(self):",
        "        \"\"\"Test enabling and disabling metrics on processor.\"\"\"",
        "        processor = CorticalTextProcessor(enable_metrics=False)",
        "        processor.process_document(\"doc1\", \"Neural networks process data.\")",
        "",
        "        metrics = processor.get_metrics()",
        "        self.assertEqual(len(metrics), 0)",
        "",
        "        # Enable metrics",
        "        processor.enable_metrics()",
        "        processor.process_document(\"doc2\", \"Machine learning algorithms.\")",
        "",
        "        metrics = processor.get_metrics()",
        "        self.assertGreater(len(metrics), 0)",
        "",
        "        # Disable again",
        "        processor.disable_metrics()",
        "        processor.reset_metrics()",
        "        processor.process_document(\"doc3\", \"Deep learning networks.\")",
        "",
        "        metrics = processor.get_metrics()",
        "        self.assertEqual(len(metrics), 0)",
        "",
        "    def test_processor_record_custom_metric(self):",
        "        \"\"\"Test recording custom metrics.\"\"\"",
        "        processor = CorticalTextProcessor(enable_metrics=True)",
        "",
        "        processor.record_metric(\"custom_counter\", 5)",
        "        processor.record_metric(\"custom_counter\", 3)",
        "",
        "        metrics = processor.get_metrics()",
        "        self.assertIn(\"custom_counter\", metrics)",
        "        self.assertEqual(metrics[\"custom_counter\"][\"count\"], 8)",
        "",
        "    def test_compute_all_timing(self):",
        "        \"\"\"Test that compute_all phases are timed.\"\"\"",
        "        processor = CorticalTextProcessor(enable_metrics=True)",
        "        processor.process_document(\"doc1\", \"Neural networks process data.\")",
        "        processor.process_document(\"doc2\", \"Machine learning algorithms.\")",
        "        processor.compute_all(verbose=False)",
        "",
        "        metrics = processor.get_metrics()",
        "",
        "        # Check individual computation methods",
        "        self.assertIn(\"compute_all\", metrics)",
        "        self.assertIn(\"propagate_activation\", metrics)",
        "        self.assertIn(\"compute_importance\", metrics)",
        "        self.assertIn(\"compute_tfidf\", metrics)",
        "",
        "    def test_query_timing(self):",
        "        \"\"\"Test that query operations are timed.\"\"\"",
        "        processor = CorticalTextProcessor(enable_metrics=True)",
        "        processor.process_document(\"doc1\", \"Neural networks process data.\")",
        "        processor.compute_all(verbose=False)",
        "",
        "        processor.find_documents_for_query(\"neural networks\")",
        "",
        "        metrics = processor.get_metrics()",
        "        self.assertIn(\"find_documents_for_query\", metrics)",
        "        self.assertGreater(metrics[\"find_documents_for_query\"][\"avg_ms\"], 0)",
        "",
        "    def test_save_timing(self):",
        "        \"\"\"Test that save operation is timed.\"\"\"",
        "        import tempfile",
        "        import os",
        "",
        "        processor = CorticalTextProcessor(enable_metrics=True)",
        "        processor.process_document(\"doc1\", \"Neural networks process data.\")",
        "        processor.compute_all(verbose=False)",
        "",
        "        with tempfile.NamedTemporaryFile(delete=False, suffix='.pkl') as f:",
        "            temp_path = f.name",
        "",
        "        try:",
        "            processor.save(temp_path, verbose=False)",
        "",
        "            metrics = processor.get_metrics()",
        "            self.assertIn(\"save\", metrics)",
        "            self.assertGreater(metrics[\"save\"][\"avg_ms\"], 0)",
        "        finally:",
        "            if os.path.exists(temp_path):",
        "                os.unlink(temp_path)",
        "",
        "    def test_cache_hit_metrics(self):",
        "        \"\"\"Test that cache hits/misses are recorded.\"\"\"",
        "        processor = CorticalTextProcessor(enable_metrics=True)",
        "        processor.process_document(\"doc1\", \"Neural networks process data.\")",
        "        processor.compute_all(verbose=False)",
        "",
        "        # First call - cache miss",
        "        processor.expand_query_cached(\"neural\")",
        "",
        "        # Second call - cache hit",
        "        processor.expand_query_cached(\"neural\")",
        "",
        "        metrics = processor.get_metrics()",
        "        self.assertIn(\"query_cache_hits\", metrics)",
        "        self.assertIn(\"query_cache_misses\", metrics)",
        "        self.assertEqual(metrics[\"query_cache_hits\"][\"count\"], 1)",
        "        self.assertEqual(metrics[\"query_cache_misses\"][\"count\"], 1)",
        "",
        "",
        "class TestGlobalMetrics(unittest.TestCase):",
        "    \"\"\"Tests for global metrics functions.\"\"\"",
        "",
        "    def setUp(self):",
        "        reset_global_metrics()",
        "",
        "    def tearDown(self):",
        "        reset_global_metrics()",
        "",
        "    def test_global_metrics_singleton(self):",
        "        \"\"\"Test global metrics collector is a singleton.\"\"\"",
        "        metrics1 = get_global_metrics()",
        "        metrics2 = get_global_metrics()",
        "        self.assertIs(metrics1, metrics2)",
        "",
        "    def test_enable_disable_global(self):",
        "        \"\"\"Test enabling/disabling global metrics.\"\"\"",
        "        metrics = get_global_metrics()",
        "",
        "        disable_global_metrics()",
        "        self.assertFalse(metrics.enabled)",
        "",
        "        enable_global_metrics()",
        "        self.assertTrue(metrics.enabled)",
        "",
        "    def test_reset_global(self):",
        "        \"\"\"Test resetting global metrics.\"\"\"",
        "        metrics = get_global_metrics()",
        "        enable_global_metrics()",
        "",
        "        metrics.record_timing(\"test_op\", 100.0)",
        "        self.assertEqual(len(metrics.operations), 1)",
        "",
        "        reset_global_metrics()",
        "        self.assertEqual(len(metrics.operations), 0)",
        "",
        "",
        "if __name__ == '__main__':",
        "    unittest.main()"
      ],
      "lines_removed": [],
      "context_before": [],
      "context_after": [],
      "change_type": "add"
    },
    {
      "file": "tests/unit/test_patterns.py",
      "function": null,
      "start_line": 0,
      "lines_added": [
        "\"\"\"",
        "Unit Tests for Pattern Detection Module",
        "========================================",
        "",
        "Task LEGACY-078: Code pattern detection capabilities.",
        "",
        "Tests the pattern detection module which identifies common programming",
        "patterns in indexed code including:",
        "- Singleton pattern",
        "- Factory pattern",
        "- Decorator usage",
        "- Context managers",
        "- Error handling patterns",
        "- Generator patterns",
        "- Async patterns",
        "- And many more",
        "",
        "These tests verify both the core pattern detection functions and the",
        "processor integration.",
        "\"\"\"",
        "",
        "import pytest",
        "",
        "from cortical.patterns import (",
        "    PATTERN_DEFINITIONS,",
        "    PATTERN_CATEGORIES,",
        "    detect_patterns_in_text,",
        "    detect_patterns_in_documents,",
        "    get_pattern_summary,",
        "    get_patterns_by_category,",
        "    get_pattern_description,",
        "    get_pattern_category,",
        "    list_all_patterns,",
        "    list_patterns_by_category,",
        "    list_all_categories,",
        "    format_pattern_report,",
        "    get_corpus_pattern_statistics,",
        ")",
        "",
        "from cortical.processor import CorticalTextProcessor",
        "",
        "",
        "# =============================================================================",
        "# PATTERN DEFINITIONS TESTS",
        "# =============================================================================",
        "",
        "",
        "class TestPatternDefinitions:",
        "    \"\"\"Tests for pattern definition structure.\"\"\"",
        "",
        "    def test_all_definitions_have_three_elements(self):",
        "        \"\"\"Each pattern definition has regex, description, and category.\"\"\"",
        "        for pattern_name, definition in PATTERN_DEFINITIONS.items():",
        "            assert len(definition) == 3, f\"{pattern_name} should have 3 elements\"",
        "            regex, description, category = definition",
        "            assert isinstance(regex, str)",
        "            assert isinstance(description, str)",
        "            assert isinstance(category, str)",
        "",
        "    def test_pattern_categories_populated(self):",
        "        \"\"\"PATTERN_CATEGORIES is correctly populated.\"\"\"",
        "        assert len(PATTERN_CATEGORIES) > 0",
        "        # Each pattern should be in exactly one category",
        "        all_patterns = set()",
        "        for category, patterns in PATTERN_CATEGORIES.items():",
        "            all_patterns.update(patterns)",
        "        assert len(all_patterns) == len(PATTERN_DEFINITIONS)",
        "",
        "    def test_essential_patterns_exist(self):",
        "        \"\"\"Essential patterns are defined.\"\"\"",
        "        essential = [",
        "            'singleton', 'factory', 'decorator', 'context_manager',",
        "            'generator', 'async_await', 'error_handling', 'property_decorator'",
        "        ]",
        "        for pattern in essential:",
        "            assert pattern in PATTERN_DEFINITIONS",
        "",
        "    def test_essential_categories_exist(self):",
        "        \"\"\"Essential categories are defined.\"\"\"",
        "        essential_cats = [",
        "            'creational', 'structural', 'behavioral', 'concurrency',",
        "            'error_handling', 'idiom', 'testing', 'functional', 'typing'",
        "        ]",
        "        for category in essential_cats:",
        "            assert category in PATTERN_CATEGORIES",
        "",
        "",
        "# =============================================================================",
        "# DETECT PATTERNS IN TEXT TESTS",
        "# =============================================================================",
        "",
        "",
        "class TestDetectPatternsInText:",
        "    \"\"\"Tests for detect_patterns_in_text function.\"\"\"",
        "",
        "    def test_detect_async_await(self):",
        "        \"\"\"Detect async/await pattern.\"\"\"",
        "        code = \"\"\"",
        "async def fetch_data():",
        "    result = await get_api_data()",
        "    return result",
        "\"\"\"",
        "        patterns = detect_patterns_in_text(code)",
        "        assert 'async_await' in patterns",
        "        assert len(patterns['async_await']) >= 2  # async def and await",
        "",
        "    def test_detect_generator(self):",
        "        \"\"\"Detect generator pattern.\"\"\"",
        "        code = \"\"\"",
        "def count_up(n):",
        "    for i in range(n):",
        "        yield i",
        "\"\"\"",
        "        patterns = detect_patterns_in_text(code)",
        "        assert 'generator' in patterns",
        "        assert 4 in patterns['generator']  # yield is on line 4 (after leading newline)",
        "",
        "    def test_detect_singleton(self):",
        "        \"\"\"Detect singleton pattern.\"\"\"",
        "        code = \"\"\"",
        "class Singleton:",
        "    _instance = None",
        "",
        "    def __new__(cls):",
        "        if not hasattr(cls, '_instance'):",
        "            cls._instance = super().__new__(cls)",
        "        return cls._instance",
        "\"\"\"",
        "        patterns = detect_patterns_in_text(code)",
        "        assert 'singleton' in patterns",
        "",
        "    def test_detect_factory(self):",
        "        \"\"\"Detect factory pattern.\"\"\"",
        "        code = \"\"\"",
        "def create_user(name):",
        "    return User(name)",
        "",
        "class UserFactory:",
        "    @staticmethod",
        "    def create(name):",
        "        return User(name)",
        "\"\"\"",
        "        patterns = detect_patterns_in_text(code)",
        "        assert 'factory' in patterns",
        "",
        "    def test_detect_context_manager(self):",
        "        \"\"\"Detect context manager pattern.\"\"\"",
        "        code = \"\"\"",
        "class FileManager:",
        "    def __enter__(self):",
        "        return self",
        "",
        "    def __exit__(self, exc_type, exc_val, exc_tb):",
        "        self.close()",
        "\"\"\"",
        "        patterns = detect_patterns_in_text(code)",
        "        assert 'context_manager' in patterns",
        "        assert 3 in patterns['context_manager']  # __enter__ (line 3 after leading newline)",
        "        assert 6 in patterns['context_manager']  # __exit__ (line 6 after leading newline)",
        "",
        "    def test_detect_decorator(self):",
        "        \"\"\"Detect decorator pattern.\"\"\"",
        "        code = \"\"\"",
        "@property",
        "def name(self):",
        "    return self._name",
        "",
        "@staticmethod",
        "def create():",
        "    pass",
        "\"\"\"",
        "        patterns = detect_patterns_in_text(code)",
        "        assert 'decorator' in patterns",
        "",
        "    def test_detect_error_handling(self):",
        "        \"\"\"Detect error handling pattern.\"\"\"",
        "        code = \"\"\"",
        "try:",
        "    risky_operation()",
        "except ValueError as e:",
        "    print(f\"Error: {e}\")",
        "finally:",
        "    cleanup()",
        "\"\"\"",
        "        patterns = detect_patterns_in_text(code)",
        "        assert 'error_handling' in patterns",
        "        assert 2 in patterns['error_handling']  # try (line 2 after leading newline)",
        "        assert 6 in patterns['error_handling']  # finally (line 6 after leading newline)",
        "",
        "    def test_detect_custom_exception(self):",
        "        \"\"\"Detect custom exception pattern.\"\"\"",
        "        code = \"\"\"",
        "class ValidationError(Exception):",
        "    pass",
        "",
        "def validate(value):",
        "    if not value:",
        "        raise ValidationError(\"Invalid value\")",
        "\"\"\"",
        "        patterns = detect_patterns_in_text(code)",
        "        assert 'custom_exception' in patterns",
        "",
        "    def test_detect_property_decorator(self):",
        "        \"\"\"Detect property decorator pattern.\"\"\"",
        "        code = \"\"\"",
        "@property",
        "def value(self):",
        "    return self._value",
        "",
        "@value.setter",
        "def value(self, new_value):",
        "    self._value = new_value",
        "\"\"\"",
        "        patterns = detect_patterns_in_text(code)",
        "        assert 'property_decorator' in patterns",
        "",
        "    def test_detect_dataclass(self):",
        "        \"\"\"Detect dataclass pattern.\"\"\"",
        "        code = \"\"\"",
        "from dataclasses import dataclass",
        "",
        "@dataclass",
        "class User:",
        "    name: str",
        "    age: int",
        "\"\"\"",
        "        patterns = detect_patterns_in_text(code)",
        "        assert 'dataclass' in patterns",
        "",
        "    def test_detect_magic_methods(self):",
        "        \"\"\"Detect magic methods pattern.\"\"\"",
        "        code = \"\"\"",
        "class Point:",
        "    def __init__(self, x, y):",
        "        self.x = x",
        "        self.y = y",
        "",
        "    def __repr__(self):",
        "        return f\"Point({self.x}, {self.y})\"",
        "",
        "    def __eq__(self, other):",
        "        return self.x == other.x and self.y == other.y",
        "\"\"\"",
        "        patterns = detect_patterns_in_text(code)",
        "        assert 'magic_methods' in patterns",
        "",
        "    def test_detect_comprehension(self):",
        "        \"\"\"Detect comprehension pattern.\"\"\"",
        "        code = \"\"\"",
        "squares = [x**2 for x in range(10)]",
        "even_squares = {x**2 for x in range(10) if x % 2 == 0}",
        "mapping = {x: x**2 for x in range(10)}",
        "\"\"\"",
        "        patterns = detect_patterns_in_text(code)",
        "        assert 'comprehension' in patterns",
        "",
        "    def test_detect_unpacking(self):",
        "        \"\"\"Detect argument unpacking pattern.\"\"\"",
        "        code = \"\"\"",
        "def func(*args, **kwargs):",
        "    pass",
        "",
        "a, *rest = [1, 2, 3, 4]",
        "\"\"\"",
        "        patterns = detect_patterns_in_text(code)",
        "        assert 'unpacking' in patterns",
        "",
        "    def test_detect_unittest_class(self):",
        "        \"\"\"Detect unittest test class pattern.\"\"\"",
        "        code = \"\"\"",
        "import unittest",
        "",
        "class TestMyCode(unittest.TestCase):",
        "    def setUp(self):",
        "        pass",
        "",
        "    def test_feature(self):",
        "        self.assertEqual(1, 1)",
        "\"\"\"",
        "        patterns = detect_patterns_in_text(code)",
        "        assert 'unittest_class' in patterns",
        "",
        "    def test_detect_pytest_test(self):",
        "        \"\"\"Detect pytest test function pattern.\"\"\"",
        "        code = \"\"\"",
        "import pytest",
        "",
        "def test_basic():",
        "    assert True",
        "",
        "@pytest.mark.skip",
        "def test_skip():",
        "    pass",
        "\"\"\"",
        "        patterns = detect_patterns_in_text(code)",
        "        assert 'pytest_test' in patterns",
        "",
        "    def test_detect_mock_usage(self):",
        "        \"\"\"Detect mocking pattern.\"\"\"",
        "        code = \"\"\"",
        "from unittest.mock import Mock, patch",
        "",
        "@patch('module.function')",
        "def test_with_mock(mock_func):",
        "    mock = Mock()",
        "    mock.return_value = 42",
        "\"\"\"",
        "        patterns = detect_patterns_in_text(code)",
        "        assert 'mock_usage' in patterns",
        "",
        "    def test_detect_lambda(self):",
        "        \"\"\"Detect lambda pattern.\"\"\"",
        "        code = \"\"\"",
        "square = lambda x: x**2",
        "add = lambda a, b: a + b",
        "\"\"\"",
        "        patterns = detect_patterns_in_text(code)",
        "        assert 'lambda' in patterns",
        "",
        "    def test_detect_type_hints(self):",
        "        \"\"\"Detect type hints pattern.\"\"\"",
        "        code = \"\"\"",
        "from typing import List, Dict, Optional",
        "",
        "def process(items: List[str]) -> Dict[str, int]:",
        "    return {item: len(item) for item in items}",
        "",
        "def maybe_get(key: str) -> Optional[str]:",
        "    pass",
        "\"\"\"",
        "        patterns = detect_patterns_in_text(code)",
        "        assert 'type_hints' in patterns",
        "",
        "    def test_empty_text_returns_empty_dict(self):",
        "        \"\"\"Empty text returns no patterns.\"\"\"",
        "        patterns = detect_patterns_in_text(\"\")",
        "        assert patterns == {}",
        "",
        "    def test_non_code_text_returns_empty_dict(self):",
        "        \"\"\"Non-code text returns no patterns.\"\"\"",
        "        patterns = detect_patterns_in_text(\"This is just plain text.\")",
        "        assert patterns == {}",
        "",
        "    def test_specific_patterns_only(self):",
        "        \"\"\"Can search for specific patterns only.\"\"\"",
        "        code = \"\"\"",
        "async def fetch():",
        "    yield 1",
        "\"\"\"",
        "        # Only search for async_await",
        "        patterns = detect_patterns_in_text(code, patterns=['async_await'])",
        "        assert 'async_await' in patterns",
        "        assert 'generator' not in patterns",
        "",
        "        # Only search for generator",
        "        patterns = detect_patterns_in_text(code, patterns=['generator'])",
        "        assert 'generator' in patterns",
        "        assert 'async_await' not in patterns",
        "",
        "    def test_unknown_pattern_name_ignored(self):",
        "        \"\"\"Unknown pattern names are ignored.\"\"\"",
        "        code = \"async def test(): pass\"",
        "        patterns = detect_patterns_in_text(code, patterns=['unknown_pattern'])",
        "        assert 'unknown_pattern' not in patterns",
        "",
        "    def test_line_numbers_accurate(self):",
        "        \"\"\"Line numbers are accurately reported.\"\"\"",
        "        code = \"\"\"line 1",
        "async def test():",
        "    pass",
        "\"\"\"",
        "        patterns = detect_patterns_in_text(code)",
        "        assert 'async_await' in patterns",
        "        assert 2 in patterns['async_await']  # async def on line 2",
        "",
        "",
        "# =============================================================================",
        "# DETECT PATTERNS IN DOCUMENTS TESTS",
        "# =============================================================================",
        "",
        "",
        "class TestDetectPatternsInDocuments:",
        "    \"\"\"Tests for detect_patterns_in_documents function.\"\"\"",
        "",
        "    def test_detect_in_multiple_documents(self):",
        "        \"\"\"Detect patterns across multiple documents.\"\"\"",
        "        docs = {",
        "            'file1.py': 'async def fetch(): pass',",
        "            'file2.py': 'def generator(): yield 1',",
        "            'file3.py': 'print(\"hello\")',  # No patterns",
        "        }",
        "        results = detect_patterns_in_documents(docs)",
        "",
        "        assert 'file1.py' in results",
        "        assert 'async_await' in results['file1.py']",
        "",
        "        assert 'file2.py' in results",
        "        assert 'generator' in results['file2.py']",
        "",
        "        # file3.py might not be in results if no patterns found",
        "        # or might have some basic patterns",
        "",
        "    def test_empty_documents(self):",
        "        \"\"\"Empty documents dict returns empty results.\"\"\"",
        "        results = detect_patterns_in_documents({})",
        "        assert results == {}",
        "",
        "    def test_documents_with_no_patterns(self):",
        "        \"\"\"Documents with no patterns are omitted from results.\"\"\"",
        "        docs = {",
        "            'file1.py': 'x = 1',",
        "            'file2.py': 'y = 2',",
        "        }",
        "        results = detect_patterns_in_documents(docs)",
        "        # Should be empty or only contain very basic patterns",
        "        # Depends on what patterns match simple assignments",
        "",
        "    def test_specific_patterns_in_documents(self):",
        "        \"\"\"Can search for specific patterns in documents.\"\"\"",
        "        docs = {",
        "            'file1.py': 'async def fetch(): yield 1',",
        "        }",
        "        results = detect_patterns_in_documents(docs, patterns=['async_await'])",
        "",
        "        assert 'file1.py' in results",
        "        assert 'async_await' in results['file1.py']",
        "        assert 'generator' not in results['file1.py']",
        "",
        "",
        "# =============================================================================",
        "# PATTERN SUMMARY TESTS",
        "# =============================================================================",
        "",
        "",
        "class TestGetPatternSummary:",
        "    \"\"\"Tests for get_pattern_summary function.\"\"\"",
        "",
        "    def test_summary_counts_occurrences(self):",
        "        \"\"\"Summary counts pattern occurrences.\"\"\"",
        "        pattern_results = {",
        "            'async_await': [1, 5, 10],",
        "            'generator': [3],",
        "            'decorator': [2, 4, 6, 8],",
        "        }",
        "        summary = get_pattern_summary(pattern_results)",
        "",
        "        assert summary['async_await'] == 3",
        "        assert summary['generator'] == 1",
        "        assert summary['decorator'] == 4",
        "",
        "    def test_empty_results(self):",
        "        \"\"\"Empty results return empty summary.\"\"\"",
        "        summary = get_pattern_summary({})",
        "        assert summary == {}",
        "",
        "",
        "# =============================================================================",
        "# PATTERNS BY CATEGORY TESTS",
        "# =============================================================================",
        "",
        "",
        "class TestGetPatternsByCategory:",
        "    \"\"\"Tests for get_patterns_by_category function.\"\"\"",
        "",
        "    def test_groups_by_category(self):",
        "        \"\"\"Patterns are grouped by category.\"\"\"",
        "        pattern_results = {",
        "            'async_await': [1, 2],",
        "            'singleton': [5],",
        "            'generator': [10],",
        "        }",
        "        by_category = get_patterns_by_category(pattern_results)",
        "",
        "        assert 'concurrency' in by_category",
        "        assert by_category['concurrency']['async_await'] == 2",
        "",
        "        assert 'creational' in by_category",
        "        assert by_category['creational']['singleton'] == 1",
        "",
        "        assert 'behavioral' in by_category",
        "        assert by_category['behavioral']['generator'] == 1",
        "",
        "    def test_empty_results(self):",
        "        \"\"\"Empty results return empty categorization.\"\"\"",
        "        by_category = get_patterns_by_category({})",
        "        assert by_category == {}",
        "",
        "",
        "# =============================================================================",
        "# PATTERN METADATA TESTS",
        "# =============================================================================",
        "",
        "",
        "class TestPatternMetadata:",
        "    \"\"\"Tests for pattern metadata functions.\"\"\"",
        "",
        "    def test_get_pattern_description(self):",
        "        \"\"\"Get description for a pattern.\"\"\"",
        "        desc = get_pattern_description('singleton')",
        "        assert 'Singleton' in desc or 'singleton' in desc",
        "        assert isinstance(desc, str)",
        "",
        "    def test_get_pattern_description_unknown(self):",
        "        \"\"\"Unknown pattern returns None.\"\"\"",
        "        desc = get_pattern_description('unknown_pattern')",
        "        assert desc is None",
        "",
        "    def test_get_pattern_category(self):",
        "        \"\"\"Get category for a pattern.\"\"\"",
        "        category = get_pattern_category('singleton')",
        "        assert category == 'creational'",
        "",
        "        category = get_pattern_category('async_await')",
        "        assert category == 'concurrency'",
        "",
        "    def test_get_pattern_category_unknown(self):",
        "        \"\"\"Unknown pattern returns None.\"\"\"",
        "        category = get_pattern_category('unknown_pattern')",
        "        assert category is None",
        "",
        "    def test_list_all_patterns(self):",
        "        \"\"\"List all available patterns.\"\"\"",
        "        patterns = list_all_patterns()",
        "        assert isinstance(patterns, list)",
        "        assert len(patterns) > 0",
        "        assert 'singleton' in patterns",
        "        assert 'async_await' in patterns",
        "        # Should be sorted",
        "        assert patterns == sorted(patterns)",
        "",
        "    def test_list_patterns_by_category(self):",
        "        \"\"\"List patterns in a specific category.\"\"\"",
        "        creational = list_patterns_by_category('creational')",
        "        assert 'singleton' in creational",
        "        assert 'factory' in creational",
        "        # Should be sorted",
        "        assert creational == sorted(creational)",
        "",
        "    def test_list_patterns_by_category_unknown(self):",
        "        \"\"\"Unknown category returns empty list.\"\"\"",
        "        patterns = list_patterns_by_category('unknown_category')",
        "        assert patterns == []",
        "",
        "    def test_list_all_categories(self):",
        "        \"\"\"List all pattern categories.\"\"\"",
        "        categories = list_all_categories()",
        "        assert isinstance(categories, list)",
        "        assert len(categories) > 0",
        "        assert 'creational' in categories",
        "        assert 'concurrency' in categories",
        "        # Should be sorted",
        "        assert categories == sorted(categories)",
        "",
        "",
        "# =============================================================================",
        "# FORMAT PATTERN REPORT TESTS",
        "# =============================================================================",
        "",
        "",
        "class TestFormatPatternReport:",
        "    \"\"\"Tests for format_pattern_report function.\"\"\"",
        "",
        "    def test_format_basic_report(self):",
        "        \"\"\"Format a basic pattern report.\"\"\"",
        "        pattern_results = {",
        "            'async_await': [1, 5],",
        "            'singleton': [10],",
        "        }",
        "        report = format_pattern_report(pattern_results)",
        "",
        "        assert 'async_await' in report",
        "        assert 'singleton' in report",
        "        assert '2 occurrences' in report or '2' in report",
        "",
        "    def test_format_with_line_numbers(self):",
        "        \"\"\"Format report with line numbers.\"\"\"",
        "        pattern_results = {",
        "            'async_await': [1, 5, 10],",
        "        }",
        "        report = format_pattern_report(pattern_results, show_lines=True)",
        "",
        "        assert '1' in report",
        "        assert '5' in report",
        "        assert '10' in report",
        "",
        "    def test_format_empty_results(self):",
        "        \"\"\"Format empty results.\"\"\"",
        "        report = format_pattern_report({})",
        "        assert 'No patterns' in report",
        "",
        "    def test_format_groups_by_category(self):",
        "        \"\"\"Report groups patterns by category.\"\"\"",
        "        pattern_results = {",
        "            'async_await': [1],",
        "            'singleton': [2],",
        "        }",
        "        report = format_pattern_report(pattern_results)",
        "",
        "        # Should show category headers",
        "        assert 'CONCURRENCY' in report or 'concurrency' in report",
        "        assert 'CREATIONAL' in report or 'creational' in report",
        "",
        "",
        "# =============================================================================",
        "# CORPUS STATISTICS TESTS",
        "# =============================================================================",
        "",
        "",
        "class TestGetCorpusPatternStatistics:",
        "    \"\"\"Tests for get_corpus_pattern_statistics function.\"\"\"",
        "",
        "    def test_compute_statistics(self):",
        "        \"\"\"Compute corpus-wide statistics.\"\"\"",
        "        doc_patterns = {",
        "            'file1.py': {'async_await': [1, 2], 'singleton': [5]},",
        "            'file2.py': {'async_await': [3]},",
        "            'file3.py': {'generator': [1, 2, 3]},",
        "        }",
        "        stats = get_corpus_pattern_statistics(doc_patterns)",
        "",
        "        assert stats['total_documents'] == 3",
        "        assert stats['patterns_found'] == 3  # async_await, singleton, generator",
        "",
        "        # async_await appears in 2 documents",
        "        assert stats['pattern_document_counts']['async_await'] == 2",
        "        # singleton appears in 1 document",
        "        assert stats['pattern_document_counts']['singleton'] == 1",
        "",
        "        # async_await has 3 total occurrences (2 in file1, 1 in file2)",
        "        assert stats['pattern_occurrences']['async_await'] == 3",
        "        # generator has 3 occurrences",
        "        assert stats['pattern_occurrences']['generator'] == 3",
        "",
        "        # Most common should be either async_await or generator (both have 3)",
        "        assert stats['most_common_pattern'] in ['async_await', 'generator']",
        "",
        "    def test_empty_corpus(self):",
        "        \"\"\"Empty corpus returns minimal statistics.\"\"\"",
        "        stats = get_corpus_pattern_statistics({})",
        "        assert stats['total_documents'] == 0",
        "        assert stats['patterns_found'] == 0",
        "        assert stats['most_common_pattern'] is None",
        "",
        "",
        "# =============================================================================",
        "# PROCESSOR INTEGRATION TESTS",
        "# =============================================================================",
        "",
        "",
        "class TestProcessorIntegration:",
        "    \"\"\"Tests for processor integration.\"\"\"",
        "",
        "    def test_detect_patterns_method(self):",
        "        \"\"\"Processor can detect patterns in a document.\"\"\"",
        "        processor = CorticalTextProcessor()",
        "        processor.process_document('code.py', 'async def fetch(): pass')",
        "",
        "        patterns = processor.detect_patterns('code.py')",
        "        assert 'async_await' in patterns",
        "",
        "    def test_detect_patterns_unknown_doc(self):",
        "        \"\"\"Detecting patterns in unknown document returns empty.\"\"\"",
        "        processor = CorticalTextProcessor()",
        "        patterns = processor.detect_patterns('unknown.py')",
        "        assert patterns == {}",
        "",
        "    def test_detect_patterns_in_corpus_method(self):",
        "        \"\"\"Processor can detect patterns in entire corpus.\"\"\"",
        "        processor = CorticalTextProcessor()",
        "        processor.process_document('file1.py', 'async def fetch(): pass')",
        "        processor.process_document('file2.py', 'def gen(): yield 1')",
        "",
        "        results = processor.detect_patterns_in_corpus()",
        "",
        "        assert 'file1.py' in results",
        "        assert 'async_await' in results['file1.py']",
        "",
        "        assert 'file2.py' in results",
        "        assert 'generator' in results['file2.py']",
        "",
        "    def test_get_pattern_summary_method(self):",
        "        \"\"\"Processor can get pattern summary for a document.\"\"\"",
        "        processor = CorticalTextProcessor()",
        "        code = \"\"\"",
        "async def fetch():",
        "    await get()",
        "async def store():",
        "    await put()",
        "\"\"\"",
        "        processor.process_document('code.py', code)",
        "",
        "        summary = processor.get_pattern_summary('code.py')",
        "        assert 'async_await' in summary",
        "        assert summary['async_await'] >= 2  # At least 2 async defs",
        "",
        "    def test_get_corpus_pattern_statistics_method(self):",
        "        \"\"\"Processor can get corpus-wide pattern statistics.\"\"\"",
        "        processor = CorticalTextProcessor()",
        "        processor.process_document('file1.py', 'async def fetch(): pass')",
        "        processor.process_document('file2.py', 'async def store(): pass')",
        "",
        "        stats = processor.get_corpus_pattern_statistics()",
        "        assert stats['total_documents'] == 2",
        "        assert 'async_await' in stats['pattern_document_counts']",
        "",
        "    def test_format_pattern_report_method(self):",
        "        \"\"\"Processor can format pattern reports.\"\"\"",
        "        processor = CorticalTextProcessor()",
        "        processor.process_document('code.py', 'async def fetch(): pass')",
        "",
        "        report = processor.format_pattern_report('code.py')",
        "        assert isinstance(report, str)",
        "        assert 'async_await' in report",
        "",
        "    def test_list_available_patterns_method(self):",
        "        \"\"\"Processor can list available patterns.\"\"\"",
        "        processor = CorticalTextProcessor()",
        "        patterns = processor.list_available_patterns()",
        "",
        "        assert isinstance(patterns, list)",
        "        assert 'singleton' in patterns",
        "        assert 'async_await' in patterns",
        "",
        "    def test_list_pattern_categories_method(self):",
        "        \"\"\"Processor can list pattern categories.\"\"\"",
        "        processor = CorticalTextProcessor()",
        "        categories = processor.list_pattern_categories()",
        "",
        "        assert isinstance(categories, list)",
        "        assert 'creational' in categories",
        "        assert 'concurrency' in categories",
        "",
        "    def test_detect_specific_patterns(self):",
        "        \"\"\"Processor can detect specific patterns only.\"\"\"",
        "        processor = CorticalTextProcessor()",
        "        code = \"\"\"",
        "async def fetch():",
        "    yield 1",
        "\"\"\"",
        "        processor.process_document('code.py', code)",
        "",
        "        # Only detect async_await",
        "        patterns = processor.detect_patterns('code.py', patterns=['async_await'])",
        "        assert 'async_await' in patterns",
        "        assert 'generator' not in patterns",
        "",
        "",
        "# =============================================================================",
        "# REAL-WORLD PATTERN DETECTION TESTS",
        "# =============================================================================",
        "",
        "",
        "class TestRealWorldPatterns:",
        "    \"\"\"Tests with realistic code samples.\"\"\"",
        "",
        "    def test_detect_patterns_in_test_file(self):",
        "        \"\"\"Detect patterns in a typical test file.\"\"\"",
        "        code = \"\"\"",
        "import pytest",
        "from unittest.mock import Mock, patch",
        "",
        "class TestMyFeature:",
        "    def setUp(self):",
        "        self.mock = Mock()",
        "",
        "    def test_basic(self):",
        "        assert True",
        "",
        "    @pytest.mark.skip",
        "    def test_skip(self):",
        "        pass",
        "",
        "    @patch('module.function')",
        "    def test_with_mock(self, mock_func):",
        "        mock_func.return_value = 42",
        "\"\"\"",
        "        patterns = detect_patterns_in_text(code)",
        "",
        "        assert 'pytest_test' in patterns or 'unittest_class' in patterns",
        "        assert 'mock_usage' in patterns",
        "        assert 'decorator' in patterns",
        "",
        "    def test_detect_patterns_in_class(self):",
        "        \"\"\"Detect patterns in a typical class.\"\"\"",
        "        code = \"\"\"",
        "from dataclasses import dataclass",
        "from typing import Optional",
        "",
        "@dataclass",
        "class User:",
        "    name: str",
        "    age: int",
        "    _email: Optional[str] = None",
        "",
        "    def __post_init__(self):",
        "        if not self.name:",
        "            raise ValueError(\"Name required\")",
        "",
        "    @property",
        "    def email(self):",
        "        return self._email",
        "",
        "    @email.setter",
        "    def email(self, value: str):",
        "        if '@' not in value:",
        "            raise ValueError(\"Invalid email\")",
        "        self._email = value",
        "\"\"\"",
        "        patterns = detect_patterns_in_text(code)",
        "",
        "        assert 'dataclass' in patterns",
        "        assert 'type_hints' in patterns",
        "        assert 'property_decorator' in patterns",
        "        assert 'custom_exception' in patterns or 'error_handling' in patterns",
        "",
        "    def test_detect_patterns_in_async_code(self):",
        "        \"\"\"Detect patterns in async code.\"\"\"",
        "        code = \"\"\"",
        "import asyncio",
        "from typing import AsyncIterator",
        "",
        "async def fetch_users() -> list:",
        "    async with aiohttp.ClientSession() as session:",
        "        async for user in get_users(session):",
        "            yield user",
        "",
        "async def process_batch(items):",
        "    await asyncio.gather(*[process(item) for item in items])",
        "\"\"\"",
        "        patterns = detect_patterns_in_text(code)",
        "",
        "        assert 'async_await' in patterns",
        "        assert 'generator' in patterns or 'async_await' in patterns",
        "        assert 'type_hints' in patterns",
        "        assert 'comprehension' in patterns"
      ],
      "lines_removed": [],
      "context_before": [],
      "context_after": [],
      "change_type": "add"
    },
    {
      "file": "tests/unit/test_processor_core.py",
      "function": "class TestComputeWrapperMethods(unittest.TestCase):",
      "start_line": 1300,
      "lines_added": [
        "    @patch('cortical.analysis.compute_bm25')",
        "    def test_compute_tfidf_calls_bm25_by_default(self, mock_bm25):",
        "        \"\"\"compute_tfidf delegates to BM25 by default (new default algorithm).\"\"\"",
        "        # BM25 is now the default algorithm",
        "        mock_bm25.assert_called_once()",
        "",
        "    @patch('cortical.analysis.compute_tfidf')",
        "    def test_compute_tfidf_calls_tfidf_when_configured(self, mock_tfidf):",
        "        \"\"\"compute_tfidf delegates to TF-IDF when explicitly configured.\"\"\"",
        "        from cortical.config import CorticalConfig",
        "        config = CorticalConfig(scoring_algorithm='tfidf')",
        "        processor = CorticalTextProcessor(config=config)",
        "        processor.process_document(\"doc1\", \"test content\")",
        "",
        "        processor.compute_tfidf(verbose=False)",
        ""
      ],
      "lines_removed": [
        "    @patch('cortical.analysis.compute_tfidf')",
        "    def test_compute_tfidf_calls_analysis(self, mock_tfidf):",
        "        \"\"\"compute_tfidf delegates to analysis module.\"\"\""
      ],
      "context_before": [
        "    def test_compute_importance_calls_analysis(self, mock_pagerank):",
        "        \"\"\"compute_importance delegates to analysis module.\"\"\"",
        "        processor = CorticalTextProcessor()",
        "        processor.process_document(\"doc1\", \"test content\")",
        "",
        "        processor.compute_importance(verbose=False)",
        "",
        "        # Should call PageRank for tokens and bigrams",
        "        self.assertEqual(mock_pagerank.call_count, 2)",
        ""
      ],
      "context_after": [
        "        processor = CorticalTextProcessor()",
        "        processor.process_document(\"doc1\", \"test content\")",
        "",
        "        processor.compute_tfidf(verbose=False)",
        "",
        "        mock_tfidf.assert_called_once()",
        "",
        "    @patch('cortical.analysis.compute_document_connections')",
        "    def test_compute_document_connections_calls_analysis(self, mock_doc_conn):",
        "        \"\"\"compute_document_connections delegates to analysis module.\"\"\"",
        "        processor = CorticalTextProcessor()",
        "        processor.process_document(\"doc1\", \"test content\")",
        "",
        "        processor.compute_document_connections(min_shared_terms=5, verbose=False)",
        ""
      ],
      "change_type": "modify"
    },
    {
      "file": "tests/unit/test_query_search.py",
      "function": "These tests use mock layers and don't require a full processor.",
      "start_line": 18,
      "lines_added": [
        "    graph_boosted_search,"
      ],
      "lines_removed": [],
      "context_before": [
        "import pytest",
        "from unittest.mock import Mock",
        "",
        "from cortical.query.search import (",
        "    find_documents_for_query,",
        "    fast_find_documents,",
        "    build_document_index,",
        "    search_with_index,",
        "    query_with_spreading_activation,",
        "    find_related_documents,"
      ],
      "context_after": [
        ")",
        "from cortical.tokenizer import Tokenizer",
        "from tests.unit.mocks import (",
        "    MockMinicolumn,",
        "    MockHierarchicalLayer,",
        "    MockLayers,",
        "    LayerBuilder,",
        ")",
        "",
        ""
      ],
      "change_type": "add"
    },
    {
      "file": "tests/unit/test_query_search.py",
      "function": "class TestFindRelatedDocuments:",
      "start_line": 1041,
      "lines_added": [
        "",
        "",
        "# =============================================================================",
        "# GRAPH_BOOSTED_SEARCH TESTS",
        "# =============================================================================",
        "",
        "",
        "class TestGraphBoostedSearch:",
        "    \"\"\"Tests for graph_boosted_search hybrid scoring function.\"\"\"",
        "",
        "    def test_basic_search(self):",
        "        \"\"\"Basic search returns ranked documents.\"\"\"",
        "        # Create tokens with tfidf and pagerank",
        "        neural = MockMinicolumn(",
        "            content=\"neural\",",
        "            id=\"L0_neural\",",
        "            layer=MockLayers.TOKENS,",
        "            tfidf=1.0,",
        "            tfidf_per_doc={\"doc1\": 0.8, \"doc2\": 0.5},",
        "            document_ids={\"doc1\", \"doc2\"},",
        "            pagerank=0.3,",
        "            lateral_connections={}",
        "        )",
        "        networks = MockMinicolumn(",
        "            content=\"networks\",",
        "            id=\"L0_networks\",",
        "            layer=MockLayers.TOKENS,",
        "            tfidf=0.9,",
        "            tfidf_per_doc={\"doc1\": 0.7, \"doc3\": 0.4},",
        "            document_ids={\"doc1\", \"doc3\"},",
        "            pagerank=0.2,",
        "            lateral_connections={}",
        "        )",
        "",
        "        layers = MockLayers.empty()",
        "        layers[MockLayers.TOKENS] = MockHierarchicalLayer([neural, networks])",
        "        layers[MockLayers.DOCUMENTS] = MockHierarchicalLayer([])",
        "        tokenizer = Tokenizer()",
        "",
        "        results = graph_boosted_search(\"neural networks\", layers, tokenizer, top_n=3)",
        "",
        "        assert len(results) > 0",
        "        # doc1 should rank highest (has both terms)",
        "        assert results[0][0] == \"doc1\"",
        "",
        "    def test_empty_query(self):",
        "        \"\"\"Empty query returns empty results.\"\"\"",
        "        layers = MockLayers.single_term(\"term\", tfidf=1.0, doc_ids=[\"doc1\"])",
        "        tokenizer = Tokenizer()",
        "",
        "        results = graph_boosted_search(\"\", layers, tokenizer, top_n=5)",
        "        assert results == []",
        "",
        "    def test_no_matching_terms(self):",
        "        \"\"\"Query with no matching terms returns empty results.\"\"\"",
        "        layers = MockLayers.single_term(\"other\", tfidf=1.0, doc_ids=[\"doc1\"])",
        "        tokenizer = Tokenizer()",
        "",
        "        results = graph_boosted_search(\"nonexistent\", layers, tokenizer, top_n=5)",
        "        assert results == []",
        "",
        "    def test_pagerank_boost(self):",
        "        \"\"\"Documents with high-PageRank terms get boosted.\"\"\"",
        "        # High PageRank term (use \"significant\" instead of \"important\" which is a stop word)",
        "        significant = MockMinicolumn(",
        "            content=\"significant\",",
        "            id=\"L0_significant\",",
        "            layer=MockLayers.TOKENS,",
        "            tfidf=1.0,",
        "            tfidf_per_doc={\"doc1\": 1.0},",
        "            document_ids={\"doc1\"},",
        "            pagerank=0.9,  # High importance",
        "            lateral_connections={}",
        "        )",
        "        # Low PageRank term",
        "        common = MockMinicolumn(",
        "            content=\"common\",",
        "            id=\"L0_common\",",
        "            layer=MockLayers.TOKENS,",
        "            tfidf=1.0,",
        "            tfidf_per_doc={\"doc2\": 1.0},",
        "            document_ids={\"doc2\"},",
        "            pagerank=0.1,  # Low importance",
        "            lateral_connections={}",
        "        )",
        "",
        "        layers = MockLayers.empty()",
        "        layers[MockLayers.TOKENS] = MockHierarchicalLayer([significant, common])",
        "        layers[MockLayers.DOCUMENTS] = MockHierarchicalLayer([])",
        "        tokenizer = Tokenizer()",
        "",
        "        # Search for both terms (using \"significant\" instead of \"important\")",
        "        results = graph_boosted_search(",
        "            \"significant common\", layers, tokenizer, top_n=5,",
        "            pagerank_weight=0.5  # High PageRank influence",
        "        )",
        "",
        "        assert len(results) == 2",
        "        # doc1 should rank higher due to PageRank boost",
        "        assert results[0][0] == \"doc1\"",
        "",
        "    def test_respects_top_n(self):",
        "        \"\"\"Returns at most top_n results.\"\"\"",
        "        terms = []",
        "        for i in range(10):",
        "            terms.append(MockMinicolumn(",
        "                content=f\"term{i}\",",
        "                id=f\"L0_term{i}\",",
        "                layer=MockLayers.TOKENS,",
        "                tfidf=1.0,",
        "                tfidf_per_doc={f\"doc{i}\": 1.0},",
        "                document_ids={f\"doc{i}\"},",
        "                pagerank=0.1,",
        "                lateral_connections={}",
        "            ))",
        "",
        "        layers = MockLayers.empty()",
        "        layers[MockLayers.TOKENS] = MockHierarchicalLayer(terms)",
        "        layers[MockLayers.DOCUMENTS] = MockHierarchicalLayer([])",
        "        tokenizer = Tokenizer()",
        "",
        "        # Query that matches multiple docs",
        "        results = graph_boosted_search(",
        "            \" \".join(f\"term{i}\" for i in range(10)),",
        "            layers, tokenizer, top_n=3",
        "        )",
        "",
        "        assert len(results) <= 3"
      ],
      "lines_removed": [],
      "context_before": [
        "",
        "        layers = MockLayers.empty()",
        "        layer3 = MockHierarchicalLayer([doc1, doc2])",
        "        layers[MockLayers.DOCUMENTS] = layer3",
        "",
        "        result = find_related_documents(\"doc1\", layers)",
        "",
        "        # If this works, get_by_id was used successfully",
        "        assert len(result) == 1",
        "        assert result[0][0] == \"doc2\""
      ],
      "context_after": [],
      "change_type": "add"
    },
    {
      "file": "tests/unit/test_repl.py",
      "function": null,
      "start_line": 0,
      "lines_added": [
        "\"\"\"",
        "Tests for the Cortical REPL.",
        "",
        "Tests the interactive REPL interface for the Cortical Text Processor.",
        "\"\"\"",
        "",
        "import unittest",
        "import sys",
        "import io",
        "import tempfile",
        "import os",
        "from pathlib import Path",
        "from unittest.mock import patch, MagicMock",
        "",
        "# Add scripts to path",
        "sys.path.insert(0, str(Path(__file__).parent.parent.parent / 'scripts'))",
        "",
        "from repl import CorticalREPL",
        "from cortical.processor import CorticalTextProcessor",
        "from cortical.layers import CorticalLayer",
        "",
        "",
        "class TestREPLBasics(unittest.TestCase):",
        "    \"\"\"Test basic REPL functionality.\"\"\"",
        "",
        "    def setUp(self):",
        "        \"\"\"Set up test fixtures.\"\"\"",
        "        self.repl = CorticalREPL()",
        "",
        "    def test_initialization_no_corpus(self):",
        "        \"\"\"Test REPL initializes without corpus.\"\"\"",
        "        self.assertIsNone(self.repl.processor)",
        "        self.assertIsNone(self.repl.corpus_file)",
        "",
        "    def test_initialization_with_invalid_corpus(self):",
        "        \"\"\"Test REPL handles invalid corpus gracefully.\"\"\"",
        "        with patch('sys.stdout', new=io.StringIO()):",
        "            repl = CorticalREPL(corpus_file='nonexistent.pkl')",
        "        self.assertIsNone(repl.processor)",
        "",
        "    def test_quit_command(self):",
        "        \"\"\"Test quit command returns True.\"\"\"",
        "        result = self.repl.do_quit('')",
        "        self.assertTrue(result)",
        "",
        "    def test_exit_command(self):",
        "        \"\"\"Test exit command is alias for quit.\"\"\"",
        "        result = self.repl.do_exit('')",
        "        self.assertTrue(result)",
        "",
        "    def test_eof_command(self):",
        "        \"\"\"Test EOF (Ctrl+D) exits.\"\"\"",
        "        result = self.repl.do_EOF('')",
        "        self.assertTrue(result)",
        "",
        "    def test_empty_line(self):",
        "        \"\"\"Test empty line does nothing.\"\"\"",
        "        result = self.repl.emptyline()",
        "        self.assertFalse(result)",
        "",
        "    def test_unknown_command(self):",
        "        \"\"\"Test unknown command handling.\"\"\"",
        "        with patch('sys.stdout', new=io.StringIO()) as mock_stdout:",
        "            self.repl.default('invalidcommand')",
        "            output = mock_stdout.getvalue()",
        "            self.assertIn('Unknown command', output)",
        "",
        "",
        "class TestREPLWithCorpus(unittest.TestCase):",
        "    \"\"\"Test REPL commands with a loaded corpus.\"\"\"",
        "",
        "    def setUp(self):",
        "        \"\"\"Set up test fixtures.\"\"\"",
        "        # Create a processor with test data",
        "        self.processor = CorticalTextProcessor(enable_metrics=True)",
        "        self.processor.process_document(",
        "            \"doc1.py\",",
        "            \"def compute_pagerank(graph):\\n\"",
        "            \"    # PageRank algorithm implementation\\n\"",
        "            \"    return pagerank_values\"",
        "        )",
        "        self.processor.process_document(",
        "            \"doc2.py\",",
        "            \"class NeuralNetwork:\\n\"",
        "            \"    def __init__(self):\\n\"",
        "            \"        self.layers = []\"",
        "        )",
        "        self.processor.compute_all()",
        "",
        "        # Create temp file and save",
        "        self.temp_file = tempfile.NamedTemporaryFile(",
        "            mode='wb', suffix='.pkl', delete=False",
        "        )",
        "        self.temp_file.close()",
        "        self.processor.save(self.temp_file.name)",
        "",
        "        # Create REPL with loaded corpus",
        "        with patch('sys.stdout', new=io.StringIO()):",
        "            self.repl = CorticalREPL(corpus_file=self.temp_file.name)",
        "",
        "    def tearDown(self):",
        "        \"\"\"Clean up temp files.\"\"\"",
        "        if os.path.exists(self.temp_file.name):",
        "            os.unlink(self.temp_file.name)",
        "",
        "    def test_load_command(self):",
        "        \"\"\"Test load command loads corpus.\"\"\"",
        "        with patch('sys.stdout', new=io.StringIO()) as mock_stdout:",
        "            self.repl.do_load(self.temp_file.name)",
        "            output = mock_stdout.getvalue()",
        "            self.assertIn('Loaded', output)",
        "            self.assertIsNotNone(self.repl.processor)",
        "",
        "    def test_load_nonexistent_file(self):",
        "        \"\"\"Test load command with nonexistent file.\"\"\"",
        "        with patch('sys.stdout', new=io.StringIO()) as mock_stdout:",
        "            self.repl.do_load('nonexistent.pkl')",
        "            output = mock_stdout.getvalue()",
        "            self.assertIn('not found', output.lower())",
        "",
        "    def test_load_no_argument(self):",
        "        \"\"\"Test load command without file argument.\"\"\"",
        "        with patch('sys.stdout', new=io.StringIO()) as mock_stdout:",
        "            self.repl.do_load('')",
        "            output = mock_stdout.getvalue()",
        "            self.assertIn('specify a file', output.lower())",
        "",
        "    def test_stats_command(self):",
        "        \"\"\"Test stats command shows corpus statistics.\"\"\"",
        "        with patch('sys.stdout', new=io.StringIO()) as mock_stdout:",
        "            self.repl.do_stats('')",
        "            output = mock_stdout.getvalue()",
        "            self.assertIn('Documents', output)",
        "            self.assertIn('Tokens', output)",
        "            self.assertIn('Bigrams', output)",
        "",
        "    def test_stats_without_corpus(self):",
        "        \"\"\"Test stats command without loaded corpus.\"\"\"",
        "        repl = CorticalREPL()",
        "        with patch('sys.stdout', new=io.StringIO()) as mock_stdout:",
        "            repl.do_stats('')",
        "            output = mock_stdout.getvalue()",
        "            self.assertIn('No corpus loaded', output)",
        "",
        "    def test_search_command(self):",
        "        \"\"\"Test search command finds documents.\"\"\"",
        "        with patch('sys.stdout', new=io.StringIO()) as mock_stdout:",
        "            self.repl.do_search('pagerank')",
        "            output = mock_stdout.getvalue()",
        "            self.assertIn('Results', output)",
        "            # Should find doc1.py which contains pagerank",
        "            self.assertIn('doc1.py', output.lower())",
        "",
        "    def test_search_no_query(self):",
        "        \"\"\"Test search command without query.\"\"\"",
        "        with patch('sys.stdout', new=io.StringIO()) as mock_stdout:",
        "            self.repl.do_search('')",
        "            output = mock_stdout.getvalue()",
        "            self.assertIn('provide a search query', output.lower())",
        "",
        "    def test_search_no_results(self):",
        "        \"\"\"Test search with no results.\"\"\"",
        "        with patch('sys.stdout', new=io.StringIO()) as mock_stdout:",
        "            self.repl.do_search('xyznonexistent')",
        "            output = mock_stdout.getvalue()",
        "            self.assertIn('No results', output)",
        "",
        "    def test_expand_command(self):",
        "        \"\"\"Test expand command shows query expansion.\"\"\"",
        "        with patch('sys.stdout', new=io.StringIO()) as mock_stdout:",
        "            self.repl.do_expand('pagerank')",
        "            output = mock_stdout.getvalue()",
        "            self.assertIn('expansion', output.lower())",
        "",
        "    def test_expand_no_term(self):",
        "        \"\"\"Test expand command without term.\"\"\"",
        "        with patch('sys.stdout', new=io.StringIO()) as mock_stdout:",
        "            self.repl.do_expand('')",
        "            output = mock_stdout.getvalue()",
        "            self.assertIn('provide a term', output.lower())",
        "",
        "    def test_concepts_command(self):",
        "        \"\"\"Test concepts command lists clusters.\"\"\"",
        "        with patch('sys.stdout', new=io.StringIO()) as mock_stdout:",
        "            self.repl.do_concepts('')",
        "            output = mock_stdout.getvalue()",
        "            self.assertIn('Concept', output)",
        "",
        "    def test_concepts_with_number(self):",
        "        \"\"\"Test concepts command with custom number.\"\"\"",
        "        with patch('sys.stdout', new=io.StringIO()) as mock_stdout:",
        "            self.repl.do_concepts('5')",
        "            output = mock_stdout.getvalue()",
        "            self.assertIn('Concept', output)",
        "",
        "    def test_concepts_invalid_number(self):",
        "        \"\"\"Test concepts command with invalid number.\"\"\"",
        "        with patch('sys.stdout', new=io.StringIO()) as mock_stdout:",
        "            self.repl.do_concepts('abc')",
        "            output = mock_stdout.getvalue()",
        "            self.assertIn('valid number', output.lower())",
        "",
        "    def test_fingerprint_command(self):",
        "        \"\"\"Test fingerprint command.\"\"\"",
        "        with patch('sys.stdout', new=io.StringIO()) as mock_stdout:",
        "            self.repl.do_fingerprint('neural network')",
        "            output = mock_stdout.getvalue()",
        "            self.assertIn('Fingerprint', output)",
        "            self.assertIn('Top terms', output)",
        "",
        "    def test_fingerprint_no_text(self):",
        "        \"\"\"Test fingerprint without text.\"\"\"",
        "        with patch('sys.stdout', new=io.StringIO()) as mock_stdout:",
        "            self.repl.do_fingerprint('')",
        "            output = mock_stdout.getvalue()",
        "            self.assertIn('provide text', output.lower())",
        "",
        "    def test_patterns_command(self):",
        "        \"\"\"Test patterns command detects code patterns.\"\"\"",
        "        with patch('sys.stdout', new=io.StringIO()) as mock_stdout:",
        "            self.repl.do_patterns('doc1.py')",
        "            output = mock_stdout.getvalue()",
        "            # Should detect some patterns or show message",
        "            self.assertTrue(len(output) > 0)",
        "",
        "    def test_patterns_no_doc(self):",
        "        \"\"\"Test patterns without doc_id.\"\"\"",
        "        with patch('sys.stdout', new=io.StringIO()) as mock_stdout:",
        "            self.repl.do_patterns('')",
        "            output = mock_stdout.getvalue()",
        "            self.assertIn('provide a document', output.lower())",
        "",
        "    def test_metrics_command(self):",
        "        \"\"\"Test metrics command shows timing metrics.\"\"\"",
        "        with patch('sys.stdout', new=io.StringIO()) as mock_stdout:",
        "            self.repl.do_metrics('')",
        "            output = mock_stdout.getvalue()",
        "            # Either shows metrics or \"no metrics\" message",
        "            self.assertTrue(len(output) > 0)",
        "",
        "    def test_stale_command(self):",
        "        \"\"\"Test stale command shows stale computations.\"\"\"",
        "        with patch('sys.stdout', new=io.StringIO()) as mock_stdout:",
        "            self.repl.do_stale('')",
        "            output = mock_stdout.getvalue()",
        "            # Should show either stale or up-to-date",
        "            self.assertTrue(len(output) > 0)",
        "",
        "    def test_relations_command(self):",
        "        \"\"\"Test relations command.\"\"\"",
        "        # First extract semantics",
        "        self.repl.processor.extract_corpus_semantics()",
        "",
        "        with patch('sys.stdout', new=io.StringIO()) as mock_stdout:",
        "            self.repl.do_relations('')",
        "            output = mock_stdout.getvalue()",
        "            self.assertTrue(len(output) > 0)",
        "",
        "    def test_relations_with_number(self):",
        "        \"\"\"Test relations with custom count.\"\"\"",
        "        self.repl.processor.extract_corpus_semantics()",
        "",
        "        with patch('sys.stdout', new=io.StringIO()) as mock_stdout:",
        "            self.repl.do_relations('5')",
        "            output = mock_stdout.getvalue()",
        "            self.assertTrue(len(output) > 0)",
        "",
        "    def test_passages_command(self):",
        "        \"\"\"Test passages command finds relevant passages.\"\"\"",
        "        with patch('sys.stdout', new=io.StringIO()) as mock_stdout:",
        "            self.repl.do_passages('pagerank')",
        "            output = mock_stdout.getvalue()",
        "            self.assertIn('Passages', output)",
        "",
        "    def test_passages_no_query(self):",
        "        \"\"\"Test passages without query.\"\"\"",
        "        with patch('sys.stdout', new=io.StringIO()) as mock_stdout:",
        "            self.repl.do_passages('')",
        "            output = mock_stdout.getvalue()",
        "            self.assertIn('provide a search query', output.lower())",
        "",
        "    def test_docs_command(self):",
        "        \"\"\"Test docs command with documentation boost.\"\"\"",
        "        with patch('sys.stdout', new=io.StringIO()) as mock_stdout:",
        "            self.repl.do_docs('pagerank')",
        "            output = mock_stdout.getvalue()",
        "            self.assertIn('Results', output)",
        "",
        "    def test_code_command(self):",
        "        \"\"\"Test code command with code-aware expansion.\"\"\"",
        "        with patch('sys.stdout', new=io.StringIO()) as mock_stdout:",
        "            self.repl.do_code('compute')",
        "            output = mock_stdout.getvalue()",
        "            self.assertIn('expansion', output.lower())",
        "",
        "    def test_intent_command(self):",
        "        \"\"\"Test intent command parses query intent.\"\"\"",
        "        with patch('sys.stdout', new=io.StringIO()) as mock_stdout:",
        "            self.repl.do_intent('where do we compute pagerank')",
        "            output = mock_stdout.getvalue()",
        "            self.assertIn('Intent', output)",
        "",
        "    def test_intent_no_query(self):",
        "        \"\"\"Test intent without query.\"\"\"",
        "        with patch('sys.stdout', new=io.StringIO()) as mock_stdout:",
        "            self.repl.do_intent('')",
        "            output = mock_stdout.getvalue()",
        "            self.assertIn('provide a query', output.lower())",
        "",
        "    def test_similar_command(self):",
        "        \"\"\"Test similar command finds similar code.\"\"\"",
        "        with patch('sys.stdout', new=io.StringIO()) as mock_stdout:",
        "            self.repl.do_similar('doc1.py:1')",
        "            output = mock_stdout.getvalue()",
        "            # Should complete without error",
        "            self.assertTrue(len(output) > 0)",
        "",
        "    def test_similar_no_arg(self):",
        "        \"\"\"Test similar without argument.\"\"\"",
        "        with patch('sys.stdout', new=io.StringIO()) as mock_stdout:",
        "            self.repl.do_similar('')",
        "            output = mock_stdout.getvalue()",
        "            self.assertIn('provide file:line', output.lower())",
        "",
        "    def test_similar_invalid_format(self):",
        "        \"\"\"Test similar with invalid format.\"\"\"",
        "        with patch('sys.stdout', new=io.StringIO()) as mock_stdout:",
        "            self.repl.do_similar('doc1.py')",
        "            output = mock_stdout.getvalue()",
        "            self.assertIn('format', output.lower())",
        "",
        "",
        "class TestREPLComputeCommands(unittest.TestCase):",
        "    \"\"\"Test REPL computation commands.\"\"\"",
        "",
        "    def setUp(self):",
        "        \"\"\"Set up test fixtures.\"\"\"",
        "        self.processor = CorticalTextProcessor(enable_metrics=True)",
        "        self.processor.process_document(\"doc1\", \"test content\")",
        "",
        "        self.temp_file = tempfile.NamedTemporaryFile(",
        "            mode='wb', suffix='.pkl', delete=False",
        "        )",
        "        self.temp_file.close()",
        "        self.processor.save(self.temp_file.name)",
        "",
        "        with patch('sys.stdout', new=io.StringIO()):",
        "            self.repl = CorticalREPL(corpus_file=self.temp_file.name)",
        "",
        "    def tearDown(self):",
        "        \"\"\"Clean up temp files.\"\"\"",
        "        if os.path.exists(self.temp_file.name):",
        "            os.unlink(self.temp_file.name)",
        "",
        "    def test_compute_all(self):",
        "        \"\"\"Test compute all command.\"\"\"",
        "        with patch('sys.stdout', new=io.StringIO()) as mock_stdout:",
        "            self.repl.do_compute('')",
        "            output = mock_stdout.getvalue()",
        "            self.assertIn('Computing', output)",
        "",
        "    def test_compute_tfidf(self):",
        "        \"\"\"Test compute tfidf command.\"\"\"",
        "        with patch('sys.stdout', new=io.StringIO()) as mock_stdout:",
        "            self.repl.do_compute('tfidf')",
        "            output = mock_stdout.getvalue()",
        "            self.assertIn('TF-IDF', output)",
        "",
        "    def test_compute_pagerank(self):",
        "        \"\"\"Test compute pagerank command.\"\"\"",
        "        with patch('sys.stdout', new=io.StringIO()) as mock_stdout:",
        "            self.repl.do_compute('pagerank')",
        "            output = mock_stdout.getvalue()",
        "            self.assertIn('PageRank', output)",
        "",
        "    def test_compute_concepts(self):",
        "        \"\"\"Test compute concepts command.\"\"\"",
        "        with patch('sys.stdout', new=io.StringIO()) as mock_stdout:",
        "            self.repl.do_compute('concepts')",
        "            output = mock_stdout.getvalue()",
        "            self.assertIn('concepts', output.lower())",
        "",
        "    def test_compute_semantics(self):",
        "        \"\"\"Test compute semantics command.\"\"\"",
        "        with patch('sys.stdout', new=io.StringIO()) as mock_stdout:",
        "            self.repl.do_compute('semantics')",
        "            output = mock_stdout.getvalue()",
        "            self.assertIn('semantic', output.lower())",
        "",
        "    def test_compute_invalid_type(self):",
        "        \"\"\"Test compute with invalid type.\"\"\"",
        "        with patch('sys.stdout', new=io.StringIO()) as mock_stdout:",
        "            self.repl.do_compute('invalid')",
        "            output = mock_stdout.getvalue()",
        "            self.assertIn('Unknown', output)",
        "",
        "",
        "class TestREPLSaveExport(unittest.TestCase):",
        "    \"\"\"Test REPL save and export commands.\"\"\"",
        "",
        "    def setUp(self):",
        "        \"\"\"Set up test fixtures.\"\"\"",
        "        self.processor = CorticalTextProcessor()",
        "        self.processor.process_document(\"doc1\", \"test content\")",
        "        self.processor.compute_all()",
        "",
        "        self.temp_file = tempfile.NamedTemporaryFile(",
        "            mode='wb', suffix='.pkl', delete=False",
        "        )",
        "        self.temp_file.close()",
        "        self.processor.save(self.temp_file.name)",
        "",
        "        with patch('sys.stdout', new=io.StringIO()):",
        "            self.repl = CorticalREPL(corpus_file=self.temp_file.name)",
        "",
        "    def tearDown(self):",
        "        \"\"\"Clean up temp files.\"\"\"",
        "        for f in [self.temp_file.name]:",
        "            if os.path.exists(f):",
        "                os.unlink(f)",
        "",
        "    def test_save_command(self):",
        "        \"\"\"Test save command saves corpus.\"\"\"",
        "        temp_save = tempfile.NamedTemporaryFile(",
        "            mode='wb', suffix='.pkl', delete=False",
        "        )",
        "        temp_save.close()",
        "",
        "        try:",
        "            with patch('sys.stdout', new=io.StringIO()) as mock_stdout:",
        "                self.repl.do_save(temp_save.name)",
        "                output = mock_stdout.getvalue()",
        "                self.assertIn('Saved', output)",
        "                self.assertTrue(os.path.exists(temp_save.name))",
        "        finally:",
        "            if os.path.exists(temp_save.name):",
        "                os.unlink(temp_save.name)",
        "",
        "    def test_save_no_file(self):",
        "        \"\"\"Test save without filename.\"\"\"",
        "        with patch('sys.stdout', new=io.StringIO()) as mock_stdout:",
        "            self.repl.do_save('')",
        "            output = mock_stdout.getvalue()",
        "            self.assertIn('specify a file', output.lower())",
        "",
        "    def test_export_json(self):",
        "        \"\"\"Test export to JSON.\"\"\"",
        "        import tempfile",
        "        import shutil",
        "",
        "        temp_dir = tempfile.mkdtemp()",
        "",
        "        try:",
        "            with patch('sys.stdout', new=io.StringIO()) as mock_stdout:",
        "                self.repl.do_export(f'{temp_dir} json')",
        "                output = mock_stdout.getvalue()",
        "                self.assertIn('Exported', output)",
        "        finally:",
        "            if os.path.exists(temp_dir):",
        "                shutil.rmtree(temp_dir)",
        "",
        "    def test_export_no_file(self):",
        "        \"\"\"Test export without filename.\"\"\"",
        "        with patch('sys.stdout', new=io.StringIO()) as mock_stdout:",
        "            self.repl.do_export('')",
        "            output = mock_stdout.getvalue()",
        "            self.assertIn('specify a path', output.lower())",
        "",
        "    def test_export_invalid_format(self):",
        "        \"\"\"Test export with invalid format.\"\"\"",
        "        with patch('sys.stdout', new=io.StringIO()) as mock_stdout:",
        "            self.repl.do_export('test_dir invalid')",
        "            output = mock_stdout.getvalue()",
        "            self.assertIn('Unknown', output)",
        "",
        "",
        "class TestREPLUtilityCommands(unittest.TestCase):",
        "    \"\"\"Test REPL utility commands.\"\"\"",
        "",
        "    def setUp(self):",
        "        \"\"\"Set up test fixtures.\"\"\"",
        "        self.processor = CorticalTextProcessor(enable_metrics=True)",
        "        self.processor.process_document(\"doc1\", \"test content\")",
        "        self.processor.compute_all()",
        "",
        "        self.temp_file = tempfile.NamedTemporaryFile(",
        "            mode='wb', suffix='.pkl', delete=False",
        "        )",
        "        self.temp_file.close()",
        "        self.processor.save(self.temp_file.name)",
        "",
        "        with patch('sys.stdout', new=io.StringIO()):",
        "            self.repl = CorticalREPL(corpus_file=self.temp_file.name)",
        "",
        "    def tearDown(self):",
        "        \"\"\"Clean up temp files.\"\"\"",
        "        if os.path.exists(self.temp_file.name):",
        "            os.unlink(self.temp_file.name)",
        "",
        "    def test_clear_command(self):",
        "        \"\"\"Test clear metrics command.\"\"\"",
        "        with patch('sys.stdout', new=io.StringIO()) as mock_stdout:",
        "            self.repl.do_clear('')",
        "            output = mock_stdout.getvalue()",
        "            self.assertIn('cleared', output.lower())",
        "",
        "    def test_reset_command(self):",
        "        \"\"\"Test reset metrics command.\"\"\"",
        "        with patch('sys.stdout', new=io.StringIO()) as mock_stdout:",
        "            self.repl.do_reset('')",
        "            output = mock_stdout.getvalue()",
        "            self.assertIn('reset', output.lower())",
        "",
        "",
        "class TestREPLCompletion(unittest.TestCase):",
        "    \"\"\"Test REPL tab completion.\"\"\"",
        "",
        "    def setUp(self):",
        "        \"\"\"Set up test fixtures.\"\"\"",
        "        self.processor = CorticalTextProcessor()",
        "        self.processor.process_document(\"doc1.py\", \"test\")",
        "        self.processor.process_document(\"doc2.py\", \"test\")",
        "",
        "        self.temp_file = tempfile.NamedTemporaryFile(",
        "            mode='wb', suffix='.pkl', delete=False",
        "        )",
        "        self.temp_file.close()",
        "        self.processor.save(self.temp_file.name)",
        "",
        "        with patch('sys.stdout', new=io.StringIO()):",
        "            self.repl = CorticalREPL(corpus_file=self.temp_file.name)",
        "",
        "    def tearDown(self):",
        "        \"\"\"Clean up temp files.\"\"\"",
        "        if os.path.exists(self.temp_file.name):",
        "            os.unlink(self.temp_file.name)",
        "",
        "    def test_complete_compute(self):",
        "        \"\"\"Test completion for compute command.\"\"\"",
        "        completions = self.repl.complete_compute('t', 'compute t', 8, 9)",
        "        self.assertIn('tfidf', completions)",
        "",
        "    def test_complete_compute_all(self):",
        "        \"\"\"Test completion includes 'all'.\"\"\"",
        "        completions = self.repl.complete_compute('a', 'compute a', 8, 9)",
        "        self.assertIn('all', completions)",
        "",
        "    def test_complete_export_format(self):",
        "        \"\"\"Test completion for export formats.\"\"\"",
        "        completions = self.repl.complete_export('j', 'export dir j', 11, 12)",
        "        self.assertIn('json', completions)",
        "",
        "",
        "if __name__ == '__main__':",
        "    unittest.main()"
      ],
      "lines_removed": [],
      "context_before": [],
      "context_after": [],
      "change_type": "add"
    },
    {
      "file": "tests/unit/test_suggest_consolidation.py",
      "function": null,
      "start_line": 0,
      "lines_added": [
        "\"\"\"",
        "Unit tests for suggest_consolidation.py script.",
        "",
        "Tests the memory consolidation suggestion functionality.",
        "\"\"\"",
        "",
        "import unittest",
        "import sys",
        "from pathlib import Path",
        "from datetime import datetime, timedelta",
        "",
        "# Add scripts to path",
        "sys.path.insert(0, str(Path(__file__).parent.parent.parent / 'scripts'))",
        "",
        "from suggest_consolidation import (",
        "    parse_memory_date,",
        "    get_memory_age_days,",
        "    is_concept_doc,",
        "    suggest_consolidations,",
        "    format_suggestions_text",
        ")",
        "",
        "from cortical.processor import CorticalTextProcessor",
        "",
        "",
        "class TestMemoryDateParsing(unittest.TestCase):",
        "    \"\"\"Test memory date parsing functions.\"\"\"",
        "",
        "    def test_parse_memory_date_basic(self):",
        "        \"\"\"Test parsing basic date format YYYY-MM-DD.\"\"\"",
        "        doc_id = \"samples/memories/2025-12-14-topic.md\"",
        "        date = parse_memory_date(doc_id)",
        "        self.assertEqual(date.year, 2025)",
        "        self.assertEqual(date.month, 12)",
        "        self.assertEqual(date.day, 14)",
        "",
        "    def test_parse_memory_date_with_timestamp(self):",
        "        \"\"\"Test parsing date with timestamp format.\"\"\"",
        "        doc_id = \"samples/memories/2025-12-14_20-54-35_3b3a-topic.md\"",
        "        date = parse_memory_date(doc_id)",
        "        self.assertEqual(date.year, 2025)",
        "        self.assertEqual(date.month, 12)",
        "        self.assertEqual(date.day, 14)",
        "",
        "    def test_parse_memory_date_concept(self):",
        "        \"\"\"Test parsing concept document (should return old date).\"\"\"",
        "        doc_id = \"samples/memories/concept-something.md\"",
        "        date = parse_memory_date(doc_id)",
        "        self.assertEqual(date.year, 2000)",
        "",
        "    def test_parse_memory_date_invalid(self):",
        "        \"\"\"Test parsing invalid date format (should return default).\"\"\"",
        "        doc_id = \"samples/memories/invalid-format.md\"",
        "        date = parse_memory_date(doc_id)",
        "        self.assertEqual(date.year, 2000)",
        "",
        "    def test_get_memory_age_days(self):",
        "        \"\"\"Test calculating memory age in days.\"\"\"",
        "        # Use today's date for a new memory",
        "        today = datetime.now()",
        "        doc_id = f\"samples/memories/{today.strftime('%Y-%m-%d')}-topic.md\"",
        "        age = get_memory_age_days(doc_id)",
        "        self.assertEqual(age, 0)",
        "",
        "        # Old memory",
        "        old_date = today - timedelta(days=30)",
        "        doc_id = f\"samples/memories/{old_date.strftime('%Y-%m-%d')}-topic.md\"",
        "        age = get_memory_age_days(doc_id)",
        "        self.assertGreaterEqual(age, 29)  # Allow for rounding",
        "",
        "    def test_is_concept_doc(self):",
        "        \"\"\"Test concept document detection.\"\"\"",
        "        self.assertTrue(is_concept_doc(\"samples/memories/concept-foo.md\"))",
        "        self.assertFalse(is_concept_doc(\"samples/memories/2025-12-14-topic.md\"))",
        "        self.assertFalse(is_concept_doc(\"samples/decisions/adr-001.md\"))",
        "",
        "",
        "class TestSuggestConsolidation(unittest.TestCase):",
        "    \"\"\"Test consolidation suggestion functions.\"\"\"",
        "",
        "    def setUp(self):",
        "        \"\"\"Create a test processor with sample memories.\"\"\"",
        "        self.processor = CorticalTextProcessor()",
        "",
        "        # Add some sample memory documents",
        "        self.processor.process_document(",
        "            \"samples/memories/2025-12-01-security-testing.md\",",
        "            \"\"\"",
        "            # Security Testing",
        "",
        "            We discovered bugs using fuzzing and hypothesis testing.",
        "            The validation checks were failing for NaN values.",
        "            \"\"\"",
        "        )",
        "",
        "        self.processor.process_document(",
        "            \"samples/memories/2025-12-02-fuzzing-results.md\",",
        "            \"\"\"",
        "            # Fuzzing Results",
        "",
        "            More fuzzing tests revealed edge cases with NaN and infinity.",
        "            Security testing found validation bugs.",
        "            \"\"\"",
        "        )",
        "",
        "        self.processor.process_document(",
        "            \"samples/memories/2025-11-01-architecture-refactor.md\",",
        "            \"\"\"",
        "            # Architecture Refactor",
        "",
        "            Refactored the processor into separate mixins.",
        "            Improved code organization and maintainability.",
        "            \"\"\"",
        "        )",
        "",
        "        self.processor.process_document(",
        "            \"samples/memories/concept-testing.md\",",
        "            \"\"\"",
        "            # Concept: Testing",
        "",
        "            Overview of testing approaches including fuzzing and unit tests.",
        "            \"\"\"",
        "        )",
        "",
        "        # Compute features",
        "        self.processor.compute_all()",
        "",
        "    def test_suggest_consolidations_basic(self):",
        "        \"\"\"Test basic consolidation suggestion.\"\"\"",
        "        suggestions = suggest_consolidations(",
        "            self.processor,",
        "            min_overlap=0.3,",
        "            min_cluster_size=2,",
        "            min_age_days=7,",
        "            verbose=False",
        "        )",
        "",
        "        self.assertIn('clusters', suggestions)",
        "        self.assertIn('similar_pairs', suggestions)",
        "        self.assertIn('old_memories', suggestions)",
        "        self.assertIn('stats', suggestions)",
        "",
        "        # Check stats",
        "        stats = suggestions['stats']",
        "        self.assertEqual(stats['total_memories'], 3)",
        "        self.assertEqual(stats['total_concepts'], 1)",
        "",
        "    def test_suggest_consolidations_high_threshold(self):",
        "        \"\"\"Test with high similarity threshold.\"\"\"",
        "        suggestions = suggest_consolidations(",
        "            self.processor,",
        "            min_overlap=0.9,",
        "            min_cluster_size=2,",
        "            verbose=False",
        "        )",
        "",
        "        # With high threshold, should find fewer pairs",
        "        self.assertIsInstance(suggestions['similar_pairs'], list)",
        "",
        "    def test_suggest_consolidations_old_memories(self):",
        "        \"\"\"Test old memory detection.\"\"\"",
        "        suggestions = suggest_consolidations(",
        "            self.processor,",
        "            min_age_days=7,",
        "            verbose=False",
        "        )",
        "",
        "        # Should detect the November memory as old",
        "        old_memories = suggestions['old_memories']",
        "        self.assertIsInstance(old_memories, list)",
        "",
        "        # Check if we found the old memory",
        "        old_doc_ids = [m['doc_id'] for m in old_memories]",
        "        self.assertTrue(",
        "            any('2025-11-01' in doc_id for doc_id in old_doc_ids),",
        "            \"Should detect November memory as old\"",
        "        )",
        "",
        "    def test_format_suggestions_text(self):",
        "        \"\"\"Test text formatting of suggestions.\"\"\"",
        "        suggestions = suggest_consolidations(",
        "            self.processor,",
        "            min_overlap=0.3,",
        "            verbose=False",
        "        )",
        "",
        "        text = format_suggestions_text(suggestions, verbose=False)",
        "",
        "        # Check that output contains expected sections",
        "        self.assertIn('MEMORY CONSOLIDATION SUGGESTIONS', text)",
        "        self.assertIn('Analyzed', text)",
        "        self.assertIn('RECOMMENDATIONS', text)",
        "",
        "    def test_format_suggestions_text_verbose(self):",
        "        \"\"\"Test verbose text formatting.\"\"\"",
        "        suggestions = suggest_consolidations(",
        "            self.processor,",
        "            min_overlap=0.3,",
        "            verbose=False",
        "        )",
        "",
        "        text = format_suggestions_text(suggestions, verbose=True)",
        "",
        "        # Verbose output should include more details",
        "        self.assertIn('MEMORY CONSOLIDATION SUGGESTIONS', text)",
        "",
        "",
        "class TestEdgeCases(unittest.TestCase):",
        "    \"\"\"Test edge cases and error handling.\"\"\"",
        "",
        "    def test_empty_corpus(self):",
        "        \"\"\"Test with empty corpus.\"\"\"",
        "        processor = CorticalTextProcessor()",
        "        processor.compute_all()",
        "",
        "        suggestions = suggest_consolidations(processor, verbose=False)",
        "",
        "        self.assertEqual(suggestions['stats']['total_memories'], 0)",
        "        self.assertEqual(len(suggestions['clusters']), 0)",
        "        self.assertEqual(len(suggestions['similar_pairs']), 0)",
        "",
        "    def test_single_memory(self):",
        "        \"\"\"Test with single memory document.\"\"\"",
        "        processor = CorticalTextProcessor()",
        "        processor.process_document(",
        "            \"samples/memories/2025-12-14-single.md\",",
        "            \"Single memory entry.\"",
        "        )",
        "        processor.compute_all()",
        "",
        "        suggestions = suggest_consolidations(",
        "            processor,",
        "            min_cluster_size=2,",
        "            verbose=False",
        "        )",
        "",
        "        # Should not crash, but won't find clusters",
        "        self.assertEqual(suggestions['stats']['total_memories'], 1)",
        "        self.assertEqual(len(suggestions['clusters']), 0)",
        "",
        "    def test_invalid_threshold(self):",
        "        \"\"\"Test that invalid thresholds are handled.\"\"\"",
        "        processor = CorticalTextProcessor()",
        "        processor.process_document(",
        "            \"samples/memories/2025-12-14-test.md\",",
        "            \"Test content\"",
        "        )",
        "        processor.compute_all()",
        "",
        "        # Should still work, even with edge case thresholds",
        "        suggestions = suggest_consolidations(",
        "            processor,",
        "            min_overlap=0.0,",
        "            verbose=False",
        "        )",
        "        self.assertIsNotNone(suggestions)",
        "",
        "        suggestions = suggest_consolidations(",
        "            processor,",
        "            min_overlap=1.0,",
        "            verbose=False",
        "        )",
        "        self.assertIsNotNone(suggestions)",
        "",
        "",
        "if __name__ == '__main__':",
        "    unittest.main()"
      ],
      "lines_removed": [],
      "context_before": [],
      "context_after": [],
      "change_type": "add"
    }
  ],
  "hour_of_day": 12,
  "day_of_week": "Monday",
  "seconds_since_last_commit": -3696,
  "is_merge": true,
  "is_initial": false,
  "parent_count": 2,
  "session_id": null,
  "related_chats": [],
  "ci_result": null,
  "reverted": false,
  "amended": false
}