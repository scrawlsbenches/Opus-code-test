{
  "hash": "1b9438eeb46571304f3fc5e3cbe5fa50c21231cd",
  "message": "Add tests for bigram connection parameters and improve coverage to 90%",
  "author": "Claude",
  "timestamp": "2025-12-11 22:26:28 +0000",
  "branch": "claude/multi-index-design-DvifZ",
  "files_changed": [
    "tests/test_semantics.py"
  ],
  "insertions": 167,
  "deletions": 0,
  "hunks": [
    {
      "file": "tests/test_semantics.py",
      "function": "class TestProcessorPatternExtraction(unittest.TestCase):",
      "start_line": 834,
      "lines_added": [
        "class TestSimilarToRelationExtraction(unittest.TestCase):",
        "    \"\"\"Test SimilarTo relation extraction with context similarity.\"\"\"",
        "",
        "    def test_similarto_with_shared_context(self):",
        "        \"\"\"Test SimilarTo extraction when terms share context.\"\"\"",
        "        from cortical.processor import CorticalTextProcessor",
        "        from cortical.semantics import extract_corpus_semantics",
        "",
        "        # Create corpus with terms that share context",
        "        # \"apple\" and \"orange\" both appear near \"fruit\", \"eat\", \"fresh\", \"juice\"",
        "        processor = CorticalTextProcessor()",
        "        processor.process_document(\"doc1\",",
        "            \"I eat fresh apple fruit. Apple juice is healthy. The apple is fresh.\")",
        "        processor.process_document(\"doc2\",",
        "            \"I eat fresh orange fruit. Orange juice is healthy. The orange is fresh.\")",
        "        processor.process_document(\"doc3\",",
        "            \"Fresh fruit juice from apple and orange. Eat fresh fruit daily.\")",
        "        processor.compute_all(verbose=False)",
        "",
        "        relations = extract_corpus_semantics(",
        "            processor.layers,",
        "            processor.documents,",
        "            processor.tokenizer,",
        "            window_size=5,",
        "            min_cooccurrence=2,",
        "            use_pattern_extraction=False  # Only test similarity",
        "        )",
        "",
        "        # Check that we get some relations",
        "        self.assertIsInstance(relations, list)",
        "",
        "        # Check relation types",
        "        relation_types = set(r[1] for r in relations)",
        "        # Should have CoOccurs at minimum",
        "        self.assertIn('CoOccurs', relation_types)",
        "",
        "    def test_extract_corpus_semantics_similarto_threshold(self):",
        "        \"\"\"Test that SimilarTo respects similarity threshold.\"\"\"",
        "        from cortical.processor import CorticalTextProcessor",
        "        from cortical.semantics import extract_corpus_semantics",
        "",
        "        # Create documents with overlapping terms",
        "        processor = CorticalTextProcessor()",
        "        for i in range(5):",
        "            processor.process_document(f\"doc{i}\",",
        "                f\"The quick brown fox jumps over the lazy dog. \"",
        "                f\"Quick foxes are brown and lazy dogs sleep. \"",
        "                f\"Brown quick lazy fox dog jump sleep.\")",
        "        processor.compute_all(verbose=False)",
        "",
        "        relations = extract_corpus_semantics(",
        "            processor.layers,",
        "            processor.documents,",
        "            processor.tokenizer,",
        "            window_size=3,",
        "            min_cooccurrence=2,",
        "            use_pattern_extraction=False",
        "        )",
        "",
        "        # Verify relation structure",
        "        for rel in relations:",
        "            self.assertEqual(len(rel), 4)",
        "            term1, rel_type, term2, weight = rel",
        "            self.assertIn(rel_type, ['CoOccurs', 'SimilarTo'])",
        "            self.assertGreater(weight, 0)",
        "            # SimilarTo is 0-1, but CoOccurs can be higher (count-based)",
        "            if rel_type == 'SimilarTo':",
        "                self.assertLessEqual(weight, 1.0)",
        "",
        "",
        "class TestBigramConnectionsVerbose(unittest.TestCase):",
        "    \"\"\"Test bigram connection verbose output and new parameters.\"\"\"",
        "",
        "    def test_max_bigrams_per_term_parameter(self):",
        "        \"\"\"Test that max_bigrams_per_term skips common terms.\"\"\"",
        "        from cortical.processor import CorticalTextProcessor",
        "",
        "        processor = CorticalTextProcessor()",
        "        # Create documents with common bigram prefix \"data\" (not a stop word)",
        "        for i in range(20):",
        "            processor.process_document(f\"doc{i}\",",
        "                f\"data processing data analysis data mining data science \"",
        "                f\"data engineering data storage data pipeline data flow\")",
        "        processor.compute_all(verbose=False, build_concepts=False)",
        "",
        "        # With very low threshold, should skip \"data\" as it appears in many bigrams",
        "        stats = processor.compute_bigram_connections(",
        "            max_bigrams_per_term=3,",
        "            verbose=False",
        "        )",
        "",
        "        self.assertIn('skipped_common_terms', stats)",
        "        self.assertGreater(stats['skipped_common_terms'], 0)",
        "",
        "    def test_max_bigrams_per_doc_parameter(self):",
        "        \"\"\"Test that max_bigrams_per_doc skips large documents.\"\"\"",
        "        from cortical.processor import CorticalTextProcessor",
        "",
        "        processor = CorticalTextProcessor()",
        "        # Create one large document and several small ones",
        "        large_doc = \" \".join([f\"word{i} word{i+1}\" for i in range(200)])",
        "        processor.process_document(\"large\", large_doc)",
        "        for i in range(5):",
        "            processor.process_document(f\"small{i}\", \"simple short document here\")",
        "        processor.compute_all(verbose=False, build_concepts=False)",
        "",
        "        # With low threshold, should skip the large document",
        "        stats = processor.compute_bigram_connections(",
        "            max_bigrams_per_doc=50,",
        "            verbose=False",
        "        )",
        "",
        "        self.assertIn('skipped_large_docs', stats)",
        "        self.assertGreater(stats['skipped_large_docs'], 0)",
        "",
        "    def test_bigram_connections_returns_all_stats(self):",
        "        \"\"\"Test that bigram connections returns complete statistics.\"\"\"",
        "        from cortical.processor import CorticalTextProcessor",
        "",
        "        processor = CorticalTextProcessor()",
        "        processor.process_document(\"doc1\", \"machine learning algorithms work well\")",
        "        processor.process_document(\"doc2\", \"deep learning neural networks train fast\")",
        "        processor.compute_all(verbose=False, build_concepts=False)",
        "",
        "        stats = processor.compute_bigram_connections(verbose=False)",
        "",
        "        # Check all expected keys",
        "        expected_keys = [",
        "            'connections_created', 'bigrams', 'component_connections',",
        "            'chain_connections', 'cooccurrence_connections',",
        "            'skipped_common_terms', 'skipped_large_docs'",
        "        ]",
        "        for key in expected_keys:",
        "            self.assertIn(key, stats)",
        "",
        "",
        "class TestProcessorVerboseOutput(unittest.TestCase):",
        "    \"\"\"Test verbose output messages.\"\"\"",
        "",
        "    def test_compute_bigram_connections_verbose_skipped(self):",
        "        \"\"\"Test verbose output includes skipped info.\"\"\"",
        "        import io",
        "        import sys",
        "        from cortical.processor import CorticalTextProcessor",
        "",
        "        processor = CorticalTextProcessor()",
        "        for i in range(15):",
        "            processor.process_document(f\"doc{i}\",",
        "                f\"the quick brown fox jumps over the lazy dog number {i}\")",
        "        processor.compute_all(verbose=False, build_concepts=False)",
        "",
        "        # Capture stdout",
        "        captured = io.StringIO()",
        "        sys.stdout = captured",
        "        try:",
        "            processor.compute_bigram_connections(",
        "                max_bigrams_per_term=3,",
        "                verbose=True",
        "            )",
        "        finally:",
        "            sys.stdout = sys.__stdout__",
        "",
        "        output = captured.getvalue()",
        "        # Should mention \"bigram connections\"",
        "        self.assertIn('bigram connections', output)",
        "",
        ""
      ],
      "lines_removed": [],
      "context_before": [
        "",
        "        relations_high = self.processor.extract_pattern_relations(",
        "            min_confidence=0.9,",
        "            verbose=False",
        "        )",
        "",
        "        # Lower confidence should find at least as many",
        "        self.assertGreaterEqual(len(relations_low), len(relations_high))",
        "",
        ""
      ],
      "context_after": [
        "if __name__ == \"__main__\":",
        "    unittest.main(verbosity=2)"
      ],
      "change_type": "add"
    }
  ],
  "hour_of_day": 22,
  "day_of_week": "Thursday",
  "seconds_since_last_commit": -314300,
  "is_merge": false,
  "is_initial": false,
  "parent_count": 1,
  "session_id": null,
  "related_chats": [],
  "ci_result": null,
  "reverted": false,
  "amended": false
}