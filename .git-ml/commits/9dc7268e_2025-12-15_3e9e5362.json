{
  "hash": "9dc7268e2cb1533662eb902c73d6d7609d4eb46b",
  "message": "fix: Update tests for BM25 default and stop word tokenization",
  "author": "Claude",
  "timestamp": "2025-12-15 12:03:55 +0000",
  "branch": "claude/multi-index-design-DvifZ",
  "files_changed": [
    "tests/unit/test_processor_core.py",
    "tests/unit/test_query_search.py"
  ],
  "insertions": 23,
  "deletions": 10,
  "hunks": [
    {
      "file": "tests/unit/test_processor_core.py",
      "function": "class TestComputeWrapperMethods(unittest.TestCase):",
      "start_line": 1300,
      "lines_added": [
        "    @patch('cortical.analysis.compute_bm25')",
        "    def test_compute_tfidf_calls_bm25_by_default(self, mock_bm25):",
        "        \"\"\"compute_tfidf delegates to BM25 by default (new default algorithm).\"\"\"",
        "        # BM25 is now the default algorithm",
        "        mock_bm25.assert_called_once()",
        "",
        "    @patch('cortical.analysis.compute_tfidf')",
        "    def test_compute_tfidf_calls_tfidf_when_configured(self, mock_tfidf):",
        "        \"\"\"compute_tfidf delegates to TF-IDF when explicitly configured.\"\"\"",
        "        from cortical.config import CorticalConfig",
        "        config = CorticalConfig(scoring_algorithm='tfidf')",
        "        processor = CorticalTextProcessor(config=config)",
        "        processor.process_document(\"doc1\", \"test content\")",
        "",
        "        processor.compute_tfidf(verbose=False)",
        ""
      ],
      "lines_removed": [
        "    @patch('cortical.analysis.compute_tfidf')",
        "    def test_compute_tfidf_calls_analysis(self, mock_tfidf):",
        "        \"\"\"compute_tfidf delegates to analysis module.\"\"\""
      ],
      "context_before": [
        "    def test_compute_importance_calls_analysis(self, mock_pagerank):",
        "        \"\"\"compute_importance delegates to analysis module.\"\"\"",
        "        processor = CorticalTextProcessor()",
        "        processor.process_document(\"doc1\", \"test content\")",
        "",
        "        processor.compute_importance(verbose=False)",
        "",
        "        # Should call PageRank for tokens and bigrams",
        "        self.assertEqual(mock_pagerank.call_count, 2)",
        ""
      ],
      "context_after": [
        "        processor = CorticalTextProcessor()",
        "        processor.process_document(\"doc1\", \"test content\")",
        "",
        "        processor.compute_tfidf(verbose=False)",
        "",
        "        mock_tfidf.assert_called_once()",
        "",
        "    @patch('cortical.analysis.compute_document_connections')",
        "    def test_compute_document_connections_calls_analysis(self, mock_doc_conn):",
        "        \"\"\"compute_document_connections delegates to analysis module.\"\"\"",
        "        processor = CorticalTextProcessor()",
        "        processor.process_document(\"doc1\", \"test content\")",
        "",
        "        processor.compute_document_connections(min_shared_terms=5, verbose=False)",
        ""
      ],
      "change_type": "modify"
    },
    {
      "file": "tests/unit/test_query_search.py",
      "function": "class TestGraphBoostedSearch:",
      "start_line": 1105,
      "lines_added": [
        "        # High PageRank term (use \"significant\" instead of \"important\" which is a stop word)",
        "        significant = MockMinicolumn(",
        "            content=\"significant\",",
        "            id=\"L0_significant\",",
        "        layers[MockLayers.TOKENS] = MockHierarchicalLayer([significant, common])",
        "        # Search for both terms (using \"significant\" instead of \"important\")",
        "            \"significant common\", layers, tokenizer, top_n=5,"
      ],
      "lines_removed": [
        "        # High PageRank term",
        "        important = MockMinicolumn(",
        "            content=\"important\",",
        "            id=\"L0_important\",",
        "        layers[MockLayers.TOKENS] = MockHierarchicalLayer([important, common])",
        "        # Search for both terms",
        "            \"important common\", layers, tokenizer, top_n=5,"
      ],
      "context_before": [
        "    def test_no_matching_terms(self):",
        "        \"\"\"Query with no matching terms returns empty results.\"\"\"",
        "        layers = MockLayers.single_term(\"other\", tfidf=1.0, doc_ids=[\"doc1\"])",
        "        tokenizer = Tokenizer()",
        "",
        "        results = graph_boosted_search(\"nonexistent\", layers, tokenizer, top_n=5)",
        "        assert results == []",
        "",
        "    def test_pagerank_boost(self):",
        "        \"\"\"Documents with high-PageRank terms get boosted.\"\"\""
      ],
      "context_after": [
        "            layer=MockLayers.TOKENS,",
        "            tfidf=1.0,",
        "            tfidf_per_doc={\"doc1\": 1.0},",
        "            document_ids={\"doc1\"},",
        "            pagerank=0.9,  # High importance",
        "            lateral_connections={}",
        "        )",
        "        # Low PageRank term",
        "        common = MockMinicolumn(",
        "            content=\"common\",",
        "            id=\"L0_common\",",
        "            layer=MockLayers.TOKENS,",
        "            tfidf=1.0,",
        "            tfidf_per_doc={\"doc2\": 1.0},",
        "            document_ids={\"doc2\"},",
        "            pagerank=0.1,  # Low importance",
        "            lateral_connections={}",
        "        )",
        "",
        "        layers = MockLayers.empty()",
        "        layers[MockLayers.DOCUMENTS] = MockHierarchicalLayer([])",
        "        tokenizer = Tokenizer()",
        "",
        "        results = graph_boosted_search(",
        "            pagerank_weight=0.5  # High PageRank influence",
        "        )",
        "",
        "        assert len(results) == 2",
        "        # doc1 should rank higher due to PageRank boost",
        "        assert results[0][0] == \"doc1\"",
        "",
        "    def test_respects_top_n(self):",
        "        \"\"\"Returns at most top_n results.\"\"\"",
        "        terms = []"
      ],
      "change_type": "modify"
    }
  ],
  "hour_of_day": 12,
  "day_of_week": "Monday",
  "seconds_since_last_commit": -6053,
  "is_merge": false,
  "is_initial": false,
  "parent_count": 1,
  "session_id": null,
  "related_chats": [],
  "ci_result": null,
  "reverted": false,
  "amended": false
}