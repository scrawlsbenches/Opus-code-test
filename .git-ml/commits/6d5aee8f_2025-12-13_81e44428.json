{
  "hash": "6d5aee8f17898f2554711fe5a2d91dcff7f25215",
  "message": "Add task #206: Replace pkl with git-friendly JSON state storage",
  "author": "Claude",
  "timestamp": "2025-12-13 21:56:48 +0000",
  "branch": "claude/multi-index-design-DvifZ",
  "files_changed": [
    "TASK_LIST.md"
  ],
  "insertions": 82,
  "deletions": 3,
  "hunks": [
    {
      "file": "TASK_LIST.md",
      "function": null,
      "start_line": 1,
      "lines_added": [
        "**Pending Tasks:** 10"
      ],
      "lines_removed": [
        "**Pending Tasks:** 9"
      ],
      "context_before": [
        "# Task List: Cortical Text Processor",
        "",
        "Active backlog for the Cortical Text Processor project. Completed tasks are archived in [TASK_ARCHIVE.md](TASK_ARCHIVE.md).",
        "",
        "**Last Updated:** 2025-12-13"
      ],
      "context_after": [
        "**Completed Tasks:** 238 (see archive)",
        "",
        "**Legacy Test Cleanup:** âœ… COMPLETE - All 8 tasks investigated (#198-205)",
        "- **KEEP (7 files, 506 tests):** Provide unique coverage not duplicated in unit tests",
        "  - #198 test_coverage_gaps.py (91 tests) - edge case coverage",
        "  - #199 test_cli_wrapper.py (96 tests) - CLI wrapper framework",
        "  - #200 test_edge_cases.py (53 tests) - robustness tests",
        "  - #201 test_incremental_indexing.py (47 tests) - script integration",
        "  - #205 Script tests: 6 files (132 tests) - scripts/ directory",
        "- **DELETED (3 files, 53 tests):** Covered by unit tests"
      ],
      "change_type": "modify"
    },
    {
      "file": "TASK_LIST.md",
      "function": "Active backlog for the Cortical Text Processor project. Completed tasks are arch",
      "start_line": 25,
      "lines_added": [
        "| 206 | Replace pkl with git-friendly JSON state storage | Arch | - | Large |"
      ],
      "lines_removed": [
        "| *None - all high priority completed* |||||"
      ],
      "context_before": [
        "---",
        "",
        "## Active Backlog",
        "",
        "<!-- Machine-parseable format for automation -->",
        "",
        "### ðŸŸ  High (Do This Week)",
        "",
        "| # | Task | Category | Depends | Effort |",
        "|---|------|----------|---------|--------|"
      ],
      "context_after": [
        "",
        "### ðŸŸ¡ Medium (Do This Month)",
        "",
        "| # | Task | Category | Depends | Effort |",
        "|---|------|----------|---------|--------|",
        "| 133 | Implement WAL + snapshot persistence (fault-tolerant rebuild) | Arch | 132 | Large |",
        "| 134 | Implement protobuf serialization for corpus | Arch | 132 | Medium |",
        "| 135 | Implement chunked parallel processing for full-analysis | Arch | 132 | Large |",
        "| 95 | Split processor.py into modules | Arch | - | Large |",
        ""
      ],
      "change_type": "modify"
    },
    {
      "file": "TASK_LIST.md",
      "function": "All completed tasks are now archived in [TASK_ARCHIVE.md](TASK_ARCHIVE.md).",
      "start_line": 109,
      "lines_added": [
        "### 206. Replace pkl with Git-Friendly JSON State Storage",
        "",
        "**Meta:** `status:pending` `priority:high` `category:arch`",
        "**Files:** `cortical/persistence.py`, `cortical/state_storage.py` (new), `cortical/chunk_index.py`",
        "**Effort:** Large",
        "",
        "**Problem:** Pickle files cause merge conflicts in git collaboration. When multiple team members index documents, the binary `.pkl` files cannot be merged, and one version must be discarded. Additionally:",
        "- Pickle is Python-version specific and can break across upgrades",
        "- Binary format cannot be code-reviewed or diff'd",
        "- Security concerns with pickle deserialization",
        "",
        "**Current State:**",
        "- `chunk_index.py` already stores documents as git-friendly JSON chunks âœ…",
        "- Full processor state (layers, connections, TF-IDF, PageRank) still uses pickle âŒ",
        "",
        "**Solution:** Extend the chunk-based architecture to store ALL processor state as JSON:",
        "",
        "```",
        "corpus_state/",
        "â”œâ”€â”€ manifest.json           # Version, checksums, staleness flags",
        "â”œâ”€â”€ chunks/                  # Document content (existing chunk_index.py)",
        "â”œâ”€â”€ layers/",
        "â”‚   â”œâ”€â”€ L0_tokens.json      # Token minicolumns",
        "â”‚   â”œâ”€â”€ L1_bigrams.json     # Bigram minicolumns",
        "â”‚   â”œâ”€â”€ L2_concepts.json    # Concept clusters",
        "â”‚   â””â”€â”€ L3_documents.json   # Document minicolumns",
        "â”œâ”€â”€ connections/",
        "â”‚   â”œâ”€â”€ lateral.json        # Lateral connections (or split by layer)",
        "â”‚   â”œâ”€â”€ typed.json          # Typed edges with relations",
        "â”‚   â””â”€â”€ cross_layer.json    # Feedforward/feedback connections",
        "â”œâ”€â”€ computed/",
        "â”‚   â”œâ”€â”€ tfidf.json          # TF-IDF scores per term",
        "â”‚   â”œâ”€â”€ pagerank.json       # PageRank values",
        "â”‚   â””â”€â”€ embeddings.json     # Graph embeddings (optional, can be large)",
        "â””â”€â”€ semantic_relations.json # Extracted relations",
        "```",
        "",
        "**Incremental Efficiency Strategy:**",
        "1. Use content hashing to detect changes (like chunk_index.py)",
        "2. Only re-serialize layers/files that changed",
        "3. Store computed values separately (can be regenerated from documents)",
        "4. Add `--rebuild-computed` flag to regenerate TF-IDF/PageRank from chunks",
        "",
        "**Implementation Phases:**",
        "",
        "**Phase 1: State Serialization Module**",
        "- Create `cortical/state_storage.py` with JSON serialization",
        "- Add `StateWriter` class (mirrors `ChunkWriter` pattern)",
        "- Add `StateLoader` class with hash validation",
        "- Implement incremental save (only changed components)",
        "",
        "**Phase 2: Integration with Processor**",
        "- Add `save_json(path)` and `load_json(path)` methods to processor",
        "- Maintain backward compatibility with `save()`/`load()` for pkl",
        "- Add migration utility: `migrate_pkl_to_json()`",
        "",
        "**Phase 3: Incremental Computed Value Updates**",
        "- Track which documents changed since last computation",
        "- Implement incremental TF-IDF update (add/remove terms)",
        "- Add manifest tracking for staleness",
        "",
        "**Quick Context:**",
        "- Entry point: `cortical/persistence.py::save_processor()` (line 25)",
        "- State structure: layers, documents, document_metadata, embeddings, semantic_relations",
        "- Existing pattern: `cortical/chunk_index.py::ChunkWriter` and `ChunkLoader` classes",
        "- Minicolumn serialization: `cortical/minicolumn.py::Minicolumn.to_dict()` (already exists)",
        "- Layer serialization: `cortical/layers.py::HierarchicalLayer.to_dict()` (already exists)",
        "",
        "**Acceptance Criteria:**",
        "- [ ] All processor state can be saved/loaded as JSON",
        "- [ ] No merge conflicts when multiple users index concurrently",
        "- [ ] Incremental saves only update changed components",
        "- [ ] Backward compatibility: can still load existing pkl files",
        "- [ ] Migration script converts pkl â†’ JSON",
        "- [ ] Full test coverage for new module",
        "- [ ] Performance: save/load within 2x of pkl for typical corpus",
        "",
        "---",
        ""
      ],
      "lines_removed": [],
      "context_before": [
        "- #198-205 Legacy test investigation COMPLETE - 8 tasks, 10 files reviewed",
        "- #197 Task list validation in CI - Added validate-task-list job to workflow",
        "- #186 Simplified facade methods - quick_search(), rag_retrieve(), explore() (23 tests)",
        "- #196 Spectral embeddings warning - RuntimeWarning for large graphs (>5000 terms)",
        "- Unit Test Coverage Initiative: 1,729 tests, 85% coverage, 19 modules at 90%+",
        "",
        "---",
        "",
        "## Pending Task Details",
        ""
      ],
      "context_after": [
        "### 184. Implement MCP Server for Claude Desktop Integration",
        "",
        "**Meta:** `status:pending` `priority:high` `category:integration`",
        "**Files:** `cortical/mcp_server.py` (new), `mcp_config.json` (new)",
        "**Effort:** Large",
        "",
        "**Problem:** AI agents must call subprocess scripts instead of native integration. Claude Desktop users can't access the processor directly.",
        "",
        "**Solution:** Create MCP (Model Context Protocol) server with tools:",
        "- `search(query, top_n)` â†’ document results"
      ],
      "change_type": "add"
    },
    {
      "file": "TASK_LIST.md",
      "function": "All completed tasks are now archived in [TASK_ARCHIVE.md](TASK_ARCHIVE.md).",
      "start_line": 323,
      "lines_added": [
        "| Arch | 6 | Architecture refactoring (#206, 133, 134, 135, 95, 100) |"
      ],
      "lines_removed": [
        "| Arch | 5 | Architecture refactoring (#133, 134, 135, 95, 100) |"
      ],
      "context_before": [
        "| processor.py | 85% | ðŸ”¶ | #165-166 |",
        "",
        "**19 of 21 modules at 90%+ coverage**",
        "",
        "---",
        "",
        "## Category Index",
        "",
        "| Category | Pending | Description |",
        "|----------|---------|-------------|"
      ],
      "context_after": [
        "| DevEx | 3 | Developer experience, scripts (#75, 78, 80) |",
        "| Samples | 1 | Sample document improvements (#130) |",
        "",
        "*Updated 2025-12-13 - 15 tasks completed via parallel sub-agents*",
        "",
        "---",
        "",
        "## Notes",
        "",
        "- **Effort estimates:** Small (<1 hour), Medium (1-4 hours), Large (1+ days)"
      ],
      "change_type": "modify"
    }
  ],
  "hour_of_day": 21,
  "day_of_week": "Saturday",
  "seconds_since_last_commit": -143280,
  "is_merge": false,
  "is_initial": false,
  "parent_count": 1,
  "session_id": null,
  "related_chats": [],
  "ci_result": null,
  "reverted": false,
  "amended": false
}