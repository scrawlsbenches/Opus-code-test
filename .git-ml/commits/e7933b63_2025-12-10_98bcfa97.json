{
  "hash": "e7933b637ffdfee3556f0dae474d19ed81e4ba3c",
  "message": "Implement Task 4: Improve clustering to reduce topic isolation",
  "author": "Claude",
  "timestamp": "2025-12-10 00:49:11 +0000",
  "branch": "claude/multi-index-design-DvifZ",
  "files_changed": [
    "TASK_list.md",
    "cortical/analysis.py",
    "cortical/processor.py",
    "tests/test_processor.py"
  ],
  "insertions": 272,
  "deletions": 36,
  "hunks": [
    {
      "file": "TASK_list.md",
      "function": "Layer 2 (Concept Layer/V4) shows 0 connections when documents cover diverse topi",
      "start_line": 32,
      "lines_added": [
        "### Task 4: Improve Clustering to Reduce Topic Isolation ✅ COMPLETED",
        "**File:** `cortical/analysis.py` (lines 482-616)",
        "- [x] Add `cluster_strictness` parameter to label propagation (0.0-1.0)",
        "- [x] Lower strictness = more cross-topic token mixing in clusters",
        "- [x] Add `bridge_weight` parameter for inter-document token bridging",
        "- [x] Add tests for different strictness levels and bridging"
      ],
      "lines_removed": [
        "### Task 4: Improve Clustering to Reduce Topic Isolation",
        "**File:** `cortical/analysis.py` (lines 482-553)",
        "- [ ] Add `cluster_strictness` parameter to label propagation (0.0-1.0)",
        "- [ ] Lower strictness = more cross-topic token mixing in clusters",
        "- [ ] Consider adding inter-document token bridging before clustering",
        "- [ ] Add tests for different strictness levels"
      ],
      "context_before": [
        "### Task 3: Connect Concepts via Shared Vocabulary/Embeddings ✅ COMPLETED",
        "**File:** `cortical/analysis.py`",
        "",
        "- [x] Add connection method based on embedding similarity between concept centroids",
        "- [x] Compute concept centroid as average of member token embeddings",
        "- [x] Connect concepts with cosine similarity above threshold",
        "- [x] Add `use_embedding_similarity=True` and `embedding_threshold=0.3` parameters",
        "- [x] Falls back gracefully if embeddings not computed",
        "- [x] Add tests for embedding-based connections",
        ""
      ],
      "context_after": [
        "",
        "",
        "### Task 5: Integration and API Updates",
        "**File:** `cortical/processor.py`",
        "",
        "- [ ] Update `compute_all()` to accept connection strategy parameters",
        "- [ ] Add `connection_strategy` enum: 'document_overlap', 'semantic', 'embedding', 'hybrid'",
        "- [ ] 'hybrid' combines all three methods with configurable weights",
        "- [ ] Update showcase.py to demonstrate different strategies",
        "- [ ] Add documentation in CLAUDE.md",
        ""
      ],
      "change_type": "modify"
    },
    {
      "file": "cortical/analysis.py",
      "function": "def propagate_activation(",
      "start_line": 475,
      "lines_added": [
        "    max_iterations: int = 20,",
        "    cluster_strictness: float = 1.0,",
        "    bridge_weight: float = 0.0",
        "",
        "",
        "        cluster_strictness: Controls clustering aggressiveness (0.0-1.0).",
        "            - 1.0 (default): Strict clustering, topics stay separate",
        "            - 0.5: Moderate mixing, allows some cross-topic clustering",
        "            - 0.0: Minimal clustering, most tokens group together",
        "            Lower values create fewer, larger clusters.",
        "        bridge_weight: Weight for synthetic inter-document connections (0.0-1.0).",
        "            When > 0, adds weak connections between tokens that appear in",
        "            different documents, helping bridge topic-isolated clusters.",
        "            - 0.0 (default): No bridging",
        "            - 0.3: Light bridging",
        "            - 0.7: Strong bridging",
        "",
        "    # Clamp parameters to valid range",
        "    cluster_strictness = max(0.0, min(1.0, cluster_strictness))",
        "    bridge_weight = max(0.0, min(1.0, bridge_weight))",
        "",
        "",
        "",
        "    # Build augmented connection weights (includes optional bridging)",
        "    augmented_connections: Dict[str, Dict[str, float]] = defaultdict(dict)",
        "",
        "    for content in columns:",
        "        col = layer.minicolumns[content]",
        "        for neighbor_id, weight in col.lateral_connections.items():",
        "            neighbor = layer.get_by_id(neighbor_id)",
        "            if neighbor:",
        "                augmented_connections[content][neighbor.content] = weight",
        "",
        "    # Add synthetic bridge connections between documents if requested",
        "    if bridge_weight > 0:",
        "        # Group tokens by document",
        "        doc_tokens: Dict[str, List[str]] = defaultdict(list)",
        "        for content in columns:",
        "            col = layer.minicolumns[content]",
        "            for doc_id in col.document_ids:",
        "                doc_tokens[doc_id].append(content)",
        "",
        "        # Create weak connections between tokens from different documents",
        "        doc_ids = list(doc_tokens.keys())",
        "        for i, doc1 in enumerate(doc_ids):",
        "            for doc2 in doc_ids[i+1:]:",
        "                tokens1 = doc_tokens[doc1]",
        "                tokens2 = doc_tokens[doc2]",
        "                # Connect a sample of tokens to avoid O(n²) explosion",
        "                sample_size = min(5, len(tokens1), len(tokens2))",
        "                for t1 in tokens1[:sample_size]:",
        "                    for t2 in tokens2[:sample_size]:",
        "                        if t1 != t2:",
        "                            # Add weak bidirectional bridge",
        "                            current = augmented_connections[t1].get(t2, 0)",
        "                            augmented_connections[t1][t2] = current + bridge_weight * 0.5",
        "                            current = augmented_connections[t2].get(t1, 0)",
        "                            augmented_connections[t2][t1] = current + bridge_weight * 0.5",
        "",
        "    # Calculate label change threshold based on strictness",
        "    # Higher strictness = requires stronger evidence to change label",
        "    change_threshold = (1.0 - cluster_strictness) * 0.3",
        "",
        "",
        "",
        "            for neighbor_content, weight in augmented_connections[content].items():",
        "                if neighbor_content in labels:",
        "                    label_weights[labels[neighbor_content]] += weight",
        "",
        "            # Apply strictness: current label gets a bonus based on strictness",
        "            current_label = labels[content]",
        "            if current_label in label_weights and cluster_strictness < 1.0:",
        "                # Lower strictness = stronger bias toward current label",
        "                label_weights[current_label] *= (1 + (1 - cluster_strictness) * 2)",
        "",
        "                best_label, best_weight = max(label_weights.items(), key=lambda x: x[1])",
        "                current_weight = label_weights.get(current_label, 0)",
        "",
        "                # Only change if the improvement exceeds threshold",
        "                if best_label != current_label:",
        "                    if current_weight == 0 or (best_weight / max(current_weight, 0.001) - 1) > change_threshold:",
        "                        labels[content] = best_label",
        "                        changed = True",
        "",
        "",
        "",
        "        label: members",
        "        for label, members in clusters.items()",
        "",
        ""
      ],
      "lines_removed": [
        "    max_iterations: int = 20",
        "    ",
        "    ",
        "        ",
        "    ",
        "    ",
        "        ",
        "            col = layer.minicolumns[content]",
        "            ",
        "            ",
        "            for neighbor_id, weight in col.lateral_connections.items():",
        "                # Use O(1) ID lookup instead of linear search",
        "                neighbor = layer.get_by_id(neighbor_id)",
        "                if neighbor and neighbor.content in labels:",
        "                    label_weights[labels[neighbor.content]] += weight",
        "            ",
        "                best_label = max(label_weights.items(), key=lambda x: x[1])[0]",
        "                if labels[content] != best_label:",
        "                    labels[content] = best_label",
        "                    changed = True",
        "        ",
        "    ",
        "    ",
        "        label: members ",
        "        for label, members in clusters.items() ",
        "    ",
        "    "
      ],
      "context_before": [
        "                continue",
        "            layer = layers[layer_enum]",
        "            for col in layer.minicolumns.values():",
        "                if col.id in new_activations:",
        "                    col.activation = new_activations[col.id]",
        "",
        "",
        "def cluster_by_label_propagation(",
        "    layer: HierarchicalLayer,",
        "    min_cluster_size: int = 3,"
      ],
      "context_after": [
        ") -> Dict[int, List[str]]:",
        "    \"\"\"",
        "    Cluster minicolumns using label propagation.",
        "    Label propagation is a semi-supervised community detection",
        "    algorithm. Each node adopts the most common label among its",
        "    neighbors, causing labels to propagate through densely",
        "    connected regions.",
        "    Args:",
        "        layer: Layer to cluster",
        "        min_cluster_size: Minimum nodes per cluster",
        "        max_iterations: Maximum iterations",
        "    Returns:",
        "        Dictionary mapping cluster_id to list of column contents",
        "    \"\"\"",
        "    # Initialize each node with unique label",
        "    labels = {col.content: i for i, col in enumerate(layer.minicolumns.values())}",
        "    # Get column list for shuffling",
        "    columns = list(layer.minicolumns.keys())",
        "    for iteration in range(max_iterations):",
        "        changed = False",
        "        # Process in order (could shuffle for better results)",
        "        for content in columns:",
        "            # Count neighbor labels weighted by connection strength",
        "            label_weights: Dict[int, float] = defaultdict(float)",
        "            # Adopt most common label",
        "            if label_weights:",
        "        if not changed:",
        "            break",
        "    # Build clusters",
        "    clusters: Dict[int, List[str]] = defaultdict(list)",
        "    for content, label in labels.items():",
        "        clusters[label].append(content)",
        "    # Filter by minimum size",
        "    filtered = {",
        "        if len(members) >= min_cluster_size",
        "    }",
        "    # Update cluster_id on minicolumns",
        "    for label, members in filtered.items():",
        "        for content in members:",
        "            if content in layer.minicolumns:",
        "                layer.minicolumns[content].cluster_id = label",
        "    return filtered",
        "",
        "",
        "def build_concept_clusters(",
        "    layers: Dict[CorticalLayer, HierarchicalLayer],",
        "    clusters: Dict[int, List[str]]",
        ") -> None:",
        "    \"\"\"",
        "    Build concept layer from token clusters.",
        "    "
      ],
      "change_type": "modify"
    },
    {
      "file": "cortical/processor.py",
      "function": "class CorticalTextProcessor:",
      "start_line": 655,
      "lines_added": [
        "    def build_concept_clusters(",
        "        self,",
        "        min_cluster_size: int = 3,",
        "        cluster_strictness: float = 1.0,",
        "        bridge_weight: float = 0.0,",
        "        verbose: bool = True",
        "    ) -> Dict[int, List[str]]:",
        "        \"\"\"",
        "        Build concept clusters from token layer using label propagation.",
        "",
        "        Args:",
        "            min_cluster_size: Minimum tokens per cluster (default 3)",
        "            cluster_strictness: Controls clustering aggressiveness (0.0-1.0).",
        "                - 1.0 (default): Strict clustering, topics stay separate",
        "                - 0.5: Moderate mixing, allows some cross-topic clustering",
        "                - 0.0: Minimal clustering, most tokens group together",
        "                Lower values create fewer, larger clusters with more connections.",
        "            bridge_weight: Weight for synthetic inter-document connections (0.0-1.0).",
        "                When > 0, adds weak connections between tokens from different",
        "                documents, helping bridge topic-isolated clusters.",
        "                - 0.0 (default): No bridging",
        "                - 0.3: Light bridging",
        "                - 0.7: Strong bridging",
        "            verbose: Print progress messages",
        "",
        "        Returns:",
        "            Dictionary mapping cluster_id to list of token contents",
        "",
        "        Example:",
        "            >>> # Default strict clustering",
        "            >>> clusters = processor.build_concept_clusters()",
        "            >>>",
        "            >>> # Looser clustering for more cross-topic connections",
        "            >>> clusters = processor.build_concept_clusters(",
        "            ...     cluster_strictness=0.5,",
        "            ...     bridge_weight=0.3",
        "            ... )",
        "        \"\"\"",
        "        clusters = analysis.cluster_by_label_propagation(",
        "            self.layers[CorticalLayer.TOKENS],",
        "            min_cluster_size=min_cluster_size,",
        "            cluster_strictness=cluster_strictness,",
        "            bridge_weight=bridge_weight",
        "        )",
        "        if verbose:",
        "            print(f\"Built {len(clusters)} concept clusters\")"
      ],
      "lines_removed": [
        "    def build_concept_clusters(self, verbose: bool = True) -> Dict[int, List[str]]:",
        "        clusters = analysis.cluster_by_label_propagation(self.layers[CorticalLayer.TOKENS])",
        "        if verbose: print(f\"Built {len(clusters)} concept clusters\")"
      ],
      "context_before": [
        "            chain_weight=chain_weight,",
        "            cooccurrence_weight=cooccurrence_weight",
        "        )",
        "        if verbose:",
        "            print(f\"Created {stats['connections_created']} bigram connections \"",
        "                  f\"(component: {stats['component_connections']}, \"",
        "                  f\"chain: {stats['chain_connections']}, \"",
        "                  f\"cooccur: {stats['cooccurrence_connections']})\")",
        "        return stats",
        ""
      ],
      "context_after": [
        "        analysis.build_concept_clusters(self.layers, clusters)",
        "        return clusters",
        "",
        "    def compute_concept_connections(",
        "        self,",
        "        use_semantics: bool = True,",
        "        min_shared_docs: int = 1,",
        "        min_jaccard: float = 0.1,",
        "        use_member_semantics: bool = False,",
        "        use_embedding_similarity: bool = False,",
        "        embedding_threshold: float = 0.3,"
      ],
      "change_type": "modify"
    },
    {
      "file": "tests/test_processor.py",
      "function": null,
      "start_line": 1,
      "lines_added": [
        "from cortical.layers import HierarchicalLayer"
      ],
      "lines_removed": [],
      "context_before": [
        "\"\"\"Tests for the CorticalTextProcessor class.\"\"\"",
        "",
        "import unittest",
        "import tempfile",
        "import os",
        "import sys",
        "sys.path.insert(0, '..')",
        "",
        "from cortical import CorticalTextProcessor, CorticalLayer"
      ],
      "context_after": [
        "",
        "",
        "class TestProcessorBasic(unittest.TestCase):",
        "    \"\"\"Test basic processor functionality.\"\"\"",
        "    ",
        "    def setUp(self):",
        "        self.processor = CorticalTextProcessor()",
        "    ",
        "    def test_process_document(self):",
        "        \"\"\"Test document processing.\"\"\""
      ],
      "change_type": "add"
    },
    {
      "file": "tests/test_processor.py",
      "function": "class TestConceptConnections(unittest.TestCase):",
      "start_line": 1317,
      "lines_added": [
        "class TestConceptClustering(unittest.TestCase):",
        "    \"\"\"Test concept clustering with strictness and bridging parameters.\"\"\"",
        "",
        "    def test_cluster_strictness_parameter(self):",
        "        \"\"\"Test that cluster_strictness affects number of clusters.\"\"\"",
        "        processor = CorticalTextProcessor()",
        "        processor.process_document(",
        "            \"doc1\", \"Neural networks process information using layers.\"",
        "        )",
        "        processor.process_document(",
        "            \"doc2\", \"Machine learning algorithms process data patterns.\"",
        "        )",
        "        processor.compute_importance(verbose=False)",
        "        processor.compute_tfidf(verbose=False)",
        "",
        "        # Strict clustering (default)",
        "        clusters_strict = processor.build_concept_clusters(",
        "            cluster_strictness=1.0, verbose=False",
        "        )",
        "",
        "        # Reset concepts layer",
        "        processor.layers[CorticalLayer.CONCEPTS] = HierarchicalLayer(CorticalLayer.CONCEPTS)",
        "",
        "        # Loose clustering",
        "        clusters_loose = processor.build_concept_clusters(",
        "            cluster_strictness=0.3, verbose=False",
        "        )",
        "",
        "        # Both should return valid cluster dictionaries",
        "        self.assertIsInstance(clusters_strict, dict)",
        "        self.assertIsInstance(clusters_loose, dict)",
        "",
        "    def test_bridge_weight_parameter(self):",
        "        \"\"\"Test that bridge_weight enables cross-document connections.\"\"\"",
        "        processor = CorticalTextProcessor()",
        "        processor.process_document(",
        "            \"doc1\", \"Neural networks learn patterns from data.\"",
        "        )",
        "        processor.process_document(",
        "            \"doc2\", \"Bread baking requires yeast and flour.\"",
        "        )",
        "        processor.compute_importance(verbose=False)",
        "        processor.compute_tfidf(verbose=False)",
        "",
        "        # No bridging (default)",
        "        clusters_no_bridge = processor.build_concept_clusters(",
        "            bridge_weight=0.0, verbose=False",
        "        )",
        "",
        "        # Reset concepts layer",
        "        processor.layers[CorticalLayer.CONCEPTS] = HierarchicalLayer(CorticalLayer.CONCEPTS)",
        "",
        "        # With bridging",
        "        clusters_with_bridge = processor.build_concept_clusters(",
        "            bridge_weight=0.5, verbose=False",
        "        )",
        "",
        "        # Both should produce valid results",
        "        self.assertIsInstance(clusters_no_bridge, dict)",
        "        self.assertIsInstance(clusters_with_bridge, dict)",
        "",
        "    def test_combined_clustering_parameters(self):",
        "        \"\"\"Test combining strictness and bridging parameters.\"\"\"",
        "        processor = CorticalTextProcessor()",
        "        processor.process_document(",
        "            \"doc1\", \"Neural networks are computational models.\"",
        "        )",
        "        processor.process_document(",
        "            \"doc2\", \"Deep learning uses neural networks for AI.\"",
        "        )",
        "        processor.compute_importance(verbose=False)",
        "        processor.compute_tfidf(verbose=False)",
        "",
        "        # Combined loose clustering with bridging",
        "        clusters = processor.build_concept_clusters(",
        "            cluster_strictness=0.5,",
        "            bridge_weight=0.3,",
        "            min_cluster_size=2,",
        "            verbose=False",
        "        )",
        "",
        "        self.assertIsInstance(clusters, dict)",
        "",
        "    def test_min_cluster_size_filter(self):",
        "        \"\"\"Test that min_cluster_size filters small clusters.\"\"\"",
        "        processor = CorticalTextProcessor()",
        "        processor.process_document(",
        "            \"doc1\", \"Neural networks process information efficiently.\"",
        "        )",
        "        processor.compute_importance(verbose=False)",
        "        processor.compute_tfidf(verbose=False)",
        "",
        "        # Large minimum size should produce fewer clusters",
        "        clusters_large_min = processor.build_concept_clusters(",
        "            min_cluster_size=10, verbose=False",
        "        )",
        "",
        "        # Reset concepts layer",
        "        processor.layers[CorticalLayer.CONCEPTS] = HierarchicalLayer(CorticalLayer.CONCEPTS)",
        "",
        "        # Small minimum size",
        "        clusters_small_min = processor.build_concept_clusters(",
        "            min_cluster_size=2, verbose=False",
        "        )",
        "",
        "        # Small min should allow at least as many clusters",
        "        self.assertGreaterEqual(len(clusters_small_min), len(clusters_large_min))",
        "",
        "    def test_cluster_strictness_bounds(self):",
        "        \"\"\"Test that cluster_strictness is clamped to valid range.\"\"\"",
        "        processor = CorticalTextProcessor()",
        "        processor.process_document(\"doc1\", \"Test document with words.\")",
        "        processor.compute_importance(verbose=False)",
        "        processor.compute_tfidf(verbose=False)",
        "",
        "        # Should handle out-of-range values gracefully",
        "        clusters_negative = processor.build_concept_clusters(",
        "            cluster_strictness=-0.5, verbose=False",
        "        )",
        "        self.assertIsInstance(clusters_negative, dict)",
        "",
        "        processor.layers[CorticalLayer.CONCEPTS] = HierarchicalLayer(CorticalLayer.CONCEPTS)",
        "",
        "        clusters_over = processor.build_concept_clusters(",
        "            cluster_strictness=1.5, verbose=False",
        "        )",
        "        self.assertIsInstance(clusters_over, dict)",
        "",
        ""
      ],
      "lines_removed": [],
      "context_before": [
        "        stats = self.processor.compute_concept_connections(verbose=False)",
        "",
        "        # Check all expected keys are present",
        "        self.assertIn('connections_created', stats)",
        "        self.assertIn('concepts', stats)",
        "        self.assertIn('doc_overlap_connections', stats)",
        "        self.assertIn('semantic_connections', stats)",
        "        self.assertIn('embedding_connections', stats)",
        "",
        ""
      ],
      "context_after": [
        "class TestBigramConnections(unittest.TestCase):",
        "    \"\"\"Test bigram lateral connection functionality.\"\"\"",
        "",
        "    @classmethod",
        "    def setUpClass(cls):",
        "        \"\"\"Set up processor with documents containing related bigrams.\"\"\"",
        "        cls.processor = CorticalTextProcessor()",
        "        # Documents with overlapping bigrams to test connections",
        "        cls.processor.process_document(",
        "            \"doc1\","
      ],
      "change_type": "add"
    }
  ],
  "hour_of_day": 0,
  "day_of_week": "Wednesday",
  "seconds_since_last_commit": -478537,
  "is_merge": false,
  "is_initial": false,
  "parent_count": 1,
  "session_id": null,
  "related_chats": [],
  "ci_result": null,
  "reverted": false,
  "amended": false
}