{
  "hash": "f0b7506aca8da42c05346fea2ca05f2599a70f3a",
  "message": "fix(#134): Use protobuf text format for git-friendly output",
  "author": "Claude",
  "timestamp": "2025-12-14 09:27:21 +0000",
  "branch": "claude/multi-index-design-DvifZ",
  "files_changed": [
    "cortical/persistence.py",
    "cortical/proto/__init__.py"
  ],
  "insertions": 32,
  "deletions": 18,
  "hunks": [
    {
      "file": "cortical/persistence.py",
      "function": "def save_processor(",
      "start_line": 67,
      "lines_added": [
        "        # Protocol Buffers serialization (text format for git-friendliness)",
        "            from google.protobuf import text_format",
        "        # Use text format for human-readable, git-friendly output",
        "        with open(filepath, 'w', encoding='utf-8') as f:",
        "            f.write(text_format.MessageToString(proto_state))"
      ],
      "lines_removed": [
        "        # Protocol Buffers serialization",
        "        with open(filepath, 'wb') as f:",
        "            f.write(proto_state.SerializeToString())"
      ],
      "context_before": [
        "        }",
        "",
        "        # Serialize layers",
        "        for layer_enum, layer in layers.items():",
        "            state['layers'][layer_enum.value] = layer.to_dict()",
        "",
        "        with open(filepath, 'wb') as f:",
        "            pickle.dump(state, f, protocol=pickle.HIGHEST_PROTOCOL)",
        "",
        "    elif format == 'protobuf':"
      ],
      "context_after": [
        "        try:",
        "            from .proto.serialization import to_proto",
        "        except ImportError as e:",
        "            raise ImportError(",
        "                \"protobuf package is required for Protocol Buffers serialization. \"",
        "                \"Install it with: pip install protobuf\"",
        "            ) from e",
        "",
        "        proto_state = to_proto(",
        "            layers, documents, document_metadata,",
        "            embeddings, semantic_relations, metadata",
        "        )",
        "",
        "",
        "    if verbose:",
        "        total_cols = sum(len(layer.minicolumns) for layer in layers.values())",
        "        total_conns = sum(layer.total_connections() for layer in layers.values())",
        "        logger.info(f\"✓ Saved processor to {filepath} (format: {format})\")",
        "        logger.info(f\"  - {len(documents)} documents\")",
        "        logger.info(f\"  - {total_cols} minicolumns\")",
        "        logger.info(f\"  - {total_conns} connections\")",
        "        if embeddings:",
        "            logger.info(f\"  - {len(embeddings)} embeddings\")"
      ],
      "change_type": "modify"
    },
    {
      "file": "cortical/persistence.py",
      "function": "def load_processor(",
      "start_line": 122,
      "lines_added": [
        "            header = f.read(64)",
        "                # Protobuf text format starts with readable text like \"version:\" or \"layers {\"",
        "                # Check if it looks like text (ASCII/UTF-8)",
        "                try:",
        "                    header_text = header.decode('utf-8')",
        "                    if 'version' in header_text or 'layers' in header_text:",
        "                        format = 'protobuf'",
        "                    else:",
        "                        # Default to pickle for unknown formats",
        "                        format = 'pickle'",
        "                except UnicodeDecodeError:",
        "                    # Binary content - assume pickle",
        "                    format = 'pickle'"
      ],
      "lines_removed": [
        "            header = f.read(16)",
        "            f.seek(0)",
        "            # Protobuf files have different structure",
        "                # Try protobuf",
        "                format = 'protobuf'"
      ],
      "context_before": [
        "",
        "    Raises:",
        "        ValueError: If layer values are invalid (must be 0-3) or format is invalid",
        "        ImportError: If format='protobuf' but protobuf package is not installed",
        "    \"\"\"",
        "    # Auto-detect format if not specified",
        "    if format is None:",
        "        # Try to detect based on file content",
        "        with open(filepath, 'rb') as f:",
        "            # Read first few bytes"
      ],
      "context_after": [
        "",
        "            # Pickle files start with 0x80 (protocol marker)",
        "            if header[0:1] == b'\\x80':",
        "                format = 'pickle'",
        "            else:",
        "",
        "    if format not in ['pickle', 'protobuf']:",
        "        raise ValueError(f\"Invalid format '{format}'. Must be 'pickle' or 'protobuf'.\")",
        "",
        "    if format == 'pickle':",
        "        # Original pickle deserialization",
        "        with open(filepath, 'rb') as f:",
        "            state = pickle.load(f)",
        "",
        "        # Reconstruct layers"
      ],
      "change_type": "modify"
    },
    {
      "file": "cortical/persistence.py",
      "function": "def load_processor(",
      "start_line": 161,
      "lines_added": [
        "        # Protocol Buffers deserialization (text format)",
        "            from google.protobuf import text_format",
        "        with open(filepath, 'r', encoding='utf-8') as f:",
        "            proto_text = f.read()",
        "        text_format.Parse(proto_text, proto_state)"
      ],
      "lines_removed": [
        "        # Protocol Buffers deserialization",
        "        with open(filepath, 'rb') as f:",
        "            proto_bytes = f.read()",
        "        proto_state.ParseFromString(proto_bytes)"
      ],
      "context_before": [
        "            layer = HierarchicalLayer.from_dict(layer_data)",
        "            layers[CorticalLayer(level_int)] = layer",
        "",
        "        documents = state.get('documents', {})",
        "        document_metadata = state.get('document_metadata', {})",
        "        embeddings = state.get('embeddings', {})",
        "        semantic_relations = state.get('semantic_relations', [])",
        "        metadata = state.get('metadata', {})",
        "",
        "    elif format == 'protobuf':"
      ],
      "context_after": [
        "        try:",
        "            from .proto.serialization import from_proto",
        "            from .proto import schema_pb2",
        "        except ImportError as e:",
        "            raise ImportError(",
        "                \"protobuf package is required for Protocol Buffers deserialization. \"",
        "                \"Install it with: pip install protobuf\"",
        "            ) from e",
        "",
        "",
        "        proto_state = schema_pb2.ProcessorState()",
        "",
        "        layers, documents, document_metadata, embeddings, semantic_relations, metadata = from_proto(proto_state)",
        "",
        "    if verbose:",
        "        total_cols = sum(len(layer.minicolumns) for layer in layers.values())",
        "        total_conns = sum(layer.total_connections() for layer in layers.values())",
        "        logger.info(f\"✓ Loaded processor from {filepath} (format: {format})\")",
        "        logger.info(f\"  - {len(documents)} documents\")",
        "        logger.info(f\"  - {total_cols} minicolumns\")",
        "        logger.info(f\"  - {total_conns} connections\")"
      ],
      "change_type": "modify"
    },
    {
      "file": "cortical/proto/__init__.py",
      "function": null,
      "start_line": 1,
      "lines_added": [
        "its state using Protocol Buffers TEXT FORMAT, allowing corpus data to be:",
        "- Human-readable and diffable in git",
        "- Shared across different programming languages",
        "- Reviewed in pull requests",
        "    from google.protobuf import text_format",
        "    # Serialize to text format (git-friendly)",
        "    text_output = text_format.MessageToString(proto_state)",
        "    # Deserialize from text format",
        "    text_format.Parse(text_input, proto_state)"
      ],
      "lines_removed": [
        "its state using Protocol Buffers, allowing corpus data to be shared across",
        "different programming languages and platforms.",
        "    # Serialize to bytes",
        "    serialized = proto_state.SerializeToString()",
        "    # Deserialize from bytes",
        "    proto_state.ParseFromString(serialized)"
      ],
      "context_before": [
        "\"\"\"",
        "Protocol Buffers Serialization Module",
        "=====================================",
        "",
        "Provides Protocol Buffers serialization for cross-language corpus sharing.",
        "",
        "This module enables the Cortical Text Processor to serialize and deserialize"
      ],
      "context_after": [
        "",
        "Usage:",
        "    from cortical.proto.serialization import to_proto, from_proto",
        "",
        "    # Convert processor state to protobuf",
        "    proto_state = to_proto(layers, documents, document_metadata,",
        "                           embeddings, semantic_relations, metadata)",
        "",
        "",
        "    proto_state = ProcessorState()",
        "",
        "    # Convert back to Python objects",
        "    state = from_proto(proto_state)",
        "\"\"\"",
        "",
        "try:",
        "    from .serialization import to_proto, from_proto",
        "    __all__ = ['to_proto', 'from_proto']",
        "except ImportError:",
        "    # Protobuf not installed - this is OK for core library functionality"
      ],
      "change_type": "modify"
    }
  ],
  "hour_of_day": 9,
  "day_of_week": "Sunday",
  "seconds_since_last_commit": -101847,
  "is_merge": false,
  "is_initial": false,
  "parent_count": 1,
  "session_id": null,
  "related_chats": [],
  "ci_result": null,
  "reverted": false,
  "amended": false
}