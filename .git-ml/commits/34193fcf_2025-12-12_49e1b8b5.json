{
  "hash": "34193fcf2ffc3571cacac86dec302efa90d23c1c",
  "message": "Complete tasks #91, #92, #93, #96, #113, #114: Documentation and code quality improvements",
  "author": "Claude",
  "timestamp": "2025-12-12 03:00:20 +0000",
  "branch": "claude/multi-index-design-DvifZ",
  "files_changed": [
    "CLAUDE.md",
    "README.md",
    "TASK_LIST.md",
    "cortical/analysis.py",
    "cortical/constants.py",
    "cortical/query/ranking.py",
    "cortical/semantics.py",
    "cortical/types.py",
    "docs/README.md",
    "tests/test_semantics.py"
  ],
  "insertions": 451,
  "deletions": 66,
  "hunks": [
    {
      "file": "CLAUDE.md",
      "function": "processor.add_document_incremental(doc_id, text)",
      "start_line": 282,
      "lines_added": [
        "### Staleness Tracking System",
        "",
        "The processor tracks which computations are up-to-date vs needing recalculation. This prevents unnecessary recomputation while ensuring data consistency.",
        "",
        "#### Computation Types",
        "",
        "| Constant | What it tracks | Computed by |",
        "|----------|---------------|-------------|",
        "| `COMP_TFIDF` | TF-IDF scores per term | `compute_tfidf()` |",
        "| `COMP_PAGERANK` | PageRank importance | `compute_importance()` |",
        "| `COMP_ACTIVATION` | Activation propagation | `propagate_activation()` |",
        "| `COMP_DOC_CONNECTIONS` | Document-to-document links | `compute_document_connections()` |",
        "| `COMP_BIGRAM_CONNECTIONS` | Bigram lateral connections | `compute_bigram_connections()` |",
        "| `COMP_CONCEPTS` | Concept clusters (Layer 2) | `build_concept_clusters()` |",
        "| `COMP_EMBEDDINGS` | Graph embeddings | `compute_graph_embeddings()` |",
        "| `COMP_SEMANTICS` | Semantic relations | `extract_corpus_semantics()` |",
        "",
        "#### How Staleness Works",
        "",
        "1. **All computations start stale** - `_mark_all_stale()` is called in `__init__`",
        "2. **Adding documents marks all stale** - `process_document()` calls `_mark_all_stale()`",
        "3. **Computing marks fresh** - Each `compute_*()` method calls `_mark_fresh()`",
        "4. **`compute_all()` recomputes only stale** - Checks each computation before running",
        "",
        "#### API Methods",
        "",
        "```python",
        "# Check if a computation is stale",
        "if processor.is_stale(processor.COMP_PAGERANK):",
        "    processor.compute_importance()",
        "",
        "# Get all stale computations",
        "stale = processor.get_stale_computations()",
        "# Returns: {'pagerank', 'tfidf', ...}",
        "```",
        "",
        "#### Incremental Updates",
        "",
        "`add_document_incremental()` is smarter - it can update TF-IDF without invalidating everything:",
        "",
        "```python",
        "# Only recomputes TF-IDF by default",
        "processor.add_document_incremental(doc_id, text, recompute='tfidf')",
        "",
        "# Recompute more",
        "processor.add_document_incremental(doc_id, text, recompute='all')",
        "",
        "# Don't recompute anything (fastest, but leaves data stale)",
        "processor.add_document_incremental(doc_id, text, recompute='none')",
        "```",
        "",
        "#### When to Check Staleness",
        "",
        "- **Before reading `col.pagerank`** - check `COMP_PAGERANK`",
        "- **Before reading `col.tfidf`** - check `COMP_TFIDF`",
        "- **Before using embeddings** - check `COMP_EMBEDDINGS`",
        "- **Before querying concepts** - check `COMP_CONCEPTS`",
        "",
        "#### Staleness After `load()`",
        "",
        "Loading a saved processor restores computation freshness state:",
        "```python",
        "processor = CorticalTextProcessor.load(\"corpus.pkl\")",
        "# Staleness state is preserved from when it was saved",
        "```",
        ""
      ],
      "lines_removed": [],
      "context_before": [
        "# WRONG - may be using stale data",
        "if processor.is_stale(processor.COMP_PAGERANK):",
        "    # PageRank values may be outdated!",
        "    pass",
        "",
        "# CORRECT - ensure freshness",
        "if processor.is_stale(processor.COMP_PAGERANK):",
        "    processor.compute_importance()",
        "```",
        ""
      ],
      "context_after": [
        "---",
        "",
        "## Development Workflow",
        "",
        "### Before Writing Code",
        "",
        "1. **Read the relevant module** - understand existing patterns",
        "2. **Check TASK_LIST.md** - see if work is already planned/done",
        "3. **Run tests first** to establish baseline:",
        "   ```bash"
      ],
      "change_type": "add"
    },
    {
      "file": "README.md",
      "function": null,
      "start_line": 1,
      "lines_added": [
        "![Python 3.8+](https://img.shields.io/badge/python-3.8%2B-blue.svg)",
        "![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)",
        "![Tests](https://img.shields.io/badge/tests-1121%20passing-brightgreen.svg)",
        "![Coverage](https://img.shields.io/badge/coverage-%3E89%25-brightgreen.svg)",
        "![Zero Dependencies](https://img.shields.io/badge/dependencies-zero-orange.svg)",
        ""
      ],
      "lines_removed": [],
      "context_before": [
        "# Cortical Text Processor",
        ""
      ],
      "context_after": [
        "A neocortex-inspired text processing library with **zero external dependencies** for semantic analysis, document retrieval, and knowledge gap detection.",
        "",
        "---",
        "",
        "> *\"What if we built a text search engine the way evolution built a brain?\"*",
        "",
        "Your visual cortex doesn't grep through pixels looking for cats. It builds hierarchiesâ€”edges become patterns, patterns become shapes, shapes become objects. This library applies the same principle to text.",
        "",
        "Feed it documents. It tokenizes them into \"minicolumns\" (Layer 0), connects co-occurring words through Hebbian learning (\"neurons that fire together, wire together\"), clusters them into concepts (Layer 2), and links documents by shared meaning (Layer 3). The result: a graph that understands your corpus well enough to expand queries, complete analogies, and tell you where your knowledge has gaps.",
        ""
      ],
      "change_type": "add"
    },
    {
      "file": "README.md",
      "function": "The processor discovers that `neural` connects to `networks` (weight: 23), `arti",
      "start_line": 328,
      "lines_added": [
        "## Documentation",
        "",
        "Detailed documentation is available in the `docs/` directory:",
        "",
        "| Document | Description |",
        "|----------|-------------|",
        "| [docs/README.md](docs/README.md) | Documentation index with reading paths |",
        "| [docs/quickstart.md](docs/quickstart.md) | 5-minute getting started guide |",
        "| [docs/architecture.md](docs/architecture.md) | 4-layer system design |",
        "| [docs/algorithms.md](docs/algorithms.md) | Core IR algorithms (PageRank, TF-IDF, Louvain) |",
        "| [docs/query-guide.md](docs/query-guide.md) | Query formulation guide |",
        "| [docs/cookbook.md](docs/cookbook.md) | Common patterns and recipes |",
        "| [docs/glossary.md](docs/glossary.md) | Terminology definitions |",
        "",
        "For AI agents, see also [docs/claude-usage.md](docs/claude-usage.md) and [CLAUDE.md](CLAUDE.md).",
        ""
      ],
      "lines_removed": [],
      "context_before": [
        "```",
        "",
        "### The Polysemy Problem",
        "",
        "Search for \"candle sticks\" and you'll find `candlestick_patterns` (trading charts) at the topâ€”but also `letterpress_printing` (composing sticks) and `wine_tasting_vocabulary`. The query tokenizes to `['candle', 'sticks']`: \"candle\" matches the trading document (which discusses \"single candle patterns\"), while \"sticks\" matches the printing document. Classic information retrieval challenge: compound words fragment, partial matches surface, and the system can't read your mind about intent.",
        "",
        "### Knowledge Gap Detection",
        "",
        "The analyzer flags `sumo_wrestling` and `medieval_falconry` as isolated documentsâ€”they don't fit well with the rest of the corpus. It also identifies weak topics: terms like `patent` appear in only 1 document. This is how you find holes in your knowledge base.",
        ""
      ],
      "context_after": [
        "## Running Tests",
        "",
        "```bash",
        "python -m unittest discover -s tests -v",
        "```",
        "",
        "## License",
        "",
        "MIT License"
      ],
      "change_type": "add"
    },
    {
      "file": "TASK_LIST.md",
      "function": "Active backlog for the Cortical Text Processor project. Completed tasks are arch",
      "start_line": 11,
      "lines_added": [
        "*All high priority tasks completed!*"
      ],
      "lines_removed": [
        "| # | Task | Category | Depends | Effort |",
        "|---|------|----------|---------|--------|",
        "| 146 | Create behavioral tests for core user workflows | Testing | - | Medium |",
        "| 91 | Create docs/README.md index | Docs | - | Small |",
        "| 92 | Add badges to README.md | DevEx | - | Small |",
        "| 93 | Update README with docs references | Docs | 91 | Small |",
        "| 96 | Centralize duplicate constants | CodeQual | - | Small |",
        "| 113 | Document staleness tracking system | AINav | - | Small |",
        "| 114 | Add type aliases for complex types | AINav | - | Small |"
      ],
      "context_before": [
        "## Active Backlog",
        "",
        "<!-- Machine-parseable format for automation -->",
        "",
        "### ðŸ”´ Critical (Do Now)",
        "",
        "*All critical tasks completed!*",
        "",
        "### ðŸŸ  High (Do This Week)",
        ""
      ],
      "context_after": [
        "",
        "### ðŸŸ¡ Medium (Do This Month)",
        "",
        "| # | Task | Category | Depends | Effort |",
        "|---|------|----------|---------|--------|",
        "| 137 | Cap bigram connections to top-K per bigram | Perf | - | Small |",
        "| 138 | Use sparse matrix multiplication for bigram connections | Perf | - | Medium |",
        "| 139 | Batch bigram connection updates to reduce dict overhead | Perf | - | Small |",
        "| 133 | Implement WAL + snapshot persistence (fault-tolerant rebuild) | Arch | 132 | Large |",
        "| 134 | Implement protobuf serialization for corpus | Arch | 132 | Medium |",
        "| 135 | Implement chunked parallel processing for full-analysis | Arch | 132 | Large |",
        "| 95 | Split processor.py into modules | Arch | 97 | Large |",
        "| 98 | Replace print() with logging | CodeQual | - | Medium |",
        "| 99 | Add input validation to public methods | CodeQual | - | Medium |",
        "| 102 | Add tests for edge cases | Testing | - | Medium |",
        "| 107 | Add Quick Context to tasks | TaskMgmt | - | Medium |",
        "| 115 | Create component interaction diagram | AINav | - | Medium |",
        "| 116 | Document return value semantics | AINav | - | Medium |",
        "",
        "### ðŸŸ¢ Low (Backlog)",
        "",
        "| # | Task | Category | Depends | Effort |",
        "|---|------|----------|---------|--------|",
        "| 73 | Add \"Find Similar Code\" command | DevEx | - | Medium |",
        "| 74 | Add \"Explain This Code\" command | DevEx | - | Medium |",
        "| 75 | Add \"What Changed?\" semantic diff | DevEx | - | Large |"
      ],
      "change_type": "modify"
    },
    {
      "file": "TASK_LIST.md",
      "function": "Active backlog for the Cortical Text Processor project. Completed tasks are arch",
      "start_line": 85,
      "lines_added": [
        "| 114 | Add type aliases for complex types | 2025-12-12 | cortical/types.py with 20+ aliases: DocumentScore, PassageResult, SemanticRelation, etc. |",
        "| 113 | Document staleness tracking system | 2025-12-12 | Comprehensive docs in CLAUDE.md: computation types, API, incremental updates |",
        "| 96 | Centralize duplicate constants | 2025-12-12 | cortical/constants.py with RELATION_WEIGHTS, DOC_TYPE_BOOSTS, query keywords |",
        "| 91 | Create docs/README.md index | 2025-12-12 | Navigation by audience, reading paths, categorized docs |",
        "| 92 | Add badges to README.md | 2025-12-12 | Python, License, Tests, Coverage, Zero Dependencies badges |",
        "| 93 | Update README with docs references | 2025-12-12 | Documentation section with table linking to docs/*.md |",
        "| 146 | Create behavioral tests for core user workflows | 2025-12-12 | 11 tests across 4 categories: Search, Performance, Quality, Robustness |"
      ],
      "lines_removed": [],
      "context_before": [
        "| # | Task | Started | Notes |",
        "|---|------|---------|-------|",
        "| 87 | Add Python code samples and showcase | 2025-12-11 | samples/*.py created |",
        "",
        "---",
        "",
        "## Recently Completed (Last 7 Days)",
        "",
        "| # | Task | Completed | Notes |",
        "|---|------|-----------|-------|"
      ],
      "context_after": [
        "| 145 | Improve graph embedding quality for common terms | 2025-12-12 | Added 'tfidf' method, IDF weighting to 'fast' method |",
        "| 143 | Investigate negative silhouette score in clustering | 2025-12-12 | Expected behavior: modularity â‰  silhouette (graph vs doc similarity) |",
        "| 142 | Investigate 74s compute_all() performance regression | 2025-12-12 | 5.2x speedup via fast embeddings + sampling (74s â†’ 14s) |",
        "| 144 | Boost exact document name matches in search | 2025-12-12 | doc_name_boost parameter in search functions |",
        "| 141 | Filter Python keywords/artifacts from analysis | 2025-12-12 | CODE_NOISE_TOKENS + filter_code_noise tokenizer option |",
        "| 94 | Split query.py into focused modules | 2025-12-12 | 8 modules: expansion, search, passages, chunking, intent, definitions, ranking, analogy |",
        "| 97 | Integrate CorticalConfig into processor | 2025-12-11 | Config stored on processor, used in method defaults, saved/loaded |",
        "| 127 | Create cluster coverage evaluation script | 2025-12-11 | scripts/evaluate_cluster.py with 24 tests |",
        "| 125 | Add clustering quality metrics (modularity, silhouette) | 2025-12-11 | compute_clustering_quality() in analysis.py, showcase display |",
        "| 124 | Add minimum cluster count regression tests | 2025-12-11 | 4 new tests: coherence, showcase count, mega-cluster, distribution |"
      ],
      "change_type": "add"
    },
    {
      "file": "cortical/analysis.py",
      "function": "Contains implementations of:",
      "start_line": 11,
      "lines_added": [
        "from .constants import RELATION_WEIGHTS"
      ],
      "lines_removed": [],
      "context_before": [
        "- Label propagation for clustering (legacy, for backward compatibility)",
        "- Activation propagation for information flow",
        "\"\"\"",
        "",
        "import math",
        "from typing import Dict, List, Tuple, Set, Optional, Any",
        "from collections import defaultdict",
        "",
        "from .layers import CorticalLayer, HierarchicalLayer",
        "from .minicolumn import Minicolumn"
      ],
      "context_after": [
        "",
        "",
        "def compute_pagerank(",
        "    layer: HierarchicalLayer,",
        "    damping: float = 0.85,",
        "    iterations: int = 20,",
        "    tolerance: float = 1e-6",
        ") -> Dict[str, float]:",
        "    \"\"\"",
        "    Compute PageRank scores for minicolumns in a layer."
      ],
      "change_type": "add"
    },
    {
      "file": "cortical/analysis.py",
      "function": "def compute_pagerank(",
      "start_line": 89,
      "lines_added": [
        "# RELATION_WEIGHTS imported from constants.py"
      ],
      "lines_removed": [
        "# Default relation weights for semantic PageRank",
        "RELATION_WEIGHTS = {",
        "    'IsA': 1.5,           # Hypernym relationships are strong",
        "    'PartOf': 1.3,        # Meronym relationships",
        "    'HasProperty': 1.2,   # Property associations",
        "    'RelatedTo': 1.0,     # Default co-occurrence",
        "    'SimilarTo': 1.4,     # Similarity relationships",
        "    'Causes': 1.1,        # Causal relationships",
        "    'UsedFor': 1.0,       # Functional relationships",
        "    'CoOccurs': 0.8,      # Basic co-occurrence",
        "    'Antonym': 0.3,       # Opposing concepts (lower weight)",
        "    'DerivedFrom': 1.2,   # Morphological derivation",
        "}"
      ],
      "context_before": [
        "        if max_diff < tolerance:",
        "            break",
        "",
        "    # Update minicolumn pagerank values",
        "    for col in layer.minicolumns.values():",
        "        col.pagerank = pagerank.get(col.id, 1.0 / n)",
        "",
        "    return pagerank",
        "",
        ""
      ],
      "context_after": [
        "",
        "",
        "def compute_semantic_pagerank(",
        "    layer: HierarchicalLayer,",
        "    semantic_relations: List[Tuple[str, str, str, float]],",
        "    relation_weights: Optional[Dict[str, float]] = None,",
        "    damping: float = 0.85,",
        "    iterations: int = 20,",
        "    tolerance: float = 1e-6",
        ") -> Dict[str, Any]:"
      ],
      "change_type": "modify"
    },
    {
      "file": "cortical/constants.py",
      "function": null,
      "start_line": 0,
      "lines_added": [
        "\"\"\"",
        "Centralized constants for the Cortical Text Processor.",
        "",
        "This module provides a single source of truth for constants used across",
        "multiple modules, preventing drift and inconsistencies.",
        "",
        "Task #96: Centralize duplicate constants",
        "\"\"\"",
        "",
        "from typing import Dict, FrozenSet",
        "",
        "# =============================================================================",
        "# RELATION TYPE WEIGHTS",
        "# =============================================================================",
        "",
        "# Weights for semantic relation types used in:",
        "# - PageRank computation (analysis.py)",
        "# - Semantic retrofitting (semantics.py)",
        "# - Query expansion (query/expansion.py)",
        "#",
        "# Higher values = stronger connections in the knowledge graph.",
        "# These are tuned based on ConceptNet-style relation semantics.",
        "",
        "RELATION_WEIGHTS: Dict[str, float] = {",
        "    # Strong semantic relationships",
        "    'SameAs': 2.0,          # Synonymy - strongest connection",
        "    'IsA': 1.5,             # Hypernym/type relationships",
        "    'SimilarTo': 1.5,       # High similarity",
        "",
        "    # Structural relationships",
        "    'PartOf': 1.3,          # Meronym relationships",
        "    'HasA': 1.2,            # Possession relationships",
        "    'HasProperty': 1.2,     # Property associations",
        "    'DerivedFrom': 1.2,     # Morphological derivation",
        "",
        "    # Causal and functional",
        "    'Causes': 1.1,          # Causal relationships",
        "    'UsedFor': 1.0,         # Functional relationships",
        "    'CapableOf': 0.9,       # Capability relationships",
        "    'DefinedBy': 1.0,       # Definition relationships",
        "",
        "    # Co-occurrence and spatial",
        "    'RelatedTo': 0.8,       # General relatedness",
        "    'CoOccurs': 0.7,        # Basic co-occurrence",
        "    'AtLocation': 0.6,      # Spatial relationships",
        "",
        "    # Negative/opposing",
        "    'Antonym': -0.5,        # Opposing concepts (negative weight)",
        "}",
        "",
        "",
        "# =============================================================================",
        "# DOCUMENT TYPE BOOSTS",
        "# =============================================================================",
        "",
        "# Boost factors for ranking documents by type in search results.",
        "# Used in query/ranking.py for multi_stage_rank().",
        "# Higher values = ranked higher in results.",
        "",
        "DOC_TYPE_BOOSTS: Dict[str, float] = {",
        "    'docs': 1.5,            # docs/ folder documentation",
        "    'root_docs': 1.3,       # Root-level markdown (CLAUDE.md, README.md)",
        "    'code': 1.0,            # Regular code files",
        "    'test': 0.8,            # Test files (often less relevant for conceptual queries)",
        "}",
        "",
        "",
        "# =============================================================================",
        "# QUERY TYPE KEYWORDS",
        "# =============================================================================",
        "",
        "# Keywords that suggest a conceptual query (should boost documentation)",
        "CONCEPTUAL_KEYWORDS: FrozenSet[str] = frozenset([",
        "    'what', 'explain', 'describe', 'overview', 'introduction', 'concept',",
        "    'architecture', 'design', 'pattern', 'algorithm', 'approach', 'method',",
        "    'how does', 'why does', 'purpose', 'goal', 'rationale', 'theory',",
        "    'understand', 'learn', 'documentation', 'guide', 'tutorial', 'example',",
        "])",
        "",
        "# Keywords that suggest an implementation query (should prefer code)",
        "IMPLEMENTATION_KEYWORDS: FrozenSet[str] = frozenset([",
        "    'where', 'implement', 'code', 'function', 'class', 'method', 'variable',",
        "    'line', 'file', 'bug', 'fix', 'error', 'exception', 'call', 'invoke',",
        "    'compute', 'calculate', 'return', 'parameter', 'argument',",
        "])",
        "",
        "",
        "# NOTE: LAYER_COLORS and LAYER_NAMES are defined in persistence.py",
        "# because they use CorticalLayer enum keys for type safety in exports."
      ],
      "lines_removed": [],
      "context_before": [],
      "context_after": [],
      "change_type": "add"
    },
    {
      "file": "cortical/query/ranking.py",
      "function": "This module provides:",
      "start_line": 8,
      "lines_added": [
        "from ..constants import DOC_TYPE_BOOSTS, CONCEPTUAL_KEYWORDS, IMPLEMENTATION_KEYWORDS",
        "# Constants imported from cortical/constants.py"
      ],
      "lines_removed": [
        "# Default boost factors for each document type",
        "# Higher values make documents of that type rank higher",
        "DOC_TYPE_BOOSTS = {",
        "    'docs': 1.5,       # docs/ folder documentation",
        "    'root_docs': 1.3,  # Root-level markdown (CLAUDE.md, README.md)",
        "    'code': 1.0,       # Regular code files",
        "    'test': 0.8,       # Test files (often less relevant for conceptual queries)",
        "}",
        "",
        "# Keywords that suggest a conceptual query (should boost documentation)",
        "CONCEPTUAL_KEYWORDS = frozenset([",
        "    'what', 'explain', 'describe', 'overview', 'introduction', 'concept',",
        "    'architecture', 'design', 'pattern', 'algorithm', 'approach', 'method',",
        "    'how does', 'why does', 'purpose', 'goal', 'rationale', 'theory',",
        "    'understand', 'learn', 'documentation', 'guide', 'tutorial', 'example',",
        "])",
        "",
        "# Keywords that suggest an implementation query (should prefer code)",
        "IMPLEMENTATION_KEYWORDS = frozenset([",
        "    'where', 'implement', 'code', 'function', 'class', 'method', 'variable',",
        "    'line', 'file', 'bug', 'fix', 'error', 'exception', 'call', 'invoke',",
        "    'compute', 'calculate', 'return', 'parameter', 'argument',",
        "])"
      ],
      "context_before": [
        "- Document type boosting (docs, code, tests)",
        "- Conceptual vs implementation query detection",
        "- Multi-stage ranking pipeline (concepts -> documents -> chunks)",
        "\"\"\"",
        "",
        "from typing import Dict, List, Tuple, Optional, Any",
        "from collections import defaultdict",
        "",
        "from ..layers import CorticalLayer, HierarchicalLayer",
        "from ..tokenizer import Tokenizer"
      ],
      "context_after": [
        "",
        "from .expansion import get_expanded_query_terms",
        "from .search import find_documents_for_query",
        "",
        "",
        "",
        "",
        "def is_conceptual_query(query_text: str) -> bool:",
        "    \"\"\"",
        "    Determine if a query is conceptual (should boost documentation).",
        "",
        "    Conceptual queries ask about concepts, architecture, design, or",
        "    explanations rather than specific code locations.",
        "",
        "    Args:"
      ],
      "change_type": "modify"
    },
    {
      "file": "cortical/semantics.py",
      "function": "import copy",
      "start_line": 16,
      "lines_added": [
        "from .constants import RELATION_WEIGHTS"
      ],
      "lines_removed": [
        "",
        "",
        "# Relation type weights for retrofitting",
        "RELATION_WEIGHTS = {",
        "    'IsA': 1.5,",
        "    'PartOf': 1.2,",
        "    'HasA': 1.0,",
        "    'UsedFor': 0.8,",
        "    'CapableOf': 0.7,",
        "    'AtLocation': 0.6,",
        "    'Causes': 0.9,",
        "    'HasProperty': 0.8,",
        "    'SameAs': 2.0,",
        "    'RelatedTo': 0.5,",
        "    'Antonym': -0.5,",
        "    'DerivedFrom': 1.0,",
        "    'SimilarTo': 1.5,",
        "    'CoOccurs': 0.6,",
        "    'DefinedBy': 1.0,",
        "}"
      ],
      "context_before": [
        "from collections import defaultdict",
        "",
        "try:",
        "    import numpy as np",
        "    HAS_NUMPY = True",
        "except ImportError:",
        "    HAS_NUMPY = False",
        "",
        "from .layers import CorticalLayer, HierarchicalLayer",
        "from .minicolumn import Minicolumn"
      ],
      "context_after": [
        "",
        "",
        "# Commonsense relation patterns with confidence scores",
        "# Format: (pattern_regex, relation_type, confidence, swap_order)",
        "# swap_order: if True, the captured groups are in reverse order (t2, t1)",
        "RELATION_PATTERNS = [",
        "    # IsA patterns (hypernym/type relations)",
        "    (r'(\\w+)\\s+(?:is|are)\\s+(?:a|an)\\s+(?:type\\s+of\\s+)?(\\w+)', 'IsA', 0.9, False),",
        "    (r'(\\w+),?\\s+(?:a|an)\\s+(?:kind|type|form)\\s+of\\s+(\\w+)', 'IsA', 0.95, False),",
        "    (r'(\\w+)\\s+(?:is|are)\\s+considered\\s+(?:a|an)?\\s*(\\w+)', 'IsA', 0.8, False),"
      ],
      "change_type": "modify"
    },
    {
      "file": "cortical/types.py",
      "function": null,
      "start_line": 0,
      "lines_added": [
        "\"\"\"",
        "Type Aliases for the Cortical Text Processor.",
        "",
        "This module provides type aliases for complex return types used throughout",
        "the library, making function signatures more readable and maintainable.",
        "",
        "Task #114: Add type aliases for complex types",
        "",
        "Usage:",
        "    from cortical.types import DocumentScore, PassageResult, SemanticRelation",
        "",
        "Example:",
        "    def find_documents(query: str) -> DocumentResults:",
        "        ...",
        "        return results  # List of (doc_id, score) tuples",
        "\"\"\"",
        "",
        "from typing import Any, Dict, List, Optional, Tuple",
        "",
        "# =============================================================================",
        "# SCORE TYPES",
        "# =============================================================================",
        "",
        "# Basic score tuple: (item_id, score)",
        "DocumentScore = Tuple[str, float]",
        "\"\"\"A (doc_id, score) tuple representing a document with its relevance score.\"\"\"",
        "",
        "TermScore = Tuple[str, float]",
        "\"\"\"A (term, score) tuple representing a term with its importance score.\"\"\"",
        "",
        "# Result lists",
        "DocumentResults = List[DocumentScore]",
        "\"\"\"List of (doc_id, score) tuples, typically sorted by relevance.\"\"\"",
        "",
        "TermResults = List[TermScore]",
        "\"\"\"List of (term, score) tuples, typically sorted by importance.\"\"\"",
        "",
        "",
        "# =============================================================================",
        "# PASSAGE TYPES",
        "# =============================================================================",
        "",
        "PassageResult = Tuple[str, float, str]",
        "\"\"\"A (doc_id, score, passage_text) tuple for chunk-level retrieval.\"\"\"",
        "",
        "PassageResults = List[PassageResult]",
        "\"\"\"List of (doc_id, score, passage_text) tuples for RAG applications.\"\"\"",
        "",
        "# Passage with position information",
        "PassageWithPosition = Tuple[str, str, int, int, float]",
        "\"\"\"A (doc_id, passage_text, start_char, end_char, score) tuple.\"\"\"",
        "",
        "PassageWithPositionResults = List[PassageWithPosition]",
        "\"\"\"List of passages with character position information.\"\"\"",
        "",
        "# Passage with expanded terms",
        "PassageWithExpansion = Tuple[str, str, int, int, float, Dict[str, float]]",
        "\"\"\"A (doc_id, passage_text, start, end, score, expanded_terms) tuple.\"\"\"",
        "",
        "PassageWithExpansionResults = List[PassageWithExpansion]",
        "\"\"\"List of passages with the query expansion used to find them.\"\"\"",
        "",
        "",
        "# =============================================================================",
        "# SEMANTIC RELATION TYPES",
        "# =============================================================================",
        "",
        "SemanticRelation = Tuple[str, str, str, float]",
        "\"\"\"A (term1, relation_type, term2, confidence) semantic relation tuple.",
        "",
        "Example: ('dog', 'IsA', 'animal', 0.95)",
        "\"\"\"",
        "",
        "SemanticRelations = List[SemanticRelation]",
        "\"\"\"List of semantic relation tuples extracted from the corpus.\"\"\"",
        "",
        "",
        "# =============================================================================",
        "# EMBEDDING TYPES",
        "# =============================================================================",
        "",
        "EmbeddingVector = List[float]",
        "\"\"\"A dense vector representation of a term.\"\"\"",
        "",
        "EmbeddingDict = Dict[str, EmbeddingVector]",
        "\"\"\"Dictionary mapping terms to their embedding vectors.\"\"\"",
        "",
        "",
        "# =============================================================================",
        "# METADATA TYPES",
        "# =============================================================================",
        "",
        "DocumentMetadata = Dict[str, Any]",
        "\"\"\"Arbitrary metadata associated with a document.\"\"\"",
        "",
        "AllDocumentMetadata = Dict[str, DocumentMetadata]",
        "\"\"\"Dictionary mapping doc_ids to their metadata.\"\"\"",
        "",
        "",
        "# =============================================================================",
        "# GRAPH TYPES",
        "# =============================================================================",
        "",
        "ConnectionWeight = float",
        "\"\"\"Weight of a connection between minicolumns.\"\"\"",
        "",
        "ConnectionMap = Dict[str, ConnectionWeight]",
        "\"\"\"Dictionary mapping target_ids to connection weights.\"\"\"",
        "",
        "IncomingConnections = Dict[str, List[Tuple[str, float]]]",
        "\"\"\"Dictionary mapping node_ids to list of (source_id, weight) incoming edges.\"\"\"",
        "",
        "",
        "# =============================================================================",
        "# INTENT QUERY TYPES",
        "# =============================================================================",
        "",
        "IntentResult = Tuple[str, float, Dict[str, Any]]",
        "\"\"\"A (doc_id, score, intent_info) tuple from intent-based search.\"\"\"",
        "",
        "IntentResults = List[IntentResult]",
        "\"\"\"List of intent-based search results with metadata.\"\"\"",
        "",
        "",
        "# =============================================================================",
        "# BATCH TYPES",
        "# =============================================================================",
        "",
        "DocumentInput = Tuple[str, str, Optional[Dict[str, Any]]]",
        "\"\"\"A (doc_id, content, metadata) tuple for batch document processing.\"\"\"",
        "",
        "DocumentBatch = List[DocumentInput]",
        "\"\"\"List of documents to process in batch.\"\"\"",
        "",
        "BatchResults = List[DocumentResults]",
        "\"\"\"Results from batch query processing - one DocumentResults per query.\"\"\"",
        "",
        "BatchPassageResults = List[PassageWithPositionResults]",
        "\"\"\"Results from batch passage retrieval - one PassageResults per query.\"\"\"",
        "",
        "",
        "# =============================================================================",
        "# SEARCH INDEX TYPES",
        "# =============================================================================",
        "",
        "SearchIndex = Dict[str, Dict[str, float]]",
        "\"\"\"Pre-built search index mapping terms to doc_id -> score dictionaries.\"\"\"",
        "",
        "TermDocScores = Dict[str, float]",
        "\"\"\"Dictionary mapping doc_ids to scores for a single term.\"\"\"",
        "",
        "",
        "# =============================================================================",
        "# CLUSTER TYPES",
        "# =============================================================================",
        "",
        "ClusterAssignments = Dict[str, str]",
        "\"\"\"Dictionary mapping term/node content to cluster_id.\"\"\"",
        "",
        "ClusterQuality = Dict[str, Any]",
        "\"\"\"Dictionary with clustering quality metrics (modularity, silhouette, etc.).\"\"\""
      ],
      "lines_removed": [],
      "context_before": [],
      "context_after": [],
      "change_type": "add"
    },
    {
      "file": "docs/README.md",
      "function": null,
      "start_line": 0,
      "lines_added": [
        "# Documentation Index",
        "",
        "Welcome to the Cortical Text Processor documentation. This index provides navigation and recommended reading paths for different audiences.",
        "",
        "---",
        "",
        "## Quick Navigation",
        "",
        "| Document | Description | Audience |",
        "|----------|-------------|----------|",
        "| [quickstart.md](quickstart.md) | 5-minute getting started guide | New users |",
        "| [architecture.md](architecture.md) | 4-layer hierarchical system design | All |",
        "| [algorithms.md](algorithms.md) | Core IR algorithms (PageRank, TF-IDF, Louvain) | Developers |",
        "| [query-guide.md](query-guide.md) | How to formulate effective queries | Users |",
        "| [cookbook.md](cookbook.md) | Common patterns and recipes | Users |",
        "| [patterns.md](patterns.md) | Advanced usage (code search, fingerprinting) | Advanced users |",
        "| [glossary.md](glossary.md) | Terminology definitions | All |",
        "",
        "---",
        "",
        "## Reading Paths",
        "",
        "### New Users",
        "",
        "1. **[quickstart.md](quickstart.md)** - Get running in 5 minutes",
        "2. **[query-guide.md](query-guide.md)** - Learn to search effectively",
        "3. **[cookbook.md](cookbook.md)** - See common patterns",
        "",
        "### Contributors",
        "",
        "1. **[quickstart.md](quickstart.md)** - Understand basic usage",
        "2. **[architecture.md](architecture.md)** - Understand the 4-layer design",
        "3. **[algorithms.md](algorithms.md)** - Learn the core algorithms",
        "4. **[code-of-ethics.md](code-of-ethics.md)** - Development standards",
        "5. **[definition-of-done.md](definition-of-done.md)** - Task completion criteria",
        "6. **[dogfooding-checklist.md](dogfooding-checklist.md)** - Testing with real usage",
        "",
        "### AI Agents (Claude)",
        "",
        "1. **[claude-usage.md](claude-usage.md)** - AI-specific search guidance",
        "2. **[cli-wrapper-guide.md](cli-wrapper-guide.md)** - CLI wrapper reference",
        "3. **[architecture.md](architecture.md)** - System structure",
        "4. **[glossary.md](glossary.md)** - Terminology reference",
        "",
        "---",
        "",
        "## Document Categories",
        "",
        "### Getting Started",
        "",
        "| Document | Purpose |",
        "|----------|---------|",
        "| [quickstart.md](quickstart.md) | 5-minute introduction |",
        "| [glossary.md](glossary.md) | Key terminology definitions |",
        "",
        "### Architecture & Algorithms",
        "",
        "| Document | Purpose |",
        "|----------|---------|",
        "| [architecture.md](architecture.md) | 4-layer system design (Tokens â†’ Bigrams â†’ Concepts â†’ Documents) |",
        "| [algorithms.md](algorithms.md) | PageRank, TF-IDF, Louvain clustering, co-occurrence |",
        "| [louvain_resolution_analysis.md](louvain_resolution_analysis.md) | Research on clustering resolution parameter |",
        "",
        "### Usage Guides",
        "",
        "| Document | Purpose |",
        "|----------|---------|",
        "| [query-guide.md](query-guide.md) | Query formulation and search tips |",
        "| [cookbook.md](cookbook.md) | Common patterns and recipes |",
        "| [patterns.md](patterns.md) | Advanced patterns: code search, fingerprinting, intent queries |",
        "",
        "### Development Process",
        "",
        "| Document | Purpose |",
        "|----------|---------|",
        "| [code-of-ethics.md](code-of-ethics.md) | Scientific rigor and documentation standards |",
        "| [definition-of-done.md](definition-of-done.md) | Task completion checklist |",
        "| [dogfooding.md](dogfooding.md) | Using the system to test itself |",
        "| [dogfooding-checklist.md](dogfooding-checklist.md) | Systematic dog-fooding checklist |",
        "",
        "### AI Agent Resources",
        "",
        "| Document | Purpose |",
        "|----------|---------|",
        "| [claude-usage.md](claude-usage.md) | Guide for Claude agents using the system |",
        "| [cli-wrapper-guide.md](cli-wrapper-guide.md) | CLI wrapper for AI assistants |",
        "",
        "---",
        "",
        "## Additional Resources",
        "",
        "- **[CLAUDE.md](../CLAUDE.md)** - Main development guide (in repo root)",
        "- **[CONTRIBUTING.md](../CONTRIBUTING.md)** - How to contribute",
        "- **[TASK_LIST.md](../TASK_LIST.md)** - Active task backlog",
        "- **[README.md](../README.md)** - Project overview",
        "",
        "---",
        "",
        "*Last updated: 2025-12-12*"
      ],
      "lines_removed": [],
      "context_before": [],
      "context_after": [],
      "change_type": "add"
    },
    {
      "file": "tests/test_semantics.py",
      "function": "class TestSemantics(unittest.TestCase):",
      "start_line": 157,
      "lines_added": [
        "        self.assertEqual(get_relation_type_weight('RelatedTo'), 0.8)  # Centralized in constants.py"
      ],
      "lines_removed": [
        "        self.assertEqual(get_relation_type_weight('RelatedTo'), 0.5)"
      ],
      "context_before": [
        "",
        "        self.assertEqual(stats['iterations'], 5)",
        "        self.assertEqual(stats['alpha'], 0.4)",
        "",
        "    def test_get_relation_type_weight(self):",
        "        \"\"\"Test getting relation type weights.\"\"\"",
        "        # Test known relation types",
        "        self.assertEqual(get_relation_type_weight('IsA'), 1.5)",
        "        self.assertEqual(get_relation_type_weight('SameAs'), 2.0)",
        "        self.assertEqual(get_relation_type_weight('Antonym'), -0.5)"
      ],
      "context_after": [
        "",
        "        # Test unknown relation type defaults to 0.5",
        "        self.assertEqual(get_relation_type_weight('UnknownRelation'), 0.5)",
        "",
        "    def test_relation_weights_constant(self):",
        "        \"\"\"Test that RELATION_WEIGHTS contains expected keys.\"\"\"",
        "        expected_relations = ['IsA', 'PartOf', 'HasA', 'SameAs', 'RelatedTo', 'CoOccurs']",
        "        for rel in expected_relations:",
        "            self.assertIn(rel, RELATION_WEIGHTS)"
      ],
      "change_type": "modify"
    }
  ],
  "hour_of_day": 3,
  "day_of_week": "Friday",
  "seconds_since_last_commit": -297868,
  "is_merge": false,
  "is_initial": false,
  "parent_count": 1,
  "session_id": null,
  "related_chats": [],
  "ci_result": null,
  "reverted": false,
  "amended": false
}