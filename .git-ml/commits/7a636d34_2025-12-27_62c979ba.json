{
  "hash": "7a636d341d1ec4a1664d0c1d634f8ef4f3df3ce5",
  "message": "fix(benchmarks): Add loud warning when training corpus is missing",
  "author": "Claude",
  "timestamp": "2025-12-27 02:57:31 +0000",
  "branch": "claude/accept-handoff-ctrSI",
  "files_changed": [
    "benchmarks/codebase_slm/train_augmented.py",
    "samples/memories/2025-12-27-knowledge-transfer-prism-model-incident.md"
  ],
  "insertions": 60,
  "deletions": 41,
  "hunks": [
    {
      "file": "benchmarks/codebase_slm/train_augmented.py",
      "function": "def load_augmented_corpus():",
      "start_line": 50,
      "lines_added": [
        "        print()",
        "        print(\"=\" * 60)",
        "        print(\"⚠️  WARNING: No training corpus found!\")",
        "        print(\"=\" * 60)",
        "        print()",
        "        print(\"The corpus/training_patterns.jsonl file is missing.\")",
        "        print(\"This means training will only use augmented_corpus.txt (~2K lines)\")",
        "        print(\"instead of the full corpus (~35K patterns).\")",
        "        print()",
        "        print(\"To generate the corpus, run:\")",
        "        print(\"  python -m benchmarks.codebase_slm.generate_corpus --full\")",
        "        print()",
        "        print(\"Then re-run this training script.\")",
        "        print()",
        "        print(\"Proceeding with limited data (NOT RECOMMENDED)...\")",
        "        print(\"=\" * 60)",
        "        print()"
      ],
      "lines_removed": [
        "        print(\"No existing patterns found\")"
      ],
      "context_before": [
        "",
        "    print(f\"Loaded {len(lines)} augmented training lines\")",
        "    return lines, str(corpus_path)",
        "",
        "",
        "def load_existing_patterns():",
        "    \"\"\"Load existing training patterns.\"\"\"",
        "    patterns_path = PROJECT_ROOT / \"benchmarks\" / \"codebase_slm\" / \"corpus\" / \"training_patterns.jsonl\"",
        "",
        "    if not patterns_path.exists():"
      ],
      "context_after": [
        "        return [], None",
        "",
        "    patterns = []",
        "    with open(patterns_path) as f:",
        "        for line in f:",
        "            try:",
        "                p = json.loads(line)",
        "                # Format as training text",
        "                ptype = p.get('pattern_type', '')",
        "                input_text = p.get('input_text', '')"
      ],
      "change_type": "modify"
    },
    {
      "file": "samples/memories/2025-12-27-knowledge-transfer-prism-model-incident.md",
      "function": "benchmarks/codebase_slm/models/backups/",
      "start_line": 159,
      "lines_added": [
        "### Root Cause: Corpus Not Regenerated Before Training",
        "**Critical finding:** The agent ran `train_augmented.py` without first running `generate_corpus.py`.",
        "The corpus IS regeneratable from the codebase:",
        "```bash",
        "python -m benchmarks.codebase_slm.generate_corpus --full",
        "# Produces: 35,582 patterns from 149 Python files + 254 Markdown files",
        "But `corpus/` is gitignored, so it must be regenerated locally. The previous agent:",
        "1. Ran `train_augmented.py` directly",
        "2. `corpus/training_patterns.jsonl` didn't exist locally",
        "3. Script printed \"No existing patterns found\" (benign message!)",
        "4. Trained on only 2,094 lines instead of 37,676",
        "5. Produced tiny 329 vocab model",
        "| What | Lines | Tracked | Regeneratable |",
        "|------|-------|---------|---------------|",
        "| Model (prism_augmented.json) | 692,026 | ✅ Yes | From corpus |",
        "| augmented_corpus.txt | 2,094 | ✅ Yes | Manual |",
        "| knowledge-base/*.md | 3,144 | ✅ Yes | Manual |",
        "| corpus/training_patterns.jsonl | 35,582 | ❌ Gitignored | ✅ **Yes!** |",
        "**Key insight:** The corpus is NOT lost - it's regenerated from the codebase each time.",
        "### Current vs Original",
        "| Metric | Original Model | Current Regenerated |",
        "|--------|----------------|---------------------|",
        "| Patterns | 37,318 | **37,676** (+358) |",
        "| Vocabulary | 15,814 | **15,876** (+62) |",
        "| Tokens | 649,107 | **653,580** (+4,473) |",
        "The codebase has MORE content now, so regenerating produces MORE training data.",
        "### Prevention: Warn When Corpus Missing",
        "**Fix applied:** `train_augmented.py` now shows a loud warning when corpus is missing:",
        "```",
        "============================================================",
        "⚠️  WARNING: No training corpus found!",
        "============================================================",
        "The corpus/training_patterns.jsonl file is missing.",
        "This means training will only use augmented_corpus.txt (~2K lines)",
        "instead of the full corpus (~35K patterns).",
        "",
        "To generate the corpus, run:",
        "  python -m benchmarks.codebase_slm.generate_corpus --full",
        "",
        "Then re-run this training script.",
        "============================================================",
        "This prevents silent training on insufficient data.",
        ""
      ],
      "lines_removed": [
        "### Root Cause: Training Data Never Tracked",
        "**Critical finding:** `benchmarks/codebase_slm/corpus/` was added to `.gitignore` from day 1.",
        "```",
        "Commit 137e5585 added to .gitignore:",
        "  benchmarks/codebase_slm/corpus/",
        "This means:",
        "1. `training_patterns.jsonl` was **never committed**",
        "2. Only the MODEL was tracked, not its source data",
        "3. The original 37,318 document corpus is **unrecoverable**",
        "| What | Lines | Status |",
        "|------|-------|--------|",
        "| Model (prism_augmented.json) | 692,026 | ✅ Tracked, restored |",
        "| augmented_corpus.txt | 1,814 | ✅ Tracked |",
        "| knowledge-base/*.md | 3,144 | ✅ Tracked |",
        "| corpus/training_patterns.jsonl | ~35,500 | ❌ **Never tracked** |",
        "**Gap:** Model had 37,318 docs but only ~5,000 lines of training data were committed.",
        "### Why 37K Documents?",
        "The commit messages tell the story:",
        "- 137e5585: \"27,998 training patterns generated\"",
        "- 982c89b6: \"35,504 total patterns\"",
        "The model was trained on **locally generated** data that was:",
        "1. Created by running `generate_corpus.py`",
        "2. Stored in `corpus/training_patterns.jsonl`",
        "3. **Never committed** (gitignored)",
        "4. Used to train the model that WAS committed",
        "### Prevention: Track Training Data",
        "**Recommended change:** Remove `benchmarks/codebase_slm/corpus/` from `.gitignore`",
        "This ensures:",
        "- Training data is versioned alongside models",
        "- Provenance is maintained",
        "- Models can be reproduced exactly",
        "Alternatively, add provenance hash to model:",
        "```json",
        "{",
        "  \"_provenance\": {",
        "    \"corpus_hash\": \"sha256:abc123...\",",
        "    \"corpus_size\": 35504,",
        "    \"generated_at\": \"2025-12-27T00:00:00Z\"",
        "  }",
        "}"
      ],
      "context_before": [
        "",
        "| Date/Time | Commit | Event |",
        "|-----------|--------|-------|",
        "| Dec 26, 22:40 | 137e5585 | Generators added, 27,998 patterns generated |",
        "| Dec 26, 23:17 | 982c89b6 | Knowledge-base added, 35,504 patterns, 626K transitions |",
        "| Dec 26, 22:44 | 02dc3a58 | train_slm.py added |",
        "| **Dec 27, 00:04** | **2b458285** | **13MB model committed (37,318 docs)** |",
        "| Dec 27, 01:45 | 079d0c00 | MODEL OVERWRITTEN (329 vocab) |",
        "| Dec 27, 01:56 | cc84e3d2 | Model restored from git |",
        ""
      ],
      "context_after": [
        "",
        "",
        "```",
        "",
        "",
        "### Data Accounting",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "```",
        "",
        "---",
        "",
        "## Key Learnings",
        "",
        "1. **Size matters for models** - Vocab shrinking from 15K→329 is catastrophic, not an optimization",
        "2. **Don't trust overall scores** - 61% overall hid a 54% regression in the primary use case",
        "3. **Safeguards prevent accidents** - A simple `--dry-run` flag would have prevented this",
        "4. **Git history is your friend** - Model was fully recoverable from git",
        "5. **Provenance is essential** - Without knowing what trained the original, we can't improve it"
      ],
      "change_type": "modify"
    }
  ],
  "hour_of_day": 2,
  "day_of_week": "Saturday",
  "seconds_since_last_commit": 335,
  "is_merge": false,
  "is_initial": false,
  "parent_count": 1,
  "session_id": "c7e7f25e",
  "related_chats": [
    "chat-20251227-015100-015a56"
  ],
  "ci_result": null,
  "reverted": false,
  "amended": false
}