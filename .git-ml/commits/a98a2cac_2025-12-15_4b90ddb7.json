{
  "hash": "a98a2cacf5754a09616dca39b3b5d7ffdd7d923d",
  "message": "Update README.md with use cases and current architecture",
  "author": "Claude",
  "timestamp": "2025-12-15 03:42:44 +0000",
  "branch": "claude/multi-index-design-DvifZ",
  "files_changed": [
    "README.md"
  ],
  "insertions": 129,
  "deletions": 20,
  "hunks": [
    {
      "file": "README.md",
      "function": "This library provides a biologically-inspired approach to text processing, organ",
      "start_line": 39,
      "lines_added": [
        "## Use Cases & When to Use",
        "",
        "### Ideal Use Cases",
        "",
        "| Use Case | Why It's a Good Fit |",
        "|----------|---------------------|",
        "| **Internal Documentation Search** | Understands domain-specific terminology through corpus-derived semantics; no training data needed |",
        "| **Knowledge Base Q&A** | Query expansion finds related documents even when exact keywords don't match |",
        "| **Code Repository Search** | Built-in code tokenization splits `getUserName` → `get`, `user`, `name`; programming synonym expansion |",
        "| **Research Paper Organization** | Concept clustering automatically groups related papers; gap detection finds missing coverage |",
        "| **RAG/LLM Context Retrieval** | Chunk-level passage retrieval with relevance scoring; designed for retrieval-augmented generation |",
        "| **Offline/Air-gapped Environments** | Zero dependencies, no API calls, works completely offline |",
        "| **Privacy-Sensitive Applications** | All processing happens locally; no data leaves your machine |",
        "| **Educational Projects** | Clean, well-documented codebase demonstrates IR algorithms (PageRank, TF-IDF, Louvain clustering) |",
        "",
        "### Good Fit For Developers Who...",
        "",
        "- **Need explainable search** - Every result can be traced through the graph; see exactly why documents matched",
        "- **Want to avoid ML complexity** - No model training, GPU requirements, or hyperparameter tuning",
        "- **Work with specialized domains** - Corpus-derived semantics adapts to your terminology automatically",
        "- **Need lightweight deployment** - Single Python package, no Docker, no external services",
        "- **Value reproducibility** - Deterministic algorithms produce consistent results",
        "- **Build RAG pipelines** - First-class support for passage retrieval with configurable chunking",
        "",
        "### When NOT to Use",
        "",
        "| Scenario | Better Alternative |",
        "|----------|-------------------|",
        "| Need state-of-the-art semantic similarity | Use sentence transformers or OpenAI embeddings |",
        "| Processing millions of documents | Use Elasticsearch, Meilisearch, or vector databases |",
        "| Need real-time indexing at scale | Use purpose-built search infrastructure |",
        "| Require cross-lingual search | Use multilingual embedding models |",
        "| Need image/multimodal search | Use CLIP or similar multimodal models |",
        "",
        "### Example: Building a Documentation Search",
        "",
        "```python",
        "from cortical import CorticalTextProcessor",
        "import os",
        "",
        "# Initialize processor",
        "processor = CorticalTextProcessor()",
        "",
        "# Index your documentation",
        "for filename in os.listdir(\"docs/\"):",
        "    if filename.endswith(\".md\"):",
        "        with open(f\"docs/{filename}\") as f:",
        "            processor.process_document(filename, f.read())",
        "",
        "# Build the semantic network",
        "processor.compute_all(verbose=False)",
        "",
        "# Search with query expansion",
        "results = processor.find_documents_for_query(\"authentication setup\")",
        "# Finds docs about \"auth\", \"login\", \"credentials\" even if \"authentication\" isn't mentioned",
        "",
        "# Get relevant passages for RAG",
        "passages = processor.find_passages_for_query(\"how to configure OAuth\", top_n=3)",
        "for passage, score, doc_id in passages:",
        "    print(f\"[{doc_id}] {passage[:100]}...\")",
        "```",
        "",
        "### Example: Code Search with Intent",
        "",
        "```python",
        "# Enable code-aware tokenization",
        "processor = CorticalTextProcessor(split_identifiers=True)",
        "",
        "# Index source files",
        "for filepath in glob.glob(\"src/**/*.py\", recursive=True):",
        "    with open(filepath) as f:",
        "        processor.process_document(filepath, f.read())",
        "",
        "processor.compute_all()",
        "",
        "# Intent-based search understands natural language questions",
        "results = processor.search_by_intent(\"where do we handle user authentication?\")",
        "# Returns files dealing with auth, login, session management",
        "",
        "# Code-specific query expansion",
        "expanded = processor.expand_query_for_code(\"fetch data\")",
        "# Expands to include: get, load, retrieve, request, download",
        "```",
        ""
      ],
      "lines_removed": [],
      "context_before": [
        "- **Corpus-Derived Semantics**: Pattern-based commonsense relation extraction without external knowledge bases",
        "- **Graph Embeddings**: Multiple embedding methods (adjacency, spectral, random walk) with semantic retrofitting",
        "- **ConceptNet-Style Relations**: Typed edges (IsA, HasA, PartOf, etc.) with multi-hop inference",
        "- **Concept Inheritance**: IsA hierarchy propagation for concept properties",
        "- **Analogy Completion**: Relation matching and vector arithmetic for analogical reasoning",
        "- **Gap Detection**: Find weak spots and isolated documents in your corpus",
        "- **Query Expansion**: Smart retrieval with synonym handling and semantic relations",
        "- **RAG System Support**: Chunk-level passage retrieval, document metadata, and multi-stage ranking",
        "- **Zero Dependencies**: Pure Python, no pip installs required",
        ""
      ],
      "context_after": [
        "## Installation",
        "",
        "Install from source:",
        "",
        "```bash",
        "git clone <repository-url>",
        "cd cortical-text-processor",
        "pip install -e .",
        "```",
        ""
      ],
      "change_type": "add"
    },
    {
      "file": "README.md",
      "function": "Tested with 92 sample documents covering topics from neural networks to medieval",
      "start_line": 232,
      "lines_added": [
        "├── __init__.py          # Public API exports",
        "├── processor/           # Main orchestrator (mixin-based architecture)",
        "│   ├── __init__.py      # CorticalTextProcessor class composition",
        "│   ├── core.py          # Initialization, staleness tracking (169 lines)",
        "│   ├── documents.py     # Document add/remove/batch (456 lines)",
        "│   ├── compute.py       # PageRank, TF-IDF, clustering (1041 lines)",
        "│   ├── query_api.py     # Search, expansion, retrieval (719 lines)",
        "│   ├── introspection.py # State inspection, summaries (357 lines)",
        "│   └── persistence_api.py # Save/load/export (245 lines)",
        "├── query/               # Search & retrieval (8 focused modules)",
        "│   ├── expansion.py     # Query expansion (459 lines)",
        "│   ├── search.py        # Document search (422 lines)",
        "│   ├── ranking.py       # Multi-stage ranking (472 lines)",
        "│   ├── passages.py      # RAG passage retrieval (407 lines)",
        "│   ├── chunking.py      # Text chunking (335 lines)",
        "│   ├── intent.py        # Intent-based queries (220 lines)",
        "│   ├── definitions.py   # Definition search (375 lines)",
        "│   └── analogy.py       # Analogy completion (330 lines)",
        "├── analysis.py          # Graph algorithms: PageRank, TF-IDF, Louvain",
        "├── semantics.py         # Relation extraction, inference, retrofitting",
        "├── minicolumn.py        # Core data structure with typed edges",
        "├── layers.py            # Hierarchical layers with O(1) lookups",
        "├── tokenizer.py         # Tokenization, stemming, code splitting",
        "├── embeddings.py        # Graph embeddings with retrofitting",
        "├── fingerprint.py       # Semantic fingerprinting",
        "├── gaps.py              # Gap detection and anomalies",
        "├── persistence.py       # Save/load with full state",
        "├── config.py            # CorticalConfig with validation",
        "├── observability.py     # Metrics, timing, tracing",
        "└── code_concepts.py     # Programming synonym expansion",
        "",
        "tests/                   # 2900+ tests (smoke, unit, integration, behavioral)",
        "├── smoke/               # Quick sanity checks",
        "├── unit/                # Fast isolated tests",
        "├── integration/         # Component interaction tests",
        "├── performance/         # Timing regression tests",
        "└── behavioral/          # Search quality tests",
        "",
        "showcase.py              # Interactive demonstration (run it!)",
        "samples/                 # 92 documents: quantum computing to cheese affinage",
        "scripts/                 # Developer tools (indexing, profiling, tasks)",
        "cat cortical/processor/__init__.py.ai_meta",
        "cat cortical/query/search.py.ai_meta",
        "Four Claude Code skills are available in `.claude/skills/`:",
        "| `task-manager` | Manage tasks with merge-friendly IDs |"
      ],
      "lines_removed": [
        "├── __init__.py      # Public API (v2.0.0)",
        "├── processor.py     # Main orchestrator",
        "├── tokenizer.py     # Tokenization + stemming",
        "├── minicolumn.py    # Core data structure with typed edges",
        "├── layers.py        # Hierarchical layers with O(1) lookups",
        "├── analysis.py      # PageRank, TF-IDF, cross-layer propagation",
        "├── semantics.py     # Semantic extraction, inference, analogy",
        "├── embeddings.py    # Graph embeddings with retrofitting",
        "├── query.py         # Search, retrieval, batch processing",
        "├── gaps.py          # Gap detection and anomalies",
        "└── persistence.py   # Save/load with full state",
        "",
        "evaluation/",
        "└── evaluator.py     # Evaluation framework",
        "",
        "tests/               # 2900+ comprehensive tests",
        "showcase.py          # Interactive demonstration (run it!)",
        "samples/             # 92 documents: from quantum computing to cheese affinage",
        "cat cortical/processor.py.ai_meta",
        "Three Claude Code skills are available in `.claude/skills/`:"
      ],
      "context_before": [
        "**What the processor discovers:**",
        "- Most central concept: `data` (PageRank: 0.0046)",
        "- Most distinctive terms: `gradient`, `pagerank`, `patent` (high TF-IDF, rare but meaningful)",
        "- Most connected document: `comprehensive_machine_learning` (91 connections to other docs)",
        "- Isolated outliers detected: `sumo_wrestling`, `medieval_falconry` (low similarity to corpus)",
        "",
        "## Package Structure",
        "",
        "```",
        "cortical/"
      ],
      "context_after": [
        "```",
        "",
        "## AI Agent Support",
        "",
        "This project includes tools designed specifically for AI coding assistants:",
        "",
        "### AI Metadata Files (`.ai_meta`)",
        "",
        "Pre-generated metadata files provide structured navigation for AI agents:",
        "",
        "```bash",
        "# Generate metadata for rapid module understanding",
        "python scripts/generate_ai_metadata.py",
        "",
        "# View a module's structure without reading source",
        "```",
        "",
        "**What metadata provides:**",
        "- Function signatures with `see_also` cross-references",
        "- Class structures with inheritance",
        "- Complexity hints for expensive operations",
        "- Logical section groupings",
        "",
        "### Claude Skills",
        "",
        "",
        "| Skill | Purpose |",
        "|-------|---------|",
        "| `codebase-search` | Semantic search over the codebase |",
        "| `corpus-indexer` | Index/re-index after code changes |",
        "| `ai-metadata` | View and use module metadata |",
        "",
        "### For AI Agents",
        "",
        "See the **AI Agent Onboarding** section in [CLAUDE.md](CLAUDE.md) for:",
        "- Step-by-step setup guide",
        "- Navigation tips for efficient exploration",
        "- Example workflow using metadata",
        "",
        "## Text-as-Memories System"
      ],
      "change_type": "modify"
    }
  ],
  "hour_of_day": 3,
  "day_of_week": "Monday",
  "seconds_since_last_commit": -36124,
  "is_merge": false,
  "is_initial": false,
  "parent_count": 1,
  "session_id": null,
  "related_chats": [],
  "ci_result": null,
  "reverted": false,
  "amended": false
}