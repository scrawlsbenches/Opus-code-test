{
  "hash": "2085418735ccad7653ee3ccd2029095bc98b8fdb",
  "message": "Add document metadata support for RAG citations (Task 9)",
  "author": "Claude",
  "timestamp": "2025-12-09 19:51:20 +0000",
  "branch": "claude/multi-index-design-DvifZ",
  "files_changed": [
    "cortical/persistence.py",
    "cortical/processor.py",
    "tests/test_persistence.py",
    "tests/test_processor.py"
  ],
  "insertions": 220,
  "deletions": 31,
  "hunks": [
    {
      "file": "cortical/persistence.py",
      "function": "import os",
      "start_line": 16,
      "lines_added": [
        "    document_metadata: Optional[Dict[str, Dict[str, Any]]] = None,",
        "",
        "        document_metadata: Per-document metadata (source, timestamp, etc.)",
        "        metadata: Optional processor metadata (version, settings, etc.)",
        "        'version': '2.1',",
        "        'document_metadata': document_metadata or {},"
      ],
      "lines_removed": [
        "    ",
        "        metadata: Optional metadata (version, settings, etc.)",
        "        'version': '2.0',"
      ],
      "context_before": [
        "from typing import Dict, Optional, Any",
        "",
        "from .layers import CorticalLayer, HierarchicalLayer",
        "from .minicolumn import Minicolumn",
        "",
        "",
        "def save_processor(",
        "    filepath: str,",
        "    layers: Dict[CorticalLayer, HierarchicalLayer],",
        "    documents: Dict[str, str],"
      ],
      "context_after": [
        "    metadata: Optional[Dict] = None,",
        "    verbose: bool = True",
        ") -> None:",
        "    \"\"\"",
        "    Save processor state to a file.",
        "    Args:",
        "        filepath: Path to save file",
        "        layers: Dictionary of all layers",
        "        documents: Document collection",
        "        verbose: Print progress",
        "    \"\"\"",
        "    state = {",
        "        'layers': {},",
        "        'documents': documents,",
        "        'metadata': metadata or {}",
        "    }",
        "    ",
        "    # Serialize layers",
        "    for layer_enum, layer in layers.items():",
        "        state['layers'][layer_enum.value] = layer.to_dict()",
        "    ",
        "    with open(filepath, 'wb') as f:",
        "        pickle.dump(state, f, protocol=pickle.HIGHEST_PROTOCOL)",
        "    "
      ],
      "change_type": "modify"
    },
    {
      "file": "cortical/persistence.py",
      "function": "def save_processor(",
      "start_line": 58,
      "lines_added": [
        "",
        "",
        "        Tuple of (layers, documents, document_metadata, metadata)",
        "",
        "",
        "    document_metadata = state.get('document_metadata', {})",
        "",
        "",
        "    return layers, documents, document_metadata, metadata"
      ],
      "lines_removed": [
        "    ",
        "        ",
        "        Tuple of (layers, documents, metadata)",
        "    ",
        "    ",
        "    ",
        "    ",
        "    return layers, documents, metadata"
      ],
      "context_before": [
        "        print(f\"  - {total_cols} minicolumns\")",
        "        print(f\"  - {total_conns} connections\")",
        "",
        "",
        "def load_processor(",
        "    filepath: str,",
        "    verbose: bool = True",
        ") -> tuple:",
        "    \"\"\"",
        "    Load processor state from a file."
      ],
      "context_after": [
        "    Args:",
        "        filepath: Path to saved file",
        "        verbose: Print progress",
        "    Returns:",
        "    \"\"\"",
        "    with open(filepath, 'rb') as f:",
        "        state = pickle.load(f)",
        "    # Reconstruct layers",
        "    layers = {}",
        "    for level_value, layer_data in state.get('layers', {}).items():",
        "        layer = HierarchicalLayer.from_dict(layer_data)",
        "        layers[CorticalLayer(int(level_value))] = layer",
        "    documents = state.get('documents', {})",
        "    metadata = state.get('metadata', {})",
        "    if verbose:",
        "        total_cols = sum(len(layer.minicolumns) for layer in layers.values())",
        "        total_conns = sum(layer.total_connections() for layer in layers.values())",
        "        print(f\"âœ“ Loaded processor from {filepath}\")",
        "        print(f\"  - {len(documents)} documents\")",
        "        print(f\"  - {total_cols} minicolumns\")",
        "        print(f\"  - {total_conns} connections\")",
        "",
        "",
        "def export_graph_json(",
        "    filepath: str,",
        "    layers: Dict[CorticalLayer, HierarchicalLayer],",
        "    layer_filter: Optional[CorticalLayer] = None,",
        "    min_weight: float = 0.0,",
        "    max_nodes: int = 500,",
        "    verbose: bool = True",
        ") -> Dict:"
      ],
      "change_type": "modify"
    },
    {
      "file": "cortical/processor.py",
      "function": "from .layers import CorticalLayer, HierarchicalLayer",
      "start_line": 13,
      "lines_added": [
        "",
        "        self.document_metadata: Dict[str, Dict[str, Any]] = {}",
        "",
        "    def process_document(",
        "        self,",
        "        doc_id: str,",
        "        content: str,",
        "        metadata: Optional[Dict[str, Any]] = None",
        "    ) -> Dict[str, int]:",
        "        \"\"\"",
        "        Process a document and add it to the corpus.",
        "",
        "        Args:",
        "            doc_id: Unique identifier for the document",
        "            content: Document text content",
        "            metadata: Optional metadata dict (source, timestamp, author, etc.)",
        "",
        "        Returns:",
        "            Dict with processing statistics (tokens, bigrams, unique_tokens)",
        "        \"\"\"",
        "",
        "        # Store metadata if provided",
        "        if metadata:",
        "            self.document_metadata[doc_id] = metadata.copy()",
        "        elif doc_id not in self.document_metadata:",
        "            self.document_metadata[doc_id] = {}",
        ""
      ],
      "lines_removed": [
        "    ",
        "    ",
        "    def process_document(self, doc_id: str, content: str) -> Dict[str, int]:",
        "        \"\"\"Process a document and add it to the corpus.\"\"\""
      ],
      "context_before": [
        "from . import analysis",
        "from . import semantics",
        "from . import embeddings as emb_module",
        "from . import query as query_module",
        "from . import gaps as gaps_module",
        "from . import persistence",
        "",
        "",
        "class CorticalTextProcessor:",
        "    \"\"\"Neocortex-inspired text processing system.\"\"\""
      ],
      "context_after": [
        "    def __init__(self, tokenizer: Optional[Tokenizer] = None):",
        "        self.tokenizer = tokenizer or Tokenizer()",
        "        self.layers: Dict[CorticalLayer, HierarchicalLayer] = {",
        "            CorticalLayer.TOKENS: HierarchicalLayer(CorticalLayer.TOKENS),",
        "            CorticalLayer.BIGRAMS: HierarchicalLayer(CorticalLayer.BIGRAMS),",
        "            CorticalLayer.CONCEPTS: HierarchicalLayer(CorticalLayer.CONCEPTS),",
        "            CorticalLayer.DOCUMENTS: HierarchicalLayer(CorticalLayer.DOCUMENTS),",
        "        }",
        "        self.documents: Dict[str, str] = {}",
        "        self.embeddings: Dict[str, List[float]] = {}",
        "        self.semantic_relations: List[Tuple[str, str, str, float]] = []",
        "        self.documents[doc_id] = content",
        "        tokens = self.tokenizer.tokenize(content)",
        "        bigrams = self.tokenizer.extract_ngrams(tokens, n=2)",
        "        ",
        "        layer0 = self.layers[CorticalLayer.TOKENS]",
        "        layer1 = self.layers[CorticalLayer.BIGRAMS]",
        "        layer3 = self.layers[CorticalLayer.DOCUMENTS]",
        "        ",
        "        doc_col = layer3.get_or_create_minicolumn(doc_id)",
        "        doc_col.occurrence_count += 1",
        "        "
      ],
      "change_type": "modify"
    },
    {
      "file": "cortical/processor.py",
      "function": "class CorticalTextProcessor:",
      "start_line": 68,
      "lines_added": [
        "",
        "    def set_document_metadata(self, doc_id: str, **kwargs) -> None:",
        "        \"\"\"",
        "        Set or update metadata for a document.",
        "",
        "        Args:",
        "            doc_id: Document identifier",
        "            **kwargs: Metadata key-value pairs to set",
        "",
        "        Example:",
        "            >>> processor.set_document_metadata(\"doc1\",",
        "            ...     source=\"https://example.com\",",
        "            ...     author=\"John Doe\",",
        "            ...     timestamp=\"2025-12-09\"",
        "            ... )",
        "        \"\"\"",
        "        if doc_id not in self.document_metadata:",
        "            self.document_metadata[doc_id] = {}",
        "        self.document_metadata[doc_id].update(kwargs)",
        "",
        "    def get_document_metadata(self, doc_id: str) -> Dict[str, Any]:",
        "        \"\"\"",
        "        Get metadata for a document.",
        "",
        "        Args:",
        "            doc_id: Document identifier",
        "",
        "        Returns:",
        "            Metadata dict (empty dict if no metadata set)",
        "        \"\"\"",
        "        return self.document_metadata.get(doc_id, {})",
        "",
        "    def get_all_document_metadata(self) -> Dict[str, Dict[str, Any]]:",
        "        \"\"\"",
        "        Get metadata for all documents.",
        "",
        "        Returns:",
        "            Dict mapping doc_id to metadata dict (deep copy)",
        "        \"\"\"",
        "        import copy",
        "        return copy.deepcopy(self.document_metadata)",
        ""
      ],
      "lines_removed": [
        "    "
      ],
      "context_before": [
        "            col = layer1.get_or_create_minicolumn(bigram)",
        "            col.occurrence_count += 1",
        "            col.document_ids.add(doc_id)",
        "            col.activation += 1.0",
        "            for part in bigram.split():",
        "                token_col = layer0.get_minicolumn(part)",
        "                if token_col:",
        "                    col.feedforward_sources.add(token_col.id)",
        "        ",
        "        return {'tokens': len(tokens), 'bigrams': len(bigrams), 'unique_tokens': len(set(tokens))}"
      ],
      "context_after": [
        "    def compute_all(self, verbose: bool = True) -> None:",
        "        \"\"\"Run all computation steps.\"\"\"",
        "        if verbose: print(\"Computing activation propagation...\")",
        "        self.propagate_activation(verbose=False)",
        "        if verbose: print(\"Computing importance (PageRank)...\")",
        "        self.compute_importance(verbose=False)",
        "        if verbose: print(\"Computing TF-IDF...\")",
        "        self.compute_tfidf(verbose=False)",
        "        if verbose: print(\"Computing document connections...\")",
        "        self.compute_document_connections(verbose=False)"
      ],
      "change_type": "modify"
    },
    {
      "file": "cortical/processor.py",
      "function": "class CorticalTextProcessor:",
      "start_line": 211,
      "lines_added": [
        "        \"\"\"Save processor state to a file.\"\"\"",
        "        metadata = {",
        "            'has_embeddings': bool(self.embeddings),",
        "            'has_relations': bool(self.semantic_relations)",
        "        }",
        "        persistence.save_processor(",
        "            filepath,",
        "            self.layers,",
        "            self.documents,",
        "            self.document_metadata,",
        "            metadata,",
        "            verbose",
        "        )",
        "",
        "        \"\"\"Load processor state from a file.\"\"\"",
        "        layers, documents, document_metadata, metadata = persistence.load_processor(filepath, verbose)",
        "        processor.document_metadata = document_metadata"
      ],
      "lines_removed": [
        "        metadata = {'has_embeddings': bool(self.embeddings), 'has_relations': bool(self.semantic_relations)}",
        "        persistence.save_processor(filepath, self.layers, self.documents, metadata, verbose)",
        "    ",
        "        layers, documents, metadata = persistence.load_processor(filepath, verbose)"
      ],
      "context_before": [
        "    def get_document_signature(self, doc_id: str, n: int = 10) -> List[Tuple[str, float]]:",
        "        layer0 = self.layers[CorticalLayer.TOKENS]",
        "        terms = [(col.content, col.tfidf_per_doc.get(doc_id, col.tfidf)) ",
        "                 for col in layer0.minicolumns.values() if doc_id in col.document_ids]",
        "        return sorted(terms, key=lambda x: x[1], reverse=True)[:n]",
        "    ",
        "    def get_corpus_summary(self) -> Dict:",
        "        return persistence.get_state_summary(self.layers, self.documents)",
        "    ",
        "    def save(self, filepath: str, verbose: bool = True) -> None:"
      ],
      "context_after": [
        "    @classmethod",
        "    def load(cls, filepath: str, verbose: bool = True) -> 'CorticalTextProcessor':",
        "        processor = cls()",
        "        processor.layers = layers",
        "        processor.documents = documents",
        "        return processor",
        "    ",
        "    def export_graph(self, filepath: str, layer: Optional[CorticalLayer] = None, max_nodes: int = 500) -> Dict:",
        "        return persistence.export_graph_json(filepath, self.layers, layer, max_nodes=max_nodes)",
        "    ",
        "    def summarize_document(self, doc_id: str, num_sentences: int = 3) -> str:",
        "        if doc_id not in self.documents: return \"\"",
        "        content = self.documents[doc_id]",
        "        sentences = re.split(r'(?<=[.!?])\\s+', content)",
        "        if len(sentences) <= num_sentences: return content"
      ],
      "change_type": "modify"
    },
    {
      "file": "tests/test_persistence.py",
      "function": "class TestSaveLoad(unittest.TestCase):",
      "start_line": 23,
      "lines_added": [
        "            save_processor(",
        "                filepath, processor.layers, processor.documents,",
        "                processor.document_metadata, verbose=False",
        "            )",
        "            layers, documents, document_metadata, metadata = load_processor(filepath, verbose=False)",
        "            save_processor(",
        "                filepath, processor.layers, processor.documents,",
        "                processor.document_metadata, verbose=False",
        "            )",
        "            layers, documents, document_metadata, metadata = load_processor(filepath, verbose=False)",
        "            save_processor(",
        "                filepath, processor.layers, processor.documents,",
        "                processor.document_metadata, verbose=False",
        "            )",
        "            layers, documents, document_metadata, metadata = load_processor(filepath, verbose=False)",
        "            save_processor(",
        "                filepath, processor.layers, processor.documents,",
        "                processor.document_metadata, verbose=False",
        "            )",
        "            layers, documents, document_metadata, metadata = load_processor(filepath, verbose=False)",
        "    def test_save_load_preserves_document_metadata(self):",
        "        \"\"\"Test that save/load preserves document metadata.\"\"\"",
        "        processor = CorticalTextProcessor()",
        "        processor.process_document(",
        "            \"doc1\", \"Neural networks process information.\",",
        "            metadata={\"source\": \"https://example.com\", \"author\": \"Test\"}",
        "        )",
        "        processor.compute_all(verbose=False)",
        "",
        "        with tempfile.TemporaryDirectory() as tmpdir:",
        "            filepath = os.path.join(tmpdir, \"test.pkl\")",
        "            save_processor(",
        "                filepath, processor.layers, processor.documents,",
        "                processor.document_metadata, verbose=False",
        "            )",
        "",
        "            layers, documents, document_metadata, metadata = load_processor(filepath, verbose=False)",
        "",
        "            self.assertEqual(document_metadata[\"doc1\"][\"source\"], \"https://example.com\")",
        "            self.assertEqual(document_metadata[\"doc1\"][\"author\"], \"Test\")",
        ""
      ],
      "lines_removed": [
        "            save_processor(filepath, processor.layers, processor.documents, verbose=False)",
        "            layers, documents, metadata = load_processor(filepath, verbose=False)",
        "            save_processor(filepath, processor.layers, processor.documents, verbose=False)",
        "            layers, documents, _ = load_processor(filepath, verbose=False)",
        "            save_processor(filepath, processor.layers, processor.documents, verbose=False)",
        "            layers, documents, _ = load_processor(filepath, verbose=False)",
        "            save_processor(filepath, processor.layers, processor.documents, verbose=False)",
        "            layers, documents, metadata = load_processor(filepath, verbose=False)"
      ],
      "context_before": [
        "",
        "    def test_save_and_load(self):",
        "        \"\"\"Test saving and loading processor state.\"\"\"",
        "        processor = CorticalTextProcessor()",
        "        processor.process_document(\"doc1\", \"Neural networks process information.\")",
        "        processor.process_document(\"doc2\", \"Machine learning algorithms learn.\")",
        "        processor.compute_all(verbose=False)",
        "",
        "        with tempfile.TemporaryDirectory() as tmpdir:",
        "            filepath = os.path.join(tmpdir, \"test.pkl\")"
      ],
      "context_after": [
        "",
        "",
        "            self.assertEqual(len(documents), 2)",
        "            self.assertIn(\"doc1\", documents)",
        "            self.assertIn(\"doc2\", documents)",
        "",
        "            # Check layers were restored",
        "            layer0 = layers[CorticalLayer.TOKENS]",
        "            self.assertGreater(len(layer0.minicolumns), 0)",
        "",
        "    def test_save_load_preserves_id_index(self):",
        "        \"\"\"Test that save/load preserves the ID index.\"\"\"",
        "        processor = CorticalTextProcessor()",
        "        processor.process_document(\"doc1\", \"neural networks deep learning\")",
        "        processor.compute_all(verbose=False)",
        "",
        "        with tempfile.TemporaryDirectory() as tmpdir:",
        "            filepath = os.path.join(tmpdir, \"test.pkl\")",
        "",
        "",
        "            layer0 = layers[CorticalLayer.TOKENS]",
        "            neural = layer0.get_minicolumn(\"neural\")",
        "",
        "            # get_by_id should work after load",
        "            retrieved = layer0.get_by_id(neural.id)",
        "            self.assertEqual(retrieved.content, \"neural\")",
        "",
        "    def test_save_load_preserves_doc_occurrence_counts(self):",
        "        \"\"\"Test that save/load preserves doc_occurrence_counts.\"\"\"",
        "        processor = CorticalTextProcessor()",
        "        processor.process_document(\"doc1\", \"neural neural neural\")  # 3 times",
        "        processor.process_document(\"doc2\", \"neural\")  # 1 time",
        "        processor.compute_all(verbose=False)",
        "",
        "        with tempfile.TemporaryDirectory() as tmpdir:",
        "            filepath = os.path.join(tmpdir, \"test.pkl\")",
        "",
        "",
        "            layer0 = layers[CorticalLayer.TOKENS]",
        "            neural = layer0.get_minicolumn(\"neural\")",
        "",
        "            self.assertEqual(neural.doc_occurrence_counts.get(\"doc1\"), 3)",
        "            self.assertEqual(neural.doc_occurrence_counts.get(\"doc2\"), 1)",
        "",
        "    def test_save_load_empty_processor(self):",
        "        \"\"\"Test saving and loading empty processor.\"\"\"",
        "        processor = CorticalTextProcessor()",
        "",
        "        with tempfile.TemporaryDirectory() as tmpdir:",
        "            filepath = os.path.join(tmpdir, \"test.pkl\")",
        "",
        "",
        "            self.assertEqual(len(documents), 0)",
        "",
        "",
        "class TestExportGraphJSON(unittest.TestCase):",
        "    \"\"\"Test graph JSON export.\"\"\"",
        "",
        "    def test_export_graph_json(self):",
        "        \"\"\"Test exporting graph to JSON.\"\"\"",
        "        processor = CorticalTextProcessor()",
        "        processor.process_document(\"doc1\", \"neural networks learning\")",
        "        processor.process_document(\"doc2\", \"machine learning algorithms\")",
        "        processor.compute_all(verbose=False)"
      ],
      "change_type": "modify"
    },
    {
      "file": "tests/test_processor.py",
      "function": "class TestProcessorQuery(unittest.TestCase):",
      "start_line": 128,
      "lines_added": [
        "class TestProcessorMetadata(unittest.TestCase):",
        "    \"\"\"Test document metadata functionality.\"\"\"",
        "",
        "    def setUp(self):",
        "        self.processor = CorticalTextProcessor()",
        "",
        "    def test_process_document_with_metadata(self):",
        "        \"\"\"Test processing document with metadata.\"\"\"",
        "        metadata = {\"source\": \"https://example.com\", \"author\": \"Test Author\"}",
        "        self.processor.process_document(\"doc1\", \"Test content.\", metadata=metadata)",
        "        retrieved = self.processor.get_document_metadata(\"doc1\")",
        "        self.assertEqual(retrieved[\"source\"], \"https://example.com\")",
        "        self.assertEqual(retrieved[\"author\"], \"Test Author\")",
        "",
        "    def test_set_document_metadata(self):",
        "        \"\"\"Test setting metadata after processing.\"\"\"",
        "        self.processor.process_document(\"doc1\", \"Test content.\")",
        "        self.processor.set_document_metadata(\"doc1\", source=\"https://test.com\", timestamp=\"2025-12-09\")",
        "        metadata = self.processor.get_document_metadata(\"doc1\")",
        "        self.assertEqual(metadata[\"source\"], \"https://test.com\")",
        "        self.assertEqual(metadata[\"timestamp\"], \"2025-12-09\")",
        "",
        "    def test_update_document_metadata(self):",
        "        \"\"\"Test updating existing metadata.\"\"\"",
        "        self.processor.process_document(\"doc1\", \"Test content.\", metadata={\"author\": \"Original\"})",
        "        self.processor.set_document_metadata(\"doc1\", author=\"Updated\", category=\"AI\")",
        "        metadata = self.processor.get_document_metadata(\"doc1\")",
        "        self.assertEqual(metadata[\"author\"], \"Updated\")",
        "        self.assertEqual(metadata[\"category\"], \"AI\")",
        "",
        "    def test_get_document_metadata_missing(self):",
        "        \"\"\"Test getting metadata for nonexistent document.\"\"\"",
        "        metadata = self.processor.get_document_metadata(\"nonexistent\")",
        "        self.assertEqual(metadata, {})",
        "",
        "    def test_get_all_document_metadata(self):",
        "        \"\"\"Test getting all document metadata.\"\"\"",
        "        self.processor.process_document(\"doc1\", \"Content 1\", metadata={\"type\": \"article\"})",
        "        self.processor.process_document(\"doc2\", \"Content 2\", metadata={\"type\": \"paper\"})",
        "        all_metadata = self.processor.get_all_document_metadata()",
        "        self.assertEqual(len(all_metadata), 2)",
        "        self.assertEqual(all_metadata[\"doc1\"][\"type\"], \"article\")",
        "        self.assertEqual(all_metadata[\"doc2\"][\"type\"], \"paper\")",
        "",
        "    def test_metadata_not_modified_externally(self):",
        "        \"\"\"Test that get_all_document_metadata returns a copy.\"\"\"",
        "        self.processor.process_document(\"doc1\", \"Content\", metadata={\"key\": \"value\"})",
        "        all_metadata = self.processor.get_all_document_metadata()",
        "        all_metadata[\"doc1\"][\"key\"] = \"modified\"",
        "        # Original should be unchanged",
        "        original = self.processor.get_document_metadata(\"doc1\")",
        "        self.assertEqual(original[\"key\"], \"value\")",
        "",
        "",
        "",
        "",
        "",
        "    def test_save_and_load_with_metadata(self):",
        "        \"\"\"Test that document metadata is preserved through save/load.\"\"\"",
        "        processor = CorticalTextProcessor()",
        "        processor.process_document(",
        "            \"doc1\",",
        "            \"Test document content.\",",
        "            metadata={\"source\": \"https://example.com\", \"author\": \"Test Author\"}",
        "        )",
        "        processor.set_document_metadata(\"doc1\", category=\"test\")",
        "        processor.compute_all(verbose=False)",
        "",
        "        with tempfile.TemporaryDirectory() as tmpdir:",
        "            filepath = os.path.join(tmpdir, \"test.pkl\")",
        "            processor.save(filepath, verbose=False)",
        "",
        "            loaded = CorticalTextProcessor.load(filepath, verbose=False)",
        "            metadata = loaded.get_document_metadata(\"doc1\")",
        "            self.assertEqual(metadata[\"source\"], \"https://example.com\")",
        "            self.assertEqual(metadata[\"author\"], \"Test Author\")",
        "            self.assertEqual(metadata[\"category\"], \"test\")",
        ""
      ],
      "lines_removed": [
        "    ",
        "        ",
        "            "
      ],
      "context_before": [
        "        results = self.processor.find_documents_for_query(\"neural networks\", top_n=2)",
        "        self.assertGreater(len(results), 0)",
        "        self.assertEqual(results[0][0], \"neural_doc\")",
        "    ",
        "    def test_query_expanded(self):",
        "        \"\"\"Test expanded query.\"\"\"",
        "        results = self.processor.query_expanded(\"learning\", top_n=5)",
        "        self.assertIsInstance(results, list)",
        "",
        ""
      ],
      "context_after": [
        "class TestProcessorPersistence(unittest.TestCase):",
        "    \"\"\"Test processor save/load functionality.\"\"\"",
        "    def test_save_and_load(self):",
        "        \"\"\"Test saving and loading processor.\"\"\"",
        "        processor = CorticalTextProcessor()",
        "        processor.process_document(\"doc1\", \"Test document content.\")",
        "        processor.compute_all(verbose=False)",
        "        with tempfile.TemporaryDirectory() as tmpdir:",
        "            filepath = os.path.join(tmpdir, \"test.pkl\")",
        "            processor.save(filepath, verbose=False)",
        "            loaded = CorticalTextProcessor.load(filepath, verbose=False)",
        "            self.assertEqual(len(loaded.documents), 1)",
        "            self.assertIn(\"doc1\", loaded.documents)",
        "",
        "",
        "class TestProcessorPassageRetrieval(unittest.TestCase):",
        "    \"\"\"Test chunk-level passage retrieval for RAG systems.\"\"\"",
        "",
        "    @classmethod",
        "    def setUpClass(cls):",
        "        cls.processor = CorticalTextProcessor()",
        "        # Create documents with distinct content for testing passage retrieval",
        "        cls.processor.process_document(\"neural_doc\", \"\"\"",
        "            Neural networks are computational models inspired by biological neurons."
      ],
      "change_type": "modify"
    }
  ],
  "hour_of_day": 19,
  "day_of_week": "Tuesday",
  "seconds_since_last_commit": -496408,
  "is_merge": false,
  "is_initial": false,
  "parent_count": 1,
  "session_id": null,
  "related_chats": [],
  "ci_result": null,
  "reverted": false,
  "amended": false
}