{
  "hash": "d0e4efb65cc3ec8766dfd01ebe4328137a89148b",
  "message": "Add synonym/concept mapping for code patterns (Task #49)",
  "author": "Claude",
  "timestamp": "2025-12-10 14:30:40 +0000",
  "branch": "claude/multi-index-design-DvifZ",
  "files_changed": [
    "TASK_LIST.md",
    "cortical/code_concepts.py",
    "cortical/processor.py",
    "cortical/query.py",
    "tests/test_code_concepts.py"
  ],
  "insertions": 622,
  "deletions": 25,
  "hunks": [
    {
      "file": "TASK_LIST.md",
      "function": "tokens = tokenizer.tokenize(\"getUserCredentials\")",
      "start_line": 1694,
      "lines_added": [
        "**Files:** `cortical/code_concepts.py`, `cortical/query.py`, `cortical/processor.py`",
        "**Status:** [x] Completed",
        "**Solution Applied:**",
        "1. Created `cortical/code_concepts.py` with 16 programming concept groups",
        "2. Added `expand_code_concepts()` function for query expansion",
        "3. Integrated with `expand_query()` via `use_code_concepts` parameter",
        "4. Added `expand_query_for_code()` convenience method to processor",
        "5. Added 33 tests in `tests/test_code_concepts.py`",
        "",
        "**Concept Groups Implemented:**",
        "- retrieval, storage, deletion, auth, error, validation",
        "- transform, network, database, async, config, logging",
        "- testing, file, iteration, lifecycle, events"
      ],
      "lines_removed": [
        "**Files:** `cortical/semantics.py`, new `cortical/code_concepts.py`",
        "**Status:** [ ] Not Started",
        "**Solution:**",
        "1. Create `CODE_CONCEPT_GROUPS` mapping common programming synonyms",
        "2. Add `expand_code_concepts()` to query expansion",
        "3. Include domain patterns: auth/security, data/storage, network/api, error/exception",
        "",
        "**Concept Groups:**",
        "```python",
        "CODE_CONCEPT_GROUPS = {",
        "    'retrieval': ['get', 'fetch', 'load', 'retrieve', 'read', 'query'],",
        "    'storage': ['save', 'store', 'write', 'persist', 'cache'],",
        "    'auth': ['auth', 'authentication', 'login', 'credentials', 'token', 'session'],",
        "    'error': ['error', 'exception', 'fail', 'catch', 'handle', 'throw'],",
        "    ...",
        "}",
        "```"
      ],
      "context_before": [
        "```",
        "",
        "**Tests Added:**",
        "- 8 tests for `split_identifier()` function (camelCase, PascalCase, underscore_style, acronyms)",
        "- 8 tests for code-aware tokenization (splitting, stop word filtering, min length, deduplication)",
        "",
        "---",
        "",
        "### 49. Add Synonym/Concept Mapping for Code Patterns",
        ""
      ],
      "context_after": [
        "**Priority:** High",
        "",
        "**Problem:**",
        "The system doesn't know that \"fetch\", \"get\", \"retrieve\", \"load\" are often interchangeable in code contexts, or that \"auth\", \"authentication\", \"credentials\", \"login\" form a concept cluster.",
        "",
        "",
        "---",
        "",
        "### 50. Add Intent-Based Query Understanding",
        "",
        "**Files:** `cortical/query.py`",
        "**Status:** [ ] Not Started",
        "**Priority:** High",
        "",
        "**Problem:**"
      ],
      "change_type": "modify"
    },
    {
      "file": "cortical/code_concepts.py",
      "function": null,
      "start_line": 0,
      "lines_added": [
        "\"\"\"",
        "Code Concepts Module",
        "====================",
        "",
        "Programming concept groups for semantic code search.",
        "",
        "Maps common programming synonyms and related terms to enable",
        "intent-based code retrieval. When a developer searches for \"get user\",",
        "the system can also find \"fetch user\", \"load user\", \"retrieve user\".",
        "\"\"\"",
        "",
        "from typing import Dict, List, Set, FrozenSet",
        "",
        "",
        "# Programming concept groups - terms that are often interchangeable in code",
        "CODE_CONCEPT_GROUPS: Dict[str, FrozenSet[str]] = {",
        "    # Data retrieval operations",
        "    'retrieval': frozenset([",
        "        'get', 'fetch', 'load', 'retrieve', 'read', 'query', 'find',",
        "        'lookup', 'obtain', 'acquire', 'pull', 'select'",
        "    ]),",
        "",
        "    # Data storage operations",
        "    'storage': frozenset([",
        "        'save', 'store', 'write', 'persist', 'cache', 'put', 'set',",
        "        'insert', 'add', 'create', 'commit', 'push', 'update'",
        "    ]),",
        "",
        "    # Deletion operations",
        "    'deletion': frozenset([",
        "        'delete', 'remove', 'drop', 'clear', 'destroy', 'purge',",
        "        'erase', 'clean', 'reset', 'dispose', 'unset'",
        "    ]),",
        "",
        "    # Authentication and security",
        "    'auth': frozenset([",
        "        'auth', 'authentication', 'login', 'logout', 'credentials',",
        "        'token', 'session', 'password', 'user', 'permission', 'role',",
        "        'access', 'authorize', 'verify', 'validate', 'identity'",
        "    ]),",
        "",
        "    # Error handling",
        "    'error': frozenset([",
        "        'error', 'exception', 'fail', 'failure', 'catch', 'handle',",
        "        'throw', 'raise', 'try', 'recover', 'retry', 'fallback',",
        "        'invalid', 'warning', 'fault', 'crash'",
        "    ]),",
        "",
        "    # Validation and checking",
        "    'validation': frozenset([",
        "        'validate', 'check', 'verify', 'assert', 'ensure', 'confirm',",
        "        'test', 'inspect', 'examine', 'sanitize', 'filter', 'guard'",
        "    ]),",
        "",
        "    # Transformation operations",
        "    'transform': frozenset([",
        "        'transform', 'convert', 'parse', 'format', 'serialize',",
        "        'deserialize', 'encode', 'decode', 'map', 'reduce', 'filter',",
        "        'normalize', 'process', 'translate', 'render'",
        "    ]),",
        "",
        "    # Network and API",
        "    'network': frozenset([",
        "        'request', 'response', 'api', 'endpoint', 'http', 'rest',",
        "        'client', 'server', 'socket', 'connection', 'send', 'receive',",
        "        'url', 'route', 'handler', 'middleware'",
        "    ]),",
        "",
        "    # Database operations",
        "    'database': frozenset([",
        "        'database', 'db', 'sql', 'query', 'table', 'record', 'row',",
        "        'column', 'index', 'schema', 'migration', 'model', 'entity',",
        "        'repository', 'orm', 'transaction'",
        "    ]),",
        "",
        "    # Async and concurrency",
        "    'async': frozenset([",
        "        'async', 'await', 'promise', 'future', 'callback', 'thread',",
        "        'concurrent', 'parallel', 'worker', 'queue', 'task', 'job',",
        "        'schedule', 'spawn', 'sync', 'lock', 'mutex'",
        "    ]),",
        "",
        "    # Configuration and settings",
        "    'config': frozenset([",
        "        'config', 'configuration', 'settings', 'options', 'preferences',",
        "        'env', 'environment', 'property', 'parameter', 'argument',",
        "        'flag', 'constant', 'default', 'override'",
        "    ]),",
        "",
        "    # Logging and monitoring",
        "    'logging': frozenset([",
        "        'log', 'logger', 'logging', 'debug', 'info', 'warn', 'trace',",
        "        'monitor', 'metric', 'telemetry', 'track', 'audit', 'record',",
        "        'print', 'output', 'verbose'",
        "    ]),",
        "",
        "    # Testing",
        "    'testing': frozenset([",
        "        'test', 'spec', 'mock', 'stub', 'fake', 'fixture', 'assert',",
        "        'expect', 'verify', 'unit', 'integration', 'coverage', 'suite',",
        "        'setup', 'teardown', 'before', 'after'",
        "    ]),",
        "",
        "    # File operations",
        "    'file': frozenset([",
        "        'file', 'path', 'directory', 'folder', 'read', 'write', 'open',",
        "        'close', 'stream', 'buffer', 'io', 'filesystem', 'upload',",
        "        'download', 'copy', 'move', 'rename'",
        "    ]),",
        "",
        "    # Iteration and collections",
        "    'iteration': frozenset([",
        "        'iterate', 'loop', 'each', 'map', 'filter', 'reduce', 'fold',",
        "        'list', 'array', 'collection', 'set', 'dict', 'hash', 'tree',",
        "        'queue', 'stack', 'sort', 'search', 'find'",
        "    ]),",
        "",
        "    # Initialization and lifecycle",
        "    'lifecycle': frozenset([",
        "        'init', 'initialize', 'setup', 'start', 'stop', 'shutdown',",
        "        'bootstrap', 'create', 'destroy', 'build', 'configure',",
        "        'register', 'unregister', 'connect', 'disconnect', 'close'",
        "    ]),",
        "",
        "    # Events and messaging",
        "    'events': frozenset([",
        "        'event', 'emit', 'listen', 'subscribe', 'publish', 'dispatch',",
        "        'handler', 'callback', 'hook', 'trigger', 'notify', 'observe',",
        "        'broadcast', 'signal', 'message', 'channel'",
        "    ]),",
        "}",
        "",
        "# Build reverse index: term -> list of concept groups it belongs to",
        "_TERM_TO_CONCEPTS: Dict[str, List[str]] = {}",
        "for concept, terms in CODE_CONCEPT_GROUPS.items():",
        "    for term in terms:",
        "        if term not in _TERM_TO_CONCEPTS:",
        "            _TERM_TO_CONCEPTS[term] = []",
        "        _TERM_TO_CONCEPTS[term].append(concept)",
        "",
        "",
        "def get_related_terms(term: str, max_terms: int = 5) -> List[str]:",
        "    \"\"\"",
        "    Get programming terms related to the given term.",
        "",
        "    Args:",
        "        term: A programming term (e.g., \"fetch\", \"authenticate\")",
        "        max_terms: Maximum number of related terms to return",
        "",
        "    Returns:",
        "        List of related terms, excluding the input term",
        "",
        "    Example:",
        "        >>> get_related_terms(\"fetch\")",
        "        ['get', 'load', 'retrieve', 'read', 'query']",
        "    \"\"\"",
        "    term_lower = term.lower()",
        "    related: Set[str] = set()",
        "",
        "    # Find all concept groups this term belongs to",
        "    concepts = _TERM_TO_CONCEPTS.get(term_lower, [])",
        "",
        "    for concept in concepts:",
        "        terms = CODE_CONCEPT_GROUPS.get(concept, frozenset())",
        "        related.update(terms)",
        "",
        "    # Remove the original term",
        "    related.discard(term_lower)",
        "",
        "    # Return top terms sorted alphabetically for consistent results",
        "    return sorted(related)[:max_terms]",
        "",
        "",
        "def expand_code_concepts(",
        "    terms: List[str],",
        "    max_expansions_per_term: int = 3,",
        "    weight: float = 0.6",
        ") -> Dict[str, float]:",
        "    \"\"\"",
        "    Expand a list of terms using code concept groups.",
        "",
        "    Args:",
        "        terms: List of query terms to expand",
        "        max_expansions_per_term: Max related terms to add per input term",
        "        weight: Weight to assign to expanded terms (0.0-1.0)",
        "",
        "    Returns:",
        "        Dict mapping expanded terms to weights",
        "",
        "    Example:",
        "        >>> expand_code_concepts([\"fetch\", \"user\"])",
        "        {'get': 0.6, 'load': 0.6, 'retrieve': 0.6, ...}",
        "    \"\"\"",
        "    expanded: Dict[str, float] = {}",
        "    input_terms = set(t.lower() for t in terms)",
        "",
        "    for term in terms:",
        "        related = get_related_terms(term, max_terms=max_expansions_per_term)",
        "        for related_term in related:",
        "            # Don't add terms that were in the original query",
        "            if related_term not in input_terms:",
        "                # Keep highest weight if term appears multiple times",
        "                if related_term not in expanded or expanded[related_term] < weight:",
        "                    expanded[related_term] = weight",
        "",
        "    return expanded",
        "",
        "",
        "def get_concept_group(term: str) -> List[str]:",
        "    \"\"\"",
        "    Get the concept group names a term belongs to.",
        "",
        "    Args:",
        "        term: A programming term",
        "",
        "    Returns:",
        "        List of concept group names",
        "",
        "    Example:",
        "        >>> get_concept_group(\"fetch\")",
        "        ['retrieval']",
        "        >>> get_concept_group(\"validate\")",
        "        ['validation', 'testing']",
        "    \"\"\"",
        "    return _TERM_TO_CONCEPTS.get(term.lower(), [])",
        "",
        "",
        "def list_concept_groups() -> List[str]:",
        "    \"\"\"",
        "    List all available concept group names.",
        "",
        "    Returns:",
        "        Sorted list of concept group names",
        "    \"\"\"",
        "    return sorted(CODE_CONCEPT_GROUPS.keys())",
        "",
        "",
        "def get_group_terms(group_name: str) -> List[str]:",
        "    \"\"\"",
        "    Get all terms in a concept group.",
        "",
        "    Args:",
        "        group_name: Name of the concept group",
        "",
        "    Returns:",
        "        Sorted list of terms in the group, or empty list if group not found",
        "    \"\"\"",
        "    terms = CODE_CONCEPT_GROUPS.get(group_name, frozenset())",
        "    return sorted(terms)"
      ],
      "lines_removed": [],
      "context_before": [],
      "context_after": [],
      "change_type": "add"
    },
    {
      "file": "cortical/processor.py",
      "function": "class CorticalTextProcessor:",
      "start_line": 1086,
      "lines_added": [
        "    def expand_query(",
        "        self,",
        "        query_text: str,",
        "        max_expansions: int = 10,",
        "        use_variants: bool = True,",
        "        use_code_concepts: bool = False,",
        "        verbose: bool = False",
        "    ) -> Dict[str, float]:",
        "        \"\"\"",
        "        Expand a query using lateral connections and concept clusters.",
        "",
        "        Args:",
        "            query_text: Original query string",
        "            max_expansions: Maximum expansion terms to add",
        "            use_variants: Try word variants when direct match fails",
        "            use_code_concepts: Include programming synonym expansions",
        "",
        "        Returns:",
        "            Dict mapping terms to weights",
        "        \"\"\"",
        "        return query_module.expand_query(",
        "            query_text,",
        "            self.layers,",
        "            self.tokenizer,",
        "            max_expansions=max_expansions,",
        "            use_variants=use_variants,",
        "            use_code_concepts=use_code_concepts",
        "        )",
        "",
        "    def expand_query_for_code(self, query_text: str, max_expansions: int = 15) -> Dict[str, float]:",
        "        \"\"\"",
        "        Expand a query optimized for code search.",
        "",
        "        Enables code concept expansion to find programming synonyms",
        "        (e.g., \"fetch\" also matches \"get\", \"load\", \"retrieve\").",
        "",
        "        Args:",
        "            query_text: Original query string",
        "            max_expansions: Maximum expansion terms to add",
        "",
        "        Returns:",
        "            Dict mapping terms to weights",
        "        \"\"\"",
        "        return query_module.expand_query(",
        "            query_text,",
        "            self.layers,",
        "            self.tokenizer,",
        "            max_expansions=max_expansions,",
        "            use_variants=True,",
        "            use_code_concepts=True",
        "        )",
        ""
      ],
      "lines_removed": [
        "    def expand_query(self, query_text: str, max_expansions: int = 10, use_variants: bool = True, verbose: bool = False) -> Dict[str, float]:",
        "        return query_module.expand_query(query_text, self.layers, self.tokenizer, max_expansions=max_expansions, use_variants=use_variants)",
        "    "
      ],
      "context_before": [
        "        stats = semantics.retrofit_embeddings(self.embeddings, self.semantic_relations, iterations, alpha)",
        "        if verbose: print(f\"Retrofitted embeddings (moved {stats['total_movement']:.2f} total)\")",
        "        return stats",
        "    ",
        "    def embedding_similarity(self, term1: str, term2: str) -> float:",
        "        return emb_module.embedding_similarity(self.embeddings, term1, term2)",
        "    ",
        "    def find_similar_by_embedding(self, term: str, top_n: int = 10) -> List[Tuple[str, float]]:",
        "        return emb_module.find_similar_by_embedding(self.embeddings, term, top_n)",
        "    "
      ],
      "context_after": [
        "    def expand_query_semantic(self, query_text: str, max_expansions: int = 10) -> Dict[str, float]:",
        "        return query_module.expand_query_semantic(query_text, self.layers, self.tokenizer, self.semantic_relations, max_expansions)",
        "",
        "    def complete_analogy(",
        "        self,",
        "        term_a: str,",
        "        term_b: str,",
        "        term_c: str,",
        "        top_n: int = 5,",
        "        use_embeddings: bool = True,"
      ],
      "change_type": "modify"
    },
    {
      "file": "cortical/query.py",
      "function": "Query expansion and search functionality.",
      "start_line": 7,
      "lines_added": [
        "from .code_concepts import expand_code_concepts",
        "    use_variants: bool = True,",
        "    use_code_concepts: bool = False",
        "",
        "    - Code concepts: programming synonym groups (get/fetch/load)",
        "",
        "        use_code_concepts: Include programming synonym expansions",
        ""
      ],
      "lines_removed": [
        "    use_variants: bool = True",
        "    ",
        "    ",
        "        "
      ],
      "context_before": [
        "Provides methods for expanding queries using lateral connections,",
        "concept clusters, and word variants, then searching the corpus",
        "using TF-IDF and graph-based scoring.",
        "\"\"\"",
        "",
        "from typing import Dict, List, Tuple, Optional",
        "from collections import defaultdict",
        "",
        "from .layers import CorticalLayer, HierarchicalLayer",
        "from .tokenizer import Tokenizer"
      ],
      "context_after": [
        "",
        "",
        "def expand_query(",
        "    query_text: str,",
        "    layers: Dict[CorticalLayer, HierarchicalLayer],",
        "    tokenizer: Tokenizer,",
        "    max_expansions: int = 10,",
        "    use_lateral: bool = True,",
        "    use_concepts: bool = True,",
        ") -> Dict[str, float]:",
        "    \"\"\"",
        "    Expand a query using lateral connections and concept clusters.",
        "    This mimics how the brain retrieves related memories when given a cue:",
        "    - Lateral connections: direct word associations (like priming)",
        "    - Concept clusters: semantic category membership",
        "    - Word variants: stemming and synonym mapping",
        "    Args:",
        "        query_text: Original query string",
        "        layers: Dictionary of layers",
        "        tokenizer: Tokenizer instance",
        "        max_expansions: Maximum number of expansion terms to add",
        "        use_lateral: Include terms from lateral connections",
        "        use_concepts: Include terms from concept clusters",
        "        use_variants: Try word variants when direct match fails",
        "    Returns:",
        "        Dict mapping terms to weights (original terms get weight 1.0)",
        "    \"\"\"",
        "    tokens = tokenizer.tokenize(query_text)",
        "    layer0 = layers[CorticalLayer.TOKENS]",
        "    layer2 = layers.get(CorticalLayer.CONCEPTS)",
        "    ",
        "    # Start with original terms at full weight",
        "    expanded: Dict[str, float] = {}",
        "    unmatched_tokens = []"
      ],
      "change_type": "modify"
    },
    {
      "file": "cortical/query.py",
      "function": "def expand_query(",
      "start_line": 103,
      "lines_added": [
        "",
        "    # Method 3: Code concept groups (programming synonyms)",
        "    if use_code_concepts:",
        "        code_expansions = expand_code_concepts(",
        "            list(expanded.keys()),",
        "            max_expansions_per_term=3,",
        "            weight=0.6",
        "        )",
        "        for term, weight in code_expansions.items():",
        "            if term not in expanded:",
        "                candidate_expansions[term] = max(",
        "                    candidate_expansions[term], weight",
        "                )",
        ""
      ],
      "lines_removed": [
        "    "
      ],
      "context_before": [
        "                for concept in layer2.minicolumns.values():",
        "                    if col.id in concept.feedforward_sources:",
        "                        for member_id in concept.feedforward_sources:",
        "                            # Use O(1) ID lookup instead of linear search",
        "                            member = layer0.get_by_id(member_id)",
        "                            if member and member.content not in expanded:",
        "                                score = concept.pagerank * member.pagerank * 0.4",
        "                                candidate_expansions[member.content] = max(",
        "                                    candidate_expansions[member.content], score",
        "                                )"
      ],
      "context_after": [
        "    # Select top expansions",
        "    sorted_candidates = sorted(",
        "        candidate_expansions.items(),",
        "        key=lambda x: x[1],",
        "        reverse=True",
        "    )[:max_expansions]",
        "    ",
        "    for term, score in sorted_candidates:",
        "        expanded[term] = score",
        "    "
      ],
      "change_type": "modify"
    },
    {
      "file": "tests/test_code_concepts.py",
      "function": null,
      "start_line": 0,
      "lines_added": [
        "\"\"\"",
        "Tests for code_concepts module.",
        "",
        "Tests the programming concept groups and expansion functions",
        "used for semantic code search.",
        "\"\"\"",
        "",
        "import unittest",
        "from cortical.code_concepts import (",
        "    CODE_CONCEPT_GROUPS,",
        "    get_related_terms,",
        "    expand_code_concepts,",
        "    get_concept_group,",
        "    list_concept_groups,",
        "    get_group_terms,",
        ")",
        "",
        "",
        "class TestCodeConceptGroups(unittest.TestCase):",
        "    \"\"\"Test the CODE_CONCEPT_GROUPS structure.\"\"\"",
        "",
        "    def test_groups_exist(self):",
        "        \"\"\"Test that concept groups are defined.\"\"\"",
        "        self.assertGreater(len(CODE_CONCEPT_GROUPS), 0)",
        "",
        "    def test_retrieval_group(self):",
        "        \"\"\"Test the retrieval concept group.\"\"\"",
        "        self.assertIn('retrieval', CODE_CONCEPT_GROUPS)",
        "        retrieval = CODE_CONCEPT_GROUPS['retrieval']",
        "        self.assertIn('get', retrieval)",
        "        self.assertIn('fetch', retrieval)",
        "        self.assertIn('load', retrieval)",
        "        self.assertIn('retrieve', retrieval)",
        "",
        "    def test_storage_group(self):",
        "        \"\"\"Test the storage concept group.\"\"\"",
        "        self.assertIn('storage', CODE_CONCEPT_GROUPS)",
        "        storage = CODE_CONCEPT_GROUPS['storage']",
        "        self.assertIn('save', storage)",
        "        self.assertIn('store', storage)",
        "        self.assertIn('write', storage)",
        "        self.assertIn('persist', storage)",
        "",
        "    def test_auth_group(self):",
        "        \"\"\"Test the authentication concept group.\"\"\"",
        "        self.assertIn('auth', CODE_CONCEPT_GROUPS)",
        "        auth = CODE_CONCEPT_GROUPS['auth']",
        "        self.assertIn('login', auth)",
        "        self.assertIn('credentials', auth)",
        "        self.assertIn('token', auth)",
        "",
        "    def test_error_group(self):",
        "        \"\"\"Test the error handling concept group.\"\"\"",
        "        self.assertIn('error', CODE_CONCEPT_GROUPS)",
        "        error = CODE_CONCEPT_GROUPS['error']",
        "        self.assertIn('exception', error)",
        "        self.assertIn('catch', error)",
        "        self.assertIn('throw', error)",
        "",
        "    def test_groups_are_frozensets(self):",
        "        \"\"\"Test that groups are immutable frozensets.\"\"\"",
        "        for group_name, terms in CODE_CONCEPT_GROUPS.items():",
        "            self.assertIsInstance(terms, frozenset)",
        "",
        "",
        "class TestGetRelatedTerms(unittest.TestCase):",
        "    \"\"\"Test the get_related_terms function.\"\"\"",
        "",
        "    def test_fetch_related_terms(self):",
        "        \"\"\"Test getting terms related to 'fetch'.\"\"\"",
        "        related = get_related_terms('fetch', max_terms=10)",
        "        self.assertIn('get', related)",
        "        self.assertIn('load', related)",
        "        self.assertNotIn('fetch', related)  # Should not include input term",
        "",
        "    def test_save_related_terms(self):",
        "        \"\"\"Test getting terms related to 'save'.\"\"\"",
        "        related = get_related_terms('save', max_terms=12)",
        "        self.assertIn('store', related)",
        "        self.assertIn('write', related)",
        "        self.assertNotIn('save', related)",
        "",
        "    def test_unknown_term(self):",
        "        \"\"\"Test with a term not in any concept group.\"\"\"",
        "        related = get_related_terms('xyzabc123')",
        "        self.assertEqual(related, [])",
        "",
        "    def test_max_terms_limit(self):",
        "        \"\"\"Test that max_terms limits the output.\"\"\"",
        "        related = get_related_terms('get', max_terms=3)",
        "        self.assertLessEqual(len(related), 3)",
        "",
        "    def test_case_insensitive(self):",
        "        \"\"\"Test that lookup is case insensitive.\"\"\"",
        "        related_lower = get_related_terms('fetch')",
        "        related_upper = get_related_terms('FETCH')",
        "        related_mixed = get_related_terms('Fetch')",
        "        self.assertEqual(set(related_lower), set(related_upper))",
        "        self.assertEqual(set(related_lower), set(related_mixed))",
        "",
        "",
        "class TestExpandCodeConcepts(unittest.TestCase):",
        "    \"\"\"Test the expand_code_concepts function.\"\"\"",
        "",
        "    def test_expand_single_term(self):",
        "        \"\"\"Test expanding a single term.\"\"\"",
        "        expanded = expand_code_concepts(['fetch'], max_expansions_per_term=10)",
        "        self.assertIn('get', expanded)",
        "        self.assertIn('load', expanded)",
        "        self.assertNotIn('fetch', expanded)  # Input terms not in output",
        "",
        "    def test_expand_multiple_terms(self):",
        "        \"\"\"Test expanding multiple terms.\"\"\"",
        "        expanded = expand_code_concepts(['fetch', 'save'], max_expansions_per_term=10)",
        "        # Should have terms from both retrieval and storage groups",
        "        self.assertIn('get', expanded)",
        "        self.assertIn('store', expanded)",
        "",
        "    def test_expand_empty_list(self):",
        "        \"\"\"Test expanding empty list.\"\"\"",
        "        expanded = expand_code_concepts([])",
        "        self.assertEqual(expanded, {})",
        "",
        "    def test_expand_unknown_terms(self):",
        "        \"\"\"Test expanding terms not in any group.\"\"\"",
        "        expanded = expand_code_concepts(['xyzabc123'])",
        "        self.assertEqual(expanded, {})",
        "",
        "    def test_weights_are_floats(self):",
        "        \"\"\"Test that expansion weights are floats.\"\"\"",
        "        expanded = expand_code_concepts(['fetch'])",
        "        for term, weight in expanded.items():",
        "            self.assertIsInstance(weight, float)",
        "            self.assertGreater(weight, 0.0)",
        "            self.assertLessEqual(weight, 1.0)",
        "",
        "    def test_custom_weight(self):",
        "        \"\"\"Test custom weight parameter.\"\"\"",
        "        expanded = expand_code_concepts(['fetch'], weight=0.8)",
        "        for term, weight in expanded.items():",
        "            self.assertEqual(weight, 0.8)",
        "",
        "    def test_max_expansions_per_term(self):",
        "        \"\"\"Test limiting expansions per term.\"\"\"",
        "        expanded = expand_code_concepts(['fetch'], max_expansions_per_term=2)",
        "        self.assertLessEqual(len(expanded), 2)",
        "",
        "    def test_no_duplicate_original_terms(self):",
        "        \"\"\"Test that original terms are not in expansions.\"\"\"",
        "        terms = ['get', 'fetch', 'load']",
        "        expanded = expand_code_concepts(terms)",
        "        for term in terms:",
        "            self.assertNotIn(term, expanded)",
        "",
        "",
        "class TestGetConceptGroup(unittest.TestCase):",
        "    \"\"\"Test the get_concept_group function.\"\"\"",
        "",
        "    def test_single_group_membership(self):",
        "        \"\"\"Test term that belongs to one group.\"\"\"",
        "        groups = get_concept_group('fetch')",
        "        self.assertIn('retrieval', groups)",
        "",
        "    def test_multiple_group_membership(self):",
        "        \"\"\"Test term that might belong to multiple groups.\"\"\"",
        "        # 'validate' is in both 'validation' and possibly 'testing'",
        "        groups = get_concept_group('validate')",
        "        self.assertIn('validation', groups)",
        "",
        "    def test_unknown_term(self):",
        "        \"\"\"Test unknown term returns empty list.\"\"\"",
        "        groups = get_concept_group('xyzabc123')",
        "        self.assertEqual(groups, [])",
        "",
        "    def test_case_insensitive(self):",
        "        \"\"\"Test case insensitive lookup.\"\"\"",
        "        groups_lower = get_concept_group('fetch')",
        "        groups_upper = get_concept_group('FETCH')",
        "        self.assertEqual(groups_lower, groups_upper)",
        "",
        "",
        "class TestListConceptGroups(unittest.TestCase):",
        "    \"\"\"Test the list_concept_groups function.\"\"\"",
        "",
        "    def test_returns_list(self):",
        "        \"\"\"Test that function returns a list.\"\"\"",
        "        groups = list_concept_groups()",
        "        self.assertIsInstance(groups, list)",
        "",
        "    def test_contains_known_groups(self):",
        "        \"\"\"Test that known groups are in the list.\"\"\"",
        "        groups = list_concept_groups()",
        "        self.assertIn('retrieval', groups)",
        "        self.assertIn('storage', groups)",
        "        self.assertIn('auth', groups)",
        "        self.assertIn('error', groups)",
        "",
        "    def test_list_is_sorted(self):",
        "        \"\"\"Test that list is sorted alphabetically.\"\"\"",
        "        groups = list_concept_groups()",
        "        self.assertEqual(groups, sorted(groups))",
        "",
        "",
        "class TestGetGroupTerms(unittest.TestCase):",
        "    \"\"\"Test the get_group_terms function.\"\"\"",
        "",
        "    def test_retrieval_terms(self):",
        "        \"\"\"Test getting terms from retrieval group.\"\"\"",
        "        terms = get_group_terms('retrieval')",
        "        self.assertIn('get', terms)",
        "        self.assertIn('fetch', terms)",
        "",
        "    def test_unknown_group(self):",
        "        \"\"\"Test unknown group returns empty list.\"\"\"",
        "        terms = get_group_terms('nonexistent_group')",
        "        self.assertEqual(terms, [])",
        "",
        "    def test_terms_are_sorted(self):",
        "        \"\"\"Test that terms are sorted alphabetically.\"\"\"",
        "        terms = get_group_terms('retrieval')",
        "        self.assertEqual(terms, sorted(terms))",
        "",
        "",
        "class TestQueryExpansionIntegration(unittest.TestCase):",
        "    \"\"\"Test code concepts integration with query expansion.\"\"\"",
        "",
        "    def setUp(self):",
        "        \"\"\"Set up test processor.\"\"\"",
        "        from cortical import CorticalTextProcessor",
        "        self.processor = CorticalTextProcessor()",
        "        # Use terms that won't be filtered as stop words",
        "        self.processor.process_document(\"doc1\", \"\"\"",
        "            The retrieve function obtains user information from the database.",
        "            It will fetch data and load settings internally.",
        "            The query method returns user profiles.",
        "        \"\"\")",
        "        self.processor.process_document(\"doc2\", \"\"\"",
        "            The persist function stores user information to the database.",
        "            It handles save operations and caching of user profiles.",
        "            The store method writes data.",
        "        \"\"\")",
        "        self.processor.compute_all()",
        "",
        "    def test_expand_query_with_code_concepts(self):",
        "        \"\"\"Test expand_query with use_code_concepts enabled.\"\"\"",
        "        expanded = self.processor.expand_query(",
        "            \"fetch data\",",
        "            use_code_concepts=True",
        "        )",
        "        # Should include original terms",
        "        self.assertIn('fetch', expanded)",
        "        self.assertIn('data', expanded)",
        "        # With code concepts enabled, should also include related terms",
        "        # like 'load', 'retrieve' (if expansion finds them)",
        "",
        "    def test_expand_query_for_code(self):",
        "        \"\"\"Test the expand_query_for_code convenience method.\"\"\"",
        "        expanded = self.processor.expand_query_for_code(\"fetch data\")",
        "        self.assertIn('fetch', expanded)",
        "        self.assertIn('data', expanded)",
        "",
        "    def test_code_concepts_adds_synonyms(self):",
        "        \"\"\"Test that code concepts adds programming synonyms.\"\"\"",
        "        # Expand 'fetch' with code concepts - not a stop word",
        "        expanded_with_code = self.processor.expand_query(",
        "            \"fetch\",",
        "            use_code_concepts=True,",
        "            max_expansions=20",
        "        )",
        "        # Should include 'fetch' as original term",
        "        self.assertIn('fetch', expanded_with_code)",
        "        # Code concepts should add related retrieval terms",
        "        # Check that at least one synonym is added",
        "        retrieval_synonyms = {'load', 'retrieve', 'query', 'obtain'}",
        "        has_synonym = any(s in expanded_with_code for s in retrieval_synonyms)",
        "        self.assertTrue(has_synonym, f\"Expected synonyms in {expanded_with_code}\")",
        "",
        "    def test_code_concepts_disabled_by_default(self):",
        "        \"\"\"Test that code concepts are disabled by default.\"\"\"",
        "        # This test verifies the parameter exists and doesn't crash",
        "        expanded_default = self.processor.expand_query(\"fetch\")",
        "        self.assertIn('fetch', expanded_default)",
        "",
        "",
        "if __name__ == '__main__':",
        "    unittest.main()"
      ],
      "lines_removed": [],
      "context_before": [],
      "context_after": [],
      "change_type": "add"
    }
  ],
  "hour_of_day": 14,
  "day_of_week": "Wednesday",
  "seconds_since_last_commit": -429248,
  "is_merge": false,
  "is_initial": false,
  "parent_count": 1,
  "session_id": null,
  "related_chats": [],
  "ci_result": null,
  "reverted": false,
  "amended": false
}