{
  "hash": "a75761b0d6f1b388a1b739f54cf3c2ad56e08592",
  "message": "feat: Add export, feedback, and quality-report commands to ML collector",
  "author": "Claude",
  "timestamp": "2025-12-15 11:28:21 +0000",
  "branch": "claude/multi-index-design-DvifZ",
  "files_changed": [
    "scripts/ml_data_collector.py"
  ],
  "insertions": 769,
  "deletions": 7,
  "hunks": [
    {
      "file": "scripts/ml_data_collector.py",
      "function": "Usage:",
      "start_line": 11,
      "lines_added": [
        "    # Analyze data quality",
        "    python scripts/ml_data_collector.py quality-report",
        "",
        "",
        "    # Add feedback to a chat",
        "    python scripts/ml_data_collector.py feedback --chat-id <id> --rating good [--comment \"text\"]",
        "",
        "    # List recent chats and their feedback status",
        "    python scripts/ml_data_collector.py feedback --list [--limit 20]",
        "",
        "    # Export data for training",
        "    python scripts/ml_data_collector.py export --format jsonl --output training_data.jsonl",
        "import shlex"
      ],
      "lines_removed": [],
      "context_before": [
        "",
        "    # Log a chat session",
        "    python scripts/ml_data_collector.py chat --query \"...\" --response \"...\"",
        "",
        "    # Show statistics",
        "    python scripts/ml_data_collector.py stats",
        "",
        "    # Estimate when training is viable",
        "    python scripts/ml_data_collector.py estimate",
        ""
      ],
      "context_after": [
        "    # Generate session handoff document",
        "    python scripts/ml_data_collector.py handoff",
        "\"\"\"",
        "",
        "import json",
        "import os",
        "import subprocess",
        "import hashlib",
        "import re",
        "import tempfile",
        "import uuid",
        "import fcntl",
        "import logging",
        "from datetime import datetime",
        "from pathlib import Path",
        "from typing import Dict, List, Optional, Any",
        "from dataclasses import dataclass, asdict, field",
        "from contextlib import contextmanager",
        ""
      ],
      "change_type": "add"
    },
    {
      "file": "scripts/ml_data_collector.py",
      "function": "COMMIT_SCHEMA = {",
      "start_line": 84,
      "lines_added": [
        "        \"user_feedback\": (dict, str, type(None)),  # Can be dict, legacy string, or None"
      ],
      "lines_removed": [],
      "context_before": [
        "    }",
        "}",
        "",
        "CHAT_SCHEMA = {",
        "    \"required\": [\"id\", \"timestamp\", \"session_id\", \"query\", \"response\",",
        "                 \"files_referenced\", \"files_modified\", \"tools_used\"],",
        "    \"types\": {",
        "        \"id\": str, \"timestamp\": str, \"session_id\": str, \"query\": str, \"response\": str,",
        "        \"files_referenced\": list, \"files_modified\": list, \"tools_used\": list,",
        "        \"query_tokens\": int, \"response_tokens\": int,"
      ],
      "context_after": [
        "    }",
        "}",
        "",
        "ACTION_SCHEMA = {",
        "    \"required\": [\"id\", \"timestamp\", \"session_id\", \"action_type\", \"target\"],",
        "    \"types\": {",
        "        \"id\": str, \"timestamp\": str, \"session_id\": str,",
        "        \"action_type\": str, \"target\": str, \"success\": bool,",
        "    }",
        "}"
      ],
      "change_type": "add"
    },
    {
      "file": "scripts/ml_data_collector.py",
      "function": "def find_chat_file(chat_id: str) -> Optional[Path]:",
      "start_line": 270,
      "lines_added": [
        "def add_chat_feedback(",
        "    chat_id: str,",
        "    rating: str,",
        "    comment: Optional[str] = None,",
        "    force: bool = False",
        ") -> bool:",
        "    \"\"\"Add or update user feedback for a chat entry.",
        "",
        "    Args:",
        "        chat_id: The chat ID to add feedback to.",
        "        rating: Rating value (good, bad, neutral).",
        "        comment: Optional feedback comment.",
        "        force: If True, overwrite existing feedback.",
        "",
        "    Returns:",
        "        True if feedback was added/updated, False if chat not found or already has feedback.",
        "    \"\"\"",
        "    # Validate rating",
        "    valid_ratings = {\"good\", \"bad\", \"neutral\"}",
        "    if rating not in valid_ratings:",
        "        raise ValueError(f\"Invalid rating '{rating}'. Must be one of: {', '.join(valid_ratings)}\")",
        "",
        "    # Find the chat file",
        "    chat_file = find_chat_file(chat_id)",
        "    if not chat_file:",
        "        return False",
        "",
        "    try:",
        "        # Load existing chat data",
        "        with open(chat_file, 'r', encoding='utf-8') as f:",
        "            chat_data = json.load(f)",
        "",
        "        # Check if feedback already exists",
        "        existing_feedback = chat_data.get('user_feedback')",
        "        if existing_feedback and not force:",
        "            # Check if it's a dict (new format) or string (legacy)",
        "            if isinstance(existing_feedback, dict):",
        "                return False",
        "            # Legacy string format - allow upgrade to dict format",
        "",
        "        # Add feedback",
        "        chat_data['user_feedback'] = {",
        "            'rating': rating,",
        "            'comment': comment,",
        "            'timestamp': datetime.now().isoformat(),",
        "        }",
        "",
        "        # Save atomically",
        "        atomic_write_json(chat_file, chat_data)",
        "        return True",
        "",
        "    except (json.JSONDecodeError, IOError) as e:",
        "        logger.error(f\"Error updating chat feedback: {e}\")",
        "        return False",
        "",
        "",
        "def list_chats_needing_feedback(limit: int = 10) -> List[Dict[str, Any]]:",
        "    \"\"\"List recent chats that don't have feedback yet.",
        "",
        "    Args:",
        "        limit: Maximum number of chats to return.",
        "",
        "    Returns:",
        "        List of chat info dicts with id, timestamp, query preview, and has_feedback status.",
        "    \"\"\"",
        "    if not CHATS_DIR.exists():",
        "        return []",
        "",
        "    chats = []",
        "",
        "    # Iterate through date directories in reverse order (most recent first)",
        "    date_dirs = sorted(CHATS_DIR.iterdir(), reverse=True)",
        "    for date_dir in date_dirs:",
        "        if not date_dir.is_dir():",
        "            continue",
        "",
        "        # Get all chat files in this date directory",
        "        chat_files = sorted(date_dir.glob(\"*.json\"), key=lambda f: f.stat().st_mtime, reverse=True)",
        "",
        "        for chat_file in chat_files:",
        "            if len(chats) >= limit:",
        "                break",
        "",
        "            try:",
        "                with open(chat_file, 'r', encoding='utf-8') as f:",
        "                    chat_data = json.load(f)",
        "",
        "                # Check if chat has feedback",
        "                feedback = chat_data.get('user_feedback')",
        "                has_feedback = False",
        "                feedback_rating = None",
        "",
        "                if feedback:",
        "                    if isinstance(feedback, dict):",
        "                        has_feedback = True",
        "                        feedback_rating = feedback.get('rating')",
        "                    elif isinstance(feedback, str):",
        "                        # Legacy string format",
        "                        has_feedback = True",
        "                        feedback_rating = feedback",
        "",
        "                chat_info = {",
        "                    'id': chat_data.get('id', 'unknown'),",
        "                    'timestamp': chat_data.get('timestamp', ''),",
        "                    'query': chat_data.get('query', '')[:100],  # First 100 chars",
        "                    'has_feedback': has_feedback,",
        "                    'feedback_rating': feedback_rating,",
        "                    'session_id': chat_data.get('session_id', ''),",
        "                }",
        "                chats.append(chat_info)",
        "",
        "            except (json.JSONDecodeError, IOError) as e:",
        "                logger.warning(f\"Error reading chat {chat_file}: {e}\")",
        "                continue",
        "",
        "        if len(chats) >= limit:",
        "            break",
        "",
        "    return chats",
        "",
        ""
      ],
      "lines_removed": [],
      "context_before": [
        "    # Chat files are organized by date",
        "    for date_dir in CHATS_DIR.iterdir():",
        "        if date_dir.is_dir():",
        "            chat_file = date_dir / f\"{chat_id}.json\"",
        "            if chat_file.exists():",
        "                return chat_file",
        "",
        "    return None",
        "",
        ""
      ],
      "context_after": [
        "def end_session(summary: Optional[str] = None) -> Optional[Dict]:",
        "    \"\"\"End the current session and archive it.",
        "",
        "    Args:",
        "        summary: Optional summary of what was accomplished.",
        "",
        "    Returns:",
        "        The ended session data or None if no session.",
        "    \"\"\"",
        "    session = get_current_session()"
      ],
      "change_type": "add"
    },
    {
      "file": "scripts/ml_data_collector.py",
      "function": "def extract_files_from_tool_inputs(tool_inputs: List[Dict]) -> tuple:",
      "start_line": 682,
      "lines_added": [
        "        elif tool == 'NotebookEdit':",
        "            # NotebookEdit modifies notebooks",
        "            path = inp.get('notebook_path', '')",
        "            if path:",
        "                files_modified.add(path)",
        "",
        "",
        "            # Common file extensions to track",
        "            FILE_EXTENSIONS = (",
        "                '.py', '.md', '.json', '.yaml', '.yml', '.toml', '.ini', '.cfg',",
        "                '.txt', '.rst', '.sh', '.bash', '.zsh',",
        "                '.js', '.ts', '.jsx', '.tsx', '.mjs', '.cjs',",
        "                '.html', '.css', '.scss', '.less',",
        "                '.c', '.cpp', '.h', '.hpp', '.cc',",
        "                '.java', '.kt', '.scala',",
        "                '.go', '.rs', '.rb', '.php', '.pl',",
        "                '.sql', '.graphql',",
        "                '.xml', '.csv', '.env',",
        "                '.dockerfile', 'Dockerfile', 'Makefile', 'Jenkinsfile'",
        "            )",
        "",
        "            # Use shlex.split() for safer parsing (handles quoted paths)",
        "            try:",
        "                words = shlex.split(cmd)",
        "            except ValueError:",
        "                # Fallback to simple split if shlex fails",
        "                words = cmd.split()",
        "",
        "            for word in words:",
        "                # Strip quotes that might remain",
        "                word = word.strip('\\'\"')",
        "",
        "                # Skip flags/options",
        "                if word.startswith('-'):",
        "                    # But check if it's a flag with a value like --cov=\"file.py\"",
        "                    if '=' in word:",
        "                        # Extract the value part after =",
        "                        _, value = word.split('=', 1)",
        "                        value = value.strip('\\'\"')",
        "                        if any(value.endswith(ext) for ext in FILE_EXTENSIONS):",
        "                            files_referenced.add(value)",
        "                    continue",
        "",
        "                # Check if it ends with a tracked extension",
        "                if any(word.endswith(ext) for ext in FILE_EXTENSIONS):",
        "                    files_referenced.add(word)",
        "                # Also catch special files without extensions (case-insensitive)",
        "                elif any(word.lower().endswith(name.lower()) for name in ('Dockerfile', 'Makefile', 'Jenkinsfile')):",
        "                    files_referenced.add(word)"
      ],
      "lines_removed": [
        "            # Simple heuristic: look for paths",
        "            for word in cmd.split():",
        "                if '/' in word and not word.startswith('-'):",
        "                    if word.endswith('.py') or word.endswith('.md') or word.endswith('.json'):",
        "                        files_referenced.add(word)"
      ],
      "context_before": [
        "        if tool == 'Read':",
        "            path = inp.get('file_path', '')",
        "            if path:",
        "                files_referenced.add(path)",
        "",
        "        elif tool in ('Edit', 'Write', 'MultiEdit'):",
        "            path = inp.get('file_path', '')",
        "            if path:",
        "                files_modified.add(path)",
        ""
      ],
      "context_after": [
        "        elif tool == 'Bash':",
        "            # Try to extract file paths from command",
        "            cmd = inp.get('command', '')",
        "",
        "        elif tool == 'Glob':",
        "            path = inp.get('path', '')",
        "            if path:",
        "                files_referenced.add(path)",
        "",
        "        elif tool == 'Grep':",
        "            path = inp.get('path', '')",
        "            if path:",
        "                files_referenced.add(path)"
      ],
      "change_type": "modify"
    },
    {
      "file": "scripts/ml_data_collector.py",
      "function": "def log_action(",
      "start_line": 1262,
      "lines_added": [
        "# ============================================================================",
        "# DATA EXPORT FOR TRAINING",
        "# ============================================================================",
        "",
        "def _summarize_diff(hunks: List[Dict]) -> str:",
        "    \"\"\"Summarize diff hunks into a concise description for training.\"\"\"",
        "    if not hunks:",
        "        return \"\"",
        "",
        "    # Group by file",
        "    files = {}",
        "    for hunk in hunks:",
        "        file = hunk.get('file', 'unknown')",
        "        if file not in files:",
        "            files[file] = {'add': 0, 'delete': 0, 'modify': 0}",
        "        change_type = hunk.get('change_type', 'modify')",
        "        files[file][change_type] = files[file].get(change_type, 0) + 1",
        "",
        "    # Create summary",
        "    parts = []",
        "    for file, changes in files.items():",
        "        change_desc = []",
        "        if changes['add'] > 0:",
        "            change_desc.append(f\"+{changes['add']}\")",
        "        if changes['delete'] > 0:",
        "            change_desc.append(f\"-{changes['delete']}\")",
        "        if changes['modify'] > 0:",
        "            change_desc.append(f\"~{changes['modify']}\")",
        "        parts.append(f\"{file}: {' '.join(change_desc)}\")",
        "",
        "    return '; '.join(parts[:10])  # Limit to first 10 files",
        "",
        "",
        "def _export_jsonl(records: List[Dict], output_path: Path):",
        "    \"\"\"Export records as JSONL (one JSON per line).\"\"\"",
        "    with open(output_path, 'w', encoding='utf-8') as f:",
        "        for record in records:",
        "            f.write(json.dumps(record, ensure_ascii=False) + '\\n')",
        "",
        "",
        "def _export_csv(records: List[Dict], output_path: Path):",
        "    \"\"\"Export records as CSV.\"\"\"",
        "    import csv",
        "",
        "    with open(output_path, 'w', encoding='utf-8', newline='') as f:",
        "        writer = csv.DictWriter(f, fieldnames=[",
        "            'type', 'timestamp', 'input', 'output',",
        "            'session_id', 'files', 'tools_used'",
        "        ])",
        "        writer.writeheader()",
        "",
        "        for record in records:",
        "            context = record.get('context', {})",
        "            row = {",
        "                'type': record.get('type', ''),",
        "                'timestamp': record.get('timestamp', ''),",
        "                'input': record.get('input', '')[:1000],  # Truncate for CSV",
        "                'output': record.get('output', '')[:1000],",
        "                'session_id': context.get('session_id', ''),",
        "                'files': '; '.join(context.get('files', []))[:500],",
        "                'tools_used': '; '.join(context.get('tools_used', [])),",
        "            }",
        "            writer.writerow(row)",
        "",
        "",
        "def _export_huggingface(records: List[Dict], output_path: Path):",
        "    \"\"\"Export records in HuggingFace Dataset dict format.\"\"\"",
        "    # HuggingFace datasets format: dict of lists",
        "    dataset = {",
        "        'type': [],",
        "        'timestamp': [],",
        "        'input': [],",
        "        'output': [],",
        "        'session_id': [],",
        "        'files': [],",
        "        'tools_used': [],",
        "    }",
        "",
        "    for record in records:",
        "        context = record.get('context', {})",
        "        dataset['type'].append(record.get('type', ''))",
        "        dataset['timestamp'].append(record.get('timestamp', ''))",
        "        dataset['input'].append(record.get('input', ''))",
        "        dataset['output'].append(record.get('output', ''))",
        "        dataset['session_id'].append(context.get('session_id', ''))",
        "        dataset['files'].append(context.get('files', []))",
        "        dataset['tools_used'].append(context.get('tools_used', []))",
        "",
        "    # Save as JSON in HuggingFace format",
        "    with open(output_path, 'w', encoding='utf-8') as f:",
        "        json.dump(dataset, f, indent=2, ensure_ascii=False)",
        "",
        "",
        "def export_data(format: str, output_path: Path) -> Dict[str, Any]:",
        "    \"\"\"Export collected ML data in training-ready formats.",
        "",
        "    Args:",
        "        format: Output format (jsonl, csv, huggingface)",
        "        output_path: Path to write the exported data",
        "",
        "    Returns:",
        "        Stats dict with counts and file paths",
        "",
        "    Raises:",
        "        ValueError: If format is invalid",
        "    \"\"\"",
        "    ensure_dirs()",
        "",
        "    # Collect all data",
        "    all_records = []",
        "",
        "    # Load commits",
        "    if COMMITS_DIR.exists():",
        "        for commit_file in COMMITS_DIR.glob(\"*.json\"):",
        "            try:",
        "                with open(commit_file, 'r', encoding='utf-8') as f:",
        "                    commit_data = json.load(f)",
        "",
        "                # Transform commit to training format",
        "                record = {",
        "                    \"type\": \"commit\",",
        "                    \"timestamp\": commit_data.get('timestamp', ''),",
        "                    \"input\": commit_data.get('message', ''),",
        "                    \"output\": _summarize_diff(commit_data.get('hunks', [])),",
        "                    \"context\": {",
        "                        \"files\": commit_data.get('files_changed', []),",
        "                        \"session_id\": commit_data.get('session_id', ''),",
        "                        \"tools_used\": [],",
        "                        \"insertions\": commit_data.get('insertions', 0),",
        "                        \"deletions\": commit_data.get('deletions', 0),",
        "                        \"branch\": commit_data.get('branch', ''),",
        "                    }",
        "                }",
        "                all_records.append(record)",
        "            except (json.JSONDecodeError, IOError) as e:",
        "                logger.warning(f\"Error reading commit {commit_file}: {e}\")",
        "",
        "    # Load chats",
        "    if CHATS_DIR.exists():",
        "        for chat_file in CHATS_DIR.glob(\"**/*.json\"):",
        "            try:",
        "                with open(chat_file, 'r', encoding='utf-8') as f:",
        "                    chat_data = json.load(f)",
        "",
        "                record = {",
        "                    \"type\": \"chat\",",
        "                    \"timestamp\": chat_data.get('timestamp', ''),",
        "                    \"input\": chat_data.get('query', ''),",
        "                    \"output\": chat_data.get('response', ''),",
        "                    \"context\": {",
        "                        \"files\": chat_data.get('files_referenced', []) + chat_data.get('files_modified', []),",
        "                        \"session_id\": chat_data.get('session_id', ''),",
        "                        \"tools_used\": chat_data.get('tools_used', []),",
        "                    }",
        "                }",
        "                all_records.append(record)",
        "            except (json.JSONDecodeError, IOError) as e:",
        "                logger.warning(f\"Error reading chat {chat_file}: {e}\")",
        "",
        "    # Sort by timestamp",
        "    all_records.sort(key=lambda r: r['timestamp'])",
        "",
        "    # Export based on format",
        "    output_path = Path(output_path)",
        "    output_path.parent.mkdir(parents=True, exist_ok=True)",
        "",
        "    if format == \"jsonl\":",
        "        _export_jsonl(all_records, output_path)",
        "    elif format == \"csv\":",
        "        _export_csv(all_records, output_path)",
        "    elif format == \"huggingface\":",
        "        _export_huggingface(all_records, output_path)",
        "    else:",
        "        raise ValueError(f\"Unknown format: {format}\")",
        "",
        "    return {",
        "        \"format\": format,",
        "        \"output_path\": str(output_path),",
        "        \"records\": len(all_records),",
        "        \"commits\": sum(1 for r in all_records if r['type'] == 'commit'),",
        "        \"chats\": sum(1 for r in all_records if r['type'] == 'chat'),",
        "    }",
        "",
        ""
      ],
      "lines_removed": [],
      "context_before": [
        "        target=target,",
        "        context=context or {},",
        "        success=success,",
        "        result_summary=result_summary,",
        "    )",
        "",
        "    save_action(entry)",
        "    return entry",
        "",
        ""
      ],
      "context_after": [
        "# ============================================================================",
        "# STATISTICS AND ESTIMATION",
        "# ============================================================================",
        "",
        "def count_data() -> Dict[str, int]:",
        "    \"\"\"Count collected data entries.\"\"\"",
        "    ensure_dirs()",
        "",
        "    counts = {",
        "        \"commits\": 0,"
      ],
      "change_type": "add"
    },
    {
      "file": "scripts/ml_data_collector.py",
      "function": "def estimate_project_size():",
      "start_line": 1436,
      "lines_added": [
        "# ============================================================================",
        "# DATA QUALITY ANALYSIS",
        "# ============================================================================",
        "",
        "def analyze_data_quality() -> Dict[str, Any]:",
        "    \"\"\"Analyze data quality across all collected ML data.",
        "",
        "    Returns:",
        "        Dictionary with completeness, diversity, anomalies, and quality score.",
        "    \"\"\"",
        "    ensure_dirs()",
        "",
        "    # Initialize metrics containers",
        "    completeness = {",
        "        'chats_complete': 0,",
        "        'chats_total': 0,",
        "        'commits_with_ci': 0,",
        "        'commits_total': 0,",
        "        'sessions_with_commits': 0,",
        "        'sessions_total': 0,",
        "        'chats_with_feedback': 0,",
        "    }",
        "",
        "    diversity = {",
        "        'unique_files': set(),",
        "        'unique_tools': {},",
        "        'query_lengths': [],",
        "        'response_lengths': [],",
        "    }",
        "",
        "    anomalies = {",
        "        'empty_responses': 0,",
        "        'zero_file_commits': 0,",
        "        'empty_sessions': 0,",
        "        'potential_duplicates': 0,",
        "    }",
        "",
        "    # Track duplicates (timestamp + content hash)",
        "    seen_entries = set()",
        "",
        "    # Analyze commits",
        "    if COMMITS_DIR.exists():",
        "        for commit_file in COMMITS_DIR.glob(\"*.json\"):",
        "            try:",
        "                with open(commit_file, 'r', encoding='utf-8') as f:",
        "                    data = json.load(f)",
        "",
        "                completeness['commits_total'] += 1",
        "",
        "                # Check CI results",
        "                if data.get('ci_result'):",
        "                    completeness['commits_with_ci'] += 1",
        "",
        "                # Track files",
        "                diversity['unique_files'].update(data.get('files_changed', []))",
        "",
        "                # Check anomalies",
        "                if not data.get('files_changed'):",
        "                    anomalies['zero_file_commits'] += 1",
        "",
        "                # Check duplicates (timestamp + message hash)",
        "                entry_key = (data.get('timestamp', ''),",
        "                           hashlib.md5(data.get('message', '').encode()).hexdigest()[:8])",
        "                if entry_key in seen_entries:",
        "                    anomalies['potential_duplicates'] += 1",
        "                else:",
        "                    seen_entries.add(entry_key)",
        "",
        "            except (json.JSONDecodeError, IOError):",
        "                continue",
        "",
        "    # Analyze chats",
        "    if CHATS_DIR.exists():",
        "        for chat_file in CHATS_DIR.glob(\"**/*.json\"):",
        "            try:",
        "                with open(chat_file, 'r', encoding='utf-8') as f:",
        "                    data = json.load(f)",
        "",
        "                completeness['chats_total'] += 1",
        "",
        "                # Check completeness (all required fields from CHAT_SCHEMA)",
        "                errors = validate_schema(data, CHAT_SCHEMA, \"chat\")",
        "                if not errors:",
        "                    completeness['chats_complete'] += 1",
        "",
        "                # Check feedback",
        "                if data.get('user_feedback'):",
        "                    completeness['chats_with_feedback'] += 1",
        "",
        "                # Track diversity",
        "                diversity['unique_files'].update(data.get('files_referenced', []))",
        "                diversity['unique_files'].update(data.get('files_modified', []))",
        "",
        "                for tool in data.get('tools_used', []):",
        "                    diversity['unique_tools'][tool] = diversity['unique_tools'].get(tool, 0) + 1",
        "",
        "                query = data.get('query', '')",
        "                response = data.get('response', '')",
        "",
        "                diversity['query_lengths'].append(len(query))",
        "                diversity['response_lengths'].append(len(response))",
        "",
        "                # Check anomalies",
        "                if not response or len(response.strip()) == 0:",
        "                    anomalies['empty_responses'] += 1",
        "",
        "                # Check duplicates (timestamp + query hash)",
        "                entry_key = (data.get('timestamp', ''),",
        "                           hashlib.md5(query.encode()).hexdigest()[:8])",
        "                if entry_key in seen_entries:",
        "                    anomalies['potential_duplicates'] += 1",
        "                else:",
        "                    seen_entries.add(entry_key)",
        "",
        "            except (json.JSONDecodeError, IOError):",
        "                continue",
        "",
        "    # Analyze sessions",
        "    if SESSIONS_DIR.exists():",
        "        for session_file in SESSIONS_DIR.glob(\"*.json\"):",
        "            try:",
        "                with open(session_file, 'r', encoding='utf-8') as f:",
        "                    data = json.load(f)",
        "",
        "                completeness['sessions_total'] += 1",
        "",
        "                # Check if session has chats",
        "                if not data.get('chat_ids'):",
        "                    anomalies['empty_sessions'] += 1",
        "",
        "            except (json.JSONDecodeError, IOError):",
        "                continue",
        "",
        "    # Count sessions with commits by checking commits with session_id",
        "    session_ids_with_commits = set()",
        "    if COMMITS_DIR.exists():",
        "        for commit_file in COMMITS_DIR.glob(\"*.json\"):",
        "            try:",
        "                with open(commit_file, 'r', encoding='utf-8') as f:",
        "                    data = json.load(f)",
        "                    session_id = data.get('session_id')",
        "                    if session_id:",
        "                        session_ids_with_commits.add(session_id)",
        "            except (json.JSONDecodeError, IOError):",
        "                continue",
        "",
        "    completeness['sessions_with_commits'] = len(session_ids_with_commits)",
        "",
        "    # Calculate percentages for completeness",
        "    completeness_metrics = {",
        "        'chats_complete_pct': (completeness['chats_complete'] / max(1, completeness['chats_total'])) * 100,",
        "        'commits_with_ci_pct': (completeness['commits_with_ci'] / max(1, completeness['commits_total'])) * 100,",
        "        'sessions_with_commits_pct': (completeness['sessions_with_commits'] / max(1, completeness['sessions_total'])) * 100,",
        "        'chats_with_feedback_pct': (completeness['chats_with_feedback'] / max(1, completeness['chats_total'])) * 100,",
        "    }",
        "",
        "    # Calculate diversity statistics",
        "    diversity_stats = {",
        "        'unique_files': len(diversity['unique_files']),",
        "        'unique_tools': len(diversity['unique_tools']),",
        "        'tool_distribution': diversity['unique_tools'],",
        "        'query_length_min': min(diversity['query_lengths']) if diversity['query_lengths'] else 0,",
        "        'query_length_avg': sum(diversity['query_lengths']) / max(1, len(diversity['query_lengths'])) if diversity['query_lengths'] else 0,",
        "        'query_length_max': max(diversity['query_lengths']) if diversity['query_lengths'] else 0,",
        "        'response_length_min': min(diversity['response_lengths']) if diversity['response_lengths'] else 0,",
        "        'response_length_avg': sum(diversity['response_lengths']) / max(1, len(diversity['response_lengths'])) if diversity['response_lengths'] else 0,",
        "        'response_length_max': max(diversity['response_lengths']) if diversity['response_lengths'] else 0,",
        "    }",
        "",
        "    # Calculate quality score (0-100)",
        "    # Weighted components:",
        "    # - Completeness: 40%",
        "    # - Low anomalies: 30%",
        "    # - Diversity: 30%",
        "",
        "    # Completeness score (average of all completeness metrics)",
        "    completeness_score = (",
        "        completeness_metrics['chats_complete_pct'] * 0.4 +",
        "        completeness_metrics['commits_with_ci_pct'] * 0.2 +",
        "        completeness_metrics['sessions_with_commits_pct'] * 0.3 +",
        "        completeness_metrics['chats_with_feedback_pct'] * 0.1",
        "    )",
        "",
        "    # Anomaly score (penalize based on anomaly percentage)",
        "    total_entries = completeness['chats_total'] + completeness['commits_total'] + completeness['sessions_total']",
        "    total_anomalies = (anomalies['empty_responses'] + anomalies['zero_file_commits'] +",
        "                      anomalies['empty_sessions'] + anomalies['potential_duplicates'])",
        "    anomaly_rate = total_anomalies / max(1, total_entries)",
        "    anomaly_score = max(0, 100 - (anomaly_rate * 200))  # Cap at 0, scale anomalies harshly",
        "",
        "    # Diversity score (based on having diverse tools and files)",
        "    # Good diversity: >5 tools, >50 files = 100%, scale down from there",
        "    tool_score = min(100, (diversity_stats['unique_tools'] / 5.0) * 100)",
        "    file_score = min(100, (diversity_stats['unique_files'] / 50.0) * 100)",
        "    diversity_score = (tool_score + file_score) / 2",
        "",
        "    # Overall quality score",
        "    quality_score = int(",
        "        completeness_score * 0.4 +",
        "        anomaly_score * 0.3 +",
        "        diversity_score * 0.3",
        "    )",
        "",
        "    return {",
        "        'completeness': {",
        "            'chats_complete': completeness['chats_complete'],",
        "            'chats_total': completeness['chats_total'],",
        "            'chats_complete_pct': completeness_metrics['chats_complete_pct'],",
        "            'commits_with_ci': completeness['commits_with_ci'],",
        "            'commits_total': completeness['commits_total'],",
        "            'commits_with_ci_pct': completeness_metrics['commits_with_ci_pct'],",
        "            'sessions_with_commits': completeness['sessions_with_commits'],",
        "            'sessions_total': completeness['sessions_total'],",
        "            'sessions_with_commits_pct': completeness_metrics['sessions_with_commits_pct'],",
        "            'chats_with_feedback': completeness['chats_with_feedback'],",
        "            'chats_with_feedback_pct': completeness_metrics['chats_with_feedback_pct'],",
        "        },",
        "        'diversity': diversity_stats,",
        "        'anomalies': anomalies,",
        "        'quality_score': quality_score,",
        "    }",
        "",
        "",
        "def print_quality_report():",
        "    \"\"\"Print a comprehensive data quality report.\"\"\"",
        "    result = analyze_data_quality()",
        "",
        "    comp = result['completeness']",
        "    div = result['diversity']",
        "    anom = result['anomalies']",
        "    score = result['quality_score']",
        "",
        "    print(\"\\n\" + \"=\" * 60)",
        "    print(\"DATA QUALITY REPORT\")",
        "    print(\"=\" * 60)",
        "",
        "    print(\"\\nüìä Completeness:\")",
        "    print(f\"   Chats with all fields:    {comp['chats_complete_pct']:>3.0f}% ({comp['chats_complete']}/{comp['chats_total']})\")",
        "    print(f\"   Commits with CI results:  {comp['commits_with_ci_pct']:>3.0f}% ({comp['commits_with_ci']}/{comp['commits_total']})\")",
        "    print(f\"   Sessions with commits:    {comp['sessions_with_commits_pct']:>3.0f}% ({comp['sessions_with_commits']}/{comp['sessions_total']})\")",
        "    print(f\"   Chats with feedback:      {comp['chats_with_feedback_pct']:>3.0f}% ({comp['chats_with_feedback']}/{comp['chats_total']})\")",
        "",
        "    print(\"\\nüìà Diversity:\")",
        "    print(f\"   Unique files:             {div['unique_files']}\")",
        "    print(f\"   Unique tools:             {div['unique_tools']}\")",
        "    if div['tool_distribution']:",
        "        print(\"   Tool usage:\")",
        "        for tool, count in sorted(div['tool_distribution'].items(), key=lambda x: -x[1])[:8]:",
        "            print(f\"      {tool}: {count}\")",
        "        if len(div['tool_distribution']) > 8:",
        "            print(f\"      ... and {len(div['tool_distribution']) - 8} more\")",
        "    print(f\"   Query length:             min={div['query_length_min']}, avg={div['query_length_avg']:.0f}, max={div['query_length_max']} chars\")",
        "    print(f\"   Response length:          min={div['response_length_min']}, avg={div['response_length_avg']:.0f}, max={div['response_length_max']} chars\")",
        "",
        "    print(\"\\n‚ö†Ô∏è  Anomalies:\")",
        "    print(f\"   Empty responses:          {anom['empty_responses']}\")",
        "    print(f\"   Zero-file commits:        {anom['zero_file_commits']}\")",
        "    print(f\"   Empty sessions:           {anom['empty_sessions']}\")",
        "    print(f\"   Potential duplicates:     {anom['potential_duplicates']}\")",
        "",
        "    print(f\"\\nüéØ Quality Score: {score}/100\")",
        "    print(\"=\" * 60 + \"\\n\")",
        "",
        ""
      ],
      "lines_removed": [],
      "context_before": [
        "    days_for_commits = (target_commits - counts[\"commits\"]) / commits_per_day",
        "    days_for_chats = (target_chats - counts[\"chats\"]) / chats_per_day",
        "",
        "    days_needed = max(days_for_commits, days_for_chats)",
        "    print(f\"   At current rate:     ~{int(days_needed)} days ({int(days_needed/30)} months)\")",
        "    print(f\"   With active use:     ~{int(days_needed * 0.5)} days (more chatting)\")",
        "",
        "    print(\"\\n\" + \"=\" * 60)",
        "",
        ""
      ],
      "context_after": [
        "# ============================================================================",
        "# GIT HOOKS",
        "# ============================================================================",
        "",
        "ML_HOOK_MARKER = \"# ML-DATA-COLLECTOR-HOOK\"",
        "",
        "POST_COMMIT_SNIPPET = '''",
        "# ML-DATA-COLLECTOR-HOOK",
        "# ML Data Collection - Post-Commit Hook",
        "# Automatically collects enriched commit data for model training"
      ],
      "change_type": "add"
    },
    {
      "file": "scripts/ml_data_collector.py",
      "function": "def install_hooks():",
      "start_line": 1507,
      "lines_added": [
        "    # Allow stats/estimate/validate/export/feedback/quality-report even when collection is disabled",
        "    read_only_commands = {\"stats\", \"estimate\", \"validate\", \"session\", \"export\", \"feedback\", \"quality-report\"}"
      ],
      "lines_removed": [
        "    # Allow stats/estimate/validate even when collection is disabled",
        "    read_only_commands = {\"stats\", \"estimate\", \"validate\", \"session\"}"
      ],
      "context_before": [
        "",
        "def main():",
        "    import sys",
        "",
        "    if len(sys.argv) < 2:",
        "        print(__doc__)",
        "        return",
        "",
        "    command = sys.argv[1]",
        ""
      ],
      "context_after": [
        "",
        "    # Check if collection is disabled (via ML_COLLECTION_ENABLED=0)",
        "    if not ML_COLLECTION_ENABLED and command not in read_only_commands:",
        "        # Silently exit for collection commands when disabled",
        "        return",
        "",
        "    if command == \"commit\":",
        "        # Collect data for current or specified commit",
        "        commit_hash = sys.argv[2] if len(sys.argv) > 2 else None",
        "        context = collect_commit_data(commit_hash)"
      ],
      "change_type": "modify"
    },
    {
      "file": "scripts/ml_data_collector.py",
      "function": "def main():",
      "start_line": 1593,
      "lines_added": [
        "    elif command == \"quality-report\":",
        "        print_quality_report()",
        ""
      ],
      "lines_removed": [],
      "context_before": [
        "            session_id=args.session,",
        "        )",
        "        print(f\"Logged action: {entry.id}\")",
        "",
        "    elif command == \"stats\":",
        "        print_stats()",
        "",
        "    elif command == \"estimate\":",
        "        estimate_project_size()",
        ""
      ],
      "context_after": [
        "    elif command == \"install-hooks\":",
        "        install_hooks()",
        "",
        "    elif command == \"validate\":",
        "        # Validate existing data against schemas",
        "        import argparse",
        "        parser = argparse.ArgumentParser()",
        "        parser.add_argument(\"--fix\", action=\"store_true\",",
        "                            help=\"Attempt to fix invalid entries\")",
        "        parser.add_argument(\"--verbose\", \"-v\", action=\"store_true\","
      ],
      "change_type": "add"
    },
    {
      "file": "scripts/ml_data_collector.py",
      "function": "def main():",
      "start_line": 1871,
      "lines_added": [
        "    elif command == \"export\":",
        "        # Export data for training",
        "        import argparse",
        "        parser = argparse.ArgumentParser()",
        "        parser.add_argument(\"--format\", required=True,",
        "                            choices=[\"jsonl\", \"csv\", \"huggingface\"],",
        "                            help=\"Output format\")",
        "        parser.add_argument(\"--output\", required=True,",
        "                            help=\"Output file path\")",
        "        args = parser.parse_args(sys.argv[2:])",
        "",
        "        output_path = Path(args.output)",
        "",
        "        # Validate output path",
        "        if output_path.exists():",
        "            response = input(f\"‚ö†Ô∏è  {output_path} already exists. Overwrite? [y/N] \")",
        "            if response.lower() != 'y':",
        "                print(\"Export cancelled.\")",
        "                sys.exit(0)",
        "",
        "        # Check if we have data to export",
        "        counts = count_data()",
        "        if counts['commits'] == 0 and counts['chats'] == 0:",
        "            print(\"‚ö†Ô∏è  No data to export. Collect some commits and chats first.\")",
        "            sys.exit(1)",
        "",
        "        print(f\"\\n{'='*60}\")",
        "        print(\"EXPORTING ML DATA\")",
        "        print(f\"{'='*60}\")",
        "        print(f\"Format: {args.format}\")",
        "        print(f\"Output: {output_path}\")",
        "        print(f\"Data: {counts['commits']} commits, {counts['chats']} chats\")",
        "        print()",
        "",
        "        try:",
        "            stats = export_data(args.format, output_path)",
        "            print(f\"‚úÖ Export complete!\")",
        "            print(f\"   Records: {stats['records']}\")",
        "            print(f\"   Commits: {stats['commits']}\")",
        "            print(f\"   Chats: {stats['chats']}\")",
        "            print(f\"   File: {stats['output_path']}\")",
        "            print(f\"{'='*60}\\n\")",
        "        except Exception as e:",
        "            print(f\"‚úó Export failed: {e}\")",
        "            sys.exit(1)",
        "",
        "    elif command == \"feedback\":",
        "        # Add or view feedback for chat entries",
        "        import argparse",
        "        parser = argparse.ArgumentParser()",
        "        parser.add_argument(\"--chat-id\",",
        "                            help=\"Chat ID to add feedback to\")",
        "        parser.add_argument(\"--rating\", choices=[\"good\", \"bad\", \"neutral\"],",
        "                            help=\"Feedback rating\")",
        "        parser.add_argument(\"--comment\",",
        "                            help=\"Optional feedback comment\")",
        "        parser.add_argument(\"--force\", action=\"store_true\",",
        "                            help=\"Overwrite existing feedback\")",
        "        parser.add_argument(\"--list\", action=\"store_true\",",
        "                            help=\"List recent chats (showing feedback status)\")",
        "        parser.add_argument(\"--limit\", type=int, default=10,",
        "                            help=\"Number of chats to show (default: 10)\")",
        "        args = parser.parse_args(sys.argv[2:])",
        "",
        "        if args.list:",
        "            # List recent chats and their feedback status",
        "            chats = list_chats_needing_feedback(limit=args.limit)",
        "",
        "            if not chats:",
        "                print(\"No chat entries found.\")",
        "                return",
        "",
        "            print(f\"\\n{'='*60}\")",
        "            print(f\"RECENT CHATS (last {args.limit})\")",
        "            print(f\"{'='*60}\\n\")",
        "",
        "            for chat in chats:",
        "                feedback_status = \"‚úì\" if chat['has_feedback'] else \"‚óã\"",
        "                rating_display = f\" [{chat['feedback_rating']}]\" if chat['feedback_rating'] else \"\"",
        "",
        "                print(f\"{feedback_status} {chat['id']}\")",
        "                print(f\"   Time: {chat['timestamp']}\")",
        "                print(f\"   Query: {chat['query']}\")",
        "                if chat['has_feedback']:",
        "                    print(f\"   Feedback: {chat['feedback_rating']}\")",
        "                print()",
        "",
        "            # Show summary",
        "            with_feedback = sum(1 for c in chats if c['has_feedback'])",
        "            without_feedback = len(chats) - with_feedback",
        "            print(f\"{'='*60}\")",
        "            print(f\"Summary: {with_feedback} with feedback, {without_feedback} without\")",
        "            print(f\"{'='*60}\\n\")",
        "",
        "        else:",
        "            # Add feedback to a specific chat",
        "            if not args.chat_id:",
        "                print(\"Error: --chat-id is required when not using --list\")",
        "                sys.exit(1)",
        "",
        "            if not args.rating:",
        "                print(\"Error: --rating is required when adding feedback\")",
        "                sys.exit(1)",
        "",
        "            try:",
        "                success = add_chat_feedback(",
        "                    chat_id=args.chat_id,",
        "                    rating=args.rating,",
        "                    comment=args.comment,",
        "                    force=args.force",
        "                )",
        "",
        "                if success:",
        "                    print(f\"‚úì Added feedback to chat {args.chat_id}\")",
        "                    print(f\"   Rating: {args.rating}\")",
        "                    if args.comment:",
        "                        print(f\"   Comment: {args.comment}\")",
        "                else:",
        "                    # Check if chat exists or already has feedback",
        "                    chat_file = find_chat_file(args.chat_id)",
        "                    if not chat_file:",
        "                        print(f\"‚úó Chat not found: {args.chat_id}\")",
        "                        sys.exit(1)",
        "                    else:",
        "                        print(f\"‚úó Chat {args.chat_id} already has feedback.\")",
        "                        print(\"   Use --force to overwrite.\")",
        "                        sys.exit(1)",
        "",
        "            except ValueError as e:",
        "                print(f\"‚úó {e}\")",
        "                sys.exit(1)",
        ""
      ],
      "lines_removed": [],
      "context_before": [
        "            print(f\"   Tools used: {', '.join(result.get('tools_used', [])) or 'none'}\")",
        "            print(f\"   Files referenced: {len(result.get('files_referenced', []))}\")",
        "            print(f\"   Files modified: {len(result.get('files_modified', []))}\")",
        "            print(f\"{'='*60}\\n\")",
        "        else:",
        "            # Minimal output for hook usage",
        "            saved = result.get('saved', 0)",
        "            if saved > 0:",
        "                print(f\"üìù ML: Captured {saved} exchange(s) from session\")",
        ""
      ],
      "context_after": [
        "    else:",
        "        print(f\"Unknown command: {command}\")",
        "        print(__doc__)",
        "",
        "",
        "if __name__ == \"__main__\":",
        "    main()"
      ],
      "change_type": "add"
    }
  ],
  "hour_of_day": 11,
  "day_of_week": "Monday",
  "seconds_since_last_commit": -8187,
  "is_merge": false,
  "is_initial": false,
  "parent_count": 1,
  "session_id": null,
  "related_chats": [],
  "ci_result": null,
  "reverted": false,
  "amended": false
}