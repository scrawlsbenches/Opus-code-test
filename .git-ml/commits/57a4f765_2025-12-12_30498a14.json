{
  "hash": "57a4f7654a08ffbeca0e3d09a8587d877aa5bf3a",
  "message": "Optimize test suite: share corpus, skip perf test under coverage",
  "author": "Claude",
  "timestamp": "2025-12-12 11:50:58 +0000",
  "branch": "claude/multi-index-design-DvifZ",
  "files_changed": [
    "tests/test_behavioral.py"
  ],
  "insertions": 31,
  "deletions": 18,
  "hunks": [
    {
      "file": "tests/test_behavioral.py",
      "function": "import os",
      "start_line": 23,
      "lines_added": [
        "# Module-level singleton for shared corpus (load once, reuse everywhere)",
        "_SHARED_PROCESSOR = None",
        "_SHARED_PROCESSOR_LOADED = False",
        "",
        "def get_shared_processor() -> CorticalTextProcessor:",
        "    \"\"\"",
        "    Get or create the shared processor with sample corpus.",
        "    This singleton ensures we only load the corpus once per test run,",
        "    dramatically reducing test time (from 5x compute_all to 1x).",
        "    global _SHARED_PROCESSOR, _SHARED_PROCESSOR_LOADED",
        "",
        "    if _SHARED_PROCESSOR_LOADED:",
        "        return _SHARED_PROCESSOR",
        "",
        "    tokenizer = Tokenizer(filter_code_noise=True)",
        "    _SHARED_PROCESSOR = processor",
        "    _SHARED_PROCESSOR_LOADED = True",
        "        cls.processor = get_shared_processor()"
      ],
      "lines_removed": [
        "def load_sample_corpus(filter_code_noise: bool = True) -> CorticalTextProcessor:",
        "    \"\"\"",
        "    Load the sample corpus for behavioral tests.",
        "    Args:",
        "        filter_code_noise: Filter common code tokens like 'self', 'def'",
        "    Returns:",
        "        Processor loaded with sample corpus and compute_all() run",
        "    tokenizer = Tokenizer(filter_code_noise=filter_code_noise)",
        "                # Use filename without extension as doc_id",
        "        cls.processor = load_sample_corpus()"
      ],
      "context_before": [
        "import sys",
        "import time",
        "import unittest",
        "",
        "sys.path.insert(0, '..')",
        "",
        "from cortical import CorticalTextProcessor, CorticalLayer",
        "from cortical.tokenizer import Tokenizer",
        "",
        ""
      ],
      "context_after": [
        "",
        "",
        "    \"\"\"",
        "    samples_dir = os.path.join(os.path.dirname(__file__), '..', 'samples')",
        "",
        "    processor = CorticalTextProcessor(tokenizer=tokenizer)",
        "",
        "    # Load all sample files",
        "    loaded = 0",
        "    for filename in os.listdir(samples_dir):",
        "        filepath = os.path.join(samples_dir, filename)",
        "        if os.path.isfile(filepath):",
        "            try:",
        "                with open(filepath, 'r', encoding='utf-8') as f:",
        "                    content = f.read()",
        "                doc_id = os.path.splitext(filename)[0]",
        "                processor.process_document(doc_id, content)",
        "                loaded += 1",
        "            except (IOError, UnicodeDecodeError):",
        "                continue",
        "",
        "    if loaded > 0:",
        "        processor.compute_all(verbose=False)",
        "",
        "    return processor",
        "",
        "",
        "class TestSearchBehavior(unittest.TestCase):",
        "    \"\"\"",
        "    Test that search feels relevant to users.",
        "",
        "    These tests verify that:",
        "    - Document names matching queries rank highly",
        "    - Query expansion improves recall without hurting precision",
        "    - Code searches prefer implementations over tests",
        "    \"\"\"",
        "",
        "    @classmethod",
        "    def setUpClass(cls):",
        "        \"\"\"Load corpus once for all search tests.\"\"\"",
        "",
        "    def test_document_name_matches_rank_highly(self):",
        "        \"\"\"",
        "        Query matching document name should return that doc in top 2.",
        "",
        "        User expectation: If I search for \"distributed systems\" and there's",
        "        a document called \"distributed_systems\", it should be in my top results.",
        "",
        "        Regression test for Task #144 (doc_name_boost fix).",
        "        \"\"\""
      ],
      "change_type": "modify"
    },
    {
      "file": "tests/test_behavioral.py",
      "function": "class TestSearchBehavior(unittest.TestCase):",
      "start_line": 179,
      "lines_added": [
        "    @unittest.skipIf(",
        "        'coverage' in sys.modules,",
        "        \"Skipping performance test under coverage (adds ~10x overhead)\"",
        "    )",
        "",
        "        NOTE: Skipped when running under coverage since instrumentation adds",
        "        significant overhead (10x+), making timing unreliable."
      ],
      "lines_removed": [],
      "context_before": [
        "",
        "class TestPerformanceBehavior(unittest.TestCase):",
        "    \"\"\"",
        "    Test that the system feels responsive.",
        "",
        "    These tests verify that:",
        "    - Full analysis completes within reasonable time",
        "    - Individual searches are fast enough for interactive use",
        "    \"\"\"",
        ""
      ],
      "context_after": [
        "    def test_compute_all_under_threshold(self):",
        "        \"\"\"",
        "        Full analysis should complete within reasonable time.",
        "",
        "        User expectation: Processing ~100 documents shouldn't take forever.",
        "        The system should feel responsive, not sluggish.",
        "",
        "        Threshold: 30 seconds for full analysis on ~100 docs",
        "        (Based on Task #142: achieved 14.21s after optimization)",
        "        \"\"\"",
        "        samples_dir = os.path.join(os.path.dirname(__file__), '..', 'samples')",
        "",
        "        tokenizer = Tokenizer(filter_code_noise=True)",
        "        processor = CorticalTextProcessor(tokenizer=tokenizer)",
        "",
        "        # Load documents",
        "        doc_count = 0",
        "        for filename in os.listdir(samples_dir):",
        "            filepath = os.path.join(samples_dir, filename)"
      ],
      "change_type": "add"
    },
    {
      "file": "tests/test_behavioral.py",
      "function": "class TestPerformanceBehavior(unittest.TestCase):",
      "start_line": 213,
      "lines_added": [
        "        # Threshold: 30 seconds for ~100 docs (realistic without coverage)",
        "        # Normal performance is ~14-20s (Task #142)",
        "        max_seconds = 30.0",
        "        processor = get_shared_processor()"
      ],
      "lines_removed": [
        "        # Threshold: 120 seconds for ~100 docs",
        "        # Normal performance is ~14-20s (Task #142), but coverage instrumentation",
        "        # can add ~4-6x overhead, especially with new features like sparse matrix",
        "        # operations. We use 120s to avoid false failures in CI.",
        "        max_seconds = 120.0",
        "        processor = load_sample_corpus()"
      ],
      "context_before": [
        "                    processor.process_document(doc_id, content)",
        "                    doc_count += 1",
        "                except (IOError, UnicodeDecodeError):",
        "                    continue",
        "",
        "        # Time compute_all()",
        "        start = time.perf_counter()",
        "        processor.compute_all(verbose=False)",
        "        elapsed = time.perf_counter() - start",
        ""
      ],
      "context_after": [
        "",
        "        self.assertLess(",
        "            elapsed,",
        "            max_seconds,",
        "            f\"compute_all() took {elapsed:.1f}s for {doc_count} documents. \"",
        "            f\"Should complete under {max_seconds}s. \"",
        "            \"Check for performance regression (Task #142).\"",
        "        )",
        "",
        "    def test_search_is_fast(self):",
        "        \"\"\"",
        "        Single query should return quickly for interactive use.",
        "",
        "        User expectation: Search results should appear almost instantly.",
        "        Waiting several seconds for a search feels broken.",
        "",
        "        Threshold: 500ms per query (generous for CI environments)",
        "        \"\"\"",
        "",
        "        # Test multiple queries",
        "        queries = [",
        "            \"neural networks\",",
        "            \"database design\",",
        "            \"machine learning\",",
        "            \"distributed systems\",",
        "            \"quantum computing\",",
        "        ]",
        ""
      ],
      "change_type": "modify"
    },
    {
      "file": "tests/test_behavioral.py",
      "function": "class TestQualityBehavior(unittest.TestCase):",
      "start_line": 277,
      "lines_added": [
        "        cls.processor = get_shared_processor()"
      ],
      "lines_removed": [
        "        cls.processor = load_sample_corpus()"
      ],
      "context_before": [
        "",
        "    These tests verify that:",
        "    - Important terms identified by PageRank are meaningful, not noise",
        "    - Clustering produces coherent groups",
        "    - Embeddings capture semantic similarity",
        "    \"\"\"",
        "",
        "    @classmethod",
        "    def setUpClass(cls):",
        "        \"\"\"Load corpus once for all quality tests.\"\"\""
      ],
      "context_after": [
        "",
        "    def test_pagerank_surfaces_meaningful_terms(self):",
        "        \"\"\"",
        "        Top PageRank terms should be domain concepts, not noise.",
        "",
        "        User expectation: The most \"important\" terms should be meaningful",
        "        concepts like \"neural\", \"learning\", \"network\" - not Python syntax",
        "        like \"self\", \"def\", or test artifacts like \"assertequal\".",
        "",
        "        Regression test for Task #141 (filter_code_noise)."
      ],
      "change_type": "modify"
    },
    {
      "file": "tests/test_behavioral.py",
      "function": "class TestRobustnessBehavior(unittest.TestCase):",
      "start_line": 427,
      "lines_added": [
        "        cls.processor = get_shared_processor()"
      ],
      "lines_removed": [
        "        cls.processor = load_sample_corpus()"
      ],
      "context_before": [
        "",
        "    These tests verify that:",
        "    - Empty or invalid queries don't crash the system",
        "    - Unknown terms are handled gracefully",
        "    - The system degrades gracefully rather than failing",
        "    \"\"\"",
        "",
        "    @classmethod",
        "    def setUpClass(cls):",
        "        \"\"\"Load corpus once for all robustness tests.\"\"\""
      ],
      "context_after": [
        "",
        "    def test_empty_query_raises_value_error(self):",
        "        \"\"\"",
        "        Empty queries should raise ValueError for explicit error handling.",
        "",
        "        User expectation: Empty queries are invalid input. The system should",
        "        fail explicitly with a clear error message rather than silently",
        "        returning empty results (which could mask bugs in calling code).",
        "",
        "        This is documented behavior - see processor.py find_documents_for_query()"
      ],
      "change_type": "modify"
    }
  ],
  "hour_of_day": 11,
  "day_of_week": "Friday",
  "seconds_since_last_commit": -266030,
  "is_merge": false,
  "is_initial": false,
  "parent_count": 1,
  "session_id": null,
  "related_chats": [],
  "ci_result": null,
  "reverted": false,
  "amended": false
}