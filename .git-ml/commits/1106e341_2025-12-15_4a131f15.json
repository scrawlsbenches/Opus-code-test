{
  "hash": "1106e341ef58ae81b289f0db598bf89f54856710",
  "message": "feat: Add automatic session capture via Claude Code Stop hook",
  "author": "Claude",
  "timestamp": "2025-12-15 10:41:11 +0000",
  "branch": "claude/multi-index-design-DvifZ",
  "files_changed": [
    "CLAUDE.md",
    "scripts/ml-session-capture-hook.sh",
    "scripts/ml_data_collector.py"
  ],
  "insertions": 388,
  "deletions": 1,
  "hunks": [
    {
      "file": "CLAUDE.md",
      "function": "python scripts/ml_data_collector.py backfill -n 100",
      "start_line": 1200,
      "lines_added": [
        "### Automatic Session Capture",
        "",
        "**Zero-friction capture via Claude Code Stop hook:**",
        "",
        "The ML data collector automatically captures complete session transcripts when Claude Code sessions end. This eliminates manual logging entirely.",
        "",
        "**Setup:**",
        "```bash",
        "# Add to ~/.claude/settings.json or project .claude/settings.json:",
        "{",
        "  \"hooks\": {",
        "    \"Stop\": [",
        "      {",
        "        \"type\": \"command\",",
        "        \"command\": \"/path/to/Opus-code-test/scripts/ml-session-capture-hook.sh\"",
        "      }",
        "    ]",
        "  }",
        "}",
        "```",
        "",
        "**What gets captured automatically:**",
        "- Full query/response pairs from the transcript",
        "- All tool uses (Task, Read, Edit, Bash, Grep, etc.)",
        "- Files referenced and modified",
        "- Thinking blocks (if present)",
        "- Session linkage to commits",
        "",
        "**Process transcript manually:**",
        "```bash",
        "# Process a specific transcript file",
        "python scripts/ml_data_collector.py transcript --file /path/to/transcript.jsonl",
        "",
        "# Dry run (show what would be captured without saving)",
        "python scripts/ml_data_collector.py transcript --file /path/to/transcript.jsonl --dry-run --verbose",
        "```",
        "",
        "Data collection is automatic via hooks:",
        "- **Stop hook**: Captures full session transcripts with all exchanges (recommended)"
      ],
      "lines_removed": [
        "Data collection is automatic via git hooks:"
      ],
      "context_before": [
        "",
        "### Disabling Collection",
        "",
        "```bash",
        "# Disable for current session",
        "export ML_COLLECTION_ENABLED=0",
        "",
        "# Stats and validation still work when disabled",
        "```",
        ""
      ],
      "context_after": [
        "### Integration",
        "",
        "- **post-commit**: Captures commit metadata with diff hunks",
        "- **pre-push**: Reports collection stats",
        "",
        "See `.claude/skills/ml-logger/SKILL.md` for detailed logging usage.",
        "",
        "---",
        "",
        "## File Quick Links",
        "",
        "- **Main API**: `cortical/processor.py` - `CorticalTextProcessor` class"
      ],
      "change_type": "modify"
    },
    {
      "file": "scripts/ml-session-capture-hook.sh",
      "function": null,
      "start_line": 0,
      "lines_added": [
        "#!/bin/bash",
        "#",
        "# ML Session Capture Hook for Claude Code",
        "#",
        "# This Stop hook automatically captures session transcripts for ML training.",
        "# It reads the transcript_path from stdin and processes it via ml_data_collector.py",
        "#",
        "# Installation: Add to ~/.claude/settings.json hooks.Stop array",
        "#",
        "",
        "# Read JSON input from stdin",
        "input=$(cat)",
        "",
        "# Check if stop hook is already active (recursion prevention)",
        "stop_hook_active=$(echo \"$input\" | jq -r '.stop_hook_active // \"false\"')",
        "if [[ \"$stop_hook_active\" == \"true\" ]]; then",
        "    exit 0",
        "fi",
        "",
        "# Check if ML collection is disabled",
        "if [[ \"${ML_COLLECTION_ENABLED:-1}\" == \"0\" ]]; then",
        "    exit 0",
        "fi",
        "",
        "# Extract transcript path from input",
        "transcript_path=$(echo \"$input\" | jq -r '.transcript_path // empty')",
        "session_id=$(echo \"$input\" | jq -r '.session_id // empty')",
        "cwd=$(echo \"$input\" | jq -r '.cwd // empty')",
        "",
        "# Bail if no transcript path",
        "if [[ -z \"$transcript_path\" ]] || [[ ! -f \"$transcript_path\" ]]; then",
        "    exit 0",
        "fi",
        "",
        "# Find the ml_data_collector.py script",
        "# Try current working directory first, then the cwd from input",
        "SCRIPT_DIR=\"$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)\"",
        "COLLECTOR=\"\"",
        "",
        "if [[ -f \"${cwd}/scripts/ml_data_collector.py\" ]]; then",
        "    COLLECTOR=\"${cwd}/scripts/ml_data_collector.py\"",
        "elif [[ -f \"${SCRIPT_DIR}/../scripts/ml_data_collector.py\" ]]; then",
        "    COLLECTOR=\"${SCRIPT_DIR}/../scripts/ml_data_collector.py\"",
        "elif [[ -f \"./scripts/ml_data_collector.py\" ]]; then",
        "    COLLECTOR=\"./scripts/ml_data_collector.py\"",
        "fi",
        "",
        "# Only proceed if we found the collector and we're in a project that uses it",
        "if [[ -z \"$COLLECTOR\" ]]; then",
        "    exit 0",
        "fi",
        "",
        "# Check if this project has ML collection enabled (has .git-ml directory or is the right project)",
        "if [[ ! -d \"${cwd}/.git-ml\" ]] && [[ ! -f \"${cwd}/scripts/ml_data_collector.py\" ]]; then",
        "    exit 0",
        "fi",
        "",
        "# Process the transcript",
        "cd \"$cwd\" 2>/dev/null || exit 0",
        "",
        "# Call the transcript processor (suppress errors to not block session end)",
        "python3 \"$COLLECTOR\" transcript \\",
        "    --file \"$transcript_path\" \\",
        "    --session-id \"$session_id\" \\",
        "    2>/dev/null || true",
        "",
        "exit 0"
      ],
      "lines_removed": [],
      "context_before": [],
      "context_after": [],
      "change_type": "add"
    },
    {
      "file": "scripts/ml_data_collector.py",
      "function": "def mark_commit_reverted(commit_hash: str, reverting_commit: Optional[str] = Non",
      "start_line": 389,
      "lines_added": [
        "# ============================================================================",
        "# TRANSCRIPT PARSING (for automatic session capture via Stop hook)",
        "# ============================================================================",
        "",
        "@dataclass",
        "class TranscriptExchange:",
        "    \"\"\"A single query/response exchange extracted from a transcript.\"\"\"",
        "    query: str",
        "    response: str",
        "    tools_used: List[str]",
        "    tool_inputs: List[Dict]",
        "    timestamp: str",
        "    thinking: Optional[str] = None",
        "",
        "",
        "def parse_transcript_jsonl(filepath: Path) -> List[TranscriptExchange]:",
        "    \"\"\"Parse a Claude Code transcript JSONL file into exchanges.",
        "",
        "    The JSONL format has entries with:",
        "    - type: \"user\" or \"assistant\"",
        "    - message.content: string (user) or array of content blocks (assistant)",
        "    - timestamp: ISO timestamp",
        "",
        "    Returns list of TranscriptExchange objects.",
        "    \"\"\"",
        "    if not filepath.exists():",
        "        logger.warning(f\"Transcript file not found: {filepath}\")",
        "        return []",
        "",
        "    exchanges = []",
        "    current_query = None",
        "    current_response_parts = []",
        "    current_tools = []",
        "    current_tool_inputs = []",
        "    current_thinking = None",
        "    current_timestamp = None",
        "",
        "    try:",
        "        with open(filepath, 'r', encoding='utf-8') as f:",
        "            for line in f:",
        "                line = line.strip()",
        "                if not line:",
        "                    continue",
        "",
        "                try:",
        "                    entry = json.loads(line)",
        "                except json.JSONDecodeError:",
        "                    continue",
        "",
        "                entry_type = entry.get('type')",
        "                message = entry.get('message', {})",
        "                timestamp = entry.get('timestamp', '')",
        "",
        "                if entry_type == 'user':",
        "                    # Save previous exchange if we have one",
        "                    if current_query and current_response_parts:",
        "                        exchanges.append(TranscriptExchange(",
        "                            query=current_query,",
        "                            response=' '.join(current_response_parts),",
        "                            tools_used=current_tools,",
        "                            tool_inputs=current_tool_inputs,",
        "                            timestamp=current_timestamp or timestamp,",
        "                            thinking=current_thinking,",
        "                        ))",
        "",
        "                    # Start new exchange",
        "                    content = message.get('content', '')",
        "                    if isinstance(content, str):",
        "                        current_query = content",
        "                    elif isinstance(content, list):",
        "                        # Extract text from content blocks",
        "                        current_query = ' '.join(",
        "                            c.get('text', '') for c in content",
        "                            if c.get('type') == 'text'",
        "                        )",
        "                    current_response_parts = []",
        "                    current_tools = []",
        "                    current_tool_inputs = []",
        "                    current_thinking = None",
        "                    current_timestamp = timestamp",
        "",
        "                elif entry_type == 'assistant':",
        "                    content = message.get('content', [])",
        "                    if isinstance(content, list):",
        "                        for block in content:",
        "                            block_type = block.get('type')",
        "",
        "                            if block_type == 'text':",
        "                                text = block.get('text', '')",
        "                                if text:",
        "                                    current_response_parts.append(text)",
        "",
        "                            elif block_type == 'thinking':",
        "                                current_thinking = block.get('thinking', '')",
        "",
        "                            elif block_type == 'tool_use':",
        "                                tool_name = block.get('name', '')",
        "                                tool_input = block.get('input', {})",
        "                                if tool_name and tool_name not in current_tools:",
        "                                    current_tools.append(tool_name)",
        "                                current_tool_inputs.append({",
        "                                    'tool': tool_name,",
        "                                    'input': tool_input,",
        "                                })",
        "",
        "        # Don't forget the last exchange",
        "        if current_query and current_response_parts:",
        "            exchanges.append(TranscriptExchange(",
        "                query=current_query,",
        "                response=' '.join(current_response_parts),",
        "                tools_used=current_tools,",
        "                tool_inputs=current_tool_inputs,",
        "                timestamp=current_timestamp or '',",
        "                thinking=current_thinking,",
        "            ))",
        "",
        "    except IOError as e:",
        "        logger.error(f\"Error reading transcript: {e}\")",
        "        return []",
        "",
        "    return exchanges",
        "",
        "",
        "def extract_files_from_tool_inputs(tool_inputs: List[Dict]) -> tuple:",
        "    \"\"\"Extract file references and modifications from tool inputs.",
        "",
        "    Returns (files_referenced, files_modified) tuple.",
        "    \"\"\"",
        "    files_referenced = set()",
        "    files_modified = set()",
        "",
        "    for ti in tool_inputs:",
        "        tool = ti.get('tool', '')",
        "        inp = ti.get('input', {})",
        "",
        "        if tool == 'Read':",
        "            path = inp.get('file_path', '')",
        "            if path:",
        "                files_referenced.add(path)",
        "",
        "        elif tool in ('Edit', 'Write', 'MultiEdit'):",
        "            path = inp.get('file_path', '')",
        "            if path:",
        "                files_modified.add(path)",
        "",
        "        elif tool == 'Bash':",
        "            # Try to extract file paths from command",
        "            cmd = inp.get('command', '')",
        "            # Simple heuristic: look for paths",
        "            for word in cmd.split():",
        "                if '/' in word and not word.startswith('-'):",
        "                    if word.endswith('.py') or word.endswith('.md') or word.endswith('.json'):",
        "                        files_referenced.add(word)",
        "",
        "        elif tool == 'Glob':",
        "            path = inp.get('path', '')",
        "            if path:",
        "                files_referenced.add(path)",
        "",
        "        elif tool == 'Grep':",
        "            path = inp.get('path', '')",
        "            if path:",
        "                files_referenced.add(path)",
        "",
        "    return list(files_referenced), list(files_modified)",
        "",
        "",
        "def process_transcript(",
        "    filepath: Path,",
        "    session_id: Optional[str] = None,",
        "    save_exchanges: bool = True",
        ") -> Dict[str, Any]:",
        "    \"\"\"Process a transcript file and optionally save exchanges.",
        "",
        "    Args:",
        "        filepath: Path to the JSONL transcript",
        "        session_id: Optional session ID to use (extracted from transcript if not provided)",
        "        save_exchanges: Whether to save exchanges to .git-ml/chats/",
        "",
        "    Returns:",
        "        Summary dict with counts and extracted data.",
        "    \"\"\"",
        "    exchanges = parse_transcript_jsonl(filepath)",
        "",
        "    if not exchanges:",
        "        return {'status': 'empty', 'exchanges': 0}",
        "",
        "    # Use provided session_id or generate one",
        "    if not session_id:",
        "        session_id = generate_session_id()",
        "",
        "    saved_count = 0",
        "    total_tools = set()",
        "    all_files_ref = set()",
        "    all_files_mod = set()",
        "",
        "    for ex in exchanges:",
        "        files_ref, files_mod = extract_files_from_tool_inputs(ex.tool_inputs)",
        "        all_files_ref.update(files_ref)",
        "        all_files_mod.update(files_mod)",
        "        total_tools.update(ex.tools_used)",
        "",
        "        if save_exchanges:",
        "            try:",
        "                entry = ChatEntry(",
        "                    id=generate_chat_id(),",
        "                    timestamp=ex.timestamp or datetime.now().isoformat(),",
        "                    session_id=session_id,",
        "                    query=ex.query[:10000],  # Limit query length",
        "                    response=ex.response[:50000],  # Limit response length",
        "                    files_referenced=files_ref,",
        "                    files_modified=files_mod,",
        "                    tools_used=ex.tools_used,",
        "                    query_tokens=len(ex.query.split()),",
        "                    response_tokens=len(ex.response.split()),",
        "                )",
        "                save_chat_entry(entry, validate=True)",
        "                add_chat_to_session(entry.id)",
        "                saved_count += 1",
        "            except Exception as e:",
        "                logger.error(f\"Error saving exchange: {e}\")",
        "",
        "    return {",
        "        'status': 'success',",
        "        'exchanges': len(exchanges),",
        "        'saved': saved_count,",
        "        'session_id': session_id,",
        "        'tools_used': list(total_tools),",
        "        'files_referenced': list(all_files_ref),",
        "        'files_modified': list(all_files_mod),",
        "    }",
        "",
        ""
      ],
      "lines_removed": [],
      "context_before": [
        "            data['reverted_by'] = reverting_commit",
        "        data['reverted_at'] = datetime.now().isoformat()",
        "",
        "        atomic_write_json(commit_file, data)",
        "        return True",
        "",
        "    except (json.JSONDecodeError, IOError):",
        "        return False",
        "",
        ""
      ],
      "context_after": [
        "# ============================================================================",
        "# DATA SCHEMAS",
        "# ============================================================================",
        "",
        "@dataclass",
        "class DiffHunk:",
        "    \"\"\"A single diff hunk from a commit.\"\"\"",
        "    file: str",
        "    function: Optional[str]  # Function/class containing the change",
        "    change_type: str  # add, modify, delete, rename"
      ],
      "change_type": "add"
    },
    {
      "file": "scripts/ml_data_collector.py",
      "function": "def main():",
      "start_line": 1436,
      "lines_added": [
        "    elif command == \"transcript\":",
        "        # Process a Claude Code transcript file (called by Stop hook)",
        "        import argparse",
        "        parser = argparse.ArgumentParser()",
        "        parser.add_argument(\"--file\", \"-f\", required=True,",
        "                            help=\"Path to transcript JSONL file\")",
        "        parser.add_argument(\"--session-id\",",
        "                            help=\"Session ID to use (auto-generated if not provided)\")",
        "        parser.add_argument(\"--dry-run\", action=\"store_true\",",
        "                            help=\"Parse and show stats without saving\")",
        "        parser.add_argument(\"--verbose\", \"-v\", action=\"store_true\",",
        "                            help=\"Show detailed output\")",
        "        args = parser.parse_args(sys.argv[2:])",
        "",
        "        filepath = Path(args.file)",
        "        if not filepath.exists():",
        "            print(f\"âœ— Transcript file not found: {filepath}\")",
        "            sys.exit(1)",
        "",
        "        if args.verbose:",
        "            print(f\"\\n{'='*60}\")",
        "            print(\"PROCESSING CLAUDE CODE TRANSCRIPT\")",
        "            print(f\"{'='*60}\")",
        "            print(f\"File: {filepath}\")",
        "            print(f\"Size: {filepath.stat().st_size / 1024:.1f} KB\")",
        "",
        "        # Process the transcript",
        "        result = process_transcript(",
        "            filepath,",
        "            session_id=args.session_id,",
        "            save_exchanges=not args.dry_run",
        "        )",
        "",
        "        if args.verbose or args.dry_run:",
        "            print(f\"\\nğŸ“Š Transcript Analysis:\")",
        "            print(f\"   Exchanges found: {result.get('exchanges', 0)}\")",
        "            if not args.dry_run:",
        "                print(f\"   Exchanges saved: {result.get('saved', 0)}\")",
        "            print(f\"   Session ID: {result.get('session_id', 'N/A')}\")",
        "            print(f\"   Tools used: {', '.join(result.get('tools_used', [])) or 'none'}\")",
        "            print(f\"   Files referenced: {len(result.get('files_referenced', []))}\")",
        "            print(f\"   Files modified: {len(result.get('files_modified', []))}\")",
        "            print(f\"{'='*60}\\n\")",
        "        else:",
        "            # Minimal output for hook usage",
        "            saved = result.get('saved', 0)",
        "            if saved > 0:",
        "                print(f\"ğŸ“ ML: Captured {saved} exchange(s) from session\")",
        ""
      ],
      "lines_removed": [],
      "context_before": [
        "                            help=\"Commit that performed the revert\")",
        "        args = parser.parse_args(sys.argv[2:])",
        "",
        "        success = mark_commit_reverted(args.commit, args.by)",
        "        if success:",
        "            print(f\"âœ“ Marked {args.commit[:8]} as reverted\")",
        "        else:",
        "            print(f\"âœ— Commit not found: {args.commit}\")",
        "            sys.exit(1)",
        ""
      ],
      "context_after": [
        "    else:",
        "        print(f\"Unknown command: {command}\")",
        "        print(__doc__)",
        "",
        "",
        "if __name__ == \"__main__\":",
        "    main()"
      ],
      "change_type": "add"
    }
  ],
  "hour_of_day": 10,
  "day_of_week": "Monday",
  "seconds_since_last_commit": -11017,
  "is_merge": false,
  "is_initial": false,
  "parent_count": 1,
  "session_id": null,
  "related_chats": [],
  "ci_result": null,
  "reverted": false,
  "amended": false
}