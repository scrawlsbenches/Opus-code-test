{
  "hash": "36be3a139d1528bf34d1471776627efb6a52c557",
  "message": "fix: Address audit findings and add documentation",
  "author": "Claude",
  "timestamp": "2025-12-15 05:18:52 +0000",
  "branch": "claude/multi-index-design-DvifZ",
  "files_changed": [
    ".claude/commands/ml-log.md",
    ".claude/commands/ml-stats.md",
    "CLAUDE.md",
    "scripts/ml_data_collector.py"
  ],
  "insertions": 201,
  "deletions": 15,
  "hunks": [
    {
      "file": ".claude/commands/ml-log.md",
      "function": null,
      "start_line": 0,
      "lines_added": [
        "# Log Chat Exchange for ML Training",
        "",
        "Log significant chat exchanges to train a project-specific micro-model.",
        "",
        "## When to Use",
        "",
        "After completing significant work (bug fix, feature implementation, debugging session), log the exchange:",
        "",
        "```bash",
        "python .claude/hooks/session_logger.py \\",
        "    --query \"USER_QUERY_HERE\" \\",
        "    --response \"BRIEF_SUMMARY_OF_RESPONSE\" \\",
        "    --files-read file1.py file2.py \\",
        "    --files-modified file3.py \\",
        "    --tools Read,Edit,Bash,Grep \\",
        "    --feedback positive",
        "```",
        "",
        "## Parameters",
        "",
        "| Parameter | Description |",
        "|-----------|-------------|",
        "| `--query` | The user's original question (2-3 sentences) |",
        "| `--response` | Summary of what was accomplished (3-5 sentences) |",
        "| `--files-read` | Files that were examined |",
        "| `--files-modified` | Files that were changed |",
        "| `--tools` | Tools used: Read, Edit, Write, Bash, Grep, Glob |",
        "| `--feedback` | positive, negative, or neutral |",
        "",
        "## Session Management",
        "",
        "```bash",
        "# Start session (optional - auto-starts on first log)",
        "python scripts/ml_data_collector.py session start",
        "",
        "# End session with summary",
        "python scripts/ml_data_collector.py session end --summary \"What was accomplished\"",
        "",
        "# Check session status",
        "python scripts/ml_data_collector.py session status",
        "```",
        "",
        "## Why This Matters",
        "",
        "This data trains a micro-model specific to THIS project that learns your coding patterns, common workflows, and project-specific terminology."
      ],
      "lines_removed": [],
      "context_before": [],
      "context_after": [],
      "change_type": "add"
    },
    {
      "file": ".claude/commands/ml-stats.md",
      "function": null,
      "start_line": 0,
      "lines_added": [
        "# ML Collection Statistics",
        "",
        "Show ML data collection progress and training viability estimates.",
        "",
        "## Instructions",
        "",
        "Run these commands to check ML data collection status:",
        "",
        "```bash",
        "# Show collection statistics",
        "python scripts/ml_data_collector.py stats",
        "",
        "# Show training estimates and timeline",
        "python scripts/ml_data_collector.py estimate",
        "```",
        "",
        "## What This Shows",
        "",
        "- **Data counts**: Commits, chats, actions, sessions collected",
        "- **Data sizes**: Storage used by each data type",
        "- **Training milestones**: Progress toward file prediction, commit messages, code suggestions",
        "- **Time estimates**: How long until training becomes viable",
        "",
        "## Disabling Collection",
        "",
        "To disable ML data collection:",
        "",
        "```bash",
        "export ML_COLLECTION_ENABLED=0",
        "```",
        "",
        "This stops collection but still allows viewing stats."
      ],
      "lines_removed": [],
      "context_before": [],
      "context_after": [],
      "change_type": "add"
    },
    {
      "file": "CLAUDE.md",
      "function": "python scripts/search_codebase.py \"what did we learn about validation\"",
      "start_line": 1152,
      "lines_added": [
        "## ML Data Collection: Project-Specific Micro-Model",
        "",
        "The project automatically collects enriched commit and chat data to train a micro-model that learns THIS project's patterns, coding style, and workflows.",
        "",
        "### What Gets Collected",
        "",
        "| Data Type | Location | Contents |",
        "|-----------|----------|----------|",
        "| **Commits** | `.git-ml/commits/` | Git history with diff hunks, temporal context, CI results |",
        "| **Chats** | `.git-ml/chats/` | Query/response pairs with files touched and tools used |",
        "| **Sessions** | `.git-ml/sessions/` | Development sessions linking chats to commits |",
        "| **Actions** | `.git-ml/actions/` | Individual tool uses and operations |",
        "",
        "**Note:** All ML data is stored in `.git-ml/` which is gitignored and regeneratable via backfill.",
        "",
        "### Quick Commands",
        "",
        "```bash",
        "# Check collection progress",
        "python scripts/ml_data_collector.py stats",
        "",
        "# Estimate when training becomes viable",
        "python scripts/ml_data_collector.py estimate",
        "",
        "# Validate collected data",
        "python scripts/ml_data_collector.py validate",
        "",
        "# Session management",
        "python scripts/ml_data_collector.py session status",
        "python scripts/ml_data_collector.py session start",
        "python scripts/ml_data_collector.py session end --summary \"What was accomplished\"",
        "",
        "# Record CI results",
        "python scripts/ml_data_collector.py ci set --commit abc123 --result pass --coverage 89.5",
        "",
        "# Backfill historical commits",
        "python scripts/ml_data_collector.py backfill -n 100",
        "```",
        "",
        "### Disabling Collection",
        "",
        "```bash",
        "# Disable for current session",
        "export ML_COLLECTION_ENABLED=0",
        "",
        "# Stats and validation still work when disabled",
        "```",
        "",
        "### Integration",
        "",
        "Data collection is automatic via git hooks:",
        "- **post-commit**: Captures commit metadata with diff hunks",
        "- **pre-push**: Reports collection stats",
        "",
        "See `.claude/skills/ml-logger/SKILL.md` for detailed logging usage.",
        "",
        "---",
        ""
      ],
      "lines_removed": [],
      "context_before": [
        "",
        "When completing a task, consider creating a memory entry from the retrospective:",
        "- What was learned?",
        "- What connections were made?",
        "- What should future developers know?",
        "",
        "See `docs/text-as-memories.md` for the full guide.",
        "",
        "---",
        ""
      ],
      "context_after": [
        "## File Quick Links",
        "",
        "- **Main API**: `cortical/processor.py` - `CorticalTextProcessor` class",
        "- **Graph algorithms**: `cortical/analysis.py` - PageRank, TF-IDF, clustering",
        "- **Search**: `cortical/query.py` - query expansion, document retrieval",
        "- **Data structures**: `cortical/minicolumn.py` - `Minicolumn`, `Edge`",
        "- **Configuration**: `cortical/config.py` - `CorticalConfig` dataclass",
        "- **Tests**: `tests/test_processor.py` - most comprehensive test file",
        "- **Demo**: `showcase.py` - interactive demonstration",
        ""
      ],
      "change_type": "add"
    },
    {
      "file": "scripts/ml_data_collector.py",
      "function": "Usage:",
      "start_line": 19,
      "lines_added": [
        "import fcntl",
        "import logging",
        "from contextlib import contextmanager",
        "",
        "# Setup logging",
        "logger = logging.getLogger(__name__)",
        "",
        "# Environment variable to disable collection",
        "ML_COLLECTION_ENABLED = os.getenv(\"ML_COLLECTION_ENABLED\", \"1\") != \"0\""
      ],
      "lines_removed": [],
      "context_before": [
        "    python scripts/ml_data_collector.py estimate",
        "\"\"\"",
        "",
        "import json",
        "import os",
        "import subprocess",
        "import hashlib",
        "import re",
        "import tempfile",
        "import uuid"
      ],
      "context_after": [
        "from datetime import datetime",
        "from pathlib import Path",
        "from typing import Dict, List, Optional, Any",
        "from dataclasses import dataclass, asdict, field",
        "",
        "",
        "class GitCommandError(Exception):",
        "    \"\"\"Raised when a git command fails.\"\"\"",
        "    pass",
        "",
        "",
        "class SchemaValidationError(Exception):",
        "    \"\"\"Raised when data fails schema validation.\"\"\"",
        "    pass"
      ],
      "change_type": "add"
    },
    {
      "file": "scripts/ml_data_collector.py",
      "function": "def validate_schema(data: dict, schema: dict, data_type: str) -> List[str]:",
      "start_line": 100,
      "lines_added": [
        "# ============================================================================",
        "# FILE LOCKING (for concurrent access safety)",
        "# ============================================================================",
        "",
        "@contextmanager",
        "def file_lock(filepath: Path, exclusive: bool = True):",
        "    \"\"\"Context manager for file locking to prevent race conditions.",
        "",
        "    Args:",
        "        filepath: Path to lock file",
        "        exclusive: True for write lock, False for read lock",
        "    \"\"\"",
        "    filepath.parent.mkdir(parents=True, exist_ok=True)",
        "    lock_file = filepath.with_suffix(filepath.suffix + '.lock')",
        "",
        "    with open(lock_file, 'w') as f:",
        "        lock_type = fcntl.LOCK_EX if exclusive else fcntl.LOCK_SH",
        "        try:",
        "            fcntl.flock(f.fileno(), lock_type)",
        "            yield",
        "        finally:",
        "            fcntl.flock(f.fileno(), fcntl.LOCK_UN)",
        "",
        "",
        "        except json.JSONDecodeError as e:",
        "            logger.warning(f\"Corrupted session file: {e}\")",
        "            return None",
        "        except IOError as e:",
        "            logger.error(f\"Cannot read session file: {e}\")"
      ],
      "lines_removed": [
        "        except (json.JSONDecodeError, IOError):"
      ],
      "context_before": [
        "    for field, expected in schema[\"types\"].items():",
        "        if field in data and data[field] is not None:",
        "            if isinstance(expected, tuple):",
        "                if not isinstance(data[field], expected):",
        "                    errors.append(f\"{data_type}: field '{field}' has wrong type\")",
        "            elif not isinstance(data[field], expected):",
        "                errors.append(f\"{data_type}: field '{field}' has type {type(data[field]).__name__}, expected {expected.__name__}\")",
        "    return errors",
        "",
        ""
      ],
      "context_after": [
        "# ============================================================================",
        "# SESSION MANAGEMENT (for commit-chat linking)",
        "# ============================================================================",
        "",
        "def get_current_session() -> Optional[Dict]:",
        "    \"\"\"Get the current active session info.",
        "",
        "    Returns dict with 'id', 'started_at', 'chat_ids' or None if no session.",
        "    \"\"\"",
        "    if CURRENT_SESSION_FILE.exists():",
        "        try:",
        "            with open(CURRENT_SESSION_FILE, 'r', encoding='utf-8') as f:",
        "                return json.load(f)",
        "            return None",
        "    return None",
        "",
        "",
        "def start_session(session_id: Optional[str] = None) -> str:",
        "    \"\"\"Start a new session for commit-chat linking.",
        "",
        "    Args:",
        "        session_id: Optional session ID. Generated if not provided.",
        ""
      ],
      "change_type": "modify"
    },
    {
      "file": "scripts/ml_data_collector.py",
      "function": "def get_or_create_session() -> str:",
      "start_line": 154,
      "lines_added": [
        "    \"\"\"Record a chat ID in the current session for later commit linking.",
        "",
        "    Uses file locking to prevent race conditions with concurrent access.",
        "    \"\"\"",
        "    ensure_dirs()",
        "    # Use file lock to prevent race conditions",
        "    with file_lock(CURRENT_SESSION_FILE):",
        "        session = get_current_session()",
        "        if not session:",
        "            # Auto-start session if needed",
        "            session = {",
        "                'id': generate_session_id(),",
        "                'started_at': datetime.now().isoformat(),",
        "                'chat_ids': [],",
        "                'action_ids': [],",
        "            }",
        "",
        "        if chat_id not in session['chat_ids']:",
        "            session['chat_ids'].append(chat_id)",
        "            atomic_write_json(CURRENT_SESSION_FILE, session)"
      ],
      "lines_removed": [
        "    \"\"\"Record a chat ID in the current session for later commit linking.\"\"\"",
        "    session = get_current_session()",
        "    if not session:",
        "        # Auto-start session if needed",
        "        session = {",
        "            'id': generate_session_id(),",
        "            'started_at': datetime.now().isoformat(),",
        "            'chat_ids': [],",
        "            'action_ids': [],",
        "        }",
        "    if chat_id not in session['chat_ids']:",
        "        session['chat_ids'].append(chat_id)",
        "        ensure_dirs()",
        "        atomic_write_json(CURRENT_SESSION_FILE, session)"
      ],
      "context_before": [
        "    Returns:",
        "        The current session ID.",
        "    \"\"\"",
        "    session = get_current_session()",
        "    if session:",
        "        return session['id']",
        "    return start_session()",
        "",
        "",
        "def add_chat_to_session(chat_id: str):"
      ],
      "context_after": [
        "",
        "",
        "",
        "def link_commit_to_session_chats(commit_hash: str) -> List[str]:",
        "    \"\"\"Link a commit to all chats from the current session.",
        "",
        "    Updates the chat entries to record that they resulted in this commit.",
        "    Also updates the commit's related_chats field.",
        "",
        "    Args:",
        "        commit_hash: The commit hash to link."
      ],
      "change_type": "modify"
    },
    {
      "file": "scripts/ml_data_collector.py",
      "function": "def install_hooks():",
      "start_line": 1083,
      "lines_added": [
        "    # Allow stats/estimate/validate even when collection is disabled",
        "    read_only_commands = {\"stats\", \"estimate\", \"validate\", \"session\"}",
        "",
        "    # Check if collection is disabled (via ML_COLLECTION_ENABLED=0)",
        "    if not ML_COLLECTION_ENABLED and command not in read_only_commands:",
        "        # Silently exit for collection commands when disabled",
        "        return",
        ""
      ],
      "lines_removed": [],
      "context_before": [
        "",
        "def main():",
        "    import sys",
        "",
        "    if len(sys.argv) < 2:",
        "        print(__doc__)",
        "        return",
        "",
        "    command = sys.argv[1]",
        ""
      ],
      "context_after": [
        "    if command == \"commit\":",
        "        # Collect data for current or specified commit",
        "        commit_hash = sys.argv[2] if len(sys.argv) > 2 else None",
        "        context = collect_commit_data(commit_hash)",
        "        save_commit_data(context)",
        "",
        "    elif command == \"backfill\":",
        "        # Backfill historical commits (no session linking for historical data)",
        "        import argparse",
        "        parser = argparse.ArgumentParser()"
      ],
      "change_type": "add"
    }
  ],
  "hour_of_day": 5,
  "day_of_week": "Monday",
  "seconds_since_last_commit": -30356,
  "is_merge": false,
  "is_initial": false,
  "parent_count": 1,
  "session_id": null,
  "related_chats": [],
  "ci_result": null,
  "reverted": false,
  "amended": false
}