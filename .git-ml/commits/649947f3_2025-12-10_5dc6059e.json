{
  "hash": "649947f31eb3c43321450d29a442b7ee29e266d2",
  "message": "Enhance README with real showcase output and examples",
  "author": "Claude",
  "timestamp": "2025-12-10 11:17:41 +0000",
  "branch": "claude/multi-index-design-DvifZ",
  "files_changed": [
    "README.md"
  ],
  "insertions": 42,
  "deletions": 10,
  "hunks": [
    {
      "file": "README.md",
      "function": null,
      "start_line": 3,
      "lines_added": [
        "No PyTorch. No transformers. No API keys. Just 337 tests, ~3000 lines of pure Python, and a data structure that would make a neuroscientist squint approvingly."
      ],
      "lines_removed": [
        "No PyTorch. No transformers. No API keys. Just 337 tests, 7000 lines of pure Python, and a data structure that would make a neuroscientist squint approvingly."
      ],
      "context_before": [
        "A neocortex-inspired text processing library with **zero external dependencies** for semantic analysis, document retrieval, and knowledge gap detection.",
        "",
        "---",
        "",
        "> *\"What if we built a text search engine the way evolution built a brain?\"*",
        "",
        "Your visual cortex doesn't grep through pixels looking for cats. It builds hierarchies‚Äîedges become patterns, patterns become shapes, shapes become objects. This library applies the same principle to text.",
        "",
        "Feed it documents. It tokenizes them into \"minicolumns\" (Layer 0), connects co-occurring words through Hebbian learning (\"neurons that fire together, wire together\"), clusters them into concepts (Layer 2), and links documents by shared meaning (Layer 3). The result: a graph that understands your corpus well enough to expand queries, complete analogies, and tell you where your knowledge has gaps.",
        ""
      ],
      "context_after": [
        "",
        "---",
        "",
        "## Overview",
        "",
        "This library provides a biologically-inspired approach to text processing, organizing information through a hierarchical structure similar to the visual cortex:",
        "",
        "| Layer | Name | Analogy | Purpose |",
        "|-------|------|---------|---------|",
        "| 0 | Tokens | V1 (edges) | Individual words |"
      ],
      "change_type": "modify"
    },
    {
      "file": "README.md",
      "function": "processor.compute_all(",
      "start_line": 157,
      "lines_added": [
        "Tested with 92 sample documents covering topics from neural networks to medieval falconry to sourdough breadmaking.",
        "| Documents processed | 92 |",
        "| Token minicolumns | 6,506 |",
        "| Bigram minicolumns | 20,114 |",
        "| Lateral connections | 116,332 |",
        "| Test coverage | 337 tests passing |",
        "| Graph algorithms | O(1) ID lookups |",
        "",
        "**What the processor discovers:**",
        "- Most central concept: `data` (PageRank: 0.0046)",
        "- Most distinctive terms: `gradient`, `pagerank`, `patent` (high TF-IDF, rare but meaningful)",
        "- Most connected document: `comprehensive_machine_learning` (91 connections to other docs)",
        "- Isolated outliers detected: `sumo_wrestling`, `medieval_falconry` (low similarity to corpus)"
      ],
      "lines_removed": [
        "Tested with 92 sample documents covering diverse topics from neural networks to wine tasting.",
        "| Test Coverage | 337 tests passing |",
        "| Semantic Extraction | 2x speedup (optimized) |",
        "| Graph Algorithms | O(1) ID lookups |",
        "| Overall Processing | 2.5x speedup with numpy |"
      ],
      "context_before": [
        "",
        "| Strategy | Description |",
        "|----------|-------------|",
        "| `document_overlap` | Traditional Jaccard similarity (default) |",
        "| `semantic` | Connect via semantic relations between members |",
        "| `embedding` | Connect via embedding centroid similarity |",
        "| `hybrid` | Combine all three for maximum connectivity |",
        "",
        "## Performance",
        ""
      ],
      "context_after": [
        "",
        "| Metric | Value |",
        "|--------|-------|",
        "",
        "## Package Structure",
        "",
        "```",
        "cortical/",
        "‚îú‚îÄ‚îÄ __init__.py      # Public API (v2.0.0)",
        "‚îú‚îÄ‚îÄ processor.py     # Main orchestrator",
        "‚îú‚îÄ‚îÄ tokenizer.py     # Tokenization + stemming",
        "‚îú‚îÄ‚îÄ minicolumn.py    # Core data structure with typed edges",
        "‚îú‚îÄ‚îÄ layers.py        # Hierarchical layers with O(1) lookups"
      ],
      "change_type": "modify"
    },
    {
      "file": "README.md",
      "function": "cortical/",
      "start_line": 186,
      "lines_added": [
        "showcase.py          # Interactive demonstration (run it!)",
        "samples/             # 92 documents: from quantum computing to cheese affinage",
        "6. **Showcase & Polish**: Interactive demo with real corpus analysis",
        "The showcase processes 92 diverse sample documents and demonstrates every major feature. Here's what you'll see:",
        "",
        "### Concept Associations (Hebbian Learning)",
        "",
        "The processor discovers that `neural` connects to `networks` (weight: 23), `artificial` (7), `knowledge` (7)‚Äîwhile `bread` meekly connects to `beer`, `wine`, and `pyruvate` (weight: 1 each). Neurons that fire together really do wire together.",
        "",
        "### Query Expansion in Action",
        "",
        "```",
        "üîç Query: 'neural networks'",
        "   Expanded with: knowledge, data, graph, network, deep, artificial",
        "",
        "   Top documents:",
        "     ‚Ä¢ comprehensive_machine_learning (score: 26.384)",
        "     ‚Ä¢ attention_mechanism_research (score: 19.178)",
        "     ‚Ä¢ cortical_semantic_networks (score: 18.470)",
        "```",
        "",
        "### The Polysemy Problem",
        "",
        "Search for \"candle sticks\" and you'll find both `candlestick_patterns` (trading charts) and `letterpress_printing` (composing sticks). The system correctly retrieves both meanings but can't read your mind about which one you wanted. Word sense disambiguation remains an open challenge.",
        "",
        "### Knowledge Gap Detection",
        "",
        "The analyzer flags `sumo_wrestling` and `medieval_falconry` as isolated documents‚Äîthey don't fit well with the rest of the corpus. It also identifies weak topics: terms like `patent` appear in only 1 document. This is how you find holes in your knowledge base."
      ],
      "lines_removed": [
        "showcase.py          # Interactive demonstration",
        "samples/             # 92 diverse sample documents",
        "6. **Performance Optimization**: 2x-2.5x speedups via numpy and algorithm improvements",
        "Demonstrates hierarchical analysis, PageRank, TF-IDF, concept associations, document relationships, query expansion, polysemy handling, gap analysis, and graph embeddings."
      ],
      "context_before": [
        "‚îú‚îÄ‚îÄ semantics.py     # Semantic extraction, inference, analogy",
        "‚îú‚îÄ‚îÄ embeddings.py    # Graph embeddings with retrofitting",
        "‚îú‚îÄ‚îÄ query.py         # Search, retrieval, batch processing",
        "‚îú‚îÄ‚îÄ gaps.py          # Gap detection and anomalies",
        "‚îî‚îÄ‚îÄ persistence.py   # Save/load with full state",
        "",
        "evaluation/",
        "‚îî‚îÄ‚îÄ evaluator.py     # Evaluation framework",
        "",
        "tests/               # 337 comprehensive tests"
      ],
      "context_after": [
        "```",
        "",
        "## Development History",
        "",
        "This project evolved through systematic improvements:",
        "",
        "1. **Initial Release**: Core hierarchical text processing",
        "2. **Code Review & Fixes**: TF-IDF calculation, O(1) lookups, type annotations",
        "3. **RAG Enhancements**: Chunk-level retrieval, metadata support, concept clustering",
        "4. **ConceptNet Integration**: Typed edges, relation-weighted PageRank, multi-hop inference",
        "5. **Connection Strategies**: Multiple strategies for Layer 2 concept connections",
        "",
        "## Running the Showcase",
        "",
        "```bash",
        "python showcase.py",
        "```",
        "",
        "",
        "## Running Tests",
        "",
        "```bash",
        "python -m unittest discover -s tests -v",
        "```",
        "",
        "## License",
        "",
        "MIT License"
      ],
      "change_type": "modify"
    }
  ],
  "hour_of_day": 11,
  "day_of_week": "Wednesday",
  "seconds_since_last_commit": -440827,
  "is_merge": false,
  "is_initial": false,
  "parent_count": 1,
  "session_id": null,
  "related_chats": [],
  "ci_result": null,
  "reverted": false,
  "amended": false
}