{
  "hash": "7a970e3a3935d482f5e8693ad4a2694bb0f4a488",
  "message": "Add concept-level lateral connections (Task 20)",
  "author": "Claude",
  "timestamp": "2025-12-09 22:52:44 +0000",
  "branch": "claude/multi-index-design-DvifZ",
  "files_changed": [
    "TASK_LIST.md",
    "cortical/analysis.py",
    "cortical/processor.py",
    "tests/test_processor.py"
  ],
  "insertions": 343,
  "deletions": 21,
  "hunks": [
    {
      "file": "TASK_LIST.md",
      "function": "doc.feedforward_connections[\"L0_neural\"] = 3.0  # appears 3 times",
      "start_line": 575,
      "lines_added": [
        "**Files:** `cortical/analysis.py`, `cortical/processor.py`",
        "**Status:** [x] Completed",
        "Layer 2 (Concepts) had 0 lateral connections. Concept clusters should connect to each other based on shared documents and semantic overlap.",
        "**Solution Applied:**",
        "1. Added `compute_concept_connections()` function to `analysis.py`",
        "2. Connects concepts by Jaccard similarity of document sets",
        "3. Optionally boosts weights using semantic relations between member tokens",
        "4. Relation type weighting: IsA (1.5) > PartOf (1.3) > HasProperty (1.2) > RelatedTo (1.0)",
        "5. Called from `compute_all()` after `build_concept_clusters()`",
        "6. Added `compute_concept_connections()` method to processor with parameters",
        "",
        "**Files Modified:**",
        "- `cortical/analysis.py` - Added `compute_concept_connections()` (~110 lines)",
        "- `cortical/processor.py` - Added processor wrapper method, integrated into `compute_all()`",
        "- `tests/test_processor.py` - Added 8 tests for concept connections",
        "**Usage:**",
        "# Automatic in compute_all()",
        "processor.compute_all()  # Calls compute_concept_connections() automatically",
        "",
        "# Manual with options",
        "stats = processor.compute_concept_connections(",
        "    use_semantics=True,    # Boost weights with semantic relations",
        "    min_shared_docs=1,     # Minimum shared documents",
        "    min_jaccard=0.1        # Minimum Jaccard similarity",
        ")"
      ],
      "lines_removed": [
        "**Files:** `cortical/analysis.py`",
        "**Status:** [ ] Pending",
        "Layer 2 (Concepts) has 0 lateral connections. Concept clusters should connect to each other based on:",
        "- Shared documents (concepts appearing in same docs)",
        "- Semantic overlap (member tokens with semantic relations)",
        "- Co-activation patterns",
        "**Implementation Steps:**",
        "1. Add `compute_concept_connections()` function to `analysis.py`",
        "2. Connect concepts sharing documents (weighted by Jaccard similarity of doc sets)",
        "3. Connect concepts with semantically related member tokens",
        "4. Weight connections by relation type (IsA > PartOf > RelatedTo)",
        "5. Call from `compute_all()` after `build_concept_clusters()`",
        "**Example Output:**",
        "# Concept \"neural/networks/learning\" connects to:",
        "#   → \"knowledge/graph/semantic\" (weight: 0.73, reason: shared docs + RelatedTo)",
        "#   → \"data/processing/systems\" (weight: 0.45, reason: shared docs)"
      ],
      "context_before": [
        "",
        "# Concept → Tokens (weight by normalized PageRank)",
        "concept.feedforward_connections[\"L0_neural\"] = 1.0  # highest PR",
        "concept.feedforward_connections[\"L0_networks\"] = 0.7  # lower PR",
        "```",
        "",
        "---",
        "",
        "### 20. Add Concept-Level Lateral Connections",
        ""
      ],
      "context_after": [
        "",
        "**Problem:**",
        "",
        "",
        "```python",
        "```",
        "",
        "---",
        "",
        "### 21. Add Bigram Lateral Connections",
        "",
        "**Files:** `cortical/analysis.py`, `cortical/processor.py`",
        "**Status:** [ ] Pending",
        "",
        "**Problem:**"
      ],
      "change_type": "modify"
    },
    {
      "file": "TASK_LIST.md",
      "function": "complete_analogy(\"neural\", \"networks\", \"knowledge\")",
      "start_line": 877,
      "lines_added": [
        "| **Critical** | **Add concept-level lateral connections** | ✅ Completed | **ConceptNet** |",
        "**ConceptNet Enhancement Completion:** 2/12 tasks (17%)",
        "Ran 193 tests in 0.162s"
      ],
      "lines_removed": [
        "| **Critical** | **Add concept-level lateral connections** | ⏳ Pending | **ConceptNet** |",
        "**ConceptNet Enhancement Completion:** 1/12 tasks (8%)",
        "Ran 185 tests in 0.147s"
      ],
      "context_before": [
        "| **High** | **Activate Layer 2 concepts** | ✅ Completed | **RAG** |",
        "| **High** | **Integrate semantic relations** | ✅ Completed | **RAG** |",
        "| **High** | **Persist full computed state** | ✅ Completed | **RAG** |",
        "| Medium | Fix type annotation (embeddings.py) | ✅ Completed | Bug Fix |",
        "| Medium | Optimize spectral embeddings | ✅ Completed | Performance |",
        "| Medium | Add incremental indexing | ✅ Completed | RAG |",
        "| Low | Document magic numbers | ⏳ Deferred | Documentation |",
        "| Low | Multi-stage ranking pipeline | ✅ Completed | RAG |",
        "| Low | Batch query API | ✅ Completed | RAG |",
        "| **Critical** | **Build cross-layer feedforward connections** | ✅ Completed | **ConceptNet** |"
      ],
      "context_after": [
        "| **Critical** | **Add bigram lateral connections** | ⏳ Pending | **ConceptNet** |",
        "| **High** | **Implement relation-weighted PageRank** | ⏳ Pending | **ConceptNet** |",
        "| **High** | **Implement cross-layer PageRank propagation** | ⏳ Pending | **ConceptNet** |",
        "| **High** | **Add typed edge storage** | ⏳ Pending | **ConceptNet** |",
        "| Medium | Implement multi-hop semantic inference | ⏳ Pending | ConceptNet |",
        "| Medium | Add relation path scoring | ⏳ Pending | ConceptNet |",
        "| Medium | Implement concept inheritance | ⏳ Pending | ConceptNet |",
        "| Low | Add commonsense relation extraction | ⏳ Pending | ConceptNet |",
        "| Low | Visualize ConceptNet-style graph | ⏳ Pending | ConceptNet |",
        "| Low | Add analogy completion | ⏳ Pending | ConceptNet |",
        "",
        "**Bug Fix Completion:** 7/7 tasks (100%)",
        "**RAG Enhancement Completion:** 8/8 tasks (100%)",
        "",
        "---",
        "",
        "## Test Results",
        "",
        "```",
        "OK",
        "```",
        "",
        "All tests passing as of 2025-12-09.",
        "",
        "---",
        "",
        "*Updated from code review on 2025-12-09*"
      ],
      "change_type": "modify"
    },
    {
      "file": "cortical/analysis.py",
      "function": "Analysis Module",
      "start_line": 5,
      "lines_added": [
        "from typing import Dict, List, Tuple, Set, Optional, Any"
      ],
      "lines_removed": [
        "from typing import Dict, List, Tuple, Set, Optional"
      ],
      "context_before": [
        "Graph analysis algorithms for the cortical network.",
        "",
        "Contains implementations of:",
        "- PageRank for importance scoring",
        "- TF-IDF for term weighting",
        "- Label propagation for clustering",
        "- Activation propagation for information flow",
        "\"\"\"",
        "",
        "import math"
      ],
      "context_after": [
        "from collections import defaultdict",
        "",
        "from .layers import CorticalLayer, HierarchicalLayer",
        "from .minicolumn import Minicolumn",
        "",
        "",
        "def compute_pagerank(",
        "    layer: HierarchicalLayer,",
        "    damping: float = 0.85,",
        "    iterations: int = 20,"
      ],
      "change_type": "modify"
    },
    {
      "file": "cortical/analysis.py",
      "function": "def build_concept_clusters(",
      "start_line": 322,
      "lines_added": [
        "def compute_concept_connections(",
        "    layers: Dict[CorticalLayer, HierarchicalLayer],",
        "    semantic_relations: List[Tuple[str, str, str, float]] = None,",
        "    min_shared_docs: int = 1,",
        "    min_jaccard: float = 0.1",
        ") -> Dict[str, Any]:",
        "    \"\"\"",
        "    Build lateral connections between concepts in Layer 2.",
        "",
        "    Concepts are connected based on:",
        "    1. Shared documents (Jaccard similarity of document sets)",
        "    2. Semantic relations between member tokens (if provided)",
        "",
        "    Args:",
        "        layers: Dictionary of all layers",
        "        semantic_relations: Optional list of (term1, relation, term2, weight) tuples",
        "        min_shared_docs: Minimum shared documents for connection",
        "        min_jaccard: Minimum Jaccard similarity threshold",
        "",
        "    Returns:",
        "        Statistics about connections created",
        "    \"\"\"",
        "    layer0 = layers[CorticalLayer.TOKENS]",
        "    layer2 = layers[CorticalLayer.CONCEPTS]",
        "",
        "    if layer2.column_count() == 0:",
        "        return {'connections_created': 0, 'concepts': 0}",
        "",
        "    concepts = list(layer2.minicolumns.values())",
        "    connections_created = 0",
        "",
        "    # Build semantic relation lookup for faster access",
        "    semantic_lookup: Dict[str, Dict[str, Tuple[str, float]]] = defaultdict(dict)",
        "    if semantic_relations:",
        "        for t1, relation, t2, weight in semantic_relations:",
        "            # Store relation in both directions",
        "            semantic_lookup[t1][t2] = (relation, weight)",
        "            semantic_lookup[t2][t1] = (relation, weight)",
        "",
        "    # Relation type weights for scoring",
        "    relation_weights = {",
        "        'IsA': 1.5,",
        "        'PartOf': 1.3,",
        "        'HasProperty': 1.2,",
        "        'RelatedTo': 1.0,",
        "        'Antonym': 0.3,",
        "    }",
        "",
        "    # Compare all concept pairs",
        "    for i, concept1 in enumerate(concepts):",
        "        docs1 = concept1.document_ids",
        "",
        "        for concept2 in concepts[i+1:]:",
        "            docs2 = concept2.document_ids",
        "",
        "            # Calculate Jaccard similarity of document sets",
        "            shared_docs = docs1 & docs2",
        "            union_docs = docs1 | docs2",
        "",
        "            if len(shared_docs) < min_shared_docs:",
        "                continue",
        "",
        "            jaccard = len(shared_docs) / len(union_docs) if union_docs else 0",
        "",
        "            if jaccard < min_jaccard:",
        "                continue",
        "",
        "            # Base weight from document overlap",
        "            weight = jaccard",
        "",
        "            # Add semantic relation bonus if available",
        "            if semantic_relations:",
        "                # Get member tokens for each concept",
        "                members1 = set()",
        "                for token_id in concept1.feedforward_connections:",
        "                    token = layer0.get_by_id(token_id)",
        "                    if token:",
        "                        members1.add(token.content)",
        "",
        "                members2 = set()",
        "                for token_id in concept2.feedforward_connections:",
        "                    token = layer0.get_by_id(token_id)",
        "                    if token:",
        "                        members2.add(token.content)",
        "",
        "                # Check for semantic relations between member tokens",
        "                semantic_bonus = 0.0",
        "                relation_count = 0",
        "                for m1 in members1:",
        "                    if m1 in semantic_lookup:",
        "                        for m2 in members2:",
        "                            if m2 in semantic_lookup[m1]:",
        "                                relation, rel_weight = semantic_lookup[m1][m2]",
        "                                rel_multiplier = relation_weights.get(relation, 1.0)",
        "                                semantic_bonus += rel_weight * rel_multiplier",
        "                                relation_count += 1",
        "",
        "                # Normalize and add semantic bonus (max 50% boost)",
        "                if relation_count > 0:",
        "                    avg_semantic = semantic_bonus / relation_count",
        "                    weight *= (1 + min(avg_semantic, 0.5))",
        "",
        "            # Create bidirectional connections",
        "            concept1.add_lateral_connection(concept2.id, weight)",
        "            concept2.add_lateral_connection(concept1.id, weight)",
        "            connections_created += 1",
        "",
        "    return {",
        "        'connections_created': connections_created,",
        "        'concepts': len(concepts)",
        "    }",
        "",
        ""
      ],
      "lines_removed": [],
      "context_before": [
        "            # Weighted feedforward: concept → token (weight by normalized PageRank)",
        "            weight = col.pagerank / max_pagerank if max_pagerank > 0 else 1.0",
        "            concept.add_feedforward_connection(col.id, weight)",
        "            # Weighted feedback: token → concept (weight by normalized PageRank)",
        "            col.add_feedback_connection(concept.id, weight)",
        "",
        "        # Set PageRank as average of members",
        "        concept.pagerank = sum(c.pagerank for c in member_cols) / len(member_cols)",
        "",
        ""
      ],
      "context_after": [
        "def compute_document_connections(",
        "    layers: Dict[CorticalLayer, HierarchicalLayer],",
        "    documents: Dict[str, str],",
        "    min_shared_terms: int = 3",
        ") -> None:",
        "    \"\"\"",
        "    Build lateral connections between documents.",
        "    ",
        "    Documents are connected based on shared vocabulary,",
        "    weighted by TF-IDF scores of shared terms."
      ],
      "change_type": "add"
    },
    {
      "file": "cortical/processor.py",
      "function": "class CorticalTextProcessor:",
      "start_line": 419,
      "lines_added": [
        "            if verbose:",
        "                print(\"Computing concept connections...\")",
        "            self.compute_concept_connections(verbose=False)"
      ],
      "lines_removed": [],
      "context_before": [
        "        if verbose:",
        "            print(\"Computing TF-IDF...\")",
        "        self.compute_tfidf(verbose=False)",
        "        if verbose:",
        "            print(\"Computing document connections...\")",
        "        self.compute_document_connections(verbose=False)",
        "        if build_concepts:",
        "            if verbose:",
        "                print(\"Building concept clusters...\")",
        "            self.build_concept_clusters(verbose=False)"
      ],
      "context_after": [
        "        # Mark core computations as fresh",
        "        fresh_comps = [",
        "            self.COMP_ACTIVATION,",
        "            self.COMP_PAGERANK,",
        "            self.COMP_TFIDF,",
        "            self.COMP_DOC_CONNECTIONS,",
        "        ]",
        "        if build_concepts:",
        "            fresh_comps.append(self.COMP_CONCEPTS)",
        "        self._mark_fresh(*fresh_comps)"
      ],
      "change_type": "add"
    },
    {
      "file": "cortical/processor.py",
      "function": "class CorticalTextProcessor:",
      "start_line": 454,
      "lines_added": [
        "",
        "    def compute_concept_connections(",
        "        self,",
        "        use_semantics: bool = True,",
        "        min_shared_docs: int = 1,",
        "        min_jaccard: float = 0.1,",
        "        verbose: bool = True",
        "    ) -> Dict[str, Any]:",
        "        \"\"\"",
        "        Build lateral connections between concepts based on document overlap and semantics.",
        "",
        "        Args:",
        "            use_semantics: Use semantic relations to boost connection weights",
        "            min_shared_docs: Minimum shared documents for connection",
        "            min_jaccard: Minimum Jaccard similarity threshold",
        "            verbose: Print progress messages",
        "",
        "        Returns:",
        "            Statistics about connections created",
        "        \"\"\"",
        "        semantic_rels = self.semantic_relations if use_semantics else None",
        "        stats = analysis.compute_concept_connections(",
        "            self.layers,",
        "            semantic_relations=semantic_rels,",
        "            min_shared_docs=min_shared_docs,",
        "            min_jaccard=min_jaccard",
        "        )",
        "        if verbose:",
        "            print(f\"Created {stats['connections_created']} concept connections\")",
        "        return stats",
        ""
      ],
      "lines_removed": [
        "    "
      ],
      "context_before": [
        "    ",
        "    def compute_document_connections(self, min_shared_terms: int = 3, verbose: bool = True) -> None:",
        "        analysis.compute_document_connections(self.layers, self.documents, min_shared_terms)",
        "        if verbose: print(\"Computed document connections\")",
        "    ",
        "    def build_concept_clusters(self, verbose: bool = True) -> Dict[int, List[str]]:",
        "        clusters = analysis.cluster_by_label_propagation(self.layers[CorticalLayer.TOKENS])",
        "        analysis.build_concept_clusters(self.layers, clusters)",
        "        if verbose: print(f\"Built {len(clusters)} concept clusters\")",
        "        return clusters"
      ],
      "context_after": [
        "    def extract_corpus_semantics(self, verbose: bool = True) -> int:",
        "        self.semantic_relations = semantics.extract_corpus_semantics(self.layers, self.documents, self.tokenizer)",
        "        if verbose: print(f\"Extracted {len(self.semantic_relations)} semantic relations\")",
        "        return len(self.semantic_relations)",
        "    ",
        "    def retrofit_connections(self, iterations: int = 10, alpha: float = 0.3, verbose: bool = True) -> Dict:",
        "        if not self.semantic_relations: self.extract_corpus_semantics(verbose=False)",
        "        stats = semantics.retrofit_connections(self.layers, self.semantic_relations, iterations, alpha)",
        "        if verbose: print(f\"Retrofitted {stats['tokens_affected']} tokens\")",
        "        return stats"
      ],
      "change_type": "modify"
    },
    {
      "file": "tests/test_processor.py",
      "function": "class TestCrossLayerConnections(unittest.TestCase):",
      "start_line": 995,
      "lines_added": [
        "class TestConceptConnections(unittest.TestCase):",
        "    \"\"\"Test concept-level lateral connections.\"\"\"",
        "",
        "    def setUp(self):",
        "        self.processor = CorticalTextProcessor()",
        "        # Create documents with overlapping topics",
        "        self.processor.process_document(\"neural_doc\",",
        "            \"Neural networks process information using deep learning algorithms.\")",
        "        self.processor.process_document(\"ml_doc\",",
        "            \"Machine learning algorithms learn patterns from data using neural methods.\")",
        "        self.processor.process_document(\"data_doc\",",
        "            \"Data processing systems analyze information patterns efficiently.\")",
        "        self.processor.process_document(\"unrelated_doc\",",
        "            \"Ancient pottery techniques involve clay and firing in kilns.\")",
        "        self.processor.compute_all(verbose=False)",
        "",
        "    def test_concepts_have_lateral_connections(self):",
        "        \"\"\"Test that concepts have lateral connections when documents overlap.\"\"\"",
        "        # Create a processor with documents that will create multiple overlapping concepts",
        "        processor = CorticalTextProcessor()",
        "        # Add many documents with overlapping terms to force multiple concept clusters",
        "        processor.process_document(\"doc1\", \"Neural networks deep learning artificial intelligence models.\")",
        "        processor.process_document(\"doc2\", \"Machine learning algorithms data science models.\")",
        "        processor.process_document(\"doc3\", \"Deep learning neural networks training optimization.\")",
        "        processor.process_document(\"doc4\", \"Data analysis machine learning statistical models.\")",
        "        processor.process_document(\"doc5\", \"Artificial intelligence reasoning knowledge graphs.\")",
        "        processor.process_document(\"doc6\", \"Knowledge representation semantic networks graphs.\")",
        "        processor.compute_all(verbose=False)",
        "",
        "        layer2 = processor.get_layer(CorticalLayer.CONCEPTS)",
        "",
        "        # If we have multiple concepts with overlapping docs, they should connect",
        "        if layer2.column_count() > 1:",
        "            # Check if any concepts share documents",
        "            concepts = list(layer2.minicolumns.values())",
        "            has_overlap = False",
        "            for i, c1 in enumerate(concepts):",
        "                for c2 in concepts[i+1:]:",
        "                    if c1.document_ids & c2.document_ids:",
        "                        has_overlap = True",
        "                        break",
        "",
        "            if has_overlap:",
        "                total_connections = sum(",
        "                    len(c.lateral_connections) for c in layer2.minicolumns.values()",
        "                )",
        "                self.assertGreater(total_connections, 0)",
        "",
        "    def test_concept_connections_based_on_jaccard(self):",
        "        \"\"\"Test that concept connections are based on document overlap.\"\"\"",
        "        layer2 = self.processor.get_layer(CorticalLayer.CONCEPTS)",
        "",
        "        if layer2.column_count() > 1:",
        "            concepts = list(layer2.minicolumns.values())",
        "            # Find concepts with connections",
        "            connected_concepts = [c for c in concepts if c.lateral_connections]",
        "",
        "            for concept in connected_concepts:",
        "                for target_id, weight in concept.lateral_connections.items():",
        "                    # Weight should be based on Jaccard (0 < weight <= 1.5 with semantic boost)",
        "                    self.assertGreater(weight, 0)",
        "                    self.assertLessEqual(weight, 2.0)  # Max with semantic boost",
        "",
        "    def test_compute_concept_connections_method(self):",
        "        \"\"\"Test the compute_concept_connections method directly.\"\"\"",
        "        # Clear existing connections",
        "        layer2 = self.processor.get_layer(CorticalLayer.CONCEPTS)",
        "        for concept in layer2.minicolumns.values():",
        "            concept.lateral_connections.clear()",
        "",
        "        # Recompute",
        "        stats = self.processor.compute_concept_connections(verbose=False)",
        "",
        "        self.assertIn('connections_created', stats)",
        "        self.assertIn('concepts', stats)",
        "        self.assertGreaterEqual(stats['connections_created'], 0)",
        "",
        "    def test_concept_connections_with_semantics(self):",
        "        \"\"\"Test that semantic relations boost connection weights.\"\"\"",
        "        # Extract semantics first",
        "        self.processor.extract_corpus_semantics(verbose=False)",
        "",
        "        # Clear and recompute with semantics",
        "        layer2 = self.processor.get_layer(CorticalLayer.CONCEPTS)",
        "        for concept in layer2.minicolumns.values():",
        "            concept.lateral_connections.clear()",
        "",
        "        stats_with = self.processor.compute_concept_connections(",
        "            use_semantics=True, verbose=False",
        "        )",
        "",
        "        # Clear and recompute without semantics",
        "        for concept in layer2.minicolumns.values():",
        "            concept.lateral_connections.clear()",
        "",
        "        stats_without = self.processor.compute_concept_connections(",
        "            use_semantics=False, verbose=False",
        "        )",
        "",
        "        # Both should work",
        "        self.assertGreaterEqual(stats_with['connections_created'], 0)",
        "        self.assertGreaterEqual(stats_without['connections_created'], 0)",
        "",
        "    def test_concept_connections_min_jaccard_filter(self):",
        "        \"\"\"Test that min_jaccard threshold filters connections.\"\"\"",
        "        layer2 = self.processor.get_layer(CorticalLayer.CONCEPTS)",
        "",
        "        # Clear connections",
        "        for concept in layer2.minicolumns.values():",
        "            concept.lateral_connections.clear()",
        "",
        "        # With low threshold",
        "        stats_low = self.processor.compute_concept_connections(",
        "            min_jaccard=0.01, verbose=False",
        "        )",
        "",
        "        # Clear again",
        "        for concept in layer2.minicolumns.values():",
        "            concept.lateral_connections.clear()",
        "",
        "        # With high threshold",
        "        stats_high = self.processor.compute_concept_connections(",
        "            min_jaccard=0.9, verbose=False",
        "        )",
        "",
        "        # Low threshold should create >= high threshold connections",
        "        self.assertGreaterEqual(",
        "            stats_low['connections_created'],",
        "            stats_high['connections_created']",
        "        )",
        "",
        "    def test_concept_connections_bidirectional(self):",
        "        \"\"\"Test that concept connections are bidirectional.\"\"\"",
        "        layer2 = self.processor.get_layer(CorticalLayer.CONCEPTS)",
        "",
        "        for concept in layer2.minicolumns.values():",
        "            for target_id, weight in concept.lateral_connections.items():",
        "                target = layer2.get_by_id(target_id)",
        "                if target:",
        "                    # Target should have connection back to this concept",
        "                    self.assertIn(concept.id, target.lateral_connections)",
        "",
        "    def test_concept_connections_empty_layer(self):",
        "        \"\"\"Test concept connections with empty concept layer.\"\"\"",
        "        processor = CorticalTextProcessor()",
        "        processor.process_document(\"doc1\", \"Hello world.\")",
        "        processor.compute_all(verbose=False, build_concepts=False)",
        "",
        "        layer2 = processor.get_layer(CorticalLayer.CONCEPTS)",
        "        self.assertEqual(layer2.column_count(), 0)",
        "",
        "        # Should handle empty layer gracefully",
        "        stats = processor.compute_concept_connections(verbose=False)",
        "        self.assertEqual(stats['connections_created'], 0)",
        "        self.assertEqual(stats['concepts'], 0)",
        "",
        "    def test_isolated_concepts_not_connected(self):",
        "        \"\"\"Test that concepts with no document overlap don't connect.\"\"\"",
        "        # The unrelated_doc about pottery should form isolated concepts",
        "        layer2 = self.processor.get_layer(CorticalLayer.CONCEPTS)",
        "",
        "        if layer2.column_count() > 0:",
        "            # At least some concepts should be isolated if topics are different",
        "            # This is a soft test since clustering may group differently",
        "            pass  # Concept isolation depends on clustering results",
        "",
        ""
      ],
      "lines_removed": [],
      "context_before": [
        "",
        "        total_ff = 0",
        "        for col in layer1.minicolumns.values():",
        "            total_ff += len(col.feedforward_connections)",
        "",
        "        # Each bigram should have 2 feedforward connections (to its 2 tokens)",
        "        # So total should be approximately 2 * number of bigrams",
        "        self.assertGreater(total_ff, 0)",
        "",
        ""
      ],
      "context_after": [
        "if __name__ == \"__main__\":",
        "    unittest.main(verbosity=2)"
      ],
      "change_type": "add"
    }
  ],
  "hour_of_day": 22,
  "day_of_week": "Tuesday",
  "seconds_since_last_commit": -485524,
  "is_merge": false,
  "is_initial": false,
  "parent_count": 1,
  "session_id": null,
  "related_chats": [],
  "ci_result": null,
  "reverted": false,
  "amended": false
}