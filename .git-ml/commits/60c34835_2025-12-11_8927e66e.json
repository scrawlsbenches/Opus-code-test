{
  "hash": "60c3483582eb848b0289ee1d66f3cc070f2e116a",
  "message": "Add direct definition pattern search for code search (Task #84)",
  "author": "Claude",
  "timestamp": "2025-12-11 03:13:34 +0000",
  "branch": "claude/multi-index-design-DvifZ",
  "files_changed": [
    "TASK_LIST.md",
    "cortical/processor.py",
    "cortical/query.py",
    "tests/test_query.py"
  ],
  "insertions": 566,
  "deletions": 24,
  "hunks": [
    {
      "file": "TASK_LIST.md",
      "function": "raw_tokens = re.findall(r'\\b[a-zA-Z][a-zA-Z0-9_]*\\b', text)",
      "start_line": 2918,
      "lines_added": [
        "**Files:** `cortical/query.py`, `cortical/processor.py`, `tests/test_query.py`",
        "**Status:** [x] Completed (2025-12-11)",
        "**Solution Applied:**",
        "1. Added `is_definition_query()` function to detect definition queries (class/def/function/method patterns)",
        "2. Added `find_definition_in_text()` to search for definition patterns in source code",
        "3. Added `find_definition_passages()` to extract high-scoring passages from definitions",
        "4. Updated `find_passages_for_query()` with `use_definition_search` parameter (default True)",
        "5. Definition passages are injected with high boost score (5.0) before regular passages",
        "6. Test files receive a penalty (0.6x) so source files rank higher",
        "7. Added processor wrapper methods: `is_definition_query()`, `find_definition_passages()`",
        "**Files Modified:**",
        "- `cortical/query.py` - Added definition search functions (~160 lines)",
        "- `cortical/processor.py` - Added processor wrappers (~65 lines)",
        "- `tests/test_query.py` - Added 19 new tests",
        "",
        "**Usage:**",
        "# Definition search is enabled by default",
        "results = processor.find_passages_for_query(\"class Minicolumn\")",
        "# Returns passage containing actual class definition first",
        "",
        "# Disable if needed",
        "results = processor.find_passages_for_query(\"class Minicolumn\", use_definition_search=False)",
        "",
        "# Check if query is a definition query",
        "is_def, def_type, name = processor.is_definition_query(\"def compute_pagerank\")",
        "# (True, 'function', 'compute_pagerank')"
      ],
      "lines_removed": [
        "**Files:** `cortical/query.py`, `scripts/search_codebase.py`",
        "**Status:** [ ] Not Started",
        "**Solution:**",
        "1. For definition queries, directly search source files for the definition pattern",
        "2. Create a synthetic high-scoring passage from the definition location",
        "3. Inject this passage into results before final ranking",
        "4. Consider using regex-based chunk extraction around definition sites",
        "**Example:**",
        "def find_definition_passage(doc_text: str, pattern: str, context_chars: int = 500):",
        "    \"\"\"Extract passage around a definition pattern match.\"\"\"",
        "    match = re.search(pattern, doc_text)",
        "    if match:",
        "        start = max(0, match.start() - 50)",
        "        end = min(len(doc_text), match.end() + context_chars)",
        "        return doc_text[start:end], start, end",
        "    return None"
      ],
      "context_before": [
        "- Affects private methods, dunder methods, internal variables",
        "",
        "**Files to Modify:**",
        "- `cortical/tokenizer.py` - Fix regex pattern",
        "- `tests/test_tokenizer.py` - Add tests for underscore identifiers",
        "",
        "---",
        "",
        "### 84. Add Direct Definition Pattern Search for Code Search",
        ""
      ],
      "context_after": [
        "**Priority:** High",
        "**Category:** Code Search",
        "",
        "**Problem:**",
        "When searching for \"class Minicolumn\", the passage containing the actual class definition (`class Minicolumn:`) scores low because TF-IDF favors chunks with more query term matches. The definition chunk is mostly docstring text with few matching terms.",
        "",
        "**Found via dog-fooding:** Even with document-level boosting, the actual class definition often doesn't appear in top results.",
        "",
        "",
        "```python",
        "```",
        "",
        "---",
        "",
        "### 85. Improve Test File vs Source File Ranking",
        "",
        "**Files:** `cortical/query.py`, `scripts/search_codebase.py`",
        "**Status:** [ ] Not Started",
        "**Priority:** Medium",
        "**Category:** Code Search"
      ],
      "change_type": "modify"
    },
    {
      "file": "TASK_LIST.md",
      "function": "def create_code_aware_chunks(text: str, target_size: int = 500):",
      "start_line": 3024,
      "lines_added": [
        "| 84 | High | Add direct definition pattern search | ✓ Done | Code Search |"
      ],
      "lines_removed": [
        "| 84 | High | Add direct definition pattern search | | Code Search |"
      ],
      "context_before": [
        "| 74 | Medium | Add \"Explain This Code\" command | | Developer Experience |",
        "| 75 | Medium | Add \"What Changed?\" semantic diff | | Developer Experience |",
        "| 76 | Medium | Add \"Suggest Related Files\" feature | | Developer Experience |",
        "| 77 | High | Add interactive \"Ask the Codebase\" mode | ✓ Done | Developer Experience |",
        "| 78 | Low | Add code pattern detection | | Developer Experience |",
        "| 79 | Low | Add corpus health dashboard | | Developer Experience |",
        "| 80 | Low | Add \"Learning Mode\" for new contributors | | Developer Experience |",
        "| 81 | High | Fix tokenizer underscore-prefixed identifiers | ✓ Done | Code Search |",
        "| 82 | High | Add code stop words filter for query expansion | ✓ Done | Code Search |",
        "| 83 | Medium | Add definition-aware boosting for class/def queries | ✓ Done | Code Search |"
      ],
      "context_after": [
        "| 85 | Medium | Improve test file vs source file ranking | | Code Search |",
        "| 86 | Medium | Add semantic chunk boundaries for code | | Code Search |",
        "",
        "---",
        "",
        "*Added 2025-12-11, completions updated 2025-12-11*"
      ],
      "change_type": "modify"
    },
    {
      "file": "cortical/processor.py",
      "function": "class CorticalTextProcessor:",
      "start_line": 1765,
      "lines_added": [
        "        use_semantic: bool = True,",
        "        use_definition_search: bool = True,",
        "        definition_boost: float = 5.0",
        "        For definition queries (e.g., \"class Minicolumn\", \"def compute_pagerank\"),",
        "        the function will directly search for definition patterns and inject those",
        "        results with a high score, ensuring actual definitions appear in top results.",
        "",
        "            use_definition_search: Whether to search for definition patterns (default True)",
        "            definition_boost: Score boost for definition matches (default 5.0)",
        "            >>> results = processor.find_passages_for_query(\"class Minicolumn\")",
        "            use_semantic=use_semantic,",
        "            use_definition_search=use_definition_search,",
        "            definition_boost=definition_boost",
        "        )",
        "",
        "    def is_definition_query(self, query_text: str) -> Tuple[bool, Optional[str], Optional[str]]:",
        "        \"\"\"",
        "        Detect if a query is looking for a code definition.",
        "",
        "        Recognizes patterns like:",
        "        - \"class Minicolumn\"",
        "        - \"def compute_pagerank\"",
        "        - \"function tokenize\"",
        "        - \"method process_document\"",
        "",
        "        Args:",
        "            query_text: The search query",
        "",
        "        Returns:",
        "            Tuple of (is_definition, definition_type, identifier_name)",
        "            If not a definition query, returns (False, None, None)",
        "",
        "        Example:",
        "            >>> is_def, def_type, name = processor.is_definition_query(\"class Minicolumn\")",
        "            >>> print(f\"Definition query: {is_def}, type: {def_type}, name: {name}\")",
        "            Definition query: True, type: class, name: Minicolumn",
        "        \"\"\"",
        "        return query_module.is_definition_query(query_text)",
        "",
        "    def find_definition_passages(",
        "        self,",
        "        query_text: str,",
        "        context_chars: int = 500,",
        "        boost: float = 5.0",
        "    ) -> List[Tuple[str, str, int, int, float]]:",
        "        \"\"\"",
        "        Find definition passages for a definition query.",
        "",
        "        If the query is looking for a class/function/method definition,",
        "        directly search source files for the definition and return",
        "        high-scoring passages.",
        "",
        "        Args:",
        "            query_text: Search query (e.g., \"class Minicolumn\", \"def compute_pagerank\")",
        "            context_chars: Characters of context to include after definition",
        "            boost: Score boost for definition matches",
        "",
        "        Returns:",
        "            List of (passage_text, doc_id, start_char, end_char, score) tuples.",
        "            Returns empty list if query is not a definition query.",
        "",
        "        Example:",
        "            >>> results = processor.find_definition_passages(\"class Minicolumn\")",
        "            >>> for passage, doc_id, start, end, score in results:",
        "            ...     print(f\"[{doc_id}] Score: {score:.2f}\")",
        "        \"\"\"",
        "        return query_module.find_definition_passages(",
        "            query_text, self.documents, context_chars, boost"
      ],
      "lines_removed": [
        "        use_semantic: bool = True",
        "            >>> results = processor.find_passages_for_query(\"neural networks\")",
        "            use_semantic=use_semantic"
      ],
      "context_before": [
        "        )",
        "",
        "    def find_passages_for_query(",
        "        self,",
        "        query_text: str,",
        "        top_n: int = 5,",
        "        chunk_size: int = 512,",
        "        overlap: int = 128,",
        "        use_expansion: bool = True,",
        "        doc_filter: Optional[List[str]] = None,"
      ],
      "context_after": [
        "    ) -> List[Tuple[str, str, int, int, float]]:",
        "        \"\"\"",
        "        Find text passages most relevant to a query (for RAG systems).",
        "",
        "        Instead of returning just document IDs, this returns actual text passages",
        "        with position information suitable for context windows and citations.",
        "",
        "        Args:",
        "            query_text: Search query",
        "            top_n: Number of passages to return",
        "            chunk_size: Size of each chunk in characters (default 512)",
        "            overlap: Overlap between chunks in characters (default 128)",
        "            use_expansion: Whether to expand query terms",
        "            doc_filter: Optional list of doc_ids to restrict search to",
        "            use_semantic: Whether to use semantic relations for expansion (if available)",
        "",
        "        Returns:",
        "            List of (passage_text, doc_id, start_char, end_char, score) tuples",
        "            ranked by relevance",
        "",
        "        Example:",
        "            >>> for passage, doc_id, start, end, score in results:",
        "            ...     print(f\"[{doc_id}:{start}-{end}] {passage[:50]}... (score: {score:.3f})\")",
        "        \"\"\"",
        "        return query_module.find_passages_for_query(",
        "            query_text,",
        "            self.layers,",
        "            self.tokenizer,",
        "            self.documents,",
        "            top_n=top_n,",
        "            chunk_size=chunk_size,",
        "            overlap=overlap,",
        "            use_expansion=use_expansion,",
        "            doc_filter=doc_filter,",
        "            semantic_relations=self.semantic_relations if use_semantic else None,",
        "        )",
        "",
        "    def find_documents_batch(",
        "        self,",
        "        queries: List[str],",
        "        top_n: int = 5,",
        "        use_expansion: bool = True,",
        "        use_semantic: bool = True",
        "    ) -> List[List[Tuple[str, float]]]:",
        "        \"\"\""
      ],
      "change_type": "modify"
    },
    {
      "file": "cortical/query.py",
      "function": "CONCEPTUAL_KEYWORDS = frozenset([",
      "start_line": 74,
      "lines_added": [
        "# =============================================================================",
        "# Definition Pattern Search",
        "# =============================================================================",
        "",
        "# Patterns for detecting definition queries",
        "DEFINITION_QUERY_PATTERNS = [",
        "    # \"class Foo\" or \"class foo\"",
        "    (r'\\bclass\\s+(\\w+)', 'class'),",
        "    # \"def bar\" or \"function bar\"",
        "    (r'\\bdef\\s+(\\w+)', 'function'),",
        "    (r'\\bfunction\\s+(\\w+)', 'function'),",
        "    # \"method baz\"",
        "    (r'\\bmethod\\s+(\\w+)', 'method'),",
        "]",
        "",
        "# Regex patterns for finding definitions in source code",
        "# Format: (pattern_template, definition_type)",
        "# pattern_template uses {name} placeholder for the identifier",
        "DEFINITION_SOURCE_PATTERNS = {",
        "    'python_class': r'^class\\s+{name}\\b[^:]*:',",
        "    'python_function': r'^def\\s+{name}\\s*\\(',",
        "    'python_method': r'^\\s+def\\s+{name}\\s*\\(',",
        "    'javascript_function': r'^function\\s+{name}\\s*\\(',",
        "    'javascript_class': r'^class\\s+{name}\\b',",
        "    'javascript_const_fn': r'^const\\s+{name}\\s*=\\s*(?:async\\s*)?\\(',",
        "}",
        "",
        "# Default boost for definition matches",
        "DEFINITION_BOOST = 5.0",
        "",
        "",
        "def is_definition_query(query_text: str) -> Tuple[bool, Optional[str], Optional[str]]:",
        "    \"\"\"",
        "    Detect if a query is looking for a code definition.",
        "",
        "    Recognizes patterns like:",
        "    - \"class Minicolumn\"",
        "    - \"def compute_pagerank\"",
        "    - \"function tokenize\"",
        "    - \"method process_document\"",
        "",
        "    Args:",
        "        query_text: The search query",
        "",
        "    Returns:",
        "        Tuple of (is_definition, definition_type, identifier_name)",
        "        If not a definition query, returns (False, None, None)",
        "    \"\"\"",
        "    query_lower = query_text.strip()",
        "",
        "    for pattern, def_type in DEFINITION_QUERY_PATTERNS:",
        "        match = re.search(pattern, query_lower, re.IGNORECASE)",
        "        if match:",
        "            identifier = match.group(1)",
        "            return (True, def_type, identifier)",
        "",
        "    return (False, None, None)",
        "",
        "",
        "def find_definition_in_text(",
        "    text: str,",
        "    identifier: str,",
        "    def_type: str,",
        "    context_chars: int = 500",
        ") -> Optional[Tuple[str, int, int]]:",
        "    \"\"\"",
        "    Find a definition in source text and extract surrounding context.",
        "",
        "    Args:",
        "        text: Source code text to search",
        "        identifier: Name of the class/function/method to find",
        "        def_type: Type of definition ('class', 'function', 'method')",
        "        context_chars: Number of characters of context to include after the definition",
        "",
        "    Returns:",
        "        Tuple of (passage_text, start_char, end_char) or None if not found",
        "    \"\"\"",
        "    # Build patterns to try based on definition type",
        "    patterns_to_try = []",
        "",
        "    if def_type == 'class':",
        "        patterns_to_try = [",
        "            DEFINITION_SOURCE_PATTERNS['python_class'],",
        "            DEFINITION_SOURCE_PATTERNS['javascript_class'],",
        "        ]",
        "    elif def_type in ('function', 'method'):",
        "        patterns_to_try = [",
        "            DEFINITION_SOURCE_PATTERNS['python_function'],",
        "            DEFINITION_SOURCE_PATTERNS['python_method'],",
        "            DEFINITION_SOURCE_PATTERNS['javascript_function'],",
        "            DEFINITION_SOURCE_PATTERNS['javascript_const_fn'],",
        "        ]",
        "",
        "    # Try each pattern",
        "    for pattern_template in patterns_to_try:",
        "        pattern = pattern_template.format(name=re.escape(identifier))",
        "        match = re.search(pattern, text, re.MULTILINE | re.IGNORECASE)",
        "        if match:",
        "            # Extract context around the definition",
        "            start = max(0, match.start() - 50)  # Small lead-in for context",
        "            end = min(len(text), match.end() + context_chars)",
        "",
        "            # Try to extend to next blank line or class/function boundary",
        "            remaining = text[match.end():end]",
        "            # Look for a good boundary (blank line followed by non-indented text)",
        "            boundary_match = re.search(r'\\n\\n(?=[^\\s])', remaining)",
        "            if boundary_match:",
        "                end = match.end() + boundary_match.end()",
        "",
        "            passage = text[start:end]",
        "            return (passage, start, end)",
        "",
        "    return None",
        "",
        "",
        "def find_definition_passages(",
        "    query_text: str,",
        "    documents: Dict[str, str],",
        "    context_chars: int = 500,",
        "    boost: float = DEFINITION_BOOST",
        ") -> List[Tuple[str, str, int, int, float]]:",
        "    \"\"\"",
        "    Find definition passages for a definition query.",
        "",
        "    If the query is looking for a class/function/method definition,",
        "    directly search source files for the definition and return",
        "    high-scoring passages.",
        "",
        "    Args:",
        "        query_text: Search query (e.g., \"class Minicolumn\", \"def compute_pagerank\")",
        "        documents: Dict mapping doc_id to document text",
        "        context_chars: Characters of context to include after definition",
        "        boost: Score boost for definition matches",
        "",
        "    Returns:",
        "        List of (passage_text, doc_id, start_char, end_char, score) tuples.",
        "        Returns empty list if query is not a definition query.",
        "    \"\"\"",
        "    is_def, def_type, identifier = is_definition_query(query_text)",
        "",
        "    if not is_def or not identifier:",
        "        return []",
        "",
        "    results = []",
        "",
        "    # Search all documents for the definition",
        "    for doc_id, text in documents.items():",
        "        # Prefer source files over test files for definitions",
        "        is_test = doc_id.startswith('tests/') or '_test' in doc_id or 'test_' in doc_id",
        "",
        "        result = find_definition_in_text(text, identifier, def_type, context_chars)",
        "        if result:",
        "            passage, start, end = result",
        "            # Apply boost, with penalty for test files",
        "            score = boost * (0.6 if is_test else 1.0)",
        "            results.append((passage, doc_id, start, end, score))",
        "",
        "    # Sort by score (highest first)",
        "    results.sort(key=lambda x: -x[4])",
        "    return results",
        "",
        ""
      ],
      "lines_removed": [],
      "context_before": [
        "])",
        "",
        "# Keywords that suggest an implementation query (should prefer code)",
        "IMPLEMENTATION_KEYWORDS = frozenset([",
        "    'where', 'implement', 'code', 'function', 'class', 'method', 'variable',",
        "    'line', 'file', 'bug', 'fix', 'error', 'exception', 'call', 'invoke',",
        "    'compute', 'calculate', 'return', 'parameter', 'argument',",
        "])",
        "",
        ""
      ],
      "context_after": [
        "def is_conceptual_query(query_text: str) -> bool:",
        "    \"\"\"",
        "    Determine if a query is conceptual (should boost documentation).",
        "",
        "    Conceptual queries ask about concepts, architecture, design, or",
        "    explanations rather than specific code locations.",
        "",
        "    Args:",
        "        query_text: The search query",
        ""
      ],
      "change_type": "add"
    },
    {
      "file": "cortical/query.py",
      "function": "def find_passages_for_query(",
      "start_line": 1431,
      "lines_added": [
        "    use_semantic: bool = True,",
        "    use_definition_search: bool = True,",
        "    definition_boost: float = DEFINITION_BOOST",
        "    For definition queries (e.g., \"class Minicolumn\", \"def compute_pagerank\"),",
        "    this function will directly search for the definition pattern and inject",
        "    those results with a high score, ensuring definitions appear in top results.",
        "",
        "        use_definition_search: Whether to search for definition patterns (default True)",
        "        definition_boost: Score boost for definition matches (default 5.0)",
        "    # Check for definition query and find definition passages",
        "    definition_passages: List[Tuple[str, str, int, int, float]] = []",
        "    if use_definition_search:",
        "        docs_to_search = documents",
        "        if doc_filter:",
        "            docs_to_search = {k: v for k, v in documents.items() if k in doc_filter}",
        "        definition_passages = find_definition_passages(",
        "            query_text, docs_to_search, chunk_size, definition_boost",
        "        )",
        "",
        "    if not query_terms and not definition_passages:",
        "    # If we only have definition results, return those",
        "    if not query_terms:",
        "        return definition_passages[:top_n]",
        ""
      ],
      "lines_removed": [
        "    use_semantic: bool = True",
        "    if not query_terms:"
      ],
      "context_before": [
        "    query_text: str,",
        "    layers: Dict[CorticalLayer, HierarchicalLayer],",
        "    tokenizer: Tokenizer,",
        "    documents: Dict[str, str],",
        "    top_n: int = 5,",
        "    chunk_size: int = 512,",
        "    overlap: int = 128,",
        "    use_expansion: bool = True,",
        "    doc_filter: Optional[List[str]] = None,",
        "    semantic_relations: Optional[List[Tuple[str, str, str, float]]] = None,"
      ],
      "context_after": [
        ") -> List[Tuple[str, str, int, int, float]]:",
        "    \"\"\"",
        "    Find text passages most relevant to a query.",
        "",
        "    This is the key function for RAG systems - instead of returning document IDs,",
        "    it returns actual text passages with position information for citations.",
        "",
        "    Args:",
        "        query_text: Search query",
        "        layers: Dictionary of layers",
        "        tokenizer: Tokenizer instance",
        "        documents: Dict mapping doc_id to document text",
        "        top_n: Number of passages to return",
        "        chunk_size: Size of each chunk in characters (default 512)",
        "        overlap: Overlap between chunks in characters (default 128)",
        "        use_expansion: Whether to expand query terms",
        "        doc_filter: Optional list of doc_ids to restrict search to",
        "        semantic_relations: Optional list of semantic relations for expansion",
        "        use_semantic: Whether to use semantic relations for expansion (if available)",
        "",
        "    Returns:",
        "        List of (passage_text, doc_id, start_char, end_char, score) tuples",
        "        ranked by relevance",
        "    \"\"\"",
        "    layer0 = layers[CorticalLayer.TOKENS]",
        "",
        "    # Get expanded query terms",
        "    query_terms = get_expanded_query_terms(",
        "        query_text, layers, tokenizer,",
        "        use_expansion=use_expansion,",
        "        semantic_relations=semantic_relations,",
        "        use_semantic=use_semantic",
        "    )",
        "",
        "        return []",
        "",
        "    # Pre-compute minicolumn lookups for query terms (optimization)",
        "    term_cols = precompute_term_cols(query_terms, layer0)",
        "",
        "    # Get candidate documents",
        "    if doc_filter:",
        "        # Use provided filter directly as candidates (caller may have pre-boosted)",
        "        # Assign dummy scores since we'll re-score passages anyway",
        "        doc_scores = [(doc_id, 1.0) for doc_id in doc_filter if doc_id in documents]",
        "    else:",
        "        # No filter - get candidates via document search"
      ],
      "change_type": "modify"
    },
    {
      "file": "cortical/query.py",
      "function": "def find_passages_for_query(",
      "start_line": 1490,
      "lines_added": [
        "    # Track definition passage locations to avoid duplicates",
        "    def_locations = {(p[1], p[2], p[3]) for p in definition_passages}",
        "",
        "            # Skip if this overlaps with a definition passage",
        "            if (doc_id, start_char, end_char) in def_locations:",
        "                continue",
        "",
        "    # Combine definition passages with regular passages",
        "    all_passages = definition_passages + passages",
        "",
        "    all_passages.sort(key=lambda x: x[4], reverse=True)",
        "    return all_passages[:top_n]"
      ],
      "lines_removed": [
        "    passages.sort(key=lambda x: x[4], reverse=True)",
        "    return passages[:top_n]"
      ],
      "context_before": [
        "            query_text, layers, tokenizer,",
        "            top_n=min(len(documents), top_n * 3),",
        "            use_expansion=use_expansion,",
        "            semantic_relations=semantic_relations,",
        "            use_semantic=use_semantic",
        "        )",
        "",
        "    # Score passages within candidate documents",
        "    passages: List[Tuple[str, str, int, int, float]] = []",
        ""
      ],
      "context_after": [
        "    for doc_id, doc_score in doc_scores:",
        "        if doc_id not in documents:",
        "            continue",
        "",
        "        text = documents[doc_id]",
        "        chunks = create_chunks(text, chunk_size, overlap)",
        "",
        "        for chunk_text, start_char, end_char in chunks:",
        "            # Use fast scoring with pre-computed lookups",
        "            chunk_tokens = tokenizer.tokenize(chunk_text)",
        "            chunk_score = score_chunk_fast(",
        "                chunk_tokens, query_terms, term_cols, doc_id",
        "            )",
        "            # Combine chunk score with document score for final ranking",
        "            combined_score = chunk_score * (1 + doc_score * 0.1)",
        "",
        "            passages.append((",
        "                chunk_text,",
        "                doc_id,",
        "                start_char,",
        "                end_char,",
        "                combined_score",
        "            ))",
        "",
        "    # Sort by score and return top passages",
        "",
        "",
        "def find_documents_batch(",
        "    queries: List[str],",
        "    layers: Dict[CorticalLayer, HierarchicalLayer],",
        "    tokenizer: Tokenizer,",
        "    top_n: int = 5,",
        "    use_expansion: bool = True,",
        "    semantic_relations: Optional[List[Tuple[str, str, str, float]]] = None,",
        "    use_semantic: bool = True"
      ],
      "change_type": "modify"
    },
    {
      "file": "tests/test_query.py",
      "function": "from cortical.query import (",
      "start_line": 31,
      "lines_added": [
        "    is_definition_query,",
        "    find_definition_in_text,",
        "    find_definition_passages,",
        "    DEFINITION_QUERY_PATTERNS,",
        "    DEFINITION_SOURCE_PATTERNS,",
        "    DEFINITION_BOOST,"
      ],
      "lines_removed": [],
      "context_before": [
        "    find_passages_for_query,",
        "    find_documents_batch,",
        "    find_passages_batch,",
        "    find_relevant_concepts,",
        "    find_relation_between,",
        "    find_terms_with_relation,",
        "    complete_analogy,",
        "    complete_analogy_simple,",
        "    query_with_spreading_activation,",
        "    VALID_RELATION_CHAINS,"
      ],
      "context_after": [
        ")",
        "",
        "",
        "class TestScoreRelationPath(unittest.TestCase):",
        "    \"\"\"Test relation path scoring.\"\"\"",
        "",
        "    def test_empty_path(self):",
        "        \"\"\"Empty path should return 1.0.\"\"\"",
        "        self.assertEqual(score_relation_path([]), 1.0)",
        ""
      ],
      "change_type": "add"
    },
    {
      "file": "tests/test_query.py",
      "function": "class TestDocTypeBoostIntegration(unittest.TestCase):",
      "start_line": 1026,
      "lines_added": [
        "class TestDefinitionPatternSearch(unittest.TestCase):",
        "    \"\"\"Test definition pattern search functionality.\"\"\"",
        "",
        "    def test_is_definition_query_class(self):",
        "        \"\"\"Detect class definition queries.\"\"\"",
        "        is_def, def_type, name = is_definition_query(\"class Minicolumn\")",
        "        self.assertTrue(is_def)",
        "        self.assertEqual(def_type, 'class')",
        "        self.assertEqual(name, 'Minicolumn')",
        "",
        "    def test_is_definition_query_def(self):",
        "        \"\"\"Detect function definition queries.\"\"\"",
        "        is_def, def_type, name = is_definition_query(\"def compute_pagerank\")",
        "        self.assertTrue(is_def)",
        "        self.assertEqual(def_type, 'function')",
        "        self.assertEqual(name, 'compute_pagerank')",
        "",
        "    def test_is_definition_query_function(self):",
        "        \"\"\"Detect function keyword queries.\"\"\"",
        "        is_def, def_type, name = is_definition_query(\"function tokenize\")",
        "        self.assertTrue(is_def)",
        "        self.assertEqual(def_type, 'function')",
        "        self.assertEqual(name, 'tokenize')",
        "",
        "    def test_is_definition_query_method(self):",
        "        \"\"\"Detect method definition queries.\"\"\"",
        "        is_def, def_type, name = is_definition_query(\"method process_document\")",
        "        self.assertTrue(is_def)",
        "        self.assertEqual(def_type, 'method')",
        "        self.assertEqual(name, 'process_document')",
        "",
        "    def test_is_definition_query_not_definition(self):",
        "        \"\"\"Non-definition queries should return False.\"\"\"",
        "        is_def, def_type, name = is_definition_query(\"neural networks\")",
        "        self.assertFalse(is_def)",
        "        self.assertIsNone(def_type)",
        "        self.assertIsNone(name)",
        "",
        "    def test_is_definition_query_case_insensitive(self):",
        "        \"\"\"Definition detection should be case insensitive.\"\"\"",
        "        is_def, def_type, name = is_definition_query(\"CLASS MyClass\")",
        "        self.assertTrue(is_def)",
        "        self.assertEqual(def_type, 'class')",
        "        self.assertEqual(name, 'MyClass')",
        "",
        "    def test_find_definition_in_text_python_class(self):",
        "        \"\"\"Find Python class definitions.\"\"\"",
        "        text = '''",
        "import os",
        "",
        "class MyProcessor:",
        "    \"\"\"A processor class.\"\"\"",
        "",
        "    def __init__(self):",
        "        pass",
        "'''",
        "        result = find_definition_in_text(text, 'MyProcessor', 'class')",
        "        self.assertIsNotNone(result)",
        "        passage, start, end = result",
        "        self.assertIn('class MyProcessor:', passage)",
        "",
        "    def test_find_definition_in_text_python_function(self):",
        "        \"\"\"Find Python function definitions.\"\"\"",
        "        text = '''",
        "def compute_score(items, weights):",
        "    \"\"\"Compute weighted score.\"\"\"",
        "    total = sum(i * w for i, w in zip(items, weights))",
        "    return total / len(items)",
        "'''",
        "        result = find_definition_in_text(text, 'compute_score', 'function')",
        "        self.assertIsNotNone(result)",
        "        passage, start, end = result",
        "        self.assertIn('def compute_score(', passage)",
        "",
        "    def test_find_definition_in_text_not_found(self):",
        "        \"\"\"Return None when definition not found.\"\"\"",
        "        text = 'def other_function(): pass'",
        "        result = find_definition_in_text(text, 'nonexistent', 'function')",
        "        self.assertIsNone(result)",
        "",
        "    def test_find_definition_in_text_method(self):",
        "        \"\"\"Find method definitions (indented def).\"\"\"",
        "        text = '''",
        "class MyClass:",
        "    def my_method(self, arg):",
        "        return arg * 2",
        "'''",
        "        result = find_definition_in_text(text, 'my_method', 'method')",
        "        self.assertIsNotNone(result)",
        "        passage, start, end = result",
        "        self.assertIn('def my_method(', passage)",
        "",
        "    def test_find_definition_passages_basic(self):",
        "        \"\"\"Find definition passages from documents.\"\"\"",
        "        documents = {",
        "            'module.py': '''",
        "class TestClass:",
        "    \"\"\"A test class for demonstration.\"\"\"",
        "",
        "    def process(self):",
        "        pass",
        "''',",
        "            'other.py': 'def helper(): pass',",
        "        }",
        "        results = find_definition_passages(\"class TestClass\", documents)",
        "        self.assertTrue(len(results) > 0)",
        "        passage, doc_id, start, end, score = results[0]",
        "        self.assertEqual(doc_id, 'module.py')",
        "        self.assertIn('class TestClass:', passage)",
        "        self.assertEqual(score, DEFINITION_BOOST)  # No test file penalty",
        "",
        "    def test_find_definition_passages_test_file_penalty(self):",
        "        \"\"\"Test files should have lower score.\"\"\"",
        "        documents = {",
        "            'src/module.py': 'class MyClass: pass',",
        "            'tests/test_module.py': 'class MyClass: pass',",
        "        }",
        "        results = find_definition_passages(\"class MyClass\", documents)",
        "        self.assertEqual(len(results), 2)",
        "",
        "        # Sort by score descending",
        "        results.sort(key=lambda x: -x[4])",
        "",
        "        # Source file should rank higher",
        "        self.assertEqual(results[0][1], 'src/module.py')",
        "        self.assertEqual(results[1][1], 'tests/test_module.py')",
        "        self.assertGreater(results[0][4], results[1][4])",
        "",
        "    def test_find_definition_passages_not_definition_query(self):",
        "        \"\"\"Non-definition queries return empty list.\"\"\"",
        "        documents = {'test.py': 'class Foo: pass'}",
        "        results = find_definition_passages(\"neural networks\", documents)",
        "        self.assertEqual(results, [])",
        "",
        "",
        "class TestDefinitionSearchIntegration(unittest.TestCase):",
        "    \"\"\"Integration tests for definition search in passage retrieval.\"\"\"",
        "",
        "    def setUp(self):",
        "        \"\"\"Set up processor with code documents.\"\"\"",
        "        self.processor = CorticalTextProcessor()",
        "",
        "        # Add a code document with class and function definitions",
        "        self.processor.process_document('cortical/minicolumn.py', '''",
        "\"\"\"Minicolumn module for cortical processing.\"\"\"",
        "",
        "from dataclasses import dataclass",
        "from typing import Dict, List, Optional",
        "",
        "class Minicolumn:",
        "    \"\"\"",
        "    Core data structure representing a minicolumn in the cortical model.",
        "",
        "    A minicolumn stores information about a single concept at a specific",
        "    layer in the hierarchy.",
        "",
        "    Attributes:",
        "        id: Unique identifier",
        "        content: The text content (word, bigram, etc.)",
        "        layer: Which layer this belongs to (0-3)",
        "    \"\"\"",
        "",
        "    def __init__(self, id: str, content: str, layer: int):",
        "        self.id = id",
        "        self.content = content",
        "        self.layer = layer",
        "        self.lateral_connections: Dict[str, float] = {}",
        "        self.pagerank: float = 0.0",
        "        self.tfidf: float = 0.0",
        "",
        "    def add_connection(self, target_id: str, weight: float = 1.0):",
        "        \"\"\"Add a lateral connection to another minicolumn.\"\"\"",
        "        if target_id in self.lateral_connections:",
        "            self.lateral_connections[target_id] += weight",
        "        else:",
        "            self.lateral_connections[target_id] = weight",
        "''')",
        "",
        "        self.processor.process_document('tests/test_minicolumn.py', '''",
        "\"\"\"Tests for minicolumn module.\"\"\"",
        "",
        "import unittest",
        "from cortical.minicolumn import Minicolumn",
        "",
        "class TestMinicolumn(unittest.TestCase):",
        "    \"\"\"Test Minicolumn class.\"\"\"",
        "",
        "    def test_init(self):",
        "        col = Minicolumn(\"L0_test\", \"test\", 0)",
        "        self.assertEqual(col.id, \"L0_test\")",
        "        self.assertEqual(col.content, \"test\")",
        "",
        "    def test_add_connection(self):",
        "        col = Minicolumn(\"L0_a\", \"a\", 0)",
        "        col.add_connection(\"L0_b\", 0.5)",
        "        self.assertIn(\"L0_b\", col.lateral_connections)",
        "''')",
        "",
        "        self.processor.compute_all()",
        "",
        "    def test_definition_search_finds_class(self):",
        "        \"\"\"Definition search should find actual class definition.\"\"\"",
        "        results = self.processor.find_passages_for_query(",
        "            \"class Minicolumn\",",
        "            top_n=5,",
        "            use_definition_search=True",
        "        )",
        "",
        "        self.assertTrue(len(results) > 0)",
        "",
        "        # First result should be from the source file, not the test",
        "        passage, doc_id, start, end, score = results[0]",
        "        self.assertEqual(doc_id, 'cortical/minicolumn.py')",
        "        self.assertIn('class Minicolumn', passage)",
        "",
        "    def test_definition_search_finds_method(self):",
        "        \"\"\"Definition search should find method definitions.\"\"\"",
        "        results = self.processor.find_passages_for_query(",
        "            \"def add_connection\",",
        "            top_n=5,",
        "            use_definition_search=True",
        "        )",
        "",
        "        self.assertTrue(len(results) > 0)",
        "        passage, doc_id, start, end, score = results[0]",
        "        self.assertIn('def add_connection', passage)",
        "",
        "    def test_definition_search_disabled(self):",
        "        \"\"\"When disabled, definition search should not run.\"\"\"",
        "        # With a definition query but definition search disabled",
        "        results_disabled = self.processor.find_passages_for_query(",
        "            \"class Minicolumn\",",
        "            top_n=5,",
        "            use_definition_search=False",
        "        )",
        "",
        "        results_enabled = self.processor.find_passages_for_query(",
        "            \"class Minicolumn\",",
        "            top_n=5,",
        "            use_definition_search=True",
        "        )",
        "",
        "        # Enabled should have higher score for definition",
        "        if results_disabled and results_enabled:",
        "            # Definition search should boost the actual definition",
        "            self.assertGreaterEqual(results_enabled[0][4], results_disabled[0][4])",
        "",
        "    def test_processor_has_definition_methods(self):",
        "        \"\"\"Processor should have definition search methods.\"\"\"",
        "        self.assertTrue(hasattr(self.processor, 'is_definition_query'))",
        "        self.assertTrue(hasattr(self.processor, 'find_definition_passages'))",
        "",
        "    def test_is_definition_query_via_processor(self):",
        "        \"\"\"Test is_definition_query via processor wrapper.\"\"\"",
        "        is_def, def_type, name = self.processor.is_definition_query(\"class Minicolumn\")",
        "        self.assertTrue(is_def)",
        "        self.assertEqual(def_type, 'class')",
        "        self.assertEqual(name, 'Minicolumn')",
        "",
        "    def test_find_definition_passages_via_processor(self):",
        "        \"\"\"Test find_definition_passages via processor wrapper.\"\"\"",
        "        results = self.processor.find_definition_passages(\"class Minicolumn\")",
        "        self.assertTrue(len(results) > 0)",
        "        passage, doc_id, start, end, score = results[0]",
        "        self.assertIn('class Minicolumn', passage)",
        "",
        ""
      ],
      "lines_removed": [],
      "context_before": [
        "        )",
        "",
        "        self.assertTrue(len(results) > 0)",
        "",
        "    def test_processor_wrapper_exists(self):",
        "        \"\"\"Processor should have find_documents_with_boost method.\"\"\"",
        "        self.assertTrue(hasattr(self.processor, 'find_documents_with_boost'))",
        "        self.assertTrue(hasattr(self.processor, 'is_conceptual_query'))",
        "",
        ""
      ],
      "context_after": [
        "if __name__ == '__main__':",
        "    unittest.main()"
      ],
      "change_type": "add"
    }
  ],
  "hour_of_day": 3,
  "day_of_week": "Thursday",
  "seconds_since_last_commit": -383474,
  "is_merge": false,
  "is_initial": false,
  "parent_count": 1,
  "session_id": null,
  "related_chats": [],
  "ci_result": null,
  "reverted": false,
  "amended": false
}