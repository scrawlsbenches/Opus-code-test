{
  "hash": "38fb4f7f0a8ae9d9c8b2ee3a82f44741990eb531",
  "message": "Add incremental document indexing (Task 15)",
  "author": "Claude",
  "timestamp": "2025-12-09 21:06:19 +0000",
  "branch": "claude/multi-index-design-DvifZ",
  "files_changed": [
    "TASK_LIST.md",
    "cortical/processor.py",
    "tests/test_processor.py"
  ],
  "insertions": 460,
  "deletions": 12,
  "hunks": [
    {
      "file": "TASK_LIST.md",
      "function": "for t, c in layer.minicolumns.items():",
      "start_line": 395,
      "lines_added": [
        "**Status:** [x] Completed",
        "**Solution Applied:**",
        "1. Added staleness tracking with `_stale_computations` set and computation type constants",
        "2. Added `add_document_incremental()` method with selectable recomputation levels:",
        "   - `'none'`: Just add document, mark computations stale (fastest)",
        "   - `'tfidf'`: Recompute TF-IDF only (good for search)",
        "   - `'full'`: Run full `compute_all()` (most accurate)",
        "3. Added `add_documents_batch()` for efficient batch additions with single recomputation",
        "4. Added `recompute()` method with levels: `'stale'`, `'tfidf'`, `'full'`",
        "5. Added helper methods: `is_stale()`, `get_stale_computations()`, `_mark_fresh()`, `_mark_all_stale()`",
        "**Files Modified:**",
        "- `cortical/processor.py` - Added incremental indexing methods (~200 lines)",
        "- `tests/test_processor.py` - Added 15 tests for incremental indexing",
        "",
        "**Usage Examples:**",
        "```python",
        "# Quick incremental update (TF-IDF only)",
        "processor.add_document_incremental(\"new_doc\", \"content\", recompute='tfidf')",
        "",
        "# Batch add with deferred recomputation",
        "processor.add_document_incremental(\"doc1\", \"content1\", recompute='none')",
        "processor.add_document_incremental(\"doc2\", \"content2\", recompute='none')",
        "processor.recompute(level='full')  # Single recomputation for batch",
        "",
        "# Efficient batch API",
        "docs = [(\"doc1\", \"content1\", {\"source\": \"web\"}), (\"doc2\", \"content2\", None)]",
        "processor.add_documents_batch(docs, recompute='full')",
        "```"
      ],
      "lines_removed": [
        "**Status:** [ ] Not Started",
        "**Implementation Steps:**",
        "1. Add `add_document_incremental()` method",
        "2. Support selective recomputation (TF-IDF only, or full)",
        "3. Track which computations are stale",
        "4. Allow batch updates with single recomputation",
        "**Files to Modify:**",
        "- `cortical/processor.py` - Add incremental method (~40 lines)"
      ],
      "context_before": [
        "",
        "# Should use:",
        "neighbor = layer.get_by_id(neighbor_id)",
        "```",
        "",
        "---",
        "",
        "### 15. Add Incremental Document Indexing",
        "",
        "**File:** `cortical/processor.py`"
      ],
      "context_after": [
        "",
        "**Problem:**",
        "Adding a document requires calling `compute_all()` which recomputes everything. For RAG systems with frequent updates, this is inefficient.",
        "",
        "",
        "",
        "---",
        "",
        "## RAG Low Priority",
        "",
        "### 16. Document Magic Numbers in Gap Detection",
        "",
        "**File:** `cortical/gaps.py`",
        "**Lines:** 62, 76, 99",
        "**Status:** [ ] Deferred (carried over)"
      ],
      "change_type": "modify"
    },
    {
      "file": "TASK_LIST.md",
      "function": "def find_documents_batch(self, queries: List[str], top_n: int = 5):",
      "start_line": 479,
      "lines_added": [
        "| Medium | Add incremental indexing | ✅ Completed | RAG |",
        "**RAG Enhancement Completion:** 6/8 tasks (75%)",
        "Ran 144 tests in 0.141s"
      ],
      "lines_removed": [
        "| Medium | Add incremental indexing | ⬜ Not Started | RAG |",
        "**RAG Enhancement Completion:** 5/8 tasks (63%)",
        "Ran 129 tests in 0.152s"
      ],
      "context_before": [
        "| Medium | Remove unused import | ✅ Completed | Bug Fix |",
        "| Medium | Add verbose parameter | ✅ Completed | Bug Fix |",
        "| Low | Add test coverage | ✅ Completed | Bug Fix |",
        "| **Critical** | **Implement chunk-level retrieval** | ✅ Completed | **RAG** |",
        "| **Critical** | **Add document metadata support** | ✅ Completed | **RAG** |",
        "| **High** | **Activate Layer 2 concepts** | ✅ Completed | **RAG** |",
        "| **High** | **Integrate semantic relations** | ✅ Completed | **RAG** |",
        "| **High** | **Persist full computed state** | ✅ Completed | **RAG** |",
        "| Medium | Fix type annotation (embeddings.py) | ✅ Completed | Bug Fix |",
        "| Medium | Optimize spectral embeddings | ✅ Completed | Performance |"
      ],
      "context_after": [
        "| Low | Document magic numbers | ⏳ Deferred | Documentation |",
        "| Low | Multi-stage ranking pipeline | ⬜ Future | RAG |",
        "| Low | Batch query API | ⬜ Future | RAG |",
        "",
        "**Bug Fix Completion:** 7/7 tasks (100%)",
        "",
        "---",
        "",
        "## Test Results",
        "",
        "```",
        "OK",
        "```",
        "",
        "All tests passing as of 2025-12-09.",
        "",
        "---",
        "",
        "*Updated from code review on 2025-12-09*"
      ],
      "change_type": "modify"
    },
    {
      "file": "cortical/processor.py",
      "function": "from . import analysis",
      "start_line": 14,
      "lines_added": [
        "    # Computation types for tracking staleness",
        "    COMP_TFIDF = 'tfidf'",
        "    COMP_PAGERANK = 'pagerank'",
        "    COMP_ACTIVATION = 'activation'",
        "    COMP_DOC_CONNECTIONS = 'doc_connections'",
        "    COMP_CONCEPTS = 'concepts'",
        "    COMP_EMBEDDINGS = 'embeddings'",
        "    COMP_SEMANTICS = 'semantics'",
        "",
        "        # Track which computations are stale and need recomputation",
        "        self._stale_computations: set = set()"
      ],
      "lines_removed": [],
      "context_before": [
        "from . import semantics",
        "from . import embeddings as emb_module",
        "from . import query as query_module",
        "from . import gaps as gaps_module",
        "from . import persistence",
        "",
        "",
        "class CorticalTextProcessor:",
        "    \"\"\"Neocortex-inspired text processing system.\"\"\"",
        ""
      ],
      "context_after": [
        "    def __init__(self, tokenizer: Optional[Tokenizer] = None):",
        "        self.tokenizer = tokenizer or Tokenizer()",
        "        self.layers: Dict[CorticalLayer, HierarchicalLayer] = {",
        "            CorticalLayer.TOKENS: HierarchicalLayer(CorticalLayer.TOKENS),",
        "            CorticalLayer.BIGRAMS: HierarchicalLayer(CorticalLayer.BIGRAMS),",
        "            CorticalLayer.CONCEPTS: HierarchicalLayer(CorticalLayer.CONCEPTS),",
        "            CorticalLayer.DOCUMENTS: HierarchicalLayer(CorticalLayer.DOCUMENTS),",
        "        }",
        "        self.documents: Dict[str, str] = {}",
        "        self.document_metadata: Dict[str, Dict[str, Any]] = {}",
        "        self.embeddings: Dict[str, List[float]] = {}",
        "        self.semantic_relations: List[Tuple[str, str, str, float]] = []",
        "",
        "    def process_document(",
        "        self,",
        "        doc_id: str,",
        "        content: str,",
        "        metadata: Optional[Dict[str, Any]] = None",
        "    ) -> Dict[str, int]:",
        "        \"\"\"",
        "        Process a document and add it to the corpus.",
        ""
      ],
      "change_type": "add"
    },
    {
      "file": "cortical/processor.py",
      "function": "class CorticalTextProcessor:",
      "start_line": 89,
      "lines_added": [
        "",
        "        # Mark all computations as stale since document corpus changed",
        "        self._mark_all_stale()",
        ""
      ],
      "lines_removed": [
        "        "
      ],
      "context_before": [
        "        ",
        "        for bigram in bigrams:",
        "            col = layer1.get_or_create_minicolumn(bigram)",
        "            col.occurrence_count += 1",
        "            col.document_ids.add(doc_id)",
        "            col.activation += 1.0",
        "            for part in bigram.split():",
        "                token_col = layer0.get_minicolumn(part)",
        "                if token_col:",
        "                    col.feedforward_sources.add(token_col.id)"
      ],
      "context_after": [
        "        return {'tokens': len(tokens), 'bigrams': len(bigrams), 'unique_tokens': len(set(tokens))}",
        "",
        "    def set_document_metadata(self, doc_id: str, **kwargs) -> None:",
        "        \"\"\"",
        "        Set or update metadata for a document.",
        "",
        "        Args:",
        "            doc_id: Document identifier",
        "            **kwargs: Metadata key-value pairs to set",
        ""
      ],
      "change_type": "modify"
    },
    {
      "file": "cortical/processor.py",
      "function": "class CorticalTextProcessor:",
      "start_line": 133,
      "lines_added": [
        "    def _mark_all_stale(self) -> None:",
        "        \"\"\"Mark all computations as stale (needing recomputation).\"\"\"",
        "        self._stale_computations = {",
        "            self.COMP_TFIDF,",
        "            self.COMP_PAGERANK,",
        "            self.COMP_ACTIVATION,",
        "            self.COMP_DOC_CONNECTIONS,",
        "            self.COMP_CONCEPTS,",
        "            self.COMP_EMBEDDINGS,",
        "            self.COMP_SEMANTICS,",
        "        }",
        "",
        "    def _mark_fresh(self, *computation_types: str) -> None:",
        "        \"\"\"Mark specified computations as fresh (up-to-date).\"\"\"",
        "        for comp in computation_types:",
        "            self._stale_computations.discard(comp)",
        "",
        "    def is_stale(self, computation_type: str) -> bool:",
        "        \"\"\"",
        "        Check if a specific computation is stale.",
        "",
        "        Args:",
        "            computation_type: One of COMP_TFIDF, COMP_PAGERANK, etc.",
        "",
        "        Returns:",
        "            True if the computation needs to be run again",
        "        \"\"\"",
        "        return computation_type in self._stale_computations",
        "",
        "    def get_stale_computations(self) -> set:",
        "        \"\"\"",
        "        Get the set of computations that are currently stale.",
        "",
        "        Returns:",
        "            Set of computation type strings that need recomputation",
        "        \"\"\"",
        "        return self._stale_computations.copy()",
        "",
        "    def add_document_incremental(",
        "        self,",
        "        doc_id: str,",
        "        content: str,",
        "        metadata: Optional[Dict[str, Any]] = None,",
        "        recompute: str = 'tfidf'",
        "    ) -> Dict[str, int]:",
        "        \"\"\"",
        "        Add a document with selective recomputation for efficiency.",
        "",
        "        Unlike process_document() + compute_all(), this method only recomputes",
        "        what's necessary based on the recompute parameter. This is more efficient",
        "        for RAG systems with frequent document updates.",
        "",
        "        Args:",
        "            doc_id: Unique identifier for the document",
        "            content: Document text content",
        "            metadata: Optional metadata dict (source, timestamp, author, etc.)",
        "            recompute: Level of recomputation to perform:",
        "                - 'none': Just add document, mark all computations stale",
        "                - 'tfidf': Recompute TF-IDF only (fast, updates term weights)",
        "                - 'full': Run compute_all() (slowest, most accurate)",
        "",
        "        Returns:",
        "            Dict with processing statistics (tokens, bigrams, unique_tokens)",
        "",
        "        Example:",
        "            >>> # Quick update for search without full recomputation",
        "            >>> processor.add_document_incremental(\"new_doc\", \"content\", recompute='tfidf')",
        "            >>>",
        "            >>> # Just queue document, recompute later in batch",
        "            >>> processor.add_document_incremental(\"doc1\", \"content1\", recompute='none')",
        "            >>> processor.add_document_incremental(\"doc2\", \"content2\", recompute='none')",
        "            >>> processor.recompute(level='full')  # Batch recomputation",
        "        \"\"\"",
        "        stats = self.process_document(doc_id, content, metadata)",
        "",
        "        if recompute == 'tfidf':",
        "            self.compute_tfidf(verbose=False)",
        "            self._mark_fresh(self.COMP_TFIDF)",
        "        elif recompute == 'full':",
        "            self.compute_all(verbose=False)",
        "            self._stale_computations.clear()",
        "        # 'none' leaves all computations marked as stale",
        "",
        "        return stats",
        "",
        "    def add_documents_batch(",
        "        self,",
        "        documents: List[Tuple[str, str, Optional[Dict[str, Any]]]],",
        "        recompute: str = 'full',",
        "        verbose: bool = True",
        "    ) -> Dict[str, Any]:",
        "        \"\"\"",
        "        Add multiple documents with a single recomputation.",
        "",
        "        More efficient than calling add_document_incremental() multiple times",
        "        when adding many documents at once.",
        "",
        "        Args:",
        "            documents: List of (doc_id, content, metadata) tuples.",
        "                       metadata can be None for documents without metadata.",
        "            recompute: Level of recomputation after all documents are added:",
        "                - 'none': Just add documents, mark all computations stale",
        "                - 'tfidf': Recompute TF-IDF only",
        "                - 'full': Run compute_all()",
        "            verbose: Print progress messages",
        "",
        "        Returns:",
        "            Dict with batch statistics:",
        "                - documents_added: Number of documents added",
        "                - total_tokens: Total tokens across all documents",
        "                - recomputation: Type of recomputation performed",
        "",
        "        Example:",
        "            >>> docs = [",
        "            ...     (\"doc1\", \"First document content\", {\"source\": \"web\"}),",
        "            ...     (\"doc2\", \"Second document content\", None),",
        "            ...     (\"doc3\", \"Third document content\", {\"author\": \"AI\"}),",
        "            ... ]",
        "            >>> processor.add_documents_batch(docs, recompute='full')",
        "        \"\"\"",
        "        total_tokens = 0",
        "        total_bigrams = 0",
        "",
        "        if verbose:",
        "            print(f\"Adding {len(documents)} documents...\")",
        "",
        "        for doc_id, content, metadata in documents:",
        "            # Use process_document directly (not add_document_incremental)",
        "            # to avoid per-document recomputation",
        "            stats = self.process_document(doc_id, content, metadata)",
        "            total_tokens += stats['tokens']",
        "            total_bigrams += stats['bigrams']",
        "",
        "        if verbose:",
        "            print(f\"Processed {total_tokens} tokens, {total_bigrams} bigrams\")",
        "",
        "        # Perform single recomputation for entire batch",
        "        if recompute == 'tfidf':",
        "            if verbose:",
        "                print(\"Recomputing TF-IDF...\")",
        "            self.compute_tfidf(verbose=False)",
        "            self._mark_fresh(self.COMP_TFIDF)",
        "        elif recompute == 'full':",
        "            if verbose:",
        "                print(\"Running full recomputation...\")",
        "            self.compute_all(verbose=False)",
        "            self._stale_computations.clear()",
        "",
        "        if verbose:",
        "            print(\"Done.\")",
        "",
        "        return {",
        "            'documents_added': len(documents),",
        "            'total_tokens': total_tokens,",
        "            'total_bigrams': total_bigrams,",
        "            'recomputation': recompute",
        "        }",
        "",
        "    def recompute(",
        "        self,",
        "        level: str = 'stale',",
        "        verbose: bool = True",
        "    ) -> Dict[str, bool]:",
        "        \"\"\"",
        "        Recompute specified analysis levels.",
        "",
        "        Use this after adding documents with recompute='none' to batch",
        "        the recomputation step.",
        "",
        "        Args:",
        "            level: What to recompute:",
        "                - 'stale': Only recompute what's marked as stale",
        "                - 'tfidf': Only TF-IDF (marks others stale)",
        "                - 'full': Run complete compute_all()",
        "            verbose: Print progress messages",
        "",
        "        Returns:",
        "            Dict indicating what was recomputed",
        "",
        "        Example:",
        "            >>> # Add documents without recomputation",
        "            >>> processor.add_document_incremental(\"doc1\", \"content\", recompute='none')",
        "            >>> processor.add_document_incremental(\"doc2\", \"content\", recompute='none')",
        "            >>> # Batch recompute",
        "            >>> processor.recompute(level='full')",
        "        \"\"\"",
        "        recomputed = {}",
        "",
        "        if level == 'full':",
        "            self.compute_all(verbose=verbose)",
        "            self._stale_computations.clear()",
        "            recomputed = {",
        "                self.COMP_ACTIVATION: True,",
        "                self.COMP_PAGERANK: True,",
        "                self.COMP_TFIDF: True,",
        "                self.COMP_DOC_CONNECTIONS: True,",
        "                self.COMP_CONCEPTS: True,",
        "            }",
        "        elif level == 'tfidf':",
        "            self.compute_tfidf(verbose=verbose)",
        "            self._mark_fresh(self.COMP_TFIDF)",
        "            recomputed[self.COMP_TFIDF] = True",
        "        elif level == 'stale':",
        "            # Recompute only what's stale, in dependency order",
        "            if self.COMP_ACTIVATION in self._stale_computations:",
        "                self.propagate_activation(verbose=verbose)",
        "                self._mark_fresh(self.COMP_ACTIVATION)",
        "                recomputed[self.COMP_ACTIVATION] = True",
        "",
        "            if self.COMP_PAGERANK in self._stale_computations:",
        "                self.compute_importance(verbose=verbose)",
        "                self._mark_fresh(self.COMP_PAGERANK)",
        "                recomputed[self.COMP_PAGERANK] = True",
        "",
        "            if self.COMP_TFIDF in self._stale_computations:",
        "                self.compute_tfidf(verbose=verbose)",
        "                self._mark_fresh(self.COMP_TFIDF)",
        "                recomputed[self.COMP_TFIDF] = True",
        "",
        "            if self.COMP_DOC_CONNECTIONS in self._stale_computations:",
        "                self.compute_document_connections(verbose=verbose)",
        "                self._mark_fresh(self.COMP_DOC_CONNECTIONS)",
        "                recomputed[self.COMP_DOC_CONNECTIONS] = True",
        "",
        "            if self.COMP_CONCEPTS in self._stale_computations:",
        "                self.build_concept_clusters(verbose=verbose)",
        "                self._mark_fresh(self.COMP_CONCEPTS)",
        "                recomputed[self.COMP_CONCEPTS] = True",
        "",
        "            if self.COMP_EMBEDDINGS in self._stale_computations:",
        "                self.compute_graph_embeddings(verbose=verbose)",
        "                self._mark_fresh(self.COMP_EMBEDDINGS)",
        "                recomputed[self.COMP_EMBEDDINGS] = True",
        "",
        "            if self.COMP_SEMANTICS in self._stale_computations:",
        "                self.extract_corpus_semantics(verbose=verbose)",
        "                self._mark_fresh(self.COMP_SEMANTICS)",
        "                recomputed[self.COMP_SEMANTICS] = True",
        "",
        "        return recomputed",
        ""
      ],
      "lines_removed": [],
      "context_before": [
        "    def get_all_document_metadata(self) -> Dict[str, Dict[str, Any]]:",
        "        \"\"\"",
        "        Get metadata for all documents.",
        "",
        "        Returns:",
        "            Dict mapping doc_id to metadata dict (deep copy)",
        "        \"\"\"",
        "        import copy",
        "        return copy.deepcopy(self.document_metadata)",
        ""
      ],
      "context_after": [
        "    def compute_all(self, verbose: bool = True, build_concepts: bool = True) -> None:",
        "        \"\"\"",
        "        Run all computation steps.",
        "",
        "        Args:",
        "            verbose: Print progress messages",
        "            build_concepts: Build concept clusters in Layer 2 (default True)",
        "                           This enables topic-based filtering and hierarchical search.",
        "        \"\"\"",
        "        if verbose:"
      ],
      "change_type": "add"
    },
    {
      "file": "cortical/processor.py",
      "function": "class CorticalTextProcessor:",
      "start_line": 158,
      "lines_added": [
        "        # Mark core computations as fresh",
        "        fresh_comps = [",
        "            self.COMP_ACTIVATION,",
        "            self.COMP_PAGERANK,",
        "            self.COMP_TFIDF,",
        "            self.COMP_DOC_CONNECTIONS,",
        "        ]",
        "        if build_concepts:",
        "            fresh_comps.append(self.COMP_CONCEPTS)",
        "        self._mark_fresh(*fresh_comps)"
      ],
      "lines_removed": [],
      "context_before": [
        "        if verbose:",
        "            print(\"Computing TF-IDF...\")",
        "        self.compute_tfidf(verbose=False)",
        "        if verbose:",
        "            print(\"Computing document connections...\")",
        "        self.compute_document_connections(verbose=False)",
        "        if build_concepts:",
        "            if verbose:",
        "                print(\"Building concept clusters...\")",
        "            self.build_concept_clusters(verbose=False)"
      ],
      "context_after": [
        "        if verbose:",
        "            print(\"Done.\")",
        "    ",
        "    def propagate_activation(self, iterations: int = 3, decay: float = 0.8, verbose: bool = True) -> None:",
        "        analysis.propagate_activation(self.layers, iterations, decay)",
        "        if verbose: print(f\"Propagated activation ({iterations} iterations)\")",
        "    ",
        "    def compute_importance(self, verbose: bool = True) -> None:",
        "        for layer_enum in [CorticalLayer.TOKENS, CorticalLayer.BIGRAMS]:",
        "            analysis.compute_pagerank(self.layers[layer_enum])"
      ],
      "change_type": "add"
    },
    {
      "file": "tests/test_processor.py",
      "function": "class TestProcessorGaps(unittest.TestCase):",
      "start_line": 353,
      "lines_added": [
        "class TestProcessorIncrementalIndexing(unittest.TestCase):",
        "    \"\"\"Test incremental document indexing functionality.\"\"\"",
        "",
        "    def setUp(self):",
        "        self.processor = CorticalTextProcessor()",
        "",
        "    def test_add_document_incremental_returns_stats(self):",
        "        \"\"\"Test that add_document_incremental returns processing stats.\"\"\"",
        "        stats = self.processor.add_document_incremental(",
        "            \"doc1\", \"Neural networks process information.\", recompute='tfidf'",
        "        )",
        "        self.assertIn('tokens', stats)",
        "        self.assertIn('bigrams', stats)",
        "        self.assertIn('unique_tokens', stats)",
        "        self.assertGreater(stats['tokens'], 0)",
        "",
        "    def test_add_document_incremental_with_metadata(self):",
        "        \"\"\"Test incremental add with metadata.\"\"\"",
        "        self.processor.add_document_incremental(",
        "            \"doc1\",",
        "            \"Test content.\",",
        "            metadata={\"source\": \"test\", \"author\": \"AI\"},",
        "            recompute='tfidf'",
        "        )",
        "        metadata = self.processor.get_document_metadata(\"doc1\")",
        "        self.assertEqual(metadata[\"source\"], \"test\")",
        "        self.assertEqual(metadata[\"author\"], \"AI\")",
        "",
        "    def test_add_document_incremental_recompute_none(self):",
        "        \"\"\"Test that recompute='none' marks computations as stale.\"\"\"",
        "        self.processor.add_document_incremental(",
        "            \"doc1\", \"Test content.\", recompute='none'",
        "        )",
        "        # Should be stale",
        "        self.assertTrue(self.processor.is_stale(CorticalTextProcessor.COMP_TFIDF))",
        "        self.assertTrue(self.processor.is_stale(CorticalTextProcessor.COMP_PAGERANK))",
        "",
        "    def test_add_document_incremental_recompute_tfidf(self):",
        "        \"\"\"Test that recompute='tfidf' only recomputes TF-IDF.\"\"\"",
        "        self.processor.add_document_incremental(",
        "            \"doc1\", \"Test content.\", recompute='tfidf'",
        "        )",
        "        # TF-IDF should be fresh",
        "        self.assertFalse(self.processor.is_stale(CorticalTextProcessor.COMP_TFIDF))",
        "        # Other computations should be stale",
        "        self.assertTrue(self.processor.is_stale(CorticalTextProcessor.COMP_PAGERANK))",
        "",
        "    def test_add_document_incremental_recompute_full(self):",
        "        \"\"\"Test that recompute='full' clears all staleness.\"\"\"",
        "        self.processor.add_document_incremental(",
        "            \"doc1\", \"Test content.\", recompute='full'",
        "        )",
        "        # All should be fresh",
        "        self.assertFalse(self.processor.is_stale(CorticalTextProcessor.COMP_TFIDF))",
        "        self.assertFalse(self.processor.is_stale(CorticalTextProcessor.COMP_PAGERANK))",
        "        self.assertFalse(self.processor.is_stale(CorticalTextProcessor.COMP_ACTIVATION))",
        "",
        "    def test_add_documents_batch_returns_stats(self):",
        "        \"\"\"Test that add_documents_batch returns batch statistics.\"\"\"",
        "        docs = [",
        "            (\"doc1\", \"First document content.\", {\"source\": \"web\"}),",
        "            (\"doc2\", \"Second document content.\", None),",
        "            (\"doc3\", \"Third document content.\", {\"author\": \"AI\"}),",
        "        ]",
        "        stats = self.processor.add_documents_batch(docs, recompute='full', verbose=False)",
        "        self.assertEqual(stats['documents_added'], 3)",
        "        self.assertIn('total_tokens', stats)",
        "        self.assertIn('total_bigrams', stats)",
        "        self.assertEqual(stats['recomputation'], 'full')",
        "",
        "    def test_add_documents_batch_preserves_metadata(self):",
        "        \"\"\"Test that batch add preserves metadata for all documents.\"\"\"",
        "        docs = [",
        "            (\"doc1\", \"First content.\", {\"type\": \"article\"}),",
        "            (\"doc2\", \"Second content.\", {\"type\": \"paper\"}),",
        "        ]",
        "        self.processor.add_documents_batch(docs, recompute='tfidf', verbose=False)",
        "        self.assertEqual(self.processor.get_document_metadata(\"doc1\")[\"type\"], \"article\")",
        "        self.assertEqual(self.processor.get_document_metadata(\"doc2\")[\"type\"], \"paper\")",
        "",
        "    def test_add_documents_batch_recompute_none(self):",
        "        \"\"\"Test batch add with no recomputation.\"\"\"",
        "        docs = [(\"doc1\", \"Content one.\", None), (\"doc2\", \"Content two.\", None)]",
        "        self.processor.add_documents_batch(docs, recompute='none', verbose=False)",
        "        self.assertTrue(self.processor.is_stale(CorticalTextProcessor.COMP_TFIDF))",
        "        self.assertEqual(len(self.processor.documents), 2)",
        "",
        "    def test_recompute_full(self):",
        "        \"\"\"Test recompute with level='full'.\"\"\"",
        "        self.processor.add_document_incremental(\"doc1\", \"Test content.\", recompute='none')",
        "        recomputed = self.processor.recompute(level='full', verbose=False)",
        "        self.assertIn(CorticalTextProcessor.COMP_TFIDF, recomputed)",
        "        self.assertIn(CorticalTextProcessor.COMP_PAGERANK, recomputed)",
        "        self.assertFalse(self.processor.is_stale(CorticalTextProcessor.COMP_TFIDF))",
        "",
        "    def test_recompute_tfidf(self):",
        "        \"\"\"Test recompute with level='tfidf'.\"\"\"",
        "        self.processor.add_document_incremental(\"doc1\", \"Test content.\", recompute='none')",
        "        recomputed = self.processor.recompute(level='tfidf', verbose=False)",
        "        self.assertEqual(recomputed, {CorticalTextProcessor.COMP_TFIDF: True})",
        "        self.assertFalse(self.processor.is_stale(CorticalTextProcessor.COMP_TFIDF))",
        "        # Others still stale",
        "        self.assertTrue(self.processor.is_stale(CorticalTextProcessor.COMP_PAGERANK))",
        "",
        "    def test_recompute_stale_only(self):",
        "        \"\"\"Test recompute with level='stale' (only recomputes stale items).\"\"\"",
        "        self.processor.add_document_incremental(\"doc1\", \"Test content.\", recompute='tfidf')",
        "        # Now only pagerank, activation, etc. are stale",
        "        recomputed = self.processor.recompute(level='stale', verbose=False)",
        "        # TF-IDF should NOT be in recomputed (it was already fresh)",
        "        self.assertNotIn(CorticalTextProcessor.COMP_TFIDF, recomputed)",
        "        # Others should be recomputed",
        "        self.assertIn(CorticalTextProcessor.COMP_PAGERANK, recomputed)",
        "",
        "    def test_get_stale_computations(self):",
        "        \"\"\"Test get_stale_computations returns correct set.\"\"\"",
        "        self.processor.add_document_incremental(\"doc1\", \"Test content.\", recompute='tfidf')",
        "        stale = self.processor.get_stale_computations()",
        "        self.assertNotIn(CorticalTextProcessor.COMP_TFIDF, stale)",
        "        self.assertIn(CorticalTextProcessor.COMP_PAGERANK, stale)",
        "",
        "    def test_is_stale(self):",
        "        \"\"\"Test is_stale returns correct boolean.\"\"\"",
        "        self.processor.add_document_incremental(\"doc1\", \"Test content.\", recompute='none')",
        "        self.assertTrue(self.processor.is_stale(CorticalTextProcessor.COMP_TFIDF))",
        "        self.processor.compute_tfidf(verbose=False)",
        "        self.processor._mark_fresh(CorticalTextProcessor.COMP_TFIDF)",
        "        self.assertFalse(self.processor.is_stale(CorticalTextProcessor.COMP_TFIDF))",
        "",
        "    def test_incremental_workflow(self):",
        "        \"\"\"Test typical incremental indexing workflow.\"\"\"",
        "        # Initial corpus",
        "        self.processor.process_document(\"doc1\", \"Neural networks process information.\")",
        "        self.processor.compute_all(verbose=False)",
        "",
        "        # Add new documents incrementally",
        "        self.processor.add_document_incremental(",
        "            \"doc2\", \"Machine learning algorithms.\", recompute='tfidf'",
        "        )",
        "",
        "        # Search should work",
        "        results = self.processor.find_documents_for_query(\"neural\", top_n=2)",
        "        self.assertIsInstance(results, list)",
        "",
        "        # Full recompute when needed",
        "        self.processor.recompute(level='full', verbose=False)",
        "        self.assertEqual(len(self.processor.get_stale_computations()), 0)",
        "",
        "    def test_batch_then_query(self):",
        "        \"\"\"Test batch add followed by querying.\"\"\"",
        "        docs = [",
        "            (\"neural\", \"Neural networks deep learning AI.\", None),",
        "            (\"ml\", \"Machine learning algorithms models.\", None),",
        "            (\"data\", \"Data processing storage retrieval.\", None),",
        "        ]",
        "        self.processor.add_documents_batch(docs, recompute='full', verbose=False)",
        "",
        "        results = self.processor.find_documents_for_query(\"neural networks\", top_n=3)",
        "        self.assertGreater(len(results), 0)",
        "        # The neural doc should rank highest",
        "        self.assertEqual(results[0][0], \"neural\")",
        "",
        ""
      ],
      "lines_removed": [],
      "context_before": [
        "        self.assertIn('isolated_documents', gaps)",
        "        self.assertIn('weak_topics', gaps)",
        "        self.assertIn('coverage_score', gaps)",
        "",
        "    def test_detect_anomalies(self):",
        "        \"\"\"Test anomaly detection.\"\"\"",
        "        anomalies = self.processor.detect_anomalies(threshold=0.1)",
        "        self.assertIsInstance(anomalies, list)",
        "",
        ""
      ],
      "context_after": [
        "if __name__ == \"__main__\":",
        "    unittest.main(verbosity=2)"
      ],
      "change_type": "add"
    }
  ],
  "hour_of_day": 21,
  "day_of_week": "Tuesday",
  "seconds_since_last_commit": -491909,
  "is_merge": false,
  "is_initial": false,
  "parent_count": 1,
  "session_id": null,
  "related_chats": [],
  "ci_result": null,
  "reverted": false,
  "amended": false
}