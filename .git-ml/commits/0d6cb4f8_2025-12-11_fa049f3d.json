{
  "hash": "0d6cb4f82b934cd5b46e8b85efef38dcbd3c4853",
  "message": "Add doc-type boosting to passage-level search (Task #66)",
  "author": "Claude",
  "timestamp": "2025-12-11 03:16:22 +0000",
  "branch": "claude/multi-index-design-DvifZ",
  "files_changed": [
    "TASK_LIST.md",
    "cortical/processor.py",
    "cortical/query.py",
    "tests/test_query.py"
  ],
  "insertions": 256,
  "deletions": 35,
  "hunks": [
    {
      "file": "TASK_LIST.md",
      "function": "def get_doc_type(doc_id: str) -> str:",
      "start_line": 2315,
      "lines_added": [
        "**Files:** `cortical/query.py`, `cortical/processor.py`, `tests/test_query.py`",
        "**Status:** [x] Completed (2025-12-11)",
        "**Solution Applied:**",
        "1. Added `apply_doc_boost` parameter to `find_passages_for_query()` (default True)",
        "2. Added `auto_detect_intent` parameter to auto-boost docs for conceptual queries (default True)",
        "3. Added `prefer_docs` parameter to always boost documentation (default False)",
        "4. Added `custom_boosts` parameter for custom boost factors",
        "5. Passage scores are multiplied by doc-type boost factor when appropriate",
        "6. Definition passages also receive doc-type boost",
        "7. Added processor wrappers with same parameters",
        "**Files Modified:**",
        "- `cortical/query.py` - Extended find_passages_for_query with boost parameters",
        "- `cortical/processor.py` - Updated processor wrapper",
        "- `tests/test_query.py` - Added 6 new tests",
        "**Usage:**",
        "# Auto-detect conceptual queries and boost docs (default)",
        "results = processor.find_passages_for_query(\"what is PageRank algorithm\")",
        "# Force docs preference",
        "results = processor.find_passages_for_query(\"PageRank\", prefer_docs=True)",
        "# Disable boosting (raw TF-IDF)",
        "results = processor.find_passages_for_query(\"PageRank\", apply_doc_boost=False)",
        "",
        "# Custom boost factors",
        "results = processor.find_passages_for_query(",
        "    \"query\",",
        "    custom_boosts={'docs': 2.0, 'code': 0.8, 'test': 0.5}",
        ")",
        "| 66 | Medium | Add doc-type boost to passage search | [x] Completed | Search Quality |"
      ],
      "lines_removed": [
        "**Files:** `cortical/query.py`, `scripts/search_codebase.py`",
        "**Status:** [ ] Not Started",
        "**Evidence (2025-12-11 dog-fooding):**",
        "```",
        "# Document-level search correctly ranks docs:",
        "TASK_LIST.md: 9.837 (root_docs)",
        "CLAUDE.md: 8.146 (root_docs)  ← Documentation found",
        "",
        "# But passage search returns code first:",
        "[1] [CODE] cortical/chunk_index.py:291 Score: 2.549",
        "[2] [TEST] tests/test_chunk_indexing.py:77 Score: 2.157",
        "# CLAUDE.md \"Chunk Compaction\" section not in top 5",
        "```",
        "**Solution:**",
        "Propagate doc-type boost to passage scoring:",
        "1. After chunking documents, apply `get_doc_type_boost()` to passage scores",
        "2. For conceptual queries (`is_conceptual_query()`), multiply passage score by doc-type boost",
        "3. Re-rank passages after boosting",
        "**Implementation Sketch:**",
        "def find_passages_for_query(..., apply_doc_boost: bool = True):",
        "    # ... existing passage retrieval ...",
        "    if apply_doc_boost and is_conceptual_query(query_text):",
        "        boosted_passages = []",
        "        for passage, doc_id, start, end, score in passages:",
        "            boost = get_doc_type_boost(doc_id, doc_metadata)",
        "            boosted_passages.append((passage, doc_id, start, end, score * boost))",
        "        passages = sorted(boosted_passages, key=lambda x: -x[4])",
        "    return passages[:top_n]",
        "| 66 | Medium | Add doc-type boost to passage search | [ ] Not Started | Search Quality |"
      ],
      "context_before": [
        "    elif doc_id.startswith('tests/'):",
        "        return 'TEST'",
        "    else:",
        "        return 'CODE'",
        "```",
        "",
        "---",
        "",
        "### 66. Add Doc-Type Boosting to Passage-Level Search",
        ""
      ],
      "context_after": [
        "**Priority:** Medium",
        "",
        "**Problem:**",
        "Document-level search correctly applies doc-type boosting (CLAUDE.md ranks #3 for \"chunk compaction\"), but passage-level search (`find_passages_for_query`) returns raw TF-IDF scores without boosting. This causes code snippets with keyword matches to rank higher than documentation passages for conceptual queries.",
        "",
        "",
        "",
        "```python",
        "",
        "",
        "```",
        "",
        "---",
        "",
        "## Dog-Fooding Summary",
        "",
        "| # | Priority | Task | Status | Category |",
        "|---|----------|------|--------|----------|",
        "| 65 | High | Add document metadata to chunk indexing | [x] Completed | Infrastructure |",
        "| 63 | High | Improve search ranking for docs | [x] Completed | Search Quality |",
        "| 64 | Low | Add document type indicator | [x] Completed | UX |",
        "",
        "**Dependency Chain:** #65 → #63 → #64 (all complete), #66 extends this work",
        "",
        "**Status Update (2025-12-11):**",
        "- Document-level search now correctly boosts documentation for conceptual queries",
        "- Passage-level search still needs boosting (#66) - docs found but code ranks higher",
        "",
        "---",
        "",
        "## Code Review Summary (PR #23)"
      ],
      "change_type": "modify"
    },
    {
      "file": "TASK_LIST.md",
      "function": "def find_passages_for_query(..., apply_doc_boost: bool = True):",
      "start_line": 2393,
      "lines_added": [
        "| 66 | Medium | Add doc-type boost to passage search | [x] Completed | Search Quality |"
      ],
      "lines_removed": [
        "| 66 | Medium | Add doc-type boost to passage search | [ ] Not Started | Search Quality |"
      ],
      "context_before": [
        "**Test Results:** 691 tests passing (including 32 new tests)",
        "",
        "---",
        "",
        "## Actionable Tasks Summary (Updated 2025-12-11)",
        "",
        "| # | Priority | Task | Status | Category |",
        "|---|----------|------|--------|----------|",
        "| 41 | Medium | Create Configuration Dataclass | [x] Completed | Code Quality |",
        "| 56 | Medium | Create Usage Patterns Documentation | [x] Completed | Documentation |"
      ],
      "context_after": [
        "| 42 | Low | Add Simple Query Language Support | [ ] Not Started | Feature |",
        "| 44 | Low | Remove Deprecated feedforward_sources | [ ] Not Started | Code Quality |",
        "| 46 | Low | Standardize Return Types with Dataclasses | [ ] Not Started | Code Quality |",
        "",
        "---",
        "",
        "*Updated 2025-12-11*",
        "",
        "---",
        ""
      ],
      "change_type": "modify"
    },
    {
      "file": "cortical/processor.py",
      "function": "class CorticalTextProcessor:",
      "start_line": 1767,
      "lines_added": [
        "        definition_boost: float = 5.0,",
        "        apply_doc_boost: bool = True,",
        "        auto_detect_intent: bool = True,",
        "        prefer_docs: bool = False,",
        "        custom_boosts: Optional[Dict[str, float]] = None",
        "        For conceptual queries (e.g., \"what is PageRank\", \"explain architecture\"),",
        "        documentation passages are boosted when auto_detect_intent=True.",
        "",
        "            apply_doc_boost: Whether to apply document-type boosting (default True)",
        "            auto_detect_intent: Auto-detect conceptual queries and boost docs (default True)",
        "            prefer_docs: Always boost documentation regardless of query type (default False)",
        "            custom_boosts: Optional custom boost factors for doc types",
        "            >>> # For conceptual queries, docs are auto-boosted",
        "            >>> results = processor.find_passages_for_query(\"what is PageRank\")",
        "            definition_boost=definition_boost,",
        "            apply_doc_boost=apply_doc_boost,",
        "            doc_metadata=self.document_metadata,",
        "            auto_detect_intent=auto_detect_intent,",
        "            prefer_docs=prefer_docs,",
        "            custom_boosts=custom_boosts"
      ],
      "lines_removed": [
        "        definition_boost: float = 5.0",
        "            >>> results = processor.find_passages_for_query(\"class Minicolumn\")",
        "            definition_boost=definition_boost"
      ],
      "context_before": [
        "    def find_passages_for_query(",
        "        self,",
        "        query_text: str,",
        "        top_n: int = 5,",
        "        chunk_size: int = 512,",
        "        overlap: int = 128,",
        "        use_expansion: bool = True,",
        "        doc_filter: Optional[List[str]] = None,",
        "        use_semantic: bool = True,",
        "        use_definition_search: bool = True,"
      ],
      "context_after": [
        "    ) -> List[Tuple[str, str, int, int, float]]:",
        "        \"\"\"",
        "        Find text passages most relevant to a query (for RAG systems).",
        "",
        "        Instead of returning just document IDs, this returns actual text passages",
        "        with position information suitable for context windows and citations.",
        "",
        "        For definition queries (e.g., \"class Minicolumn\", \"def compute_pagerank\"),",
        "        the function will directly search for definition patterns and inject those",
        "        results with a high score, ensuring actual definitions appear in top results.",
        "",
        "        Args:",
        "            query_text: Search query",
        "            top_n: Number of passages to return",
        "            chunk_size: Size of each chunk in characters (default 512)",
        "            overlap: Overlap between chunks in characters (default 128)",
        "            use_expansion: Whether to expand query terms",
        "            doc_filter: Optional list of doc_ids to restrict search to",
        "            use_semantic: Whether to use semantic relations for expansion (if available)",
        "            use_definition_search: Whether to search for definition patterns (default True)",
        "            definition_boost: Score boost for definition matches (default 5.0)",
        "",
        "        Returns:",
        "            List of (passage_text, doc_id, start_char, end_char, score) tuples",
        "            ranked by relevance",
        "",
        "        Example:",
        "            >>> for passage, doc_id, start, end, score in results:",
        "            ...     print(f\"[{doc_id}:{start}-{end}] {passage[:50]}... (score: {score:.3f})\")",
        "        \"\"\"",
        "        return query_module.find_passages_for_query(",
        "            query_text,",
        "            self.layers,",
        "            self.tokenizer,",
        "            self.documents,",
        "            top_n=top_n,",
        "            chunk_size=chunk_size,",
        "            overlap=overlap,",
        "            use_expansion=use_expansion,",
        "            doc_filter=doc_filter,",
        "            semantic_relations=self.semantic_relations if use_semantic else None,",
        "            use_semantic=use_semantic,",
        "            use_definition_search=use_definition_search,",
        "        )",
        "",
        "    def is_definition_query(self, query_text: str) -> Tuple[bool, Optional[str], Optional[str]]:",
        "        \"\"\"",
        "        Detect if a query is looking for a code definition.",
        "",
        "        Recognizes patterns like:",
        "        - \"class Minicolumn\"",
        "        - \"def compute_pagerank\"",
        "        - \"function tokenize\""
      ],
      "change_type": "modify"
    },
    {
      "file": "cortical/query.py",
      "function": "def find_passages_for_query(",
      "start_line": 1595,
      "lines_added": [
        "    definition_boost: float = DEFINITION_BOOST,",
        "    apply_doc_boost: bool = True,",
        "    doc_metadata: Optional[Dict[str, Dict[str, Any]]] = None,",
        "    auto_detect_intent: bool = True,",
        "    prefer_docs: bool = False,",
        "    custom_boosts: Optional[Dict[str, float]] = None",
        "    For conceptual queries (e.g., \"what is PageRank\", \"explain architecture\"),",
        "    documentation passages are boosted to appear higher in results when",
        "    auto_detect_intent=True.",
        "",
        "        apply_doc_boost: Whether to apply document-type boosting (default True)",
        "        doc_metadata: Optional metadata dict {doc_id: {doc_type: ..., ...}}",
        "        auto_detect_intent: Auto-detect conceptual queries and boost docs (default True)",
        "        prefer_docs: Always boost documentation regardless of query type (default False)",
        "        custom_boosts: Optional custom boost factors for doc types",
        "    # Determine if we should apply doc-type boosting",
        "    should_boost = apply_doc_boost and (",
        "        prefer_docs or (auto_detect_intent and is_conceptual_query(query_text))",
        "    )",
        ""
      ],
      "lines_removed": [
        "    definition_boost: float = DEFINITION_BOOST"
      ],
      "context_before": [
        "    tokenizer: Tokenizer,",
        "    documents: Dict[str, str],",
        "    top_n: int = 5,",
        "    chunk_size: int = 512,",
        "    overlap: int = 128,",
        "    use_expansion: bool = True,",
        "    doc_filter: Optional[List[str]] = None,",
        "    semantic_relations: Optional[List[Tuple[str, str, str, float]]] = None,",
        "    use_semantic: bool = True,",
        "    use_definition_search: bool = True,"
      ],
      "context_after": [
        ") -> List[Tuple[str, str, int, int, float]]:",
        "    \"\"\"",
        "    Find text passages most relevant to a query.",
        "",
        "    This is the key function for RAG systems - instead of returning document IDs,",
        "    it returns actual text passages with position information for citations.",
        "",
        "    For definition queries (e.g., \"class Minicolumn\", \"def compute_pagerank\"),",
        "    this function will directly search for the definition pattern and inject",
        "    those results with a high score, ensuring definitions appear in top results.",
        "",
        "    Args:",
        "        query_text: Search query",
        "        layers: Dictionary of layers",
        "        tokenizer: Tokenizer instance",
        "        documents: Dict mapping doc_id to document text",
        "        top_n: Number of passages to return",
        "        chunk_size: Size of each chunk in characters (default 512)",
        "        overlap: Overlap between chunks in characters (default 128)",
        "        use_expansion: Whether to expand query terms",
        "        doc_filter: Optional list of doc_ids to restrict search to",
        "        semantic_relations: Optional list of semantic relations for expansion",
        "        use_semantic: Whether to use semantic relations for expansion (if available)",
        "        use_definition_search: Whether to search for definition patterns (default True)",
        "        definition_boost: Score boost for definition matches (default 5.0)",
        "",
        "    Returns:",
        "        List of (passage_text, doc_id, start_char, end_char, score) tuples",
        "        ranked by relevance",
        "    \"\"\"",
        "    layer0 = layers[CorticalLayer.TOKENS]",
        "",
        "    # Check for definition query and find definition passages",
        "    definition_passages: List[Tuple[str, str, int, int, float]] = []",
        "    if use_definition_search:",
        "        docs_to_search = documents",
        "        if doc_filter:",
        "            docs_to_search = {k: v for k, v in documents.items() if k in doc_filter}",
        "        definition_passages = find_definition_passages(",
        "            query_text, docs_to_search, chunk_size, definition_boost",
        "        )",
        ""
      ],
      "change_type": "modify"
    },
    {
      "file": "cortical/query.py",
      "function": "def find_passages_for_query(",
      "start_line": 1649,
      "lines_added": [
        "    # If we only have definition results, apply boosting and return",
        "        if should_boost:",
        "            definition_passages = [",
        "                (p[0], p[1], p[2], p[3], p[4] * get_doc_type_boost(p[1], doc_metadata, custom_boosts))",
        "                for p in definition_passages",
        "            ]",
        "            definition_passages.sort(key=lambda x: -x[4])"
      ],
      "lines_removed": [
        "    # If we only have definition results, return those"
      ],
      "context_before": [
        "    query_terms = get_expanded_query_terms(",
        "        query_text, layers, tokenizer,",
        "        use_expansion=use_expansion,",
        "        semantic_relations=semantic_relations,",
        "        use_semantic=use_semantic",
        "    )",
        "",
        "    if not query_terms and not definition_passages:",
        "        return []",
        ""
      ],
      "context_after": [
        "    if not query_terms:",
        "        return definition_passages[:top_n]",
        "",
        "    # Pre-compute minicolumn lookups for query terms (optimization)",
        "    term_cols = precompute_term_cols(query_terms, layer0)",
        "",
        "    # Get candidate documents",
        "    if doc_filter:",
        "        # Use provided filter directly as candidates (caller may have pre-boosted)",
        "        # Assign dummy scores since we'll re-score passages anyway",
        "        doc_scores = [(doc_id, 1.0) for doc_id in doc_filter if doc_id in documents]"
      ],
      "change_type": "modify"
    },
    {
      "file": "cortical/query.py",
      "function": "def find_passages_for_query(",
      "start_line": 1684,
      "lines_added": [
        "        # Pre-compute doc-type boost for this document",
        "        doc_type_boost = get_doc_type_boost(doc_id, doc_metadata, custom_boosts) if should_boost else 1.0",
        "",
        "            # Apply document-type boost",
        "            combined_score *= doc_type_boost",
        "",
        "    # Apply doc-type boost to definition passages too",
        "    if should_boost:",
        "        definition_passages = [",
        "            (p[0], p[1], p[2], p[3], p[4] * get_doc_type_boost(p[1], doc_metadata, custom_boosts))",
        "            for p in definition_passages",
        "        ]",
        ""
      ],
      "lines_removed": [],
      "context_before": [
        "    # Track definition passage locations to avoid duplicates",
        "    def_locations = {(p[1], p[2], p[3]) for p in definition_passages}",
        "",
        "    for doc_id, doc_score in doc_scores:",
        "        if doc_id not in documents:",
        "            continue",
        "",
        "        text = documents[doc_id]",
        "        chunks = create_chunks(text, chunk_size, overlap)",
        ""
      ],
      "context_after": [
        "        for chunk_text, start_char, end_char in chunks:",
        "            # Skip if this overlaps with a definition passage",
        "            if (doc_id, start_char, end_char) in def_locations:",
        "                continue",
        "",
        "            # Use fast scoring with pre-computed lookups",
        "            chunk_tokens = tokenizer.tokenize(chunk_text)",
        "            chunk_score = score_chunk_fast(",
        "                chunk_tokens, query_terms, term_cols, doc_id",
        "            )",
        "            # Combine chunk score with document score for final ranking",
        "            combined_score = chunk_score * (1 + doc_score * 0.1)",
        "",
        "            passages.append((",
        "                chunk_text,",
        "                doc_id,",
        "                start_char,",
        "                end_char,",
        "                combined_score",
        "            ))",
        "",
        "    # Combine definition passages with regular passages",
        "    all_passages = definition_passages + passages",
        "",
        "    # Sort by score and return top passages",
        "    all_passages.sort(key=lambda x: x[4], reverse=True)",
        "    return all_passages[:top_n]",
        "",
        "",
        "def find_documents_batch(",
        "    queries: List[str],"
      ],
      "change_type": "add"
    },
    {
      "file": "tests/test_query.py",
      "function": "class TestMinicolumn(unittest.TestCase):",
      "start_line": 1299,
      "lines_added": [
        "class TestPassageDocTypeBoost(unittest.TestCase):",
        "    \"\"\"Test doc-type boosting for passage-level search.\"\"\"",
        "",
        "    def setUp(self):",
        "        \"\"\"Set up processor with code and documentation.\"\"\"",
        "        self.processor = CorticalTextProcessor()",
        "",
        "        # Add a code file",
        "        self.processor.process_document('cortical/analysis.py', '''",
        "\"\"\"Analysis module for computing PageRank and TF-IDF.\"\"\"",
        "",
        "def compute_pagerank(layers, damping=0.85):",
        "    \"\"\"Compute PageRank scores for all minicolumns.",
        "",
        "    PageRank is an iterative algorithm that assigns importance scores",
        "    to nodes based on the structure of incoming links.",
        "",
        "    Args:",
        "        layers: Dictionary of hierarchical layers",
        "        damping: Damping factor (default 0.85)",
        "",
        "    Returns:",
        "        Dict mapping node IDs to PageRank scores",
        "    \"\"\"",
        "    # Implementation details...",
        "    pass",
        "''', metadata={'doc_type': 'code'})",
        "",
        "        # Add a documentation file",
        "        self.processor.process_document('docs/algorithms.md', '''",
        "# PageRank Algorithm",
        "",
        "PageRank is the foundational algorithm that revolutionized web search.",
        "It computes importance scores for nodes in a graph by iteratively",
        "propagating scores through connections.",
        "",
        "## How PageRank Works",
        "",
        "1. Initialize all nodes with equal score",
        "2. Iteratively update scores based on incoming links",
        "3. Apply damping factor to prevent score accumulation",
        "4. Converge when changes are below tolerance",
        "",
        "The damping factor (typically 0.85) represents the probability that",
        "a random walker continues following links rather than jumping randomly.",
        "''', metadata={'doc_type': 'docs'})",
        "",
        "        # Add a test file",
        "        self.processor.process_document('tests/test_analysis.py', '''",
        "\"\"\"Tests for analysis module.\"\"\"",
        "",
        "import unittest",
        "",
        "class TestPageRank(unittest.TestCase):",
        "    def test_compute_pagerank(self):",
        "        \"\"\"Test PageRank computation.\"\"\"",
        "        result = compute_pagerank(self.layers)",
        "        self.assertIsInstance(result, dict)",
        "",
        "    def test_pagerank_damping(self):",
        "        \"\"\"Test PageRank with custom damping.\"\"\"",
        "        result = compute_pagerank(self.layers, damping=0.9)",
        "        self.assertGreater(len(result), 0)",
        "''', metadata={'doc_type': 'test'})",
        "",
        "        self.processor.compute_all()",
        "",
        "    def test_conceptual_query_boosts_docs(self):",
        "        \"\"\"Conceptual queries should boost documentation passages.\"\"\"",
        "        # Conceptual query - should boost docs",
        "        results = self.processor.find_passages_for_query(",
        "            \"what is PageRank algorithm\",",
        "            top_n=5,",
        "            auto_detect_intent=True,",
        "            apply_doc_boost=True",
        "        )",
        "",
        "        self.assertTrue(len(results) > 0)",
        "",
        "        # Check that docs/ folder file appears in results with boost",
        "        doc_ids = [r[1] for r in results]",
        "        # With boosting, docs should be prioritized for conceptual queries",
        "        self.assertIn('docs/algorithms.md', doc_ids)",
        "",
        "    def test_prefer_docs_always_boosts(self):",
        "        \"\"\"prefer_docs=True should always boost documentation.\"\"\"",
        "        # Implementation query that would normally prefer code",
        "        results = self.processor.find_passages_for_query(",
        "            \"compute pagerank\",",
        "            top_n=5,",
        "            prefer_docs=True,",
        "            apply_doc_boost=True",
        "        )",
        "",
        "        self.assertTrue(len(results) > 0)",
        "        # Results should include docs even for implementation query",
        "",
        "    def test_disable_doc_boost(self):",
        "        \"\"\"apply_doc_boost=False should use raw scores.\"\"\"",
        "        # Same query with and without boost",
        "        results_no_boost = self.processor.find_passages_for_query(",
        "            \"explain PageRank algorithm\",",
        "            top_n=5,",
        "            apply_doc_boost=False",
        "        )",
        "",
        "        results_with_boost = self.processor.find_passages_for_query(",
        "            \"explain PageRank algorithm\",",
        "            top_n=5,",
        "            apply_doc_boost=True,",
        "            auto_detect_intent=True",
        "        )",
        "",
        "        # Both should return results",
        "        self.assertTrue(len(results_no_boost) > 0)",
        "        self.assertTrue(len(results_with_boost) > 0)",
        "",
        "        # With boosting, if doc is found, it might have higher score",
        "        # (depends on corpus content and scores)",
        "",
        "    def test_implementation_query_no_boost(self):",
        "        \"\"\"Implementation queries should not boost docs when auto_detect_intent=True.\"\"\"",
        "        # Implementation query",
        "        results = self.processor.find_passages_for_query(",
        "            \"compute pagerank function code\",",
        "            top_n=5,",
        "            auto_detect_intent=True,",
        "            apply_doc_boost=True",
        "        )",
        "",
        "        self.assertTrue(len(results) > 0)",
        "        # Implementation queries shouldn't trigger doc boost",
        "",
        "    def test_custom_boosts(self):",
        "        \"\"\"Custom boost factors should be applied.\"\"\"",
        "        custom = {'docs': 3.0, 'code': 0.5, 'test': 0.3}",
        "",
        "        results = self.processor.find_passages_for_query(",
        "            \"what is PageRank\",",
        "            top_n=5,",
        "            prefer_docs=True,",
        "            custom_boosts=custom",
        "        )",
        "",
        "        self.assertTrue(len(results) > 0)",
        "",
        "",
        "class TestPassageDocTypeBoostIntegration(unittest.TestCase):",
        "    \"\"\"Integration tests for doc-type boost in passage search.\"\"\"",
        "",
        "    def test_find_passages_has_boost_params(self):",
        "        \"\"\"find_passages_for_query should accept boost parameters.\"\"\"",
        "        processor = CorticalTextProcessor()",
        "        processor.process_document('test.py', 'def foo(): pass')",
        "        processor.compute_all()",
        "",
        "        # Should not raise",
        "        results = processor.find_passages_for_query(",
        "            \"foo\",",
        "            apply_doc_boost=True,",
        "            auto_detect_intent=True,",
        "            prefer_docs=False,",
        "            custom_boosts={'code': 1.0}",
        "        )",
        "        # Results may be empty for simple doc but params should work",
        "",
        ""
      ],
      "lines_removed": [],
      "context_before": [
        "        self.assertEqual(name, 'Minicolumn')",
        "",
        "    def test_find_definition_passages_via_processor(self):",
        "        \"\"\"Test find_definition_passages via processor wrapper.\"\"\"",
        "        results = self.processor.find_definition_passages(\"class Minicolumn\")",
        "        self.assertTrue(len(results) > 0)",
        "        passage, doc_id, start, end, score = results[0]",
        "        self.assertIn('class Minicolumn', passage)",
        "",
        ""
      ],
      "context_after": [
        "if __name__ == '__main__':",
        "    unittest.main()"
      ],
      "change_type": "add"
    }
  ],
  "hour_of_day": 3,
  "day_of_week": "Thursday",
  "seconds_since_last_commit": -383306,
  "is_merge": false,
  "is_initial": false,
  "parent_count": 1,
  "session_id": null,
  "related_chats": [],
  "ci_result": null,
  "reverted": false,
  "amended": false
}