{
  "hash": "cac3fbd066ab4c388d7125675b682726fbde93a0",
  "message": "Merge pull request #62 from scrawlsbenches/claude/deduplicate-connections-storage-01QZNtGR9ZxnHZJyYCNJTWDJ",
  "author": "scrawlsbenches",
  "timestamp": "2025-12-13 10:05:43 -0500",
  "branch": "claude/multi-index-design-DvifZ",
  "files_changed": [
    "TASK_LIST.md",
    "cortical/minicolumn.py",
    "cortical/semantics.py",
    "tests/test_coverage_gaps.py",
    "tests/unit/test_minicolumn.py"
  ],
  "insertions": 402,
  "deletions": 50,
  "hunks": [
    {
      "file": "TASK_LIST.md",
      "function": null,
      "start_line": 1,
      "lines_added": [
        "**Pending Tasks:** 24",
        "**Completed Tasks:** 223 (see archive)"
      ],
      "lines_removed": [
        "**Pending Tasks:** 25",
        "**Completed Tasks:** 222 (see archive)"
      ],
      "context_before": [
        "# Task List: Cortical Text Processor",
        "",
        "Active backlog for the Cortical Text Processor project. Completed tasks are archived in [TASK_ARCHIVE.md](TASK_ARCHIVE.md).",
        "",
        "**Last Updated:** 2025-12-13"
      ],
      "context_after": [
        "",
        "**Legacy Test Cleanup:** âœ… COMPLETE - All 8 tasks investigated (#198-205)",
        "- **KEEP (7 files, 506 tests):** Provide unique coverage not duplicated in unit tests",
        "  - #198 test_coverage_gaps.py (91 tests) - edge case coverage",
        "  - #199 test_cli_wrapper.py (96 tests) - CLI wrapper framework",
        "  - #200 test_edge_cases.py (53 tests) - robustness tests",
        "  - #201 test_incremental_indexing.py (47 tests) - script integration",
        "  - #205 Script tests: 6 files (132 tests) - scripts/ directory",
        "- **DELETED (3 files, 53 tests):** Covered by unit tests",
        "  - #202 test_intent_query.py - covered by tests/unit/test_query.py"
      ],
      "change_type": "modify"
    },
    {
      "file": "TASK_LIST.md",
      "function": "Active backlog for the Cortical Text Processor project. Completed tasks are arch",
      "start_line": 26,
      "lines_added": [],
      "lines_removed": [
        "| 192 | Deduplicate lateral_connections and typed_connections storage | Memory | - | Medium |"
      ],
      "context_before": [
        "",
        "## Active Backlog",
        "",
        "<!-- Machine-parseable format for automation -->",
        "",
        "### ðŸŸ  High (Do This Week)",
        "",
        "| # | Task | Category | Depends | Effort |",
        "|---|------|----------|---------|--------|",
        "| 184 | Implement MCP Server for Claude Desktop integration | Integration | - | Large |"
      ],
      "context_after": [
        "",
        "### ðŸŸ¡ Medium (Do This Month)",
        "",
        "| # | Task | Category | Depends | Effort |",
        "|---|------|----------|---------|--------|",
        "| 133 | Implement WAL + snapshot persistence (fault-tolerant rebuild) | Arch | 132 | Large |",
        "| 134 | Implement protobuf serialization for corpus | Arch | 132 | Medium |",
        "| 135 | Implement chunked parallel processing for full-analysis | Arch | 132 | Large |",
        "| 95 | Split processor.py into modules | Arch | - | Large |",
        "| 99 | Add input validation to public methods | CodeQual | - | Medium |"
      ],
      "change_type": "delete"
    },
    {
      "file": "TASK_LIST.md",
      "function": "Active backlog for the Cortical Text Processor project. Completed tasks are arch",
      "start_line": 96,
      "lines_added": [
        "- #192 Deduplicate connections storage - typed_connections is now single source of truth, lateral_connections is cached property (15 tests)"
      ],
      "lines_removed": [],
      "context_before": [
        "",
        "<!-- Note: Task #87 was completed 2025-12-13, moved to archive -->",
        "",
        "---",
        "",
        "## Recently Completed",
        "",
        "All completed tasks are now archived in [TASK_ARCHIVE.md](TASK_ARCHIVE.md).",
        "",
        "**Latest completions (2025-12-13):**"
      ],
      "context_after": [
        "- #198-205 Legacy test investigation COMPLETE - 8 tasks, 10 files reviewed",
        "  - DELETED 3 duplicate files (53 tests): test_behavioral.py, test_intent_query.py, test_query_optimization.py",
        "  - KEPT 7 unique files (506 tests): test_coverage_gaps.py, test_cli_wrapper.py, test_edge_cases.py, test_incremental_indexing.py, + 6 script tests",
        "- #197 Task list validation in CI - Added validate-task-list job to workflow",
        "- #186 Simplified facade methods - quick_search(), rag_retrieve(), explore() (23 tests)",
        "- #196 Spectral embeddings warning - RuntimeWarning for large graphs (>5000 terms)",
        "- #193 Unify alpha validation - retrofit_embeddings() now accepts [0,1] consistently",
        "- #194 Layer validation - Added checks for invalid layer values (0-3) in persistence/layers",
        "- #195 Stopwords import - semantics.py now uses Tokenizer.DEFAULT_STOP_WORDS",
        "- #148 Performance test refactor - Moved to small synthetic corpus (25 docs)"
      ],
      "change_type": "add"
    },
    {
      "file": "TASK_LIST.md",
      "function": "All completed tasks are now archived in [TASK_ARCHIVE.md](TASK_ARCHIVE.md).",
      "start_line": 143,
      "lines_added": [],
      "lines_removed": [
        "### 192. Deduplicate lateral_connections and typed_connections storage",
        "",
        "**Meta:** `status:pending` `priority:high` `category:memory`",
        "**Files:** `cortical/minicolumn.py`",
        "",
        "**Problem:**",
        "Every typed connection is duplicated in `lateral_connections` for backward compatibility (`minicolumn.py:209-212`). For large graphs, this doubles memory for edge weights.",
        "",
        "**Options:**",
        "1. Deprecate `lateral_connections` in favor of `typed_connections`",
        "2. Make `lateral_connections` a property that derives from `typed_connections`",
        "3. Keep both but document the trade-off",
        "",
        "**Context from code review (2025-12-13):**",
        "- Found in comprehensive code review of core classes",
        "- Memory concern for large corpora with millions of edges",
        "",
        ""
      ],
      "context_before": [
        "- `add_document(doc_id, content)` â†’ index document",
        "",
        "**Acceptance:**",
        "- [ ] Works in Claude Desktop",
        "- [ ] 5+ core tools implemented",
        "- [ ] Documentation for installation",
        "- [ ] Example MCP config file",
        "",
        "---",
        ""
      ],
      "context_after": [
        "## Unit Test Coverage Baseline",
        "",
        "âœ… **Unit test coverage as of 2025-12-13 (1,729 tests, 85% overall):**",
        "",
        "| Module | Coverage | Status | Task |",
        "|--------|----------|--------|------|",
        "| config.py | 100% | âœ… | #168 |",
        "| minicolumn.py | 100% | âœ… | #162 |",
        "| definitions.py | 100% | âœ… | #173 |",
        "| tokenizer.py | 99% | âœ… | #159 |"
      ],
      "change_type": "delete"
    },
    {
      "file": "TASK_LIST.md",
      "function": "Every typed connection is duplicated in `lateral_connections` for backward compa",
      "start_line": 207,
      "lines_added": [],
      "lines_removed": [
        "| Memory | 1 | Optimization (#192) |"
      ],
      "context_before": [
        "|----------|---------|-------------|",
        "| Arch | 6 | Architecture refactoring (#133, 134, 135, 95, 100, 101) |",
        "| CodeQual | 1 | Code quality improvements (#99) |",
        "| Testing | 1 | Test coverage (#129) |",
        "| TaskMgmt | 3 | Task management system (#106, 107, 108) |",
        "| AINav | 2 | AI assistant navigation (#117, 118) |",
        "| DevEx | 7 | Developer experience, scripts (#73-80) |",
        "| Research | 2 | Research and analysis (#140, 131) |",
        "| Samples | 1 | Sample document improvements (#130) |",
        "| Integration | 1 | MCP Server (#184) |"
      ],
      "context_after": [
        "",
        "*Updated 2025-12-13 - Unit test initiative COMPLETE (85% coverage, 1,729 tests)*",
        "",
        "---",
        "",
        "## Notes",
        "",
        "- **Effort estimates:** Small (<1 hour), Medium (1-4 hours), Large (1+ days)",
        "- **Dependencies:** Complete dependent tasks first",
        "- **Quick Context:** Key info to start task without searching"
      ],
      "change_type": "delete"
    },
    {
      "file": "cortical/minicolumn.py",
      "function": "class Minicolumn:",
      "start_line": 84,
      "lines_added": [
        "        'document_ids', '_lateral_cache', '_lateral_cache_valid', 'typed_connections',",
        "        self._lateral_cache: Dict[str, float] = {}  # Cached view of typed_connections weights",
        "        self._lateral_cache_valid: bool = True  # Cache starts valid (empty matches empty)",
        "        self.typed_connections: Dict[str, Edge] = {}  # Single source of truth for connections",
        "",
        "    @property",
        "    def lateral_connections(self) -> Dict[str, float]:",
        "        \"\"\"",
        "        Get lateral connections as a simple weight dictionary.",
        "",
        "        This is a cached view derived from typed_connections. For backward",
        "        compatibility, this returns a dict mapping target_id to weight.",
        "        The cache is invalidated when connections are added/modified.",
        "",
        "        Returns:",
        "            Dictionary mapping target_id to connection weight",
        "",
        "        Note:",
        "            This property returns a reference to the internal cache. Modifying",
        "            it directly is deprecated - use add_lateral_connection() or",
        "            set_lateral_connection_weight() instead.",
        "        \"\"\"",
        "        if not self._lateral_cache_valid:",
        "            self._lateral_cache = {",
        "                target_id: edge.weight",
        "                for target_id, edge in self.typed_connections.items()",
        "            }",
        "            self._lateral_cache_valid = True",
        "        return self._lateral_cache",
        "",
        "    @lateral_connections.setter",
        "    def lateral_connections(self, value: Dict[str, float]) -> None:",
        "        \"\"\"",
        "        Set lateral connections from a dictionary (for deserialization).",
        "",
        "        This converts simple weight entries to typed connections with",
        "        default metadata (relation_type='co_occurrence', source='corpus').",
        "",
        "        Args:",
        "            value: Dictionary mapping target_id to weight",
        "        \"\"\"",
        "        # Clear existing and rebuild from the provided dict",
        "        self.typed_connections.clear()",
        "        for target_id, weight in value.items():",
        "            self.typed_connections[target_id] = Edge(",
        "                target_id=target_id,",
        "                weight=weight,",
        "                relation_type='co_occurrence',",
        "                confidence=1.0,",
        "                source='corpus'",
        "            )",
        "        self._lateral_cache = dict(value)  # Copy to avoid external mutation",
        "        self._lateral_cache_valid = True",
        "",
        "    def _invalidate_lateral_cache(self) -> None:",
        "        \"\"\"Invalidate the lateral connections cache.\"\"\"",
        "        self._lateral_cache_valid = False",
        "",
        "        if target_id in self.typed_connections:",
        "            existing = self.typed_connections[target_id]",
        "            self.typed_connections[target_id] = Edge(",
        "                target_id=target_id,",
        "                weight=existing.weight + weight,",
        "                relation_type=existing.relation_type,",
        "                confidence=existing.confidence,",
        "                source=existing.source",
        "            )",
        "        else:",
        "            self.typed_connections[target_id] = Edge(",
        "                target_id=target_id,",
        "                weight=weight,",
        "                relation_type='co_occurrence',",
        "                confidence=1.0,",
        "                source='corpus'",
        "            )",
        "        self._invalidate_lateral_cache()",
        "        typed = self.typed_connections",
        "            if target_id in typed:",
        "                existing = typed[target_id]",
        "                typed[target_id] = Edge(",
        "                    target_id=target_id,",
        "                    weight=existing.weight + weight,",
        "                    relation_type=existing.relation_type,",
        "                    confidence=existing.confidence,",
        "                    source=existing.source",
        "                )",
        "            else:",
        "                typed[target_id] = Edge(",
        "                    target_id=target_id,",
        "                    weight=weight,",
        "                    relation_type='co_occurrence',",
        "                    confidence=1.0,",
        "                    source='corpus'",
        "                )",
        "        self._invalidate_lateral_cache()",
        "",
        "    def set_lateral_connection_weight(self, target_id: str, weight: float) -> None:",
        "        \"\"\"",
        "        Set the weight of a lateral connection directly (not additive).",
        "",
        "        Unlike add_lateral_connection() which adds to existing weight,",
        "        this method sets the weight to an exact value. Used primarily",
        "        by semantic retrofitting which needs to adjust weights directly.",
        "",
        "        Args:",
        "            target_id: ID of the target minicolumn",
        "            weight: Exact weight to set (replaces existing weight)",
        "",
        "        Note:",
        "            If the connection doesn't exist, it will be created with",
        "            default metadata (relation_type='co_occurrence', source='corpus').",
        "        \"\"\"",
        "        if target_id in self.typed_connections:",
        "            existing = self.typed_connections[target_id]",
        "            self.typed_connections[target_id] = Edge(",
        "                target_id=target_id,",
        "                weight=weight,",
        "                relation_type=existing.relation_type,",
        "                confidence=existing.confidence,",
        "                source=existing.source",
        "            )",
        "        else:",
        "            self.typed_connections[target_id] = Edge(",
        "                target_id=target_id,",
        "                weight=weight,",
        "                relation_type='co_occurrence',",
        "                confidence=1.0,",
        "                source='corpus'",
        "            )",
        "        self._invalidate_lateral_cache()"
      ],
      "lines_removed": [
        "        'document_ids', 'lateral_connections', 'typed_connections',",
        "        self.lateral_connections: Dict[str, float] = {}",
        "        self.typed_connections: Dict[str, Edge] = {}  # ConceptNet-style typed edges",
        "    ",
        "        self.lateral_connections[target_id] = (",
        "            self.lateral_connections.get(target_id, 0) + weight",
        "        )",
        "        lateral = self.lateral_connections",
        "            lateral[target_id] = lateral.get(target_id, 0) + weight"
      ],
      "context_before": [
        "",
        "    Example:",
        "        col = Minicolumn(\"L0_neural\", \"neural\", 0)",
        "        col.occurrence_count = 15",
        "        col.add_lateral_connection(\"L0_network\", 0.8)",
        "        col.add_typed_connection(\"L0_network\", 0.8, relation_type='RelatedTo')",
        "    \"\"\"",
        "",
        "    __slots__ = [",
        "        'id', 'content', 'layer', 'activation', 'occurrence_count',"
      ],
      "context_after": [
        "        'feedforward_sources', 'feedforward_connections', 'feedback_connections',",
        "        'tfidf', 'tfidf_per_doc', 'pagerank', 'cluster_id',",
        "        'doc_occurrence_counts'",
        "    ]",
        "    ",
        "    def __init__(self, id: str, content: str, layer: int):",
        "        \"\"\"",
        "        Initialize a minicolumn.",
        "        ",
        "        Args:",
        "            id: Unique identifier for this column",
        "            content: The content this column represents",
        "            layer: Layer number (0-3)",
        "        \"\"\"",
        "        self.id = id",
        "        self.content = content",
        "        self.layer = layer",
        "        self.activation = 0.0",
        "        self.occurrence_count = 0",
        "        self.document_ids: Set[str] = set()",
        "        self.feedforward_sources: Set[str] = set()  # Deprecated: use feedforward_connections",
        "        self.feedforward_connections: Dict[str, float] = {}  # Weighted links to lower layer",
        "        self.feedback_connections: Dict[str, float] = {}  # Weighted links to higher layer",
        "        self.tfidf = 0.0",
        "        self.tfidf_per_doc: Dict[str, float] = {}",
        "        self.pagerank = 1.0",
        "        self.cluster_id: Optional[int] = None",
        "        self.doc_occurrence_counts: Dict[str, int] = {}",
        "    def add_lateral_connection(self, target_id: str, weight: float = 1.0) -> None:",
        "        \"\"\"",
        "        Add or strengthen a lateral connection to another column.",
        "",
        "        Lateral connections represent associations learned through",
        "        co-occurrence (like Hebbian learning: \"neurons that fire together",
        "        wire together\").",
        "",
        "        Args:",
        "            target_id: ID of the target minicolumn",
        "            weight: Connection strength to add",
        "        \"\"\"",
        "",
        "    def add_lateral_connections_batch(self, connections: Dict[str, float]) -> None:",
        "        \"\"\"",
        "        Add or strengthen multiple lateral connections at once.",
        "",
        "        More efficient than calling add_lateral_connection() in a loop",
        "        because it reduces function call overhead.",
        "",
        "        Args:",
        "            connections: Dictionary mapping target_id to weight to add",
        "        \"\"\"",
        "        for target_id, weight in connections.items():",
        "",
        "    def add_typed_connection(",
        "        self,",
        "        target_id: str,",
        "        weight: float = 1.0,",
        "        relation_type: str = 'co_occurrence',",
        "        confidence: float = 1.0,",
        "        source: str = 'corpus'",
        "    ) -> None:",
        "        \"\"\""
      ],
      "change_type": "modify"
    },
    {
      "file": "cortical/minicolumn.py",
      "function": "class Minicolumn:",
      "start_line": 199,
      "lines_added": [
        "        # Invalidate cache so lateral_connections property rebuilds on next access",
        "        self._invalidate_lateral_cache()"
      ],
      "lines_removed": [
        "        # Also update simple lateral_connections for backward compatibility",
        "        self.lateral_connections[target_id] = (",
        "            self.lateral_connections.get(target_id, 0) + weight",
        "        )"
      ],
      "context_before": [
        "            )",
        "        else:",
        "            self.typed_connections[target_id] = Edge(",
        "                target_id=target_id,",
        "                weight=weight,",
        "                relation_type=relation_type,",
        "                confidence=confidence,",
        "                source=source",
        "            )",
        ""
      ],
      "context_after": [
        "",
        "    def get_typed_connection(self, target_id: str) -> Optional[Edge]:",
        "        \"\"\"",
        "        Get a typed connection by target ID.",
        "",
        "        Args:",
        "            target_id: ID of the target minicolumn",
        "",
        "        Returns:",
        "            Edge object if exists, None otherwise"
      ],
      "change_type": "modify"
    },
    {
      "file": "cortical/minicolumn.py",
      "function": "class Minicolumn:",
      "start_line": 333,
      "lines_added": [
        "        Handles backward compatibility: if typed_connections is present, use it.",
        "        If only lateral_connections is present (old format), convert it.",
        "",
        "",
        "        # Handle connection deserialization with backward compatibility",
        "        lateral_conn_data = data.get('lateral_connections', {})",
        "",
        "        if typed_conn_data:",
        "            # New format: deserialize typed connections directly",
        "            col.typed_connections = {",
        "                target_id: Edge.from_dict(edge_data)",
        "                for target_id, edge_data in typed_conn_data.items()",
        "            }",
        "            col._lateral_cache_valid = False  # Will rebuild on first access",
        "        elif lateral_conn_data:",
        "            # Old format: convert lateral_connections to typed_connections",
        "            col.lateral_connections = lateral_conn_data  # Uses setter",
        "        # else: both empty, nothing to do (already initialized empty)",
        ""
      ],
      "lines_removed": [
        "        col.lateral_connections = data.get('lateral_connections', {})",
        "        # Deserialize typed connections",
        "        col.typed_connections = {",
        "            target_id: Edge.from_dict(edge_data)",
        "            for target_id, edge_data in typed_conn_data.items()",
        "        }"
      ],
      "context_before": [
        "            'pagerank': self.pagerank,",
        "            'cluster_id': self.cluster_id,",
        "            'doc_occurrence_counts': self.doc_occurrence_counts",
        "        }",
        "    ",
        "    @classmethod",
        "    def from_dict(cls, data: Dict) -> 'Minicolumn':",
        "        \"\"\"",
        "        Create a minicolumn from dictionary representation.",
        ""
      ],
      "context_after": [
        "        Args:",
        "            data: Dictionary with minicolumn data",
        "",
        "        Returns:",
        "            New Minicolumn instance",
        "        \"\"\"",
        "        col = cls(data['id'], data['content'], data['layer'])",
        "        col.activation = data.get('activation', 0.0)",
        "        col.occurrence_count = data.get('occurrence_count', 0)",
        "        col.document_ids = set(data.get('document_ids', []))",
        "        typed_conn_data = data.get('typed_connections', {})",
        "        col.feedforward_sources = set(data.get('feedforward_sources', []))",
        "        col.feedforward_connections = data.get('feedforward_connections', {})",
        "        col.feedback_connections = data.get('feedback_connections', {})",
        "        col.tfidf = data.get('tfidf', 0.0)",
        "        col.tfidf_per_doc = data.get('tfidf_per_doc', {})",
        "        col.pagerank = data.get('pagerank', 1.0)",
        "        col.cluster_id = data.get('cluster_id')",
        "        col.doc_occurrence_counts = data.get('doc_occurrence_counts', {})",
        "        return col",
        "    "
      ],
      "change_type": "modify"
    },
    {
      "file": "cortical/semantics.py",
      "function": "def retrofit_connections(",
      "start_line": 442,
      "lines_added": [
        "",
        "",
        "                    col.set_lateral_connection_weight(target_id, new_weight)",
        "",
        "                    col.set_lateral_connection_weight(target_id, (1 - alpha) * semantic_weight)"
      ],
      "lines_removed": [
        "                ",
        "                ",
        "                    col.lateral_connections[target_id] = new_weight",
        "            ",
        "                    col.lateral_connections[target_id] = (1 - alpha) * semantic_weight"
      ],
      "context_before": [
        "                if neighbor_col:",
        "                    semantic_targets[neighbor_col.id] = weight",
        "            ",
        "            if not semantic_targets:",
        "                continue",
        "            ",
        "            # Adjust each connection",
        "            for target_id in list(col.lateral_connections.keys()):",
        "                original = original_weights[term].get(target_id, 0)",
        "                semantic = semantic_targets.get(target_id, 0)"
      ],
      "context_after": [
        "                # Blend original and semantic",
        "                new_weight = alpha * original + (1 - alpha) * semantic",
        "                if new_weight > 0:",
        "                    adjustment = abs(col.lateral_connections[target_id] - new_weight)",
        "                    iteration_adjustment += adjustment",
        "            # Add new semantic connections",
        "            for target_id, semantic_weight in semantic_targets.items():",
        "                if target_id not in col.lateral_connections:",
        "                    iteration_adjustment += (1 - alpha) * semantic_weight",
        "        ",
        "        total_adjustment += iteration_adjustment",
        "    ",
        "    return {",
        "        'iterations': iterations,",
        "        'alpha': alpha,",
        "        'tokens_affected': len(tokens_affected),",
        "        'total_adjustment': total_adjustment,",
        "        'relations_used': len(semantic_relations)"
      ],
      "change_type": "modify"
    },
    {
      "file": "tests/test_coverage_gaps.py",
      "function": "class TestPersistenceTypedConnections(unittest.TestCase):",
      "start_line": 1259,
      "lines_added": [
        "        # Process two separate words to create tokens without co-occurrence connections",
        "        processor.process_document(\"doc1\", \"neural\")",
        "        processor.process_document(\"doc2\", \"network\")",
        "        # Don't call compute_all() - we want to test typed edges without",
        "        # co-occurrence connections that would accumulate weights",
        "            # Low weight typed connection only"
      ],
      "lines_removed": [
        "        processor.process_document(\"doc1\", \"neural network\")",
        "        processor.compute_all(verbose=False)",
        "            # Low weight connection"
      ],
      "context_before": [
        "            # Should have edges",
        "            self.assertIn('edges', result)",
        "        finally:",
        "            os.unlink(temp_path)",
        "",
        "    def test_export_conceptnet_filters_by_weight(self):",
        "        \"\"\"Test typed edges below min_weight are excluded.\"\"\"",
        "        from cortical.persistence import export_conceptnet_json",
        "",
        "        processor = CorticalTextProcessor()"
      ],
      "context_after": [
        "",
        "        layer0 = processor.layers[CorticalLayer.TOKENS]",
        "        col1 = layer0.get_minicolumn(\"neural\")",
        "        col2 = layer0.get_minicolumn(\"network\")",
        "        if col1 and col2:",
        "            col1.add_typed_connection(col2.id, weight=0.3, relation_type='IsA', confidence=0.9)",
        "",
        "        with tempfile.NamedTemporaryFile(suffix='.json', delete=False) as f:",
        "            temp_path = f.name",
        "",
        "        try:",
        "            result = export_conceptnet_json(",
        "                temp_path,",
        "                processor.layers,",
        "                include_typed_edges=True,"
      ],
      "change_type": "modify"
    },
    {
      "file": "tests/unit/test_minicolumn.py",
      "function": "class TestSerialization:",
      "start_line": 702,
      "lines_added": [
        "",
        "",
        "# =============================================================================",
        "# CONNECTION DEDUPLICATION TESTS (Task #192)",
        "# =============================================================================",
        "",
        "",
        "class TestConnectionDeduplication:",
        "    \"\"\"",
        "    Tests for Task #192: Deduplicate lateral_connections and typed_connections.",
        "",
        "    These tests verify that:",
        "    1. typed_connections is the single source of truth",
        "    2. lateral_connections is a cached property derived from typed_connections",
        "    3. No duplicate storage occurs",
        "    4. Backward compatibility is maintained",
        "    \"\"\"",
        "",
        "    def test_add_lateral_stores_in_typed_only(self):",
        "        \"\"\"add_lateral_connection stores only in typed_connections (no duplication).\"\"\"",
        "        col = Minicolumn(\"L0_test\", \"test\", 0)",
        "        col.add_lateral_connection(\"L0_target\", 2.5)",
        "",
        "        # Should create an Edge in typed_connections",
        "        assert \"L0_target\" in col.typed_connections",
        "        edge = col.typed_connections[\"L0_target\"]",
        "        assert edge.weight == 2.5",
        "        assert edge.relation_type == \"co_occurrence\"",
        "        assert edge.source == \"corpus\"",
        "",
        "        # lateral_connections should derive from typed_connections",
        "        assert col.lateral_connections[\"L0_target\"] == 2.5",
        "",
        "    def test_lateral_connections_is_derived_view(self):",
        "        \"\"\"lateral_connections property returns dict derived from typed_connections.\"\"\"",
        "        col = Minicolumn(\"L0_test\", \"test\", 0)",
        "",
        "        # Add via typed_connections directly",
        "        col.add_typed_connection(\"L0_target\", 3.0, relation_type=\"IsA\")",
        "",
        "        # lateral_connections should reflect typed_connections weights",
        "        assert col.lateral_connections[\"L0_target\"] == 3.0",
        "",
        "    def test_cache_invalidation_on_add_lateral(self):",
        "        \"\"\"Cache is invalidated when adding lateral connection.\"\"\"",
        "        col = Minicolumn(\"L0_test\", \"test\", 0)",
        "        col.add_lateral_connection(\"L0_target1\", 1.0)",
        "",
        "        # Access to populate cache",
        "        _ = col.lateral_connections",
        "",
        "        # Add another connection",
        "        col.add_lateral_connection(\"L0_target2\", 2.0)",
        "",
        "        # Should see new connection (cache was invalidated)",
        "        assert \"L0_target2\" in col.lateral_connections",
        "        assert col.lateral_connections[\"L0_target2\"] == 2.0",
        "",
        "    def test_cache_invalidation_on_add_typed(self):",
        "        \"\"\"Cache is invalidated when adding typed connection.\"\"\"",
        "        col = Minicolumn(\"L0_test\", \"test\", 0)",
        "        col.add_lateral_connection(\"L0_target1\", 1.0)",
        "",
        "        # Access to populate cache",
        "        _ = col.lateral_connections",
        "",
        "        # Add typed connection",
        "        col.add_typed_connection(\"L0_target2\", 3.0, relation_type=\"RelatedTo\")",
        "",
        "        # Should see new connection",
        "        assert col.lateral_connections[\"L0_target2\"] == 3.0",
        "",
        "    def test_cache_invalidation_on_batch_add(self):",
        "        \"\"\"Cache is invalidated when batch adding connections.\"\"\"",
        "        col = Minicolumn(\"L0_test\", \"test\", 0)",
        "        col.add_lateral_connection(\"L0_existing\", 1.0)",
        "",
        "        # Access to populate cache",
        "        _ = col.lateral_connections",
        "",
        "        # Batch add",
        "        col.add_lateral_connections_batch({\"L0_new1\": 2.0, \"L0_new2\": 3.0})",
        "",
        "        # Should see new connections",
        "        assert col.lateral_connections[\"L0_new1\"] == 2.0",
        "        assert col.lateral_connections[\"L0_new2\"] == 3.0",
        "",
        "    def test_set_lateral_connection_weight(self):",
        "        \"\"\"set_lateral_connection_weight sets exact weight (not additive).\"\"\"",
        "        col = Minicolumn(\"L0_test\", \"test\", 0)",
        "        col.add_lateral_connection(\"L0_target\", 5.0)",
        "",
        "        # Set to specific weight (not add)",
        "        col.set_lateral_connection_weight(\"L0_target\", 2.0)",
        "",
        "        # Should be exactly 2.0, not 7.0",
        "        assert col.lateral_connections[\"L0_target\"] == 2.0",
        "        assert col.typed_connections[\"L0_target\"].weight == 2.0",
        "",
        "    def test_set_lateral_connection_weight_new_target(self):",
        "        \"\"\"set_lateral_connection_weight creates new connection if doesn't exist.\"\"\"",
        "        col = Minicolumn(\"L0_test\", \"test\", 0)",
        "        col.set_lateral_connection_weight(\"L0_new\", 3.5)",
        "",
        "        assert col.lateral_connections[\"L0_new\"] == 3.5",
        "        assert col.typed_connections[\"L0_new\"].weight == 3.5",
        "",
        "    def test_set_lateral_connection_preserves_metadata(self):",
        "        \"\"\"set_lateral_connection_weight preserves typed connection metadata.\"\"\"",
        "        col = Minicolumn(\"L0_test\", \"test\", 0)",
        "        col.add_typed_connection(\"L0_target\", 2.0, relation_type=\"IsA\", source=\"semantic\")",
        "",
        "        # Set new weight",
        "        col.set_lateral_connection_weight(\"L0_target\", 5.0)",
        "",
        "        # Weight changed but metadata preserved",
        "        edge = col.typed_connections[\"L0_target\"]",
        "        assert edge.weight == 5.0",
        "        assert edge.relation_type == \"IsA\"",
        "        assert edge.source == \"semantic\"",
        "",
        "    def test_lateral_setter_converts_to_typed(self):",
        "        \"\"\"Setting lateral_connections (e.g., from deserialize) converts to typed.\"\"\"",
        "        col = Minicolumn(\"L0_test\", \"test\", 0)",
        "",
        "        # Simulate setting from old format data",
        "        col.lateral_connections = {\"L0_target1\": 1.5, \"L0_target2\": 2.5}",
        "",
        "        # Should be stored in typed_connections",
        "        assert len(col.typed_connections) == 2",
        "        assert col.typed_connections[\"L0_target1\"].weight == 1.5",
        "        assert col.typed_connections[\"L0_target2\"].weight == 2.5",
        "",
        "        # With default metadata",
        "        assert col.typed_connections[\"L0_target1\"].relation_type == \"co_occurrence\"",
        "        assert col.typed_connections[\"L0_target1\"].source == \"corpus\"",
        "",
        "    def test_from_dict_backward_compat_lateral_only(self):",
        "        \"\"\"from_dict handles old format with only lateral_connections.\"\"\"",
        "        # Simulate old format data (before typed_connections existed)",
        "        old_format = {",
        "            \"id\": \"L0_test\",",
        "            \"content\": \"test\",",
        "            \"layer\": 0,",
        "            \"lateral_connections\": {\"L0_target1\": 1.0, \"L0_target2\": 2.0}",
        "            # No typed_connections key",
        "        }",
        "",
        "        col = Minicolumn.from_dict(old_format)",
        "",
        "        # Should be converted to typed_connections",
        "        assert len(col.typed_connections) == 2",
        "        assert col.typed_connections[\"L0_target1\"].weight == 1.0",
        "        assert col.typed_connections[\"L0_target2\"].weight == 2.0",
        "",
        "        # lateral_connections property should work",
        "        assert col.lateral_connections[\"L0_target1\"] == 1.0",
        "        assert col.lateral_connections[\"L0_target2\"] == 2.0",
        "",
        "    def test_from_dict_prefers_typed_over_lateral(self):",
        "        \"\"\"from_dict prefers typed_connections over lateral_connections if both present.\"\"\"",
        "        # Data with both (typed_connections is authoritative)",
        "        data = {",
        "            \"id\": \"L0_test\",",
        "            \"content\": \"test\",",
        "            \"layer\": 0,",
        "            \"lateral_connections\": {\"L0_target\": 1.0},  # Old data",
        "            \"typed_connections\": {",
        "                \"L0_target\": {",
        "                    \"target_id\": \"L0_target\",",
        "                    \"weight\": 5.0,  # Different weight",
        "                    \"relation_type\": \"IsA\",",
        "                    \"confidence\": 0.9,",
        "                    \"source\": \"semantic\"",
        "                }",
        "            }",
        "        }",
        "",
        "        col = Minicolumn.from_dict(data)",
        "",
        "        # Should use typed_connections data",
        "        assert col.typed_connections[\"L0_target\"].weight == 5.0",
        "        assert col.typed_connections[\"L0_target\"].relation_type == \"IsA\"",
        "        assert col.lateral_connections[\"L0_target\"] == 5.0",
        "",
        "    def test_no_memory_duplication(self):",
        "        \"\"\"Verify there's no duplicate storage in internal data structures.\"\"\"",
        "        col = Minicolumn(\"L0_test\", \"test\", 0)",
        "",
        "        # Add connections both ways",
        "        col.add_lateral_connection(\"L0_lateral\", 1.0)",
        "        col.add_typed_connection(\"L0_typed\", 2.0, relation_type=\"IsA\")",
        "",
        "        # Both should only exist in typed_connections",
        "        assert len(col.typed_connections) == 2",
        "        assert \"L0_lateral\" in col.typed_connections",
        "        assert \"L0_typed\" in col.typed_connections",
        "",
        "        # _lateral_cache should be invalid or empty until accessed",
        "        # (implementation detail, but we can verify no pre-populated duplicate)",
        "        # After accessing lateral_connections, cache is populated",
        "        _ = col.lateral_connections",
        "        assert col._lateral_cache_valid is True",
        "",
        "    def test_lateral_connections_reflects_weight_changes(self):",
        "        \"\"\"lateral_connections property reflects changes to typed_connections weights.\"\"\"",
        "        col = Minicolumn(\"L0_test\", \"test\", 0)",
        "        col.add_lateral_connection(\"L0_target\", 1.0)",
        "",
        "        assert col.lateral_connections[\"L0_target\"] == 1.0",
        "",
        "        # Accumulate weight",
        "        col.add_lateral_connection(\"L0_target\", 2.0)",
        "",
        "        # Should reflect accumulated weight",
        "        assert col.lateral_connections[\"L0_target\"] == 3.0",
        "",
        "    def test_empty_minicolumn_lateral_connections(self):",
        "        \"\"\"Empty minicolumn returns empty lateral_connections.\"\"\"",
        "        col = Minicolumn(\"L0_test\", \"test\", 0)",
        "        assert col.lateral_connections == {}",
        "        assert col.typed_connections == {}",
        "",
        "    def test_add_lateral_preserves_existing_typed_metadata(self):",
        "        \"\"\"add_lateral_connection preserves existing typed connection metadata.\"\"\"",
        "        col = Minicolumn(\"L0_test\", \"test\", 0)",
        "",
        "        # Add typed connection with metadata",
        "        col.add_typed_connection(\"L0_target\", 2.0, relation_type=\"IsA\", source=\"semantic\")",
        "",
        "        # Add more weight via lateral (which should preserve metadata)",
        "        col.add_lateral_connection(\"L0_target\", 3.0)",
        "",
        "        edge = col.typed_connections[\"L0_target\"]",
        "        assert edge.weight == 5.0  # Accumulated",
        "        assert edge.relation_type == \"IsA\"  # Preserved",
        "        assert edge.source == \"semantic\"  # Preserved"
      ],
      "lines_removed": [],
      "context_before": [
        "        assert restored.document_ids == {\"doc1\", \"doc2\"}",
        "        assert restored.lateral_connections[\"L0_network\"] == 2.0",
        "        assert \"L0_brain\" in restored.typed_connections",
        "        assert restored.feedforward_connections[\"L0_component\"] == 1.0",
        "        assert restored.feedback_connections[\"L1_bigram\"] == 2.0",
        "        assert restored.tfidf == 4.5",
        "        assert restored.tfidf_per_doc == {\"doc1\": 3.0, \"doc2\": 6.0}",
        "        assert restored.pagerank == 0.7",
        "        assert restored.cluster_id == 3",
        "        assert restored.doc_occurrence_counts == {\"doc1\": 10, \"doc2\": 5}"
      ],
      "context_after": [],
      "change_type": "add"
    }
  ],
  "hour_of_day": 15,
  "day_of_week": "Saturday",
  "seconds_since_last_commit": -167945,
  "is_merge": true,
  "is_initial": false,
  "parent_count": 2,
  "session_id": null,
  "related_chats": [],
  "ci_result": null,
  "reverted": false,
  "amended": false
}