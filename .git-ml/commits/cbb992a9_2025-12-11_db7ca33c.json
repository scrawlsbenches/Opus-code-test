{
  "hash": "cbb992a906815d0e441adb12cd34559e063ec079",
  "message": "Improve CLAUDE.md for AI assistant usability",
  "author": "Claude",
  "timestamp": "2025-12-11 12:10:43 +0000",
  "branch": "claude/multi-index-design-DvifZ",
  "files_changed": [
    "CLAUDE.md"
  ],
  "insertions": 111,
  "deletions": 12,
  "hunks": [
    {
      "file": "CLAUDE.md",
      "function": "Layer 3 (DOCUMENTS) → Full documents          [IT analogy: objects]",
      "start_line": 30,
      "lines_added": [
        "├── processor.py      # Main orchestrator (2,301 lines) - START HERE",
        "├── query.py          # Search, retrieval, query expansion (2,719 lines)",
        "├── analysis.py       # Graph algorithms: PageRank, TF-IDF, clustering (1,123 lines)",
        "├── semantics.py      # Relation extraction, inheritance, retrofitting (915 lines)",
        "├── persistence.py    # Save/load with full state preservation (606 lines)",
        "├── chunk_index.py    # Git-friendly chunk-based storage (574 lines)",
        "├── tokenizer.py      # Tokenization, stemming, stop word removal (398 lines)",
        "├── minicolumn.py     # Core data structure with typed Edge connections (357 lines)",
        "├── config.py         # CorticalConfig dataclass with validation (352 lines)",
        "├── fingerprint.py    # Semantic fingerprinting and similarity (315 lines)",
        "├── layers.py         # HierarchicalLayer with O(1) ID lookups via _id_index (294 lines)",
        "├── code_concepts.py  # Programming concept synonyms for code search (249 lines)",
        "├── gaps.py           # Knowledge gap detection and anomaly analysis (245 lines)",
        "└── embeddings.py     # Graph embeddings (adjacency, spectral, random walk) (209 lines)",
        "**Total:** ~10,700 lines of core library code",
        "",
        "### Module Purpose Quick Reference",
        "",
        "| If you need to... | Look in... |",
        "|-------------------|------------|",
        "| Add/modify public API | `processor.py` - wrapper methods call other modules |",
        "| Implement search/retrieval | `query.py` - all search functions |",
        "| Add graph algorithms | `analysis.py` - PageRank, TF-IDF, clustering |",
        "| Add semantic relations | `semantics.py` - pattern extraction, retrofitting |",
        "| Modify data structures | `minicolumn.py` - Minicolumn, Edge classes |",
        "| Change layer behavior | `layers.py` - HierarchicalLayer class |",
        "| Adjust tokenization | `tokenizer.py` - stemming, stop words, ngrams |",
        "| Change configuration | `config.py` - CorticalConfig dataclass |",
        "| Modify persistence | `persistence.py` - save/load, export formats |",
        "| Add code search features | `code_concepts.py` - programming synonyms |",
        "| Modify embeddings | `embeddings.py` - graph embedding methods |",
        "| Change gap detection | `gaps.py` - knowledge gap analysis |",
        "| Add fingerprinting | `fingerprint.py` - semantic fingerprints |",
        "| Modify chunk storage | `chunk_index.py` - git-friendly indexing |",
        "",
        "### Test File Locations",
        "",
        "| When testing... | Add tests to... |",
        "|-----------------|-----------------|",
        "| Processor methods | `tests/test_processor.py` (most comprehensive) |",
        "| Query functions | `tests/test_query.py` |",
        "| Analysis algorithms | `tests/test_analysis.py` |",
        "| Semantic extraction | `tests/test_semantics.py` |",
        "| Persistence/save/load | `tests/test_persistence.py` |",
        "| Tokenization | `tests/test_tokenizer.py` |",
        "| Configuration | `tests/test_config.py` |",
        "| Layers | `tests/test_layers.py` |",
        "| Embeddings | `tests/test_embeddings.py` |",
        "| Gap detection | `tests/test_gaps.py` |",
        "| Fingerprinting | `tests/test_fingerprint.py` |",
        "| Code concepts | `tests/test_code_concepts.py` |",
        "| Chunk indexing | `tests/test_chunk_indexing.py` |",
        "| Incremental updates | `tests/test_incremental_indexing.py` |",
        "| Intent queries | `tests/test_intent_query.py` |",
        "",
        "Historical note: Bigram separator mismatch bugs have been **fixed**. Bigrams now correctly use space separators throughout the codebase (see `tokenizer.py:extract_ngrams` and `analysis.py:compute_bigram_connections`).",
        "1. **Bigrams use SPACE separators** (from `tokenizer.py:319-332`):",
        "### Common Mistakes to Avoid",
        "",
        "**❌ DON'T iterate to find by ID:**",
        "```python",
        "# WRONG - O(n) linear scan",
        "for col in layer.minicolumns.values():",
        "    if col.id == target_id:",
        "        return col",
        "",
        "# CORRECT - O(1) lookup",
        "col = layer.get_by_id(target_id)",
        "```",
        "",
        "**❌ DON'T use underscores in bigrams:**",
        "```python",
        "# WRONG - bigrams use spaces",
        "bigram = f\"{term1}_{term2}\"",
        "",
        "# CORRECT",
        "bigram = f\"{term1} {term2}\"",
        "```",
        "",
        "**❌ DON'T confuse global TF-IDF with per-document TF-IDF:**",
        "```python",
        "# WRONG - global TF-IDF (uses total corpus occurrence)",
        "score = col.tfidf",
        "",
        "# CORRECT - per-document TF-IDF",
        "score = col.tfidf_per_doc.get(doc_id, 0.0)",
        "```",
        "",
        "**❌ DON'T assume compute_all() is always needed:**",
        "```python",
        "# WRONG - overkill for incremental updates",
        "processor.add_document_incremental(doc_id, text)",
        "processor.compute_all()  # Recomputes EVERYTHING",
        "",
        "# CORRECT - let incremental handle it",
        "processor.add_document_incremental(doc_id, text)",
        "# TF-IDF and connections updated automatically",
        "```",
        "",
        "**❌ DON'T forget to check staleness before relying on computed values:**",
        "```python",
        "# WRONG - may be using stale data",
        "if processor.is_stale(processor.COMP_PAGERANK):",
        "    # PageRank values may be outdated!",
        "    pass",
        "",
        "# CORRECT - ensure freshness",
        "if processor.is_stale(processor.COMP_PAGERANK):",
        "    processor.compute_importance()",
        "```",
        ""
      ],
      "lines_removed": [
        "├── processor.py      # Main orchestrator (1,596 lines) - START HERE",
        "├── analysis.py       # Graph algorithms: PageRank, TF-IDF, clustering",
        "├── query.py          # Search, retrieval, query expansion, analogies",
        "├── semantics.py      # Relation extraction, inheritance, retrofitting",
        "├── minicolumn.py     # Core data structure with typed Edge connections",
        "├── layers.py         # HierarchicalLayer with O(1) ID lookups via _id_index",
        "├── embeddings.py     # Graph embeddings (adjacency, spectral, random walk)",
        "├── gaps.py           # Knowledge gap detection and anomaly analysis",
        "├── persistence.py    # Save/load with full state preservation",
        "└── tokenizer.py      # Tokenization, stemming, stop word removal",
        "The bigram separator mismatch bugs in `query.py:1442-1468` and `analysis.py:927` have been **fixed**. Bigrams now correctly use space separators throughout the codebase.",
        "1. **Bigrams use SPACE separators** (from `tokenizer.py:179`):"
      ],
      "context_before": [
        "- **Label propagation** for concept clustering (`analysis.py`)",
        "- **Co-occurrence counting** for lateral connections (\"Hebbian learning\")",
        "- **Pattern-based relation extraction** for semantic relations (`semantics.py`)",
        "",
        "---",
        "",
        "## Architecture Map",
        "",
        "```",
        "cortical/"
      ],
      "context_after": [
        "│                     # CorticalTextProcessor is the public API",
        "```",
        "",
        "**Key data structures:**",
        "- `Minicolumn`: Core unit with `lateral_connections`, `typed_connections`, `feedforward_connections`, `feedback_connections`",
        "- `Edge`: Typed connection with `relation_type`, `weight`, `confidence`, `source`",
        "- `HierarchicalLayer`: Container with `minicolumns` dict and `_id_index` for O(1) lookups",
        "",
        "---",
        "",
        "## Critical Knowledge",
        "",
        "### Fixed Bugs (2025-12-10)",
        "",
        "### Important Implementation Details",
        "",
        "   ```python",
        "   ' '.join(tokens[i:i+n])  # \"neural networks\", not \"neural_networks\"",
        "   ```",
        "",
        "2. **Global `col.tfidf` is NOT per-document TF-IDF** - it uses total corpus occurrence count. Use `col.tfidf_per_doc[doc_id]` for true per-document TF-IDF.",
        "",
        "3. **O(1) ID lookups**: Always use `layer.get_by_id(col_id)` instead of iterating `layer.minicolumns`. The `_id_index` provides O(1) access.",
        "",
        "4. **Layer enum values**:",
        "   ```python",
        "   CorticalLayer.TOKENS = 0",
        "   CorticalLayer.BIGRAMS = 1",
        "   CorticalLayer.CONCEPTS = 2",
        "   CorticalLayer.DOCUMENTS = 3",
        "   ```",
        "",
        "5. **Minicolumn IDs follow pattern**: `L{layer}_{content}` (e.g., `L0_neural`, `L1_neural networks`)",
        "",
        "---",
        "",
        "## Development Workflow",
        "",
        "### Before Writing Code",
        "",
        "1. **Read the relevant module** - understand existing patterns",
        "2. **Check TASK_LIST.md** - see if work is already planned/done",
        "3. **Run tests first** to establish baseline:",
        "   ```bash"
      ],
      "change_type": "modify"
    }
  ],
  "hour_of_day": 12,
  "day_of_week": "Thursday",
  "seconds_since_last_commit": -351245,
  "is_merge": false,
  "is_initial": false,
  "parent_count": 1,
  "session_id": null,
  "related_chats": [],
  "ci_result": null,
  "reverted": false,
  "amended": false
}