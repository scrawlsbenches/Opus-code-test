{
  "hash": "d96c2d2b49fbecf1f1352bcb0be05518fff07587",
  "message": "test: Add security test suite and Hypothesis fuzzing (SEC-009, SEC-010)",
  "author": "Claude",
  "timestamp": "2025-12-14 16:46:07 +0000",
  "branch": "claude/multi-index-design-DvifZ",
  "files_changed": [
    "cortical/config.py",
    "tasks/2025-12-14_11-15-01_41d5.json",
    "tests/security/__init__.py",
    "tests/security/test_fuzzing.py",
    "tests/security/test_security.py"
  ],
  "insertions": 820,
  "deletions": 8,
  "hunks": [
    {
      "file": "cortical/config.py",
      "function": "Example:",
      "start_line": 18,
      "lines_added": [
        "import math"
      ],
      "lines_removed": [],
      "context_before": [
        "        isolation_threshold=0.03",
        "    )",
        "    processor = CorticalTextProcessor(config=config)",
        "",
        "    # Or modify defaults",
        "    config = CorticalConfig()",
        "    config.pagerank_iterations = 50",
        "    processor = CorticalTextProcessor(config=config)",
        "\"\"\"",
        ""
      ],
      "context_after": [
        "from dataclasses import dataclass, field",
        "from typing import Dict, Tuple, FrozenSet",
        "",
        "",
        "@dataclass",
        "class CorticalConfig:",
        "    \"\"\"",
        "    Configuration settings for the Cortical Text Processor.",
        "",
        "    All values have sensible defaults that work well for typical text corpora."
      ],
      "change_type": "add"
    },
    {
      "file": "cortical/config.py",
      "function": "class CorticalConfig:",
      "start_line": 171,
      "lines_added": [
        "        if math.isnan(self.louvain_resolution) or math.isinf(self.louvain_resolution):",
        "            raise ValueError(",
        "                f\"louvain_resolution must be a finite number, got {self.louvain_resolution}\"",
        "            )"
      ],
      "lines_removed": [],
      "context_before": [
        "",
        "        # Clustering validation",
        "        if self.min_cluster_size < 1:",
        "            raise ValueError(",
        "                f\"min_cluster_size must be at least 1, got {self.min_cluster_size}\"",
        "            )",
        "        if not (0 <= self.cluster_strictness <= 1):",
        "            raise ValueError(",
        "                f\"cluster_strictness must be between 0 and 1, got {self.cluster_strictness}\"",
        "            )"
      ],
      "context_after": [
        "        if self.louvain_resolution <= 0:",
        "            raise ValueError(",
        "                f\"louvain_resolution must be positive, got {self.louvain_resolution}\"",
        "            )",
        "        if self.louvain_resolution > 20:",
        "            import warnings",
        "            warnings.warn(",
        "                f\"louvain_resolution={self.louvain_resolution} is very high. \"",
        "                f\"This may produce hundreds of tiny clusters. \"",
        "                f\"Typical range is 1.0-10.0.\""
      ],
      "change_type": "add"
    },
    {
      "file": "tasks/2025-12-14_11-15-01_41d5.json",
      "function": null,
      "start_line": 178,
      "lines_added": [
        "      \"status\": \"completed\",",
        "      \"updated_at\": \"2025-12-14T16:45:00.000000\",",
        "      \"completed_at\": \"2025-12-14T16:45:00.000000\",",
        "      \"retrospective\": {",
        "        \"notes\": \"Created tests/security/ directory with test_security.py containing 22 tests: TestPathTraversalPrevention (3 tests), TestInputValidation (6 tests), TestLargeInputHandling (5 tests), TestMaliciousInputRejection (3 tests), TestConfigurationSecurity (2 tests), TestSignatureVerificationIntegration (3 tests). All tests pass.\"",
        "      }",
        "      \"status\": \"completed\",",
        "      \"updated_at\": \"2025-12-14T16:45:00.000000\",",
        "      \"completed_at\": \"2025-12-14T16:45:00.000000\",",
        "      \"retrospective\": {",
        "        \"notes\": \"Created test_fuzzing.py with 17 Hypothesis-based fuzz tests covering: document processing, queries, config validation, persistence, tokenization, and layer operations. Fuzzing discovered a bug: CorticalConfig accepted NaN and inf for louvain_resolution. Fixed by adding math.isnan/math.isinf checks in config.py validation.\"",
        "      }"
      ],
      "lines_removed": [
        "      \"status\": \"pending\",",
        "      \"updated_at\": null,",
        "      \"completed_at\": null,",
        "      \"retrospective\": null",
        "      \"status\": \"pending\",",
        "      \"updated_at\": null,",
        "      \"completed_at\": null,",
        "      \"retrospective\": null"
      ],
      "context_before": [
        "          \"cortical/persistence.py\"",
        "        ]",
        "      },",
        "      \"retrospective\": {",
        "        \"notes\": \"Implemented in commit 90b989f\"",
        "      }",
        "    },",
        "    {",
        "      \"id\": \"T-20251214-111501-41d5-009\",",
        "      \"title\": \"SEC-009: Add security-focused test suite\","
      ],
      "context_after": [
        "      \"priority\": \"low\",",
        "      \"category\": \"security\",",
        "      \"description\": \"Create tests/security/ directory with security-focused tests.\\n\\nTest cases:\\n- Path traversal prevention in file operations\\n- Input validation on public API methods\\n- Pickle signature verification (if SEC-003 implemented)\\n- Large input handling (DoS prevention)\\n\\nEffort: 4 hours\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"medium\",",
        "      \"created_at\": \"2025-12-14T11:15:01.281877\",",
        "      \"context\": {",
        "        \"files\": [",
        "          \"tests/security/\"",
        "        ]",
        "      },",
        "    },",
        "    {",
        "      \"id\": \"T-20251214-111501-41d5-010\",",
        "      \"title\": \"SEC-010: Implement input fuzzing with Hypothesis\",",
        "      \"priority\": \"low\",",
        "      \"category\": \"security\",",
        "      \"description\": \"Add property-based testing with Hypothesis for input fuzzing.\\n\\nTarget methods:\\n- process_document() with random content\\n- find_documents_for_query() with malformed queries\\n- expand_query() with edge case inputs\\n\\nInstall: pip install hypothesis\\nAdd to tests/security/test_fuzzing.py\\n\\nEffort: 8 hours\",",
        "      \"depends_on\": [],",
        "      \"effort\": \"large\",",
        "      \"created_at\": \"2025-12-14T11:15:01.281884\",",
        "      \"context\": {",
        "        \"files\": [",
        "          \"tests/security/test_fuzzing.py\"",
        "        ]",
        "      },",
        "    }",
        "  ]",
        "}"
      ],
      "change_type": "modify"
    },
    {
      "file": "tests/security/__init__.py",
      "function": null,
      "start_line": 0,
      "lines_added": [
        "\"\"\"",
        "Security-focused tests for the Cortical Text Processor.",
        "",
        "SEC-009: Test cases covering:",
        "- Path traversal prevention in file operations",
        "- Input validation on public API methods",
        "- Large input handling (DoS prevention)",
        "- Signature verification (see tests/unit/test_persistence.py for comprehensive coverage)",
        "\"\"\""
      ],
      "lines_removed": [],
      "context_before": [],
      "context_after": [],
      "change_type": "add"
    },
    {
      "file": "tests/security/test_fuzzing.py",
      "function": null,
      "start_line": 0,
      "lines_added": [
        "\"\"\"",
        "Property-based fuzzing tests using Hypothesis.",
        "",
        "SEC-010: Automatically generates random inputs to find edge cases",
        "and potential security issues that manual tests might miss.",
        "",
        "Target methods:",
        "- process_document() with random content",
        "- find_documents_for_query() with malformed queries",
        "- expand_query() with edge case inputs",
        "\"\"\"",
        "",
        "import os",
        "import sys",
        "import tempfile",
        "import string",
        "",
        "import pytest",
        "from hypothesis import given, settings, assume, HealthCheck",
        "from hypothesis import strategies as st",
        "",
        "# Add parent directory to path for imports",
        "sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.dirname(__file__))))",
        "",
        "from cortical import CorticalTextProcessor, CorticalConfig",
        "",
        "",
        "# Custom strategies for generating test data",
        "# Text that's likely to be valid for processing",
        "safe_text = st.text(",
        "    alphabet=string.ascii_letters + string.digits + \" .,!?'\\\"-\",",
        "    min_size=1,",
        "    max_size=10000",
        ")",
        "",
        "# Document IDs - any string that isn't empty",
        "doc_ids = st.text(min_size=1, max_size=100)",
        "",
        "# Queries - non-empty text",
        "queries = st.text(min_size=1, max_size=1000)",
        "",
        "# Unicode text including potentially problematic characters",
        "unicode_text = st.text(min_size=1, max_size=1000)",
        "",
        "# Numbers for numeric parameters",
        "positive_ints = st.integers(min_value=1, max_value=1000)",
        "non_negative_ints = st.integers(min_value=0, max_value=1000)",
        "floats_0_1 = st.floats(min_value=0.001, max_value=0.999)",
        "",
        "",
        "class TestProcessDocumentFuzzing:",
        "    \"\"\"Fuzz testing for process_document() method.\"\"\"",
        "",
        "    @given(doc_id=doc_ids, content=safe_text)",
        "    @settings(max_examples=100, suppress_health_check=[HealthCheck.too_slow])",
        "    def test_process_document_never_crashes(self, doc_id, content):",
        "        \"\"\"process_document should never crash with valid-ish inputs.\"\"\"",
        "        processor = CorticalTextProcessor()",
        "",
        "        # Skip empty strings (known to be invalid)",
        "        assume(doc_id.strip())",
        "        assume(content.strip())",
        "",
        "        try:",
        "            processor.process_document(doc_id, content)",
        "            # Should not crash",
        "            assert True",
        "        except ValueError:",
        "            # ValueError for invalid input is acceptable",
        "            pass",
        "",
        "    @given(doc_id=doc_ids, content=unicode_text)",
        "    @settings(max_examples=50, suppress_health_check=[HealthCheck.too_slow])",
        "    def test_process_document_handles_unicode(self, doc_id, content):",
        "        \"\"\"process_document should handle arbitrary Unicode safely.\"\"\"",
        "        processor = CorticalTextProcessor()",
        "",
        "        assume(doc_id.strip())",
        "        assume(content.strip())",
        "",
        "        try:",
        "            processor.process_document(doc_id, content)",
        "            # If successful, document should be stored",
        "            assert doc_id in processor.documents",
        "        except (ValueError, UnicodeError):",
        "            # Rejection of problematic Unicode is acceptable",
        "            pass",
        "",
        "    @given(count=st.integers(min_value=1, max_value=50))",
        "    @settings(max_examples=10, suppress_health_check=[HealthCheck.too_slow])",
        "    def test_multiple_documents_never_crash(self, count):",
        "        \"\"\"Adding multiple documents should never crash.\"\"\"",
        "        processor = CorticalTextProcessor()",
        "",
        "        for i in range(count):",
        "            processor.process_document(f\"doc_{i}\", f\"Content for document {i}.\")",
        "",
        "        assert len(processor.documents) == count",
        "",
        "",
        "class TestQueryFuzzing:",
        "    \"\"\"Fuzz testing for query methods.\"\"\"",
        "",
        "    @given(query=queries)",
        "    @settings(max_examples=100, suppress_health_check=[HealthCheck.too_slow])",
        "    def test_find_documents_never_crashes(self, query):",
        "        \"\"\"find_documents_for_query should never crash with valid queries.\"\"\"",
        "        processor = CorticalTextProcessor()",
        "        processor.process_document(\"doc1\", \"Test document with some content.\")",
        "        processor.compute_all()",
        "",
        "        # Skip whitespace-only queries (known to be invalid)",
        "        assume(query.strip())",
        "",
        "        try:",
        "            results = processor.find_documents_for_query(query)",
        "            # Should return a list",
        "            assert isinstance(results, list)",
        "        except ValueError:",
        "            # ValueError for invalid query is acceptable",
        "            pass",
        "",
        "    @given(query=unicode_text)",
        "    @settings(max_examples=50, suppress_health_check=[HealthCheck.too_slow])",
        "    def test_query_handles_unicode(self, query):",
        "        \"\"\"Query methods should handle arbitrary Unicode safely.\"\"\"",
        "        processor = CorticalTextProcessor()",
        "        processor.process_document(\"doc1\", \"Test document.\")",
        "        processor.compute_all()",
        "",
        "        assume(query.strip())",
        "",
        "        try:",
        "            results = processor.find_documents_for_query(query)",
        "            assert isinstance(results, list)",
        "        except (ValueError, UnicodeError):",
        "            # Rejection is acceptable",
        "            pass",
        "",
        "    @given(top_n=st.integers(min_value=-100, max_value=1000))",
        "    @settings(max_examples=50, suppress_health_check=[HealthCheck.too_slow])",
        "    def test_top_n_boundaries(self, top_n):",
        "        \"\"\"top_n parameter should handle boundary values safely.\"\"\"",
        "        processor = CorticalTextProcessor()",
        "        processor.process_document(\"doc1\", \"Test document.\")",
        "        processor.compute_all()",
        "",
        "        try:",
        "            if top_n <= 0:",
        "                # Should reject non-positive values",
        "                with pytest.raises(ValueError):",
        "                    processor.find_documents_for_query(\"test\", top_n=top_n)",
        "            else:",
        "                results = processor.find_documents_for_query(\"test\", top_n=top_n)",
        "                assert len(results) <= top_n",
        "        except (ValueError, OverflowError):",
        "            # These are acceptable responses to boundary values",
        "            pass",
        "",
        "",
        "class TestExpandQueryFuzzing:",
        "    \"\"\"Fuzz testing for expand_query() method.\"\"\"",
        "",
        "    @given(query=queries)",
        "    @settings(max_examples=100, suppress_health_check=[HealthCheck.too_slow])",
        "    def test_expand_query_never_crashes(self, query):",
        "        \"\"\"expand_query should never crash with arbitrary queries.\"\"\"",
        "        processor = CorticalTextProcessor()",
        "        processor.process_document(\"doc1\", \"Neural networks process data efficiently.\")",
        "        processor.compute_all()",
        "",
        "        assume(query.strip())",
        "",
        "        try:",
        "            expanded = processor.expand_query(query)",
        "            # Should return a dict",
        "            assert isinstance(expanded, dict)",
        "        except ValueError:",
        "            # Rejection is acceptable",
        "            pass",
        "",
        "    @given(max_expansions=st.integers(min_value=-10, max_value=100))",
        "    @settings(max_examples=50, suppress_health_check=[HealthCheck.too_slow])",
        "    def test_max_expansions_boundaries(self, max_expansions):",
        "        \"\"\"max_expansions parameter should handle boundary values.\"\"\"",
        "        processor = CorticalTextProcessor()",
        "        processor.process_document(\"doc1\", \"Neural networks machine learning.\")",
        "        processor.compute_all()",
        "",
        "        try:",
        "            if max_expansions <= 0:",
        "                # May reject or return minimal results",
        "                expanded = processor.expand_query(\"neural\", max_expansions=max_expansions)",
        "                # If it doesn't reject, should return limited results",
        "                assert len(expanded) <= max(0, max_expansions) or len(expanded) >= 1",
        "            else:",
        "                expanded = processor.expand_query(\"neural\", max_expansions=max_expansions)",
        "                assert len(expanded) <= max_expansions + 10  # Some tolerance",
        "        except ValueError:",
        "            # Rejection is acceptable",
        "            pass",
        "",
        "",
        "class TestConfigFuzzing:",
        "    \"\"\"Fuzz testing for configuration validation.\"\"\"",
        "",
        "    @given(damping=st.floats(allow_nan=True, allow_infinity=True))",
        "    @settings(max_examples=100)",
        "    def test_pagerank_damping_validation(self, damping):",
        "        \"\"\"pagerank_damping should reject invalid values.\"\"\"",
        "        import math",
        "",
        "        try:",
        "            config = CorticalConfig(pagerank_damping=damping)",
        "            # If it accepted, must be valid",
        "            assert 0 < damping < 1",
        "            assert not math.isnan(damping)",
        "            assert not math.isinf(damping)",
        "        except (ValueError, TypeError):",
        "            # Rejection is expected for invalid values",
        "            pass",
        "",
        "    @given(resolution=st.floats(allow_nan=True, allow_infinity=True))",
        "    @settings(max_examples=100)",
        "    def test_louvain_resolution_validation(self, resolution):",
        "        \"\"\"louvain_resolution should reject invalid values.\"\"\"",
        "        import math",
        "        import warnings",
        "",
        "        try:",
        "            with warnings.catch_warnings():",
        "                warnings.simplefilter(\"ignore\")  # High values trigger warnings",
        "                config = CorticalConfig(louvain_resolution=resolution)",
        "            # If it accepted, must be valid (positive, finite)",
        "            assert resolution > 0",
        "            assert not math.isnan(resolution)",
        "            assert not math.isinf(resolution)",
        "        except (ValueError, TypeError):",
        "            # Rejection is expected for invalid values",
        "            pass",
        "",
        "    @given(iterations=st.integers(min_value=-1000, max_value=1000))",
        "    @settings(max_examples=100)",
        "    def test_pagerank_iterations_validation(self, iterations):",
        "        \"\"\"pagerank_iterations should reject invalid values.\"\"\"",
        "        try:",
        "            config = CorticalConfig(pagerank_iterations=iterations)",
        "            # If it accepted, must be valid",
        "            assert iterations >= 1",
        "        except ValueError:",
        "            # Rejection is expected for invalid values",
        "            pass",
        "",
        "",
        "class TestPersistenceFuzzing:",
        "    \"\"\"Fuzz testing for save/load operations.\"\"\"",
        "",
        "    @given(content=safe_text)",
        "    @settings(max_examples=20, suppress_health_check=[HealthCheck.too_slow])",
        "    def test_save_load_roundtrip(self, content):",
        "        \"\"\"Save/load roundtrip should preserve data.\"\"\"",
        "        assume(content.strip())",
        "",
        "        processor = CorticalTextProcessor()",
        "        processor.process_document(\"doc1\", content)",
        "",
        "        with tempfile.TemporaryDirectory() as tmpdir:",
        "            path = os.path.join(tmpdir, \"test.pkl\")",
        "            processor.save(path)",
        "",
        "            loaded = CorticalTextProcessor.load(path)",
        "            assert loaded.documents.get(\"doc1\") == content",
        "",
        "    @given(key=st.binary(min_size=16, max_size=64))",
        "    @settings(max_examples=20, suppress_health_check=[HealthCheck.too_slow])",
        "    def test_signed_save_load_with_random_keys(self, key):",
        "        \"\"\"Signed save/load should work with random keys.\"\"\"",
        "        processor = CorticalTextProcessor()",
        "        processor.process_document(\"doc1\", \"Test content.\")",
        "",
        "        with tempfile.TemporaryDirectory() as tmpdir:",
        "            path = os.path.join(tmpdir, \"test.pkl\")",
        "            processor.save(path, signing_key=key)",
        "",
        "            loaded = CorticalTextProcessor.load(path, verify_key=key)",
        "            assert \"doc1\" in loaded.documents",
        "",
        "",
        "class TestTokenizerFuzzing:",
        "    \"\"\"Fuzz testing for tokenization.\"\"\"",
        "",
        "    @given(text=unicode_text)",
        "    @settings(max_examples=100, suppress_health_check=[HealthCheck.too_slow])",
        "    def test_tokenize_never_crashes(self, text):",
        "        \"\"\"Tokenization should never crash with arbitrary input.\"\"\"",
        "        from cortical import Tokenizer",
        "",
        "        tokenizer = Tokenizer()",
        "",
        "        try:",
        "            tokens = tokenizer.tokenize(text)",
        "            # Should return a list",
        "            assert isinstance(tokens, list)",
        "            # All tokens should be strings",
        "            assert all(isinstance(t, str) for t in tokens)",
        "        except (ValueError, UnicodeError):",
        "            # Rejection is acceptable",
        "            pass",
        "",
        "    @given(text=st.text(min_size=0, max_size=100))",
        "    @settings(max_examples=100)",
        "    def test_extract_ngrams_never_crashes(self, text):",
        "        \"\"\"N-gram extraction should never crash.\"\"\"",
        "        from cortical import Tokenizer",
        "",
        "        tokenizer = Tokenizer()",
        "",
        "        try:",
        "            # First tokenize, then extract ngrams",
        "            tokens = tokenizer.tokenize(text)",
        "            if tokens:  # Only extract ngrams if there are tokens",
        "                bigrams = tokenizer.extract_ngrams(tokens, n=2)",
        "                # Should return a list",
        "                assert isinstance(bigrams, list)",
        "        except (ValueError, UnicodeError):",
        "            # Rejection is acceptable",
        "            pass",
        "",
        "",
        "class TestLayerFuzzing:",
        "    \"\"\"Fuzz testing for layer operations.\"\"\"",
        "",
        "    @given(term=st.text(min_size=1, max_size=100))",
        "    @settings(max_examples=100)",
        "    def test_get_minicolumn_never_crashes(self, term):",
        "        \"\"\"get_minicolumn should never crash with arbitrary terms.\"\"\"",
        "        processor = CorticalTextProcessor()",
        "        processor.process_document(\"doc1\", \"Test content.\")",
        "",
        "        from cortical import CorticalLayer",
        "",
        "        layer = processor.layers[CorticalLayer.TOKENS]",
        "",
        "        # Should return None for missing terms, never crash",
        "        result = layer.get_minicolumn(term)",
        "        assert result is None or hasattr(result, 'content')",
        "",
        "    @given(col_id=st.text(min_size=1, max_size=100))",
        "    @settings(max_examples=100)",
        "    def test_get_by_id_never_crashes(self, col_id):",
        "        \"\"\"get_by_id should never crash with arbitrary IDs.\"\"\"",
        "        processor = CorticalTextProcessor()",
        "        processor.process_document(\"doc1\", \"Test content.\")",
        "",
        "        from cortical import CorticalLayer",
        "",
        "        layer = processor.layers[CorticalLayer.TOKENS]",
        "",
        "        # Should return None for missing IDs, never crash",
        "        result = layer.get_by_id(col_id)",
        "        assert result is None or hasattr(result, 'id')",
        "",
        "",
        "if __name__ == \"__main__\":",
        "    pytest.main([__file__, \"-v\", \"--hypothesis-show-statistics\"])"
      ],
      "lines_removed": [],
      "context_before": [],
      "context_after": [],
      "change_type": "add"
    },
    {
      "file": "tests/security/test_security.py",
      "function": null,
      "start_line": 0,
      "lines_added": [
        "\"\"\"",
        "Security-focused test suite for the Cortical Text Processor.",
        "",
        "SEC-009: Comprehensive security tests covering:",
        "- Path traversal prevention",
        "- Input validation",
        "- Large input handling (DoS prevention)",
        "- Malicious input rejection",
        "\"\"\"",
        "",
        "import os",
        "import sys",
        "import tempfile",
        "import unittest",
        "from unittest.mock import patch, MagicMock",
        "",
        "import pytest",
        "",
        "# Add parent directory to path for imports",
        "sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.dirname(__file__))))",
        "",
        "from cortical import CorticalTextProcessor, CorticalConfig",
        "from cortical.persistence import (",
        "    save_processor,",
        "    load_processor,",
        "    SignatureVerificationError,",
        ")",
        "from cortical.validation import (",
        "    validate_non_empty_string,",
        "    validate_positive_int,",
        "    validate_range,",
        ")",
        "",
        "",
        "class TestPathTraversalPrevention:",
        "    \"\"\"",
        "    Test that file operations prevent path traversal attacks.",
        "",
        "    Path traversal attacks attempt to access files outside the intended",
        "    directory by using sequences like '../' or absolute paths.",
        "    \"\"\"",
        "",
        "    def test_save_rejects_path_traversal_sequences(self):",
        "        \"\"\"Save should not allow path traversal in filenames.\"\"\"",
        "        processor = CorticalTextProcessor()",
        "        processor.process_document(\"test\", \"Test content\")",
        "",
        "        # Attempting path traversal with ../ should either:",
        "        # 1. Fail (if the system prevents it)",
        "        # 2. Create the file in a safe location (normalized path)",
        "        with tempfile.TemporaryDirectory() as tmpdir:",
        "            # Try to escape the directory",
        "            malicious_path = os.path.join(tmpdir, \"..\", \"escaped.pkl\")",
        "",
        "            # This should either raise an error or normalize the path",
        "            # The important thing is it shouldn't create files outside tmpdir parent",
        "            try:",
        "                processor.save(malicious_path)",
        "                # If it succeeded, verify the file is in a reasonable location",
        "                # (os.path normalizes the path, so \"../escaped.pkl\" becomes parent/escaped.pkl)",
        "                # This is acceptable as long as we document the behavior",
        "                assert os.path.exists(malicious_path) or os.path.exists(",
        "                    os.path.normpath(malicious_path)",
        "                )",
        "            except (OSError, ValueError):",
        "                # Rejection is also acceptable",
        "                pass",
        "",
        "    def test_save_handles_absolute_paths_safely(self):",
        "        \"\"\"Save with absolute path should work normally.\"\"\"",
        "        processor = CorticalTextProcessor()",
        "        processor.process_document(\"test\", \"Test content\")",
        "",
        "        with tempfile.TemporaryDirectory() as tmpdir:",
        "            abs_path = os.path.join(tmpdir, \"test.pkl\")",
        "            processor.save(abs_path)",
        "            assert os.path.exists(abs_path)",
        "",
        "    def test_document_id_with_path_characters(self):",
        "        \"\"\"Document IDs with path-like characters should be sanitized or rejected.\"\"\"",
        "        processor = CorticalTextProcessor()",
        "",
        "        # These should either be accepted (if IDs are just keys, not files)",
        "        # or rejected if they could cause security issues",
        "        suspicious_ids = [",
        "            \"../etc/passwd\",",
        "            \"/etc/passwd\",",
        "            \"..\\\\..\\\\windows\\\\system32\",",
        "            \"doc|id\",  # Pipe character",
        "            \"doc\\x00id\",  # Null byte",
        "        ]",
        "",
        "        for doc_id in suspicious_ids:",
        "            try:",
        "                processor.process_document(doc_id, \"Test content\")",
        "                # If accepted, verify it's stored as-is (just a dict key)",
        "                # This is acceptable since doc_ids are not used as filenames",
        "                assert doc_id in processor.documents",
        "            except (ValueError, KeyError):",
        "                # Rejection is also acceptable",
        "                pass",
        "",
        "",
        "class TestInputValidation:",
        "    \"\"\"",
        "    Test input validation on public API methods.",
        "",
        "    Public APIs should validate inputs to prevent:",
        "    - Type confusion attacks",
        "    - Buffer overflow-like attacks (very large inputs)",
        "    - Injection attacks",
        "    \"\"\"",
        "",
        "    def test_empty_query_rejected(self):",
        "        \"\"\"Empty queries should be rejected.\"\"\"",
        "        processor = CorticalTextProcessor()",
        "        processor.process_document(\"doc1\", \"Test content\")",
        "        processor.compute_all()",
        "",
        "        with pytest.raises(ValueError):",
        "            processor.find_documents_for_query(\"\")",
        "",
        "        with pytest.raises(ValueError):",
        "            processor.find_documents_for_query(\"   \")  # Whitespace only",
        "",
        "    def test_none_query_rejected(self):",
        "        \"\"\"None query should be rejected.\"\"\"",
        "        processor = CorticalTextProcessor()",
        "        processor.process_document(\"doc1\", \"Test content\")",
        "        processor.compute_all()",
        "",
        "        with pytest.raises((ValueError, TypeError, AttributeError)):",
        "            processor.find_documents_for_query(None)",
        "",
        "    def test_invalid_top_n_rejected(self):",
        "        \"\"\"Invalid top_n values should be rejected.\"\"\"",
        "        processor = CorticalTextProcessor()",
        "        processor.process_document(\"doc1\", \"Test content\")",
        "        processor.compute_all()",
        "",
        "        with pytest.raises(ValueError):",
        "            processor.find_documents_for_query(\"test\", top_n=0)",
        "",
        "        with pytest.raises(ValueError):",
        "            processor.find_documents_for_query(\"test\", top_n=-1)",
        "",
        "    def test_non_string_document_rejected(self):",
        "        \"\"\"Non-string document content should be rejected.\"\"\"",
        "        processor = CorticalTextProcessor()",
        "",
        "        with pytest.raises((ValueError, TypeError, AttributeError)):",
        "            processor.process_document(\"doc1\", None)",
        "",
        "        with pytest.raises((ValueError, TypeError, AttributeError)):",
        "            processor.process_document(\"doc1\", 12345)",
        "",
        "        with pytest.raises((ValueError, TypeError, AttributeError)):",
        "            processor.process_document(\"doc1\", [\"list\", \"of\", \"words\"])",
        "",
        "    def test_empty_document_id_rejected(self):",
        "        \"\"\"Empty document IDs should be rejected.\"\"\"",
        "        processor = CorticalTextProcessor()",
        "",
        "        with pytest.raises(ValueError):",
        "            processor.process_document(\"\", \"Test content\")",
        "",
        "    def test_validation_decorators(self):",
        "        \"\"\"Test validation utility functions.\"\"\"",
        "        # validate_non_empty_string",
        "        with pytest.raises(ValueError):",
        "            validate_non_empty_string(\"\", \"test\")",
        "",
        "        with pytest.raises(ValueError):",
        "            validate_non_empty_string(None, \"test\")",
        "",
        "        with pytest.raises(ValueError):",
        "            validate_non_empty_string(123, \"test\")",
        "",
        "        # Should not raise",
        "        validate_non_empty_string(\"valid\", \"test\")",
        "",
        "        # validate_positive_int",
        "        with pytest.raises(ValueError):",
        "            validate_positive_int(0, \"test\")",
        "",
        "        with pytest.raises(ValueError):",
        "            validate_positive_int(-1, \"test\")",
        "",
        "        with pytest.raises(ValueError):",
        "            validate_positive_int(1.5, \"test\")",
        "",
        "        # Should not raise",
        "        validate_positive_int(1, \"test\")",
        "",
        "        # validate_range",
        "        with pytest.raises(ValueError):",
        "            validate_range(1.5, \"test\", min_val=0.0, max_val=1.0)",
        "",
        "        with pytest.raises(ValueError):",
        "            validate_range(-0.1, \"test\", min_val=0.0)",
        "",
        "",
        "class TestLargeInputHandling:",
        "    \"\"\"",
        "    Test handling of very large inputs (DoS prevention).",
        "",
        "    Large inputs should either:",
        "    - Be processed reasonably",
        "    - Be rejected with clear limits",
        "    - Not cause crashes or excessive memory usage",
        "    \"\"\"",
        "",
        "    def test_very_large_document_handled(self):",
        "        \"\"\"Very large documents should be handled without crashing.\"\"\"",
        "        processor = CorticalTextProcessor()",
        "",
        "        # Create a large document (100KB of text)",
        "        large_text = \"test word \" * 10000",
        "",
        "        # Should not crash",
        "        processor.process_document(\"large_doc\", large_text)",
        "",
        "        # Should have processed tokens",
        "        assert processor.layers is not None",
        "",
        "    def test_many_documents_handled(self):",
        "        \"\"\"Many documents should be handled without crashing.\"\"\"",
        "        processor = CorticalTextProcessor()",
        "",
        "        # Add 100 documents",
        "        for i in range(100):",
        "            processor.process_document(f\"doc_{i}\", f\"Document number {i} with some content.\")",
        "",
        "        # Should have all documents",
        "        assert len(processor.documents) == 100",
        "",
        "    def test_very_long_query_handled(self):",
        "        \"\"\"Very long queries should be handled without crashing.\"\"\"",
        "        processor = CorticalTextProcessor()",
        "        processor.process_document(\"doc1\", \"Test content for searching.\")",
        "        processor.compute_all()",
        "",
        "        # Create a long query (1000 words)",
        "        long_query = \" \".join([\"word\"] * 1000)",
        "",
        "        # Should not crash (may return empty results, but shouldn't crash)",
        "        try:",
        "            results = processor.find_documents_for_query(long_query)",
        "            assert isinstance(results, list)",
        "        except ValueError:",
        "            # Rejecting very long queries is also acceptable",
        "            pass",
        "",
        "    def test_repeated_same_document_id(self):",
        "        \"\"\"Processing the same document ID multiple times should be handled.\"\"\"",
        "        processor = CorticalTextProcessor()",
        "",
        "        # Process the same document 100 times",
        "        for i in range(100):",
        "            processor.process_document(\"doc1\", f\"Version {i} of the document.\")",
        "",
        "        # Should only have one document (latest version)",
        "        assert len(processor.documents) == 1",
        "        assert \"Version 99\" in processor.documents[\"doc1\"]",
        "",
        "    def test_unicode_document_handling(self):",
        "        \"\"\"Unicode characters in documents should be handled safely.\"\"\"",
        "        processor = CorticalTextProcessor()",
        "",
        "        # Various Unicode test cases",
        "        unicode_tests = [",
        "            \"Hello ‰∏ñÁïå üåç\",  # Chinese + emoji",
        "            \"ŸÖÿ±ÿ≠ÿ®ÿß ÿ®ÿßŸÑÿπÿßŸÑŸÖ\",  # Arabic (RTL)",
        "            \"–ü—Ä–∏–≤–µ—Ç –º–∏—Ä\",  # Cyrillic",
        "            \"\\u0000\\u0001\\u0002\",  # Control characters",
        "            \"a\" * 10000 + \"üî•\",  # Long string with emoji",
        "        ]",
        "",
        "        for i, text in enumerate(unicode_tests):",
        "            # Should not crash",
        "            try:",
        "                processor.process_document(f\"unicode_{i}\", text)",
        "            except (ValueError, UnicodeError):",
        "                # Rejection of invalid Unicode is acceptable",
        "                pass",
        "",
        "",
        "class TestMaliciousInputRejection:",
        "    \"\"\"",
        "    Test rejection of potentially malicious inputs.",
        "",
        "    This includes:",
        "    - SQL injection-like patterns (shouldn't affect us, but test anyway)",
        "    - Script injection patterns",
        "    - Format string attacks",
        "    \"\"\"",
        "",
        "    def test_script_like_content_safe(self):",
        "        \"\"\"Script-like content should be stored safely as text.\"\"\"",
        "        processor = CorticalTextProcessor()",
        "",
        "        script_content = \"\"\"",
        "        <script>alert('xss')</script>",
        "        <?php system('whoami'); ?>",
        "        $(rm -rf /)",
        "        \"\"\"",
        "",
        "        # Should be stored as plain text",
        "        processor.process_document(\"script_doc\", script_content)",
        "        assert processor.documents[\"script_doc\"] == script_content",
        "",
        "    def test_sql_like_content_safe(self):",
        "        \"\"\"SQL-like content should be stored safely as text.\"\"\"",
        "        processor = CorticalTextProcessor()",
        "",
        "        sql_content = \"'; DROP TABLE users; --\"",
        "",
        "        # Should be stored as plain text (we don't use SQL)",
        "        processor.process_document(\"sql_doc\", sql_content)",
        "        assert processor.documents[\"sql_doc\"] == sql_content",
        "",
        "    def test_format_string_content_safe(self):",
        "        \"\"\"Format string patterns should be stored safely.\"\"\"",
        "        processor = CorticalTextProcessor()",
        "",
        "        format_content = \"%s%s%s%n%n%n{0}{1}{2}\"",
        "",
        "        # Should be stored as plain text",
        "        processor.process_document(\"format_doc\", format_content)",
        "        assert processor.documents[\"format_doc\"] == format_content",
        "",
        "",
        "class TestConfigurationSecurity:",
        "    \"\"\"Test security aspects of configuration handling.\"\"\"",
        "",
        "    def test_config_rejects_invalid_ranges(self):",
        "        \"\"\"Configuration should reject values outside valid ranges.\"\"\"",
        "        # pagerank_damping should be in (0, 1) exclusive",
        "        with pytest.raises(ValueError):",
        "            CorticalConfig(pagerank_damping=0.0)",
        "",
        "        with pytest.raises(ValueError):",
        "            CorticalConfig(pagerank_damping=1.0)",
        "",
        "        with pytest.raises(ValueError):",
        "            CorticalConfig(pagerank_damping=-0.5)",
        "",
        "        with pytest.raises(ValueError):",
        "            CorticalConfig(pagerank_damping=1.5)",
        "",
        "    def test_config_rejects_negative_counts(self):",
        "        \"\"\"Configuration should reject negative count values.\"\"\"",
        "        with pytest.raises(ValueError):",
        "            CorticalConfig(pagerank_iterations=-1)",
        "",
        "        with pytest.raises(ValueError):",
        "            CorticalConfig(louvain_resolution=-1.0)",
        "",
        "",
        "class TestSignatureVerificationIntegration:",
        "    \"\"\"",
        "    Integration tests for signature verification.",
        "",
        "    Note: Unit tests are in tests/unit/test_persistence.py.",
        "    These tests verify the full save/load workflow.",
        "    \"\"\"",
        "",
        "    def test_signed_save_load_roundtrip(self):",
        "        \"\"\"Signed files should load correctly with the right key.\"\"\"",
        "        processor = CorticalTextProcessor()",
        "        processor.process_document(\"doc1\", \"Test content\")",
        "",
        "        key = b\"test_secret_key_32bytes_minimum!\"",
        "",
        "        with tempfile.TemporaryDirectory() as tmpdir:",
        "            path = os.path.join(tmpdir, \"signed.pkl\")",
        "",
        "            # Save with signature",
        "            processor.save(path, signing_key=key)",
        "",
        "            # Should have created signature file",
        "            assert os.path.exists(f\"{path}.sig\")",
        "",
        "            # Load with verification",
        "            loaded = CorticalTextProcessor.load(path, verify_key=key)",
        "            assert \"doc1\" in loaded.documents",
        "",
        "    def test_tampered_file_rejected(self):",
        "        \"\"\"Tampered files should be rejected.\"\"\"",
        "        processor = CorticalTextProcessor()",
        "        processor.process_document(\"doc1\", \"Test content\")",
        "",
        "        key = b\"test_secret_key_32bytes_minimum!\"",
        "",
        "        with tempfile.TemporaryDirectory() as tmpdir:",
        "            path = os.path.join(tmpdir, \"signed.pkl\")",
        "",
        "            # Save with signature",
        "            processor.save(path, signing_key=key)",
        "",
        "            # Tamper with the file",
        "            with open(path, 'ab') as f:",
        "                f.write(b\"tampered\")",
        "",
        "            # Load should fail",
        "            with pytest.raises(SignatureVerificationError):",
        "                CorticalTextProcessor.load(path, verify_key=key)",
        "",
        "    def test_wrong_key_rejected(self):",
        "        \"\"\"Loading with wrong key should be rejected.\"\"\"",
        "        processor = CorticalTextProcessor()",
        "        processor.process_document(\"doc1\", \"Test content\")",
        "",
        "        key1 = b\"correct_key_here_32bytes_minimum\"",
        "        key2 = b\"wrong_key_here_32_bytes_minimum!\"",
        "",
        "        with tempfile.TemporaryDirectory() as tmpdir:",
        "            path = os.path.join(tmpdir, \"signed.pkl\")",
        "",
        "            # Save with key1",
        "            processor.save(path, signing_key=key1)",
        "",
        "            # Load with key2 should fail",
        "            with pytest.raises(SignatureVerificationError):",
        "                CorticalTextProcessor.load(path, verify_key=key2)",
        "",
        "",
        "if __name__ == \"__main__\":",
        "    pytest.main([__file__, \"-v\"])"
      ],
      "lines_removed": [],
      "context_before": [],
      "context_after": [],
      "change_type": "add"
    }
  ],
  "hour_of_day": 16,
  "day_of_week": "Sunday",
  "seconds_since_last_commit": -75521,
  "is_merge": false,
  "is_initial": false,
  "parent_count": 1,
  "session_id": null,
  "related_chats": [],
  "ci_result": null,
  "reverted": false,
  "amended": false
}