{
  "hash": "f0cef255545ab014212d0ffeecc87e0b1d5f4a50",
  "message": "Add performance benchmarks documentation with real numbers",
  "author": "Claude",
  "timestamp": "2025-12-15 04:37:45 +0000",
  "branch": "claude/multi-index-design-DvifZ",
  "files_changed": [
    "docs/benchmarks.md"
  ],
  "insertions": 309,
  "deletions": 0,
  "hunks": [
    {
      "file": "docs/benchmarks.md",
      "function": null,
      "start_line": 0,
      "lines_added": [
        "# Performance Benchmarks",
        "",
        "This document provides real performance numbers for the Cortical Text Processor, measured on representative workloads.",
        "",
        "**Test Environment:**",
        "- Platform: Linux 4.4.0",
        "- Python: 3.x",
        "- Date: December 2025",
        "",
        "---",
        "",
        "## Quick Reference",
        "",
        "| Operation | Small Corpus (25 docs) | Real Codebase (151 files) |",
        "|-----------|------------------------|---------------------------|",
        "| Document processing | 0.31 ms/doc | 26.45 ms/doc |",
        "| compute_all() | 141 ms | 49.4 s |",
        "| Standard search | 0.13 ms | 1.22 ms |",
        "| Fast search | 0.06 ms | 0.66 ms |",
        "| Passage retrieval | 0.36 ms | 64.9 ms |",
        "",
        "---",
        "",
        "## Small Corpus Benchmarks (25 Documents)",
        "",
        "### Corpus Profile",
        "| Metric | Value |",
        "|--------|-------|",
        "| Documents | 25 |",
        "| Tokens (Layer 0) | 460 |",
        "| Bigrams (Layer 1) | 592 |",
        "| Concepts (Layer 2) | 31 |",
        "| L0 Connections | 3,323 |",
        "",
        "### Document Processing",
        "",
        "| Metric | Time |",
        "|--------|------|",
        "| Total (25 docs) | 7.8 ms |",
        "| Average per document | 0.31 ms |",
        "| Min per document | 0.22 ms |",
        "| Max per document | 0.58 ms |",
        "",
        "### Compute Phases",
        "",
        "Individual phase timings reveal where processing time is spent:",
        "",
        "| Phase | Time (ms) | % of Total |",
        "|-------|-----------|------------|",
        "| bigram_connections | 106.9 | 68.6% |",
        "| concept_clusters | 14.8 | 9.5% |",
        "| pagerank | 13.1 | 8.4% |",
        "| activation_propagation | 12.4 | 8.0% |",
        "| graph_embeddings | 4.7 | 3.0% |",
        "| doc_connections | 3.5 | 2.2% |",
        "| tfidf | 0.4 | 0.2% |",
        "| **TOTAL** | **155.8** | **100%** |",
        "",
        "Full `compute_all()` pipeline: **140.9 ms**",
        "",
        "### Query Operations",
        "",
        "| Operation | Avg (ms) | Min (ms) | Max (ms) |",
        "|-----------|----------|----------|----------|",
        "| Standard search | 0.13 | 0.06 | 0.25 |",
        "| Fast search | 0.06 | 0.05 | 0.08 |",
        "| Query expansion | 0.05 | 0.03 | 0.07 |",
        "| Passage retrieval | 0.36 | 0.23 | 0.62 |",
        "",
        "**Fast search speedup: 2.0x** over standard search",
        "",
        "### Persistence",
        "",
        "| Operation | Time | Size |",
        "|-----------|------|------|",
        "| Save | 137.1 ms | 1.33 MB |",
        "| Load | 45.4 ms | - |",
        "",
        "---",
        "",
        "## Real Codebase Benchmarks (151 Python Files)",
        "",
        "Benchmarked using the actual `cortical/`, `scripts/`, and `tests/` directories.",
        "",
        "### Corpus Profile",
        "| Metric | Value |",
        "|--------|-------|",
        "| Files | 151 |",
        "| Characters | 2,949,713 |",
        "| Lines | 83,272 |",
        "| Tokens (Layer 0) | 11,557 |",
        "| Bigrams (Layer 1) | 84,978 |",
        "| Concepts (Layer 2) | 54 |",
        "| L0 Connections | 388,178 |",
        "",
        "### Processing Times",
        "",
        "| Operation | Time |",
        "|-----------|------|",
        "| Document processing (total) | 3,993.8 ms |",
        "| Per-document average | 26.45 ms |",
        "| compute_all() | 49,437.6 ms (~49 s) |",
        "",
        "### Query Performance",
        "",
        "| Operation | Average Time |",
        "|-----------|--------------|",
        "| Standard search | 1.22 ms |",
        "| Fast search | 0.66 ms |",
        "| Passage retrieval | 64.94 ms |",
        "| Intent search | 0.14 ms |",
        "",
        "**Fast search speedup: 1.8x** over standard search",
        "",
        "### Persistence",
        "",
        "| Operation | Time | Size |",
        "|-----------|------|------|",
        "| Save | 21.9 s | 212.35 MB |",
        "| Load | 16.7 s | - |",
        "",
        "---",
        "",
        "## Scaling Characteristics",
        "",
        "How performance scales with corpus size:",
        "",
        "| Documents | Tokens | Process (ms) | Compute (ms) | Query (ms) |",
        "|-----------|--------|--------------|--------------|------------|",
        "| 10 | 36 | 11.9 | 4.5 | 0.04 |",
        "| 25 | 36 | 26.6 | 5.2 | 0.05 |",
        "| 50 | 36 | 53.3 | 7.8 | 0.07 |",
        "| 100 | 36 | 109.0 | 17.3 | 0.13 |",
        "| 200 | 36 | 215.3 | 44.9 | 0.22 |",
        "",
        "**Observations:**",
        "- Document processing scales linearly (O(n))",
        "- Query time scales sub-linearly due to indexed lookups",
        "- Compute time scales slightly super-linearly due to connection building",
        "",
        "---",
        "",
        "## Performance Thresholds",
        "",
        "These thresholds are used in CI to catch performance regressions:",
        "",
        "| Operation | Threshold | Notes |",
        "|-----------|-----------|-------|",
        "| compute_all() (25 docs) | 5,000 ms | Generous for CI variability |",
        "| propagate_activation | 1,000 ms | Per-phase limit |",
        "| compute_importance | 1,000 ms | PageRank phase |",
        "| compute_tfidf | 1,000 ms | TF-IDF phase |",
        "| compute_bigram_connections | 2,000 ms | Most expensive phase |",
        "| build_concept_clusters | 2,000 ms | Louvain clustering |",
        "| compute_graph_embeddings | 2,000 ms | Embedding phase |",
        "| Single query | 200 ms | Interactive use |",
        "| Query expansion | 100 ms | Per expansion |",
        "| Passage retrieval | 500 ms | Including chunking |",
        "",
        "---",
        "",
        "## Bottleneck Analysis",
        "",
        "### Primary Bottleneck: Bigram Connections",
        "",
        "On small corpora, `compute_bigram_connections` dominates at **68.6%** of compute time. This is due to O(n²) complexity when building co-occurrence connections.",
        "",
        "**Mitigation parameters:**",
        "```python",
        "CorticalConfig(",
        "    max_bigrams_per_term=100,   # Limits per-term connections",
        "    max_bigrams_per_doc=500,    # Limits per-document processing",
        ")",
        "```",
        "",
        "### Secondary Bottleneck: Semantic Extraction",
        "",
        "On larger corpora, semantic extraction can become expensive due to similarity computation across all term pairs.",
        "",
        "**Mitigation parameters:**",
        "```python",
        "CorticalConfig(",
        "    max_similarity_pairs=100000,  # Cap total similarity computations",
        "    min_context_keys=3,           # Require minimum context overlap",
        ")",
        "```",
        "",
        "### Lessons Learned",
        "",
        "From profiling sessions (documented in `samples/performance_profiling_process.txt`):",
        "",
        "1. **Profile before optimizing** - The obvious bottleneck (Louvain clustering) was actually fast (2.2s); the real culprits were bigram connections and semantics",
        "2. **O(n²) patterns explode** - Common terms like \"self\" creating millions of pairs",
        "3. **Parameter limits are essential** - Trading completeness for tractability",
        "",
        "---",
        "",
        "## Running Benchmarks",
        "",
        "### Quick Performance Check",
        "```bash",
        "# Run performance tests (without coverage)",
        "python -m pytest tests/performance/ -v --no-cov",
        "```",
        "",
        "### Profile Full Analysis",
        "```bash",
        "# Profile all compute phases",
        "python scripts/profile_full_analysis.py",
        "",
        "# Profile specific phase",
        "python scripts/profile_full_analysis.py --phase louvain",
        "python scripts/profile_full_analysis.py --phase semantics",
        "python scripts/profile_full_analysis.py --phase bigram",
        "",
        "# With custom timeout",
        "python scripts/profile_full_analysis.py --timeout 60",
        "```",
        "",
        "### Custom Benchmarks",
        "",
        "```python",
        "from cortical import CorticalTextProcessor",
        "import time",
        "",
        "processor = CorticalTextProcessor(enable_metrics=True)",
        "",
        "# Process documents",
        "for doc_id, content in documents.items():",
        "    processor.process_document(doc_id, content)",
        "",
        "# Run compute phases",
        "processor.compute_all(verbose=True)  # Shows phase timings",
        "",
        "# Get metrics summary",
        "print(processor.get_metrics_summary())",
        "```",
        "",
        "---",
        "",
        "## Optimizing for Your Use Case",
        "",
        "### High-Throughput Document Processing",
        "",
        "```python",
        "# Use batch processing",
        "processor.add_documents_batch(doc_dict)  # More efficient than individual adds",
        "",
        "# Skip expensive phases if not needed",
        "processor.compute_tfidf()  # Just TF-IDF",
        "processor.compute_importance()  # Just PageRank",
        "# Skip: bigram_connections, concept_clusters, semantics",
        "```",
        "",
        "### Low-Latency Search",
        "",
        "```python",
        "# Use fast search for interactive queries",
        "results = processor.fast_find_documents(query, top_n=10)",
        "",
        "# Pre-build search index for repeated queries",
        "index = processor.build_search_index()",
        "results = processor.search_with_index(query, index)",
        "",
        "# Cache query expansions",
        "expanded = processor.expand_query_cached(query)",
        "```",
        "",
        "### Memory-Constrained Environments",
        "",
        "```python",
        "# Use streaming document processing",
        "for doc_id, content in large_corpus:",
        "    processor.add_document_incremental(doc_id, content, recompute='none')",
        "",
        "# Compute in batches",
        "processor.compute_tfidf()  # Lightweight",
        "processor.compute_importance()  # Moderate",
        "# Defer expensive operations",
        "```",
        "",
        "### Git-Friendly Collaborative Indexing",
        "",
        "```bash",
        "# Use chunk-based storage for team workflows",
        "python scripts/index_codebase.py --incremental --use-chunks",
        "",
        "# Periodic compaction",
        "python scripts/index_codebase.py --compact --use-chunks",
        "```",
        "",
        "---",
        "",
        "## Historical Performance Fixes",
        "",
        "| Date | Issue | Before | After | Fix |",
        "|------|-------|--------|-------|-----|",
        "| 2025-12-11 | bigram_connections timeout | 20.85s timeout | 10.79s | `max_bigrams_per_term=100` |",
        "| 2025-12-11 | semantics timeout | 30.05s timeout | 5.56s | `max_similarity_pairs=100000` |",
        "| 2025-12-11 | louvain (not a bottleneck) | 2.2s | 2.2s | No change needed |",
        "",
        "---",
        "",
        "## Notes",
        "",
        "- All timings measured without coverage instrumentation (coverage adds ~10x overhead)",
        "- Timings will vary based on hardware, Python version, and corpus characteristics",
        "- Query performance depends heavily on corpus vocabulary and connection density",
        "- Persistence times are I/O bound and vary with storage medium"
      ],
      "lines_removed": [],
      "context_before": [],
      "context_after": [],
      "change_type": "add"
    }
  ],
  "hour_of_day": 4,
  "day_of_week": "Monday",
  "seconds_since_last_commit": -32823,
  "is_merge": false,
  "is_initial": false,
  "parent_count": 1,
  "session_id": null,
  "related_chats": [],
  "ci_result": null,
  "reverted": false,
  "amended": false
}