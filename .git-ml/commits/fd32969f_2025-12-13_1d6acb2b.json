{
  "hash": "fd32969fb81c576e419f0423fdfabface624faf8",
  "message": "Add legacy-style unit tests for coverage",
  "author": "Claude",
  "timestamp": "2025-12-13 05:04:09 +0000",
  "branch": "claude/multi-index-design-DvifZ",
  "files_changed": [
    "tests/test_fluent.py",
    "tests/test_progress.py",
    "tests/test_results.py"
  ],
  "insertions": 881,
  "deletions": 0,
  "hunks": [
    {
      "file": "tests/test_fluent.py",
      "function": null,
      "start_line": 0,
      "lines_added": [
        "\"\"\"",
        "Tests for the FluentProcessor API.",
        "",
        "Ensures the fluent/chainable interface works correctly.",
        "\"\"\"",
        "",
        "import os",
        "import tempfile",
        "import unittest",
        "",
        "from cortical import CorticalTextProcessor, CorticalConfig",
        "from cortical.fluent import FluentProcessor",
        "",
        "",
        "class TestFluentProcessorInit(unittest.TestCase):",
        "    \"\"\"Test FluentProcessor initialization.\"\"\"",
        "",
        "    def test_default_init(self):",
        "        \"\"\"Test default initialization.\"\"\"",
        "        fp = FluentProcessor()",
        "        self.assertIsNotNone(fp)",
        "        self.assertIsInstance(fp.processor, CorticalTextProcessor)",
        "        self.assertFalse(fp.is_built)",
        "",
        "    def test_init_with_config(self):",
        "        \"\"\"Test initialization with config.\"\"\"",
        "        config = CorticalConfig(pagerank_damping=0.9)",
        "        fp = FluentProcessor(config=config)",
        "        self.assertEqual(fp.processor.config.pagerank_damping, 0.9)",
        "",
        "    def test_from_existing(self):",
        "        \"\"\"Test wrapping existing processor.\"\"\"",
        "        proc = CorticalTextProcessor()",
        "        proc.process_document(\"doc1\", \"Test content\")",
        "        fp = FluentProcessor.from_existing(proc)",
        "        self.assertEqual(fp.processor, proc)",
        "",
        "    def test_repr(self):",
        "        \"\"\"Test string representation.\"\"\"",
        "        fp = FluentProcessor()",
        "        self.assertIn(\"FluentProcessor\", repr(fp))",
        "",
        "",
        "class TestFluentProcessorChaining(unittest.TestCase):",
        "    \"\"\"Test method chaining.\"\"\"",
        "",
        "    def test_add_document_returns_self(self):",
        "        \"\"\"add_document returns self for chaining.\"\"\"",
        "        fp = FluentProcessor()",
        "        result = fp.add_document(\"doc1\", \"Content\")",
        "        self.assertIs(result, fp)",
        "",
        "    def test_add_documents_returns_self(self):",
        "        \"\"\"add_documents returns self for chaining.\"\"\"",
        "        fp = FluentProcessor()",
        "        result = fp.add_documents({\"doc1\": \"Content\"})",
        "        self.assertIs(result, fp)",
        "",
        "    def test_build_returns_self(self):",
        "        \"\"\"build returns self for chaining.\"\"\"",
        "        fp = FluentProcessor()",
        "        fp.add_document(\"doc1\", \"Content\")",
        "        result = fp.build(verbose=False)",
        "        self.assertIs(result, fp)",
        "",
        "    def test_full_chain(self):",
        "        \"\"\"Test complete method chain.\"\"\"",
        "        results = (FluentProcessor()",
        "            .add_document(\"doc1\", \"Neural networks process data\")",
        "            .add_document(\"doc2\", \"Machine learning is powerful\")",
        "            .build(verbose=False)",
        "            .search(\"neural\", top_n=2))",
        "        self.assertIsInstance(results, list)",
        "",
        "",
        "class TestFluentProcessorDocuments(unittest.TestCase):",
        "    \"\"\"Test document handling.\"\"\"",
        "",
        "    def test_add_single_document(self):",
        "        \"\"\"Test adding a single document.\"\"\"",
        "        fp = FluentProcessor()",
        "        fp.add_document(\"doc1\", \"Test content here\")",
        "        self.assertIn(\"doc1\", fp.processor.documents)",
        "",
        "    def test_add_document_with_metadata(self):",
        "        \"\"\"Test adding document with metadata.\"\"\"",
        "        fp = FluentProcessor()",
        "        fp.add_document(\"doc1\", \"Content\", metadata={\"author\": \"test\"})",
        "        self.assertIn(\"doc1\", fp.processor.documents)",
        "",
        "    def test_add_documents_dict(self):",
        "        \"\"\"Test adding multiple documents from dict.\"\"\"",
        "        fp = FluentProcessor()",
        "        fp.add_documents({",
        "            \"doc1\": \"Content one\",",
        "            \"doc2\": \"Content two\"",
        "        })",
        "        self.assertIn(\"doc1\", fp.processor.documents)",
        "        self.assertIn(\"doc2\", fp.processor.documents)",
        "",
        "    def test_add_documents_tuples(self):",
        "        \"\"\"Test adding documents from list of tuples.\"\"\"",
        "        fp = FluentProcessor()",
        "        fp.add_documents([",
        "            (\"doc1\", \"Content one\"),",
        "            (\"doc2\", \"Content two\")",
        "        ])",
        "        self.assertIn(\"doc1\", fp.processor.documents)",
        "        self.assertIn(\"doc2\", fp.processor.documents)",
        "",
        "    def test_add_documents_invalid_type(self):",
        "        \"\"\"Test error on invalid input type.\"\"\"",
        "        fp = FluentProcessor()",
        "        with self.assertRaises(TypeError):",
        "            fp.add_documents(\"invalid\")",
        "",
        "",
        "class TestFluentProcessorBuild(unittest.TestCase):",
        "    \"\"\"Test build functionality.\"\"\"",
        "",
        "    def test_build_marks_built(self):",
        "        \"\"\"Test that build marks processor as built.\"\"\"",
        "        fp = FluentProcessor()",
        "        fp.add_document(\"doc1\", \"Content\")",
        "        self.assertFalse(fp.is_built)",
        "        fp.build(verbose=False)",
        "        self.assertTrue(fp.is_built)",
        "",
        "    def test_add_after_build_marks_unbuilt(self):",
        "        \"\"\"Test adding document after build marks as unbuilt.\"\"\"",
        "        fp = FluentProcessor()",
        "        fp.add_document(\"doc1\", \"Content\")",
        "        fp.build(verbose=False)",
        "        self.assertTrue(fp.is_built)",
        "        fp.add_document(\"doc2\", \"More content\")",
        "        self.assertFalse(fp.is_built)",
        "",
        "",
        "class TestFluentProcessorSearch(unittest.TestCase):",
        "    \"\"\"Test search functionality.\"\"\"",
        "",
        "    def setUp(self):",
        "        \"\"\"Set up a built processor.\"\"\"",
        "        self.fp = (FluentProcessor()",
        "            .add_document(\"neural\", \"Neural networks are computational models\")",
        "            .add_document(\"ml\", \"Machine learning algorithms learn from data\")",
        "            .add_document(\"deep\", \"Deep learning uses neural network layers\")",
        "            .build(verbose=False))",
        "",
        "    def test_search_returns_results(self):",
        "        \"\"\"Test basic search returns results.\"\"\"",
        "        results = self.fp.search(\"neural\", top_n=3)",
        "        self.assertIsInstance(results, list)",
        "        self.assertGreater(len(results), 0)",
        "",
        "    def test_search_result_structure(self):",
        "        \"\"\"Test search result tuple structure.\"\"\"",
        "        results = self.fp.search(\"neural\", top_n=1)",
        "        self.assertEqual(len(results[0]), 2)  # (doc_id, score)",
        "",
        "    def test_fast_search(self):",
        "        \"\"\"Test fast search method.\"\"\"",
        "        results = self.fp.fast_search(\"neural\", top_n=3)",
        "        self.assertIsInstance(results, list)",
        "",
        "    def test_search_passages(self):",
        "        \"\"\"Test passage search.\"\"\"",
        "        results = self.fp.search_passages(\"neural\", top_n=2)",
        "        self.assertIsInstance(results, list)",
        "",
        "    def test_expand_query(self):",
        "        \"\"\"Test query expansion.\"\"\"",
        "        expanded = self.fp.expand(\"neural\", max_expansions=5)",
        "        self.assertIsInstance(expanded, dict)",
        "",
        "",
        "class TestFluentProcessorPersistence(unittest.TestCase):",
        "    \"\"\"Test save/load functionality.\"\"\"",
        "",
        "    def test_save_and_load(self):",
        "        \"\"\"Test saving and loading processor.\"\"\"",
        "        with tempfile.NamedTemporaryFile(suffix='.pkl', delete=False) as f:",
        "            path = f.name",
        "",
        "        try:",
        "            # Save",
        "            (FluentProcessor()",
        "                .add_document(\"doc1\", \"Test content\")",
        "                .build(verbose=False)",
        "                .save(path))",
        "",
        "            # Load",
        "            fp = FluentProcessor.load(path)",
        "            self.assertTrue(fp.is_built)",
        "            self.assertIn(\"doc1\", fp.processor.documents)",
        "        finally:",
        "            if os.path.exists(path):",
        "                os.unlink(path)",
        "",
        "",
        "class TestFluentProcessorFiles(unittest.TestCase):",
        "    \"\"\"Test file loading functionality.\"\"\"",
        "",
        "    def test_from_files(self):",
        "        \"\"\"Test loading from files.\"\"\"",
        "        with tempfile.TemporaryDirectory() as tmpdir:",
        "            # Create test files",
        "            file1 = os.path.join(tmpdir, \"test1.txt\")",
        "            file2 = os.path.join(tmpdir, \"test2.txt\")",
        "            with open(file1, 'w') as f:",
        "                f.write(\"Content of file one\")",
        "            with open(file2, 'w') as f:",
        "                f.write(\"Content of file two\")",
        "",
        "            fp = FluentProcessor.from_files([file1, file2])",
        "            self.assertEqual(len(fp.processor.documents), 2)",
        "",
        "    def test_from_directory(self):",
        "        \"\"\"Test loading from directory.\"\"\"",
        "        with tempfile.TemporaryDirectory() as tmpdir:",
        "            # Create test files",
        "            for i in range(3):",
        "                path = os.path.join(tmpdir, f\"test{i}.txt\")",
        "                with open(path, 'w') as f:",
        "                    f.write(f\"Content of file {i}\")",
        "",
        "            fp = FluentProcessor.from_directory(tmpdir, pattern=\"*.txt\")",
        "            self.assertEqual(len(fp.processor.documents), 3)",
        "",
        "",
        "if __name__ == '__main__':",
        "    unittest.main()"
      ],
      "lines_removed": [],
      "context_before": [],
      "context_after": [],
      "change_type": "add"
    },
    {
      "file": "tests/test_progress.py",
      "function": null,
      "start_line": 0,
      "lines_added": [
        "\"\"\"",
        "Tests for the progress reporting system.",
        "",
        "Ensures progress feedback during long operations works correctly.",
        "\"\"\"",
        "",
        "import io",
        "import sys",
        "import unittest",
        "",
        "from cortical import CorticalTextProcessor",
        "from cortical.progress import (",
        "    ConsoleProgressReporter,",
        "    CallbackProgressReporter,",
        "    SilentProgressReporter,",
        "    MultiPhaseProgress,",
        ")",
        "",
        "",
        "class TestConsoleProgressReporter(unittest.TestCase):",
        "    \"\"\"Test ConsoleProgressReporter.\"\"\"",
        "",
        "    def test_update_formats_correctly(self):",
        "        \"\"\"Test update produces correct format.\"\"\"",
        "        output = io.StringIO()",
        "        reporter = ConsoleProgressReporter(file=output, width=20)",
        "        reporter.update(\"Testing\", 50)",
        "        output_str = output.getvalue()",
        "        self.assertIn(\"Testing\", output_str)",
        "        self.assertIn(\"50%\", output_str)",
        "",
        "    def test_complete_shows_100_percent(self):",
        "        \"\"\"Test complete shows 100%.\"\"\"",
        "        output = io.StringIO()",
        "        reporter = ConsoleProgressReporter(file=output)",
        "        reporter.complete(\"Testing\")",
        "        output_str = output.getvalue()",
        "        self.assertIn(\"100%\", output_str)",
        "",
        "    def test_complete_shows_elapsed_time(self):",
        "        \"\"\"Test complete shows elapsed time.\"\"\"",
        "        output = io.StringIO()",
        "        reporter = ConsoleProgressReporter(file=output)",
        "        reporter.update(\"Testing\", 50)  # Start tracking",
        "        reporter.complete(\"Testing\")",
        "        output_str = output.getvalue()",
        "        # Should have time indicator",
        "        self.assertIn(\"s\", output_str)",
        "",
        "    def test_update_with_message(self):",
        "        \"\"\"Test update with custom message.\"\"\"",
        "        output = io.StringIO()",
        "        reporter = ConsoleProgressReporter(file=output)",
        "        reporter.update(\"Testing\", 50, \"Processing items\")",
        "        output_str = output.getvalue()",
        "        self.assertIn(\"50%\", output_str)",
        "",
        "    def test_progress_bar_width(self):",
        "        \"\"\"Test progress bar respects width.\"\"\"",
        "        output = io.StringIO()",
        "        reporter = ConsoleProgressReporter(file=output, width=10)",
        "        reporter.update(\"Testing\", 50)",
        "        output_str = output.getvalue()",
        "        self.assertIn(\"Testing\", output_str)",
        "",
        "    def test_unicode_vs_ascii(self):",
        "        \"\"\"Test Unicode vs ASCII mode.\"\"\"",
        "        output1 = io.StringIO()",
        "        output2 = io.StringIO()",
        "",
        "        reporter1 = ConsoleProgressReporter(file=output1, use_unicode=True)",
        "        reporter2 = ConsoleProgressReporter(file=output2, use_unicode=False)",
        "",
        "        reporter1.update(\"Test\", 50)",
        "        reporter2.update(\"Test\", 50)",
        "",
        "        # Both should produce output",
        "        self.assertTrue(len(output1.getvalue()) > 0)",
        "        self.assertTrue(len(output2.getvalue()) > 0)",
        "",
        "    def test_percentage_clamping(self):",
        "        \"\"\"Test percentage is handled correctly.\"\"\"",
        "        output = io.StringIO()",
        "        reporter = ConsoleProgressReporter(file=output)",
        "",
        "        # Should not crash with various values",
        "        reporter.update(\"Test\", 0)",
        "        reporter.update(\"Test\", 100)",
        "        self.assertIn(\"%\", output.getvalue())",
        "",
        "",
        "class TestCallbackProgressReporter(unittest.TestCase):",
        "    \"\"\"Test CallbackProgressReporter.\"\"\"",
        "",
        "    def test_callback_invoked_on_update(self):",
        "        \"\"\"Test callback is called on update.\"\"\"",
        "        calls = []",
        "        def callback(phase, pct, msg):",
        "            calls.append((phase, pct, msg))",
        "",
        "        reporter = CallbackProgressReporter(callback)",
        "        reporter.update(\"Testing\", 50, \"message\")",
        "",
        "        self.assertEqual(len(calls), 1)",
        "        self.assertEqual(calls[0][0], \"Testing\")",
        "        self.assertEqual(calls[0][1], 50)",
        "",
        "    def test_callback_invoked_on_complete(self):",
        "        \"\"\"Test callback is called on complete.\"\"\"",
        "        calls = []",
        "        def callback(phase, pct, msg):",
        "            calls.append((phase, pct, msg))",
        "",
        "        reporter = CallbackProgressReporter(callback)",
        "        reporter.complete(\"Testing\")",
        "",
        "        self.assertEqual(len(calls), 1)",
        "        self.assertEqual(calls[0][1], 100)",
        "",
        "    def test_multiple_updates(self):",
        "        \"\"\"Test multiple update calls.\"\"\"",
        "        calls = []",
        "        def callback(phase, pct, msg):",
        "            calls.append(pct)",
        "",
        "        reporter = CallbackProgressReporter(callback)",
        "        reporter.update(\"Test\", 25)",
        "        reporter.update(\"Test\", 50)",
        "        reporter.update(\"Test\", 75)",
        "        reporter.complete(\"Test\")",
        "",
        "        self.assertEqual(calls, [25, 50, 75, 100])",
        "",
        "",
        "class TestSilentProgressReporter(unittest.TestCase):",
        "    \"\"\"Test SilentProgressReporter.\"\"\"",
        "",
        "    def test_update_does_nothing(self):",
        "        \"\"\"Test update doesn't crash.\"\"\"",
        "        reporter = SilentProgressReporter()",
        "        reporter.update(\"Test\", 50)  # Should not raise",
        "        reporter.update(\"Test\", 100, \"message\")  # Should not raise",
        "",
        "    def test_complete_does_nothing(self):",
        "        \"\"\"Test complete doesn't crash.\"\"\"",
        "        reporter = SilentProgressReporter()",
        "        reporter.complete(\"Test\")  # Should not raise",
        "        reporter.complete(\"Test\", \"message\")  # Should not raise",
        "",
        "",
        "class TestMultiPhaseProgress(unittest.TestCase):",
        "    \"\"\"Test MultiPhaseProgress helper.\"\"\"",
        "",
        "    def test_initialization(self):",
        "        \"\"\"Test initialization with phases.\"\"\"",
        "        phases = {\"phase1\": 30, \"phase2\": 70}",
        "        reporter = SilentProgressReporter()",
        "        progress = MultiPhaseProgress(reporter, phases)",
        "        self.assertEqual(len(progress.phases), 2)",
        "",
        "    def test_phase_normalization(self):",
        "        \"\"\"Test phase weights are normalized.\"\"\"",
        "        phases = {\"phase1\": 50, \"phase2\": 50}",
        "        reporter = SilentProgressReporter()",
        "        progress = MultiPhaseProgress(reporter, phases)",
        "        # Weights should sum to 100",
        "        total = sum(progress.phases.values())",
        "        self.assertAlmostEqual(total, 100.0, places=5)",
        "",
        "    def test_start_phase(self):",
        "        \"\"\"Test starting a phase.\"\"\"",
        "        calls = []",
        "        def callback(phase, pct, msg):",
        "            calls.append((phase, pct))",
        "",
        "        phases = {\"phase1\": 50, \"phase2\": 50}",
        "        reporter = CallbackProgressReporter(callback)",
        "        progress = MultiPhaseProgress(reporter, phases)",
        "        progress.start_phase(\"phase1\")",
        "",
        "        self.assertGreater(len(calls), 0)",
        "",
        "    def test_update_within_phase(self):",
        "        \"\"\"Test updating progress within a phase.\"\"\"",
        "        calls = []",
        "        def callback(phase, pct, msg):",
        "            calls.append(pct)",
        "",
        "        phases = {\"phase1\": 100}",
        "        reporter = CallbackProgressReporter(callback)",
        "        progress = MultiPhaseProgress(reporter, phases)",
        "        progress.start_phase(\"phase1\")",
        "        progress.update(50)",
        "",
        "        # Should have some progress reported",
        "        self.assertGreater(len(calls), 0)",
        "",
        "    def test_complete_phase(self):",
        "        \"\"\"Test completing a phase.\"\"\"",
        "        calls = []",
        "        def callback(phase, pct, msg):",
        "            calls.append(pct)",
        "",
        "        phases = {\"phase1\": 50, \"phase2\": 50}",
        "        reporter = CallbackProgressReporter(callback)",
        "        progress = MultiPhaseProgress(reporter, phases)",
        "        progress.start_phase(\"phase1\")",
        "        progress.complete_phase()",
        "",
        "        # Should have completed first phase",
        "        self.assertGreater(len(calls), 0)",
        "",
        "    def test_sequential_phases(self):",
        "        \"\"\"Test running phases sequentially.\"\"\"",
        "        calls = []",
        "        def callback(phase, pct, msg):",
        "            calls.append(pct)",
        "",
        "        phases = {\"phase1\": 50, \"phase2\": 50}",
        "        reporter = CallbackProgressReporter(callback)",
        "        progress = MultiPhaseProgress(reporter, phases)",
        "",
        "        progress.start_phase(\"phase1\")",
        "        progress.update(50)",
        "        progress.complete_phase()",
        "",
        "        progress.start_phase(\"phase2\")",
        "        progress.update(50)",
        "        progress.complete_phase()",
        "",
        "        # Should have multiple updates",
        "        self.assertGreater(len(calls), 2)",
        "",
        "    def test_unknown_phase_raises(self):",
        "        \"\"\"Test starting unknown phase raises error.\"\"\"",
        "        phases = {\"phase1\": 100}",
        "        reporter = SilentProgressReporter()",
        "        progress = MultiPhaseProgress(reporter, phases)",
        "",
        "        with self.assertRaises(ValueError):",
        "            progress.start_phase(\"unknown\")",
        "",
        "",
        "class TestProcessorIntegration(unittest.TestCase):",
        "    \"\"\"Test integration with CorticalTextProcessor.\"\"\"",
        "",
        "    def test_compute_all_silent_default(self):",
        "        \"\"\"Test compute_all is silent by default.\"\"\"",
        "        proc = CorticalTextProcessor()",
        "        proc.process_document(\"doc1\", \"Test content\")",
        "",
        "        # Should not raise",
        "        proc.compute_all()",
        "",
        "    def test_compute_all_with_callback(self):",
        "        \"\"\"Test compute_all with progress callback.\"\"\"",
        "        proc = CorticalTextProcessor()",
        "        proc.process_document(\"doc1\", \"Test content\")",
        "",
        "        phases = []",
        "        def callback(phase, pct, msg):",
        "            if phase not in phases:",
        "                phases.append(phase)",
        "",
        "        reporter = CallbackProgressReporter(callback)",
        "        proc.compute_all(progress_callback=reporter)",
        "",
        "        # Should have reported some phases",
        "        self.assertGreater(len(phases), 0)",
        "",
        "    def test_compute_all_with_show_progress(self):",
        "        \"\"\"Test compute_all with show_progress flag.\"\"\"",
        "        proc = CorticalTextProcessor()",
        "        proc.process_document(\"doc1\", \"Test content\")",
        "",
        "        # Redirect stderr to capture progress",
        "        old_stderr = sys.stderr",
        "        sys.stderr = io.StringIO()",
        "",
        "        try:",
        "            proc.compute_all(show_progress=True)",
        "            output = sys.stderr.getvalue()",
        "        finally:",
        "            sys.stderr = old_stderr",
        "",
        "        # Should have some progress output",
        "        self.assertGreater(len(output), 0)",
        "",
        "    def test_backward_compatibility(self):",
        "        \"\"\"Test that old code still works.\"\"\"",
        "        proc = CorticalTextProcessor()",
        "        proc.process_document(\"doc1\", \"Test content here\")",
        "",
        "        # Old-style call without any progress arguments",
        "        proc.compute_all()",
        "",
        "        # Should complete successfully",
        "        self.assertFalse(proc.is_stale(proc.COMP_TFIDF))",
        "",
        "",
        "if __name__ == '__main__':",
        "    unittest.main()"
      ],
      "lines_removed": [],
      "context_before": [],
      "context_after": [],
      "change_type": "add"
    },
    {
      "file": "tests/test_results.py",
      "function": null,
      "start_line": 0,
      "lines_added": [
        "\"\"\"",
        "Tests for the result dataclasses.",
        "",
        "Ensures DocumentMatch, PassageMatch, and QueryResult work correctly.",
        "\"\"\"",
        "",
        "import unittest",
        "",
        "from cortical.results import (",
        "    DocumentMatch,",
        "    PassageMatch,",
        "    QueryResult,",
        "    convert_document_matches,",
        "    convert_passage_matches,",
        ")",
        "",
        "",
        "class TestDocumentMatch(unittest.TestCase):",
        "    \"\"\"Test DocumentMatch dataclass.\"\"\"",
        "",
        "    def test_creation_minimal(self):",
        "        \"\"\"Test creating with required fields only.\"\"\"",
        "        match = DocumentMatch(doc_id=\"doc1\", score=0.95)",
        "        self.assertEqual(match.doc_id, \"doc1\")",
        "        self.assertEqual(match.score, 0.95)",
        "        self.assertIsNone(match.metadata)",
        "",
        "    def test_creation_with_metadata(self):",
        "        \"\"\"Test creating with metadata.\"\"\"",
        "        match = DocumentMatch(",
        "            doc_id=\"doc1\",",
        "            score=0.95,",
        "            metadata={\"author\": \"test\"}",
        "        )",
        "        self.assertEqual(match.metadata[\"author\"], \"test\")",
        "",
        "    def test_immutable(self):",
        "        \"\"\"Test that dataclass is frozen.\"\"\"",
        "        match = DocumentMatch(doc_id=\"doc1\", score=0.95)",
        "        with self.assertRaises(AttributeError):",
        "            match.score = 0.5",
        "",
        "    def test_repr(self):",
        "        \"\"\"Test string representation.\"\"\"",
        "        match = DocumentMatch(doc_id=\"doc1\", score=0.95)",
        "        repr_str = repr(match)",
        "        self.assertIn(\"doc1\", repr_str)",
        "        self.assertIn(\"0.95\", repr_str)",
        "",
        "    def test_to_dict(self):",
        "        \"\"\"Test conversion to dictionary.\"\"\"",
        "        match = DocumentMatch(doc_id=\"doc1\", score=0.95)",
        "        d = match.to_dict()",
        "        self.assertEqual(d[\"doc_id\"], \"doc1\")",
        "        self.assertEqual(d[\"score\"], 0.95)",
        "",
        "    def test_to_tuple(self):",
        "        \"\"\"Test conversion to tuple.\"\"\"",
        "        match = DocumentMatch(doc_id=\"doc1\", score=0.95)",
        "        t = match.to_tuple()",
        "        self.assertEqual(t, (\"doc1\", 0.95))",
        "",
        "    def test_from_tuple(self):",
        "        \"\"\"Test creation from tuple arguments.\"\"\"",
        "        match = DocumentMatch.from_tuple(\"doc1\", 0.95)",
        "        self.assertEqual(match.doc_id, \"doc1\")",
        "        self.assertEqual(match.score, 0.95)",
        "",
        "    def test_from_tuple_with_metadata(self):",
        "        \"\"\"Test creation from tuple with metadata.\"\"\"",
        "        match = DocumentMatch.from_tuple(\"doc1\", 0.95, {\"key\": \"value\"})",
        "        self.assertEqual(match.metadata[\"key\"], \"value\")",
        "",
        "    def test_from_dict(self):",
        "        \"\"\"Test creation from dictionary.\"\"\"",
        "        match = DocumentMatch.from_dict({\"doc_id\": \"doc1\", \"score\": 0.95})",
        "        self.assertEqual(match.doc_id, \"doc1\")",
        "        self.assertEqual(match.score, 0.95)",
        "",
        "    def test_roundtrip_dict(self):",
        "        \"\"\"Test dict roundtrip preserves data.\"\"\"",
        "        original = DocumentMatch(doc_id=\"doc1\", score=0.95, metadata={\"key\": \"value\"})",
        "        restored = DocumentMatch.from_dict(original.to_dict())",
        "        self.assertEqual(original.doc_id, restored.doc_id)",
        "        self.assertEqual(original.score, restored.score)",
        "        self.assertEqual(original.metadata, restored.metadata)",
        "",
        "",
        "class TestPassageMatch(unittest.TestCase):",
        "    \"\"\"Test PassageMatch dataclass.\"\"\"",
        "",
        "    def test_creation_minimal(self):",
        "        \"\"\"Test creating with required fields.\"\"\"",
        "        match = PassageMatch(",
        "            doc_id=\"doc1\",",
        "            text=\"Sample text\",",
        "            score=0.85,",
        "            start=0,",
        "            end=11",
        "        )",
        "        self.assertEqual(match.doc_id, \"doc1\")",
        "        self.assertEqual(match.text, \"Sample text\")",
        "        self.assertEqual(match.score, 0.85)",
        "        self.assertEqual(match.start, 0)",
        "        self.assertEqual(match.end, 11)",
        "",
        "    def test_creation_with_metadata(self):",
        "        \"\"\"Test creating with metadata.\"\"\"",
        "        match = PassageMatch(",
        "            doc_id=\"doc1\",",
        "            text=\"Sample text\",",
        "            score=0.85,",
        "            start=0,",
        "            end=11,",
        "            metadata={\"highlight\": True}",
        "        )",
        "        self.assertTrue(match.metadata[\"highlight\"])",
        "",
        "    def test_immutable(self):",
        "        \"\"\"Test that dataclass is frozen.\"\"\"",
        "        match = PassageMatch(doc_id=\"doc1\", text=\"Text\", score=0.5, start=0, end=4)",
        "        with self.assertRaises(AttributeError):",
        "            match.text = \"Changed\"",
        "",
        "    def test_location_property(self):",
        "        \"\"\"Test location property for citations.\"\"\"",
        "        match = PassageMatch(",
        "            doc_id=\"file.py\",",
        "            text=\"Sample\",",
        "            score=0.5,",
        "            start=100,",
        "            end=150",
        "        )",
        "        self.assertEqual(match.location, \"file.py:100-150\")",
        "",
        "    def test_length_property(self):",
        "        \"\"\"Test length property.\"\"\"",
        "        match = PassageMatch(doc_id=\"doc1\", text=\"Test\", score=0.5, start=10, end=60)",
        "        self.assertEqual(match.length, 50)",
        "",
        "    def test_to_dict(self):",
        "        \"\"\"Test conversion to dictionary.\"\"\"",
        "        match = PassageMatch(doc_id=\"doc1\", text=\"Text\", score=0.5, start=0, end=4)",
        "        d = match.to_dict()",
        "        self.assertEqual(d[\"doc_id\"], \"doc1\")",
        "        self.assertEqual(d[\"text\"], \"Text\")",
        "        self.assertEqual(d[\"score\"], 0.5)",
        "        self.assertEqual(d[\"start\"], 0)",
        "        self.assertEqual(d[\"end\"], 4)",
        "",
        "    def test_to_tuple(self):",
        "        \"\"\"Test conversion to tuple (doc_id, text, start, end, score).\"\"\"",
        "        match = PassageMatch(doc_id=\"doc1\", text=\"Text\", score=0.5, start=0, end=4)",
        "        t = match.to_tuple()",
        "        # Order is: doc_id, text, start, end, score",
        "        self.assertEqual(t, (\"doc1\", \"Text\", 0, 4, 0.5))",
        "",
        "    def test_from_tuple(self):",
        "        \"\"\"Test creation from tuple arguments.\"\"\"",
        "        # Order is: doc_id, text, start, end, score",
        "        match = PassageMatch.from_tuple(\"doc1\", \"Text\", 0, 4, 0.5)",
        "        self.assertEqual(match.doc_id, \"doc1\")",
        "        self.assertEqual(match.text, \"Text\")",
        "        self.assertEqual(match.start, 0)",
        "        self.assertEqual(match.end, 4)",
        "        self.assertEqual(match.score, 0.5)",
        "",
        "    def test_from_dict(self):",
        "        \"\"\"Test creation from dictionary.\"\"\"",
        "        match = PassageMatch.from_dict({",
        "            \"doc_id\": \"doc1\",",
        "            \"text\": \"Text\",",
        "            \"score\": 0.5,",
        "            \"start\": 0,",
        "            \"end\": 4",
        "        })",
        "        self.assertEqual(match.doc_id, \"doc1\")",
        "",
        "    def test_repr_truncates_long_text(self):",
        "        \"\"\"Test repr truncates long text.\"\"\"",
        "        long_text = \"A\" * 100",
        "        match = PassageMatch(doc_id=\"doc1\", text=long_text, score=0.5, start=0, end=100)",
        "        repr_str = repr(match)",
        "        self.assertLess(len(repr_str), len(long_text) + 100)",
        "",
        "",
        "class TestQueryResult(unittest.TestCase):",
        "    \"\"\"Test QueryResult wrapper.\"\"\"",
        "",
        "    def test_creation_with_document_matches(self):",
        "        \"\"\"Test creating with document matches.\"\"\"",
        "        matches = [",
        "            DocumentMatch(doc_id=\"doc1\", score=0.9),",
        "            DocumentMatch(doc_id=\"doc2\", score=0.7)",
        "        ]",
        "        result = QueryResult(query=\"test\", matches=matches)",
        "        self.assertEqual(result.query, \"test\")",
        "        self.assertEqual(len(result.matches), 2)",
        "",
        "    def test_creation_with_passage_matches(self):",
        "        \"\"\"Test creating with passage matches.\"\"\"",
        "        matches = [",
        "            PassageMatch(doc_id=\"doc1\", text=\"Text\", score=0.9, start=0, end=4)",
        "        ]",
        "        result = QueryResult(query=\"test\", matches=matches)",
        "        self.assertEqual(len(result.matches), 1)",
        "",
        "    def test_creation_with_all_fields(self):",
        "        \"\"\"Test creating with all optional fields.\"\"\"",
        "        result = QueryResult(",
        "            query=\"test\",",
        "            matches=[DocumentMatch(doc_id=\"doc1\", score=0.9)],",
        "            expansion_terms={\"test\": 1.0, \"testing\": 0.8},",
        "            timing_ms=15.5,",
        "            metadata={\"source\": \"api\"}",
        "        )",
        "        self.assertEqual(result.expansion_terms[\"testing\"], 0.8)",
        "        self.assertEqual(result.timing_ms, 15.5)",
        "",
        "    def test_top_match_property(self):",
        "        \"\"\"Test top_match returns highest scoring.\"\"\"",
        "        matches = [",
        "            DocumentMatch(doc_id=\"doc1\", score=0.5),",
        "            DocumentMatch(doc_id=\"doc2\", score=0.9),",
        "            DocumentMatch(doc_id=\"doc3\", score=0.7)",
        "        ]",
        "        result = QueryResult(query=\"test\", matches=matches)",
        "        self.assertEqual(result.top_match.doc_id, \"doc2\")",
        "",
        "    def test_top_match_empty(self):",
        "        \"\"\"Test top_match with no matches.\"\"\"",
        "        result = QueryResult(query=\"test\", matches=[])",
        "        self.assertIsNone(result.top_match)",
        "",
        "    def test_match_count_property(self):",
        "        \"\"\"Test match_count property.\"\"\"",
        "        matches = [",
        "            DocumentMatch(doc_id=\"doc1\", score=0.5),",
        "            DocumentMatch(doc_id=\"doc2\", score=0.9)",
        "        ]",
        "        result = QueryResult(query=\"test\", matches=matches)",
        "        self.assertEqual(result.match_count, 2)",
        "",
        "    def test_average_score_property(self):",
        "        \"\"\"Test average_score calculation.\"\"\"",
        "        matches = [",
        "            DocumentMatch(doc_id=\"doc1\", score=0.4),",
        "            DocumentMatch(doc_id=\"doc2\", score=0.6)",
        "        ]",
        "        result = QueryResult(query=\"test\", matches=matches)",
        "        self.assertEqual(result.average_score, 0.5)",
        "",
        "    def test_average_score_empty(self):",
        "        \"\"\"Test average_score with no matches.\"\"\"",
        "        result = QueryResult(query=\"test\", matches=[])",
        "        self.assertEqual(result.average_score, 0.0)",
        "",
        "    def test_to_dict(self):",
        "        \"\"\"Test conversion to dictionary.\"\"\"",
        "        result = QueryResult(",
        "            query=\"test\",",
        "            matches=[DocumentMatch(doc_id=\"doc1\", score=0.9)]",
        "        )",
        "        d = result.to_dict()",
        "        self.assertEqual(d[\"query\"], \"test\")",
        "        self.assertEqual(len(d[\"matches\"]), 1)",
        "",
        "    def test_from_dict_document_matches(self):",
        "        \"\"\"Test creation from dict with document matches.\"\"\"",
        "        d = {",
        "            \"query\": \"test\",",
        "            \"matches\": [{\"doc_id\": \"doc1\", \"score\": 0.9, \"metadata\": None}]",
        "        }",
        "        result = QueryResult.from_dict(d)",
        "        self.assertEqual(result.query, \"test\")",
        "        self.assertIsInstance(result.matches[0], DocumentMatch)",
        "",
        "    def test_from_dict_passage_matches(self):",
        "        \"\"\"Test creation from dict with passage matches.\"\"\"",
        "        d = {",
        "            \"query\": \"test\",",
        "            \"matches\": [{\"doc_id\": \"doc1\", \"text\": \"Text\", \"score\": 0.9, \"start\": 0, \"end\": 4, \"metadata\": None}]",
        "        }",
        "        result = QueryResult.from_dict(d)",
        "        self.assertIsInstance(result.matches[0], PassageMatch)",
        "",
        "",
        "class TestHelperFunctions(unittest.TestCase):",
        "    \"\"\"Test conversion helper functions.\"\"\"",
        "",
        "    def test_convert_document_matches_basic(self):",
        "        \"\"\"Test converting list of tuples.\"\"\"",
        "        raw = [(\"doc1\", 0.9), (\"doc2\", 0.7)]",
        "        matches = convert_document_matches(raw)",
        "        self.assertEqual(len(matches), 2)",
        "        self.assertIsInstance(matches[0], DocumentMatch)",
        "        self.assertEqual(matches[0].doc_id, \"doc1\")",
        "",
        "    def test_convert_document_matches_empty(self):",
        "        \"\"\"Test converting empty list.\"\"\"",
        "        matches = convert_document_matches([])",
        "        self.assertEqual(matches, [])",
        "",
        "    def test_convert_document_matches_with_metadata(self):",
        "        \"\"\"Test converting with metadata dict.\"\"\"",
        "        raw = [(\"doc1\", 0.9), (\"doc2\", 0.7)]",
        "        metadata = {\"doc1\": {\"author\": \"test\"}}",
        "        matches = convert_document_matches(raw, metadata)",
        "        self.assertEqual(matches[0].metadata[\"author\"], \"test\")",
        "        self.assertIsNone(matches[1].metadata)",
        "",
        "    def test_convert_passage_matches_basic(self):",
        "        \"\"\"Test converting passage tuples (doc_id, text, start, end, score).\"\"\"",
        "        raw = [(\"doc1\", \"Sample\", 0, 6, 0.9)]",
        "        matches = convert_passage_matches(raw)",
        "        self.assertEqual(len(matches), 1)",
        "        self.assertIsInstance(matches[0], PassageMatch)",
        "        self.assertEqual(matches[0].text, \"Sample\")",
        "",
        "    def test_convert_passage_matches_empty(self):",
        "        \"\"\"Test converting empty list.\"\"\"",
        "        matches = convert_passage_matches([])",
        "        self.assertEqual(matches, [])",
        "",
        "",
        "class TestIntegration(unittest.TestCase):",
        "    \"\"\"Test integration with CorticalTextProcessor.\"\"\"",
        "",
        "    def test_document_search_workflow(self):",
        "        \"\"\"Test converting actual search results.\"\"\"",
        "        from cortical import CorticalTextProcessor",
        "",
        "        proc = CorticalTextProcessor()",
        "        proc.process_document(\"doc1\", \"Neural networks process data\")",
        "        proc.process_document(\"doc2\", \"Machine learning is powerful\")",
        "        proc.compute_all()",
        "",
        "        raw_results = proc.find_documents_for_query(\"neural\", top_n=2)",
        "        matches = convert_document_matches(raw_results)",
        "",
        "        self.assertGreater(len(matches), 0)",
        "        self.assertIsInstance(matches[0], DocumentMatch)",
        "        self.assertIsInstance(matches[0].score, float)",
        "",
        "",
        "if __name__ == '__main__':",
        "    unittest.main()"
      ],
      "lines_removed": [],
      "context_before": [],
      "context_after": [],
      "change_type": "add"
    }
  ],
  "hour_of_day": 5,
  "day_of_week": "Saturday",
  "seconds_since_last_commit": -204039,
  "is_merge": false,
  "is_initial": false,
  "parent_count": 1,
  "session_id": null,
  "related_chats": [],
  "ci_result": null,
  "reverted": false,
  "amended": false
}