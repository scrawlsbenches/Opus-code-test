{
  "hash": "79d3f6f379e2c959d0306aaafd1640ca3c0150dd",
  "message": "Add Mixture of Expert (MoE) index architecture documentation",
  "author": "Claude",
  "timestamp": "2025-12-15 06:06:59 +0000",
  "branch": "claude/multi-index-design-DvifZ",
  "files_changed": [
    "docs/moe-index-design.md",
    "docs/moe-index-implementation-plan.md",
    "docs/moe-index-knowledge-transfer.md"
  ],
  "insertions": 3155,
  "deletions": 0,
  "hunks": [
    {
      "file": "docs/moe-index-design.md",
      "function": null,
      "start_line": 0,
      "lines_added": [
        "# Mixture of Expert Indexes: Technical Design Document",
        "",
        "**Author:** Claude (AI Assistant)",
        "**Date:** 2025-12-15",
        "**Status:** Design Proposal",
        "**Version:** 1.0",
        "**Prerequisites:** [moe-index-knowledge-transfer.md](moe-index-knowledge-transfer.md)",
        "",
        "---",
        "",
        "## Table of Contents",
        "",
        "1. [Overview](#1-overview)",
        "2. [System Architecture](#2-system-architecture)",
        "3. [Expert Index Specifications](#3-expert-index-specifications)",
        "4. [Gating Network Design](#4-gating-network-design)",
        "5. [Result Fusion](#5-result-fusion)",
        "6. [Cross-Index Communication](#6-cross-index-communication)",
        "7. [Data Structures](#7-data-structures)",
        "8. [API Design](#8-api-design)",
        "9. [Integration with Existing System](#9-integration-with-existing-system)",
        "10. [Persistence and Synchronization](#10-persistence-and-synchronization)",
        "11. [Configuration](#11-configuration)",
        "12. [Testing Strategy](#12-testing-strategy)",
        "",
        "---",
        "",
        "## 1. Overview",
        "",
        "### 1.1 Design Goals",
        "",
        "1. **Improved query latency** for simple queries (target: <50ms for exact match)",
        "2. **Better relevance** through specialized handling",
        "3. **Extensibility** to add new expert indexes",
        "4. **Backward compatibility** with existing API",
        "5. **Zero external dependencies** (per project philosophy)",
        "",
        "### 1.2 Non-Goals",
        "",
        "1. ~~ML-based routing~~ (use rule-based/statistical instead)",
        "2. ~~Real-time expert retraining~~ (static specialization)",
        "3. ~~Distributed indexes~~ (single-machine focus for now)",
        "",
        "### 1.3 Key Design Decisions",
        "",
        "| Decision | Choice | Rationale |",
        "|----------|--------|-----------|",
        "| Routing approach | Feature + intent based | No ML dependencies |",
        "| Expert count | 5 initial | Cover primary use cases |",
        "| Default activation | Top-2 | Balance speed vs coverage |",
        "| Fusion strategy | Weighted RRF | Robust to score differences |",
        "| Storage | Shared + expert-specific | Minimize redundancy |",
        "",
        "---",
        "",
        "## 2. System Architecture",
        "",
        "### 2.1 High-Level Architecture",
        "",
        "```",
        "┌──────────────────────────────────────────────────────────────────────────┐",
        "│                           MoEIndexProcessor                               │",
        "│  (Extends/wraps CorticalTextProcessor)                                   │",
        "├──────────────────────────────────────────────────────────────────────────┤",
        "│                                                                          │",
        "│  ┌────────────────────────────────────────────────────────────────────┐ │",
        "│  │                         Query Router                                │ │",
        "│  │  ┌─────────────┐  ┌─────────────┐  ┌─────────────────────────────┐│ │",
        "│  │  │   Feature   │  │   Intent    │  │     Feedback Tracker        ││ │",
        "│  │  │  Extractor  │  │   Parser    │  │  (query patterns → weights) ││ │",
        "│  │  └──────┬──────┘  └──────┬──────┘  └─────────────┬───────────────┘│ │",
        "│  │         └────────────────┼───────────────────────┘                 │ │",
        "│  │                          ▼                                          │ │",
        "│  │                  ┌───────────────┐                                  │ │",
        "│  │                  │ Weight Combiner│                                 │ │",
        "│  │                  └───────┬───────┘                                  │ │",
        "│  └──────────────────────────┼──────────────────────────────────────────┘ │",
        "│                             │                                            │",
        "│                   expert_weights: Dict[str, float]                       │",
        "│                             │                                            │",
        "│  ┌──────────────────────────┼──────────────────────────────────────────┐ │",
        "│  │                    Expert Registry                                   │ │",
        "│  │                          │                                           │ │",
        "│  │    ┌─────────────────────┼─────────────────────────────────┐        │ │",
        "│  │    │           │         │         │           │           │        │ │",
        "│  │    ▼           ▼         ▼         ▼           ▼           │        │ │",
        "│  │ ┌──────┐  ┌──────┐  ┌──────┐  ┌──────┐  ┌──────────┐       │        │ │",
        "│  │ │Lexical│  │Semantic│ │Struct│  │Temporal│ │Episodic │      │        │ │",
        "│  │ │Expert │  │Expert │  │Expert│  │Expert │  │Expert   │      │        │ │",
        "│  │ └───┬──┘  └───┬───┘  └───┬──┘  └───┬───┘  └────┬────┘      │        │ │",
        "│  │     │         │          │         │           │            │        │ │",
        "│  └─────┼─────────┼──────────┼─────────┼───────────┼────────────┘        │ │",
        "│        │         │          │         │           │                      │",
        "│        └─────────┴──────────┴─────────┴───────────┘                      │",
        "│                             │                                            │",
        "│                    expert_results: Dict[str, ExpertResult]               │",
        "│                             │                                            │",
        "│  ┌──────────────────────────┼──────────────────────────────────────────┐ │",
        "│  │                    Result Fusioner                                   │ │",
        "│  │  ┌─────────────────────────────────────────────────────────────────┐│ │",
        "│  │  │  Cross-Pollination  →  Score Normalization  →  Rank Fusion      ││ │",
        "│  │  └─────────────────────────────────────────────────────────────────┘│ │",
        "│  └──────────────────────────┬──────────────────────────────────────────┘ │",
        "│                             │                                            │",
        "│                      MoEResult                                           │",
        "│                             │                                            │",
        "└─────────────────────────────┼────────────────────────────────────────────┘",
        "                              ▼",
        "                         User Response",
        "```",
        "",
        "### 2.2 Module Organization",
        "",
        "```",
        "cortical/",
        "├── moe/                           # NEW: MoE index package",
        "│   ├── __init__.py               # Public exports",
        "│   ├── router.py                 # Query routing logic (~300 lines)",
        "│   ├── experts/                  # Expert index implementations",
        "│   │   ├── __init__.py",
        "│   │   ├── base.py              # Abstract ExpertIndex base (~150 lines)",
        "│   │   ├── lexical.py           # Lexical expert (~400 lines)",
        "│   │   ├── semantic.py          # Semantic expert (wraps current) (~200 lines)",
        "│   │   ├── structural.py        # Structural expert (~500 lines)",
        "│   │   ├── temporal.py          # Temporal expert (~350 lines)",
        "│   │   └── episodic.py          # Episodic expert (~250 lines)",
        "│   ├── fusion.py                 # Result combination (~200 lines)",
        "│   ├── feedback.py               # Feedback tracking (~150 lines)",
        "│   └── types.py                  # Shared types (~100 lines)",
        "├── processor/                     # Existing (minimal changes)",
        "│   └── ...",
        "└── ...",
        "```",
        "",
        "**Estimated new code:** ~2,100 lines",
        "",
        "### 2.3 Component Responsibilities",
        "",
        "| Component | Responsibility | Dependencies |",
        "|-----------|----------------|--------------|",
        "| `MoEIndexProcessor` | Top-level orchestrator | All components |",
        "| `QueryRouter` | Compute expert weights | Feature extractor, intent parser |",
        "| `ExpertRegistry` | Manage expert lifecycle | Expert implementations |",
        "| `ResultFusioner` | Combine expert results | Fusion strategies |",
        "| `FeedbackTracker` | Learn from interactions | Persistence layer |",
        "| `ExpertIndex` (base) | Interface for experts | None |",
        "",
        "---",
        "",
        "## 3. Expert Index Specifications",
        "",
        "### 3.1 Abstract Base Class",
        "",
        "```python",
        "# cortical/moe/experts/base.py",
        "",
        "from abc import ABC, abstractmethod",
        "from typing import List, Dict, Optional, Set",
        "from dataclasses import dataclass",
        "",
        "@dataclass",
        "class ExpertResult:",
        "    \"\"\"Result from a single expert.\"\"\"",
        "    documents: List[str]           # Ranked doc_ids",
        "    scores: Dict[str, float]       # doc_id → relevance score",
        "    metadata: Dict[str, any]       # Expert-specific metadata",
        "    latency_ms: float              # Query latency",
        "    confidence: float              # Self-reported confidence [0, 1]",
        "",
        "class ExpertIndex(ABC):",
        "    \"\"\"Abstract base class for expert indexes.\"\"\"",
        "",
        "    @property",
        "    @abstractmethod",
        "    def name(self) -> str:",
        "        \"\"\"Unique expert identifier.\"\"\"",
        "        pass",
        "",
        "    @property",
        "    @abstractmethod",
        "    def description(self) -> str:",
        "        \"\"\"Human-readable description.\"\"\"",
        "        pass",
        "",
        "    @property",
        "    @abstractmethod",
        "    def capabilities(self) -> Set[str]:",
        "        \"\"\"Set of capability tags: {'exact_match', 'semantic', 'structural', ...}\"\"\"",
        "        pass",
        "",
        "    @abstractmethod",
        "    def query(",
        "        self,",
        "        query_text: str,",
        "        top_n: int = 10,",
        "        context: Optional[Dict] = None",
        "    ) -> ExpertResult:",
        "        \"\"\"Execute query and return results.\"\"\"",
        "        pass",
        "",
        "    @abstractmethod",
        "    def add_document(self, doc_id: str, content: str, metadata: Dict) -> None:",
        "        \"\"\"Index a document.\"\"\"",
        "        pass",
        "",
        "    @abstractmethod",
        "    def remove_document(self, doc_id: str) -> None:",
        "        \"\"\"Remove a document from index.\"\"\"",
        "        pass",
        "",
        "    @abstractmethod",
        "    def is_stale(self) -> bool:",
        "        \"\"\"Check if index needs recomputation.\"\"\"",
        "        pass",
        "",
        "    @abstractmethod",
        "    def recompute(self) -> None:",
        "        \"\"\"Recompute derived structures.\"\"\"",
        "        pass",
        "",
        "    @abstractmethod",
        "    def save(self, path: str) -> None:",
        "        \"\"\"Persist index to disk.\"\"\"",
        "        pass",
        "",
        "    @classmethod",
        "    @abstractmethod",
        "    def load(cls, path: str) -> 'ExpertIndex':",
        "        \"\"\"Load index from disk.\"\"\"",
        "        pass",
        "",
        "    def get_stats(self) -> Dict[str, any]:",
        "        \"\"\"Return index statistics.\"\"\"",
        "        return {",
        "            'name': self.name,",
        "            'capabilities': list(self.capabilities),",
        "        }",
        "```",
        "",
        "### 3.2 Lexical Expert",
        "",
        "**Purpose:** Fast exact and near-exact matching.",
        "",
        "**Data Structures:**",
        "",
        "```python",
        "# cortical/moe/experts/lexical.py",
        "",
        "class LexicalExpert(ExpertIndex):",
        "    \"\"\"Fast lexical search using inverted index.\"\"\"",
        "",
        "    def __init__(self, config: LexicalConfig):",
        "        # Core index: term → [(doc_id, positions, tf)]",
        "        self._inverted_index: Dict[str, List[Posting]] = {}",
        "",
        "        # Document metadata: doc_id → (length, max_tf)",
        "        self._doc_stats: Dict[str, DocStats] = {}",
        "",
        "        # Collection statistics",
        "        self._total_docs: int = 0",
        "        self._avg_doc_length: float = 0.0",
        "",
        "        # Optional: prefix trie for autocomplete",
        "        self._prefix_trie: Optional[PrefixTrie] = None",
        "",
        "        # BM25 parameters",
        "        self._k1: float = config.bm25_k1  # 1.2",
        "        self._b: float = config.bm25_b    # 0.75",
        "",
        "@dataclass",
        "class Posting:",
        "    \"\"\"Inverted index posting.\"\"\"",
        "    doc_id: str",
        "    positions: List[int]  # Word positions for phrase queries",
        "    term_frequency: int",
        "",
        "@dataclass",
        "class DocStats:",
        "    \"\"\"Per-document statistics.\"\"\"",
        "    length: int           # Token count",
        "    max_tf: int          # Maximum term frequency",
        "```",
        "",
        "**Scoring Algorithm:** BM25",
        "",
        "```python",
        "def _bm25_score(self, term: str, doc_id: str) -> float:",
        "    \"\"\"Calculate BM25 score for term in document.\"\"\"",
        "    posting = self._get_posting(term, doc_id)",
        "    if not posting:",
        "        return 0.0",
        "",
        "    tf = posting.term_frequency",
        "    doc_length = self._doc_stats[doc_id].length",
        "",
        "    # IDF component",
        "    df = len(self._inverted_index.get(term, []))",
        "    idf = math.log((self._total_docs - df + 0.5) / (df + 0.5) + 1)",
        "",
        "    # TF component with saturation",
        "    tf_component = (tf * (self._k1 + 1)) / (",
        "        tf + self._k1 * (1 - self._b + self._b * doc_length / self._avg_doc_length)",
        "    )",
        "",
        "    return idf * tf_component",
        "```",
        "",
        "**Capabilities:** `{'exact_match', 'phrase_match', 'autocomplete', 'fast'}`",
        "",
        "### 3.3 Semantic Expert",
        "",
        "**Purpose:** Meaning-based retrieval using existing system.",
        "",
        "**Implementation:** Wraps `CorticalTextProcessor` with minimal changes.",
        "",
        "```python",
        "# cortical/moe/experts/semantic.py",
        "",
        "class SemanticExpert(ExpertIndex):",
        "    \"\"\"Semantic search using existing Cortical Text Processor.\"\"\"",
        "",
        "    def __init__(self, processor: CorticalTextProcessor):",
        "        self._processor = processor",
        "",
        "    def query(",
        "        self,",
        "        query_text: str,",
        "        top_n: int = 10,",
        "        context: Optional[Dict] = None",
        "    ) -> ExpertResult:",
        "        \"\"\"Delegate to processor with expansion.\"\"\"",
        "        start = time.perf_counter()",
        "",
        "        # Use existing query expansion",
        "        results = self._processor.find_documents_for_query(",
        "            query_text,",
        "            top_n=top_n,",
        "            use_expansion=True",
        "        )",
        "",
        "        latency = (time.perf_counter() - start) * 1000",
        "",
        "        return ExpertResult(",
        "            documents=[doc_id for doc_id, _ in results],",
        "            scores={doc_id: score for doc_id, score in results},",
        "            metadata={'expansion_used': True},",
        "            latency_ms=latency,",
        "            confidence=0.8  # Base confidence",
        "        )",
        "```",
        "",
        "**Capabilities:** `{'semantic', 'query_expansion', 'concept_clusters'}`",
        "",
        "### 3.4 Structural Expert",
        "",
        "**Purpose:** Code-aware structural search.",
        "",
        "**Data Structures:**",
        "",
        "```python",
        "# cortical/moe/experts/structural.py",
        "",
        "class StructuralExpert(ExpertIndex):",
        "    \"\"\"Code structure-aware search.\"\"\"",
        "",
        "    def __init__(self, config: StructuralConfig):",
        "        # Symbol table: symbol_name → [(doc_id, line, kind)]",
        "        self._symbols: Dict[str, List[SymbolDef]] = {}",
        "",
        "        # Call graph: caller → [callees]",
        "        self._calls: Dict[str, Set[str]] = defaultdict(set)",
        "",
        "        # Reverse call graph: callee → [callers]",
        "        self._called_by: Dict[str, Set[str]] = defaultdict(set)",
        "",
        "        # Import graph: importer → [imported]",
        "        self._imports: Dict[str, Set[str]] = defaultdict(set)",
        "",
        "        # Document → symbols mapping",
        "        self._doc_symbols: Dict[str, Set[str]] = defaultdict(set)",
        "",
        "@dataclass",
        "class SymbolDef:",
        "    \"\"\"Symbol definition.\"\"\"",
        "    doc_id: str",
        "    line: int",
        "    kind: str  # 'function', 'class', 'method', 'variable'",
        "    scope: str  # Fully qualified scope",
        "```",
        "",
        "**Query Types:**",
        "",
        "```python",
        "def query(self, query_text: str, top_n: int = 10, context: Optional[Dict] = None) -> ExpertResult:",
        "    \"\"\"Handle structural queries.\"\"\"",
        "    # Parse query intent",
        "    if 'calls' in query_text.lower():",
        "        return self._find_callees(query_text, top_n)",
        "    elif 'called by' in query_text.lower() or 'callers' in query_text.lower():",
        "        return self._find_callers(query_text, top_n)",
        "    elif 'imports' in query_text.lower():",
        "        return self._find_imports(query_text, top_n)",
        "    else:",
        "        return self._symbol_search(query_text, top_n)",
        "```",
        "",
        "**Capabilities:** `{'structural', 'call_graph', 'symbol_search', 'imports'}`",
        "",
        "### 3.5 Temporal Expert",
        "",
        "**Purpose:** Change-aware retrieval.",
        "",
        "**Data Structures:**",
        "",
        "```python",
        "# cortical/moe/experts/temporal.py",
        "",
        "class TemporalExpert(ExpertIndex):",
        "    \"\"\"Time-aware search over document history.\"\"\"",
        "",
        "    def __init__(self, config: TemporalConfig):",
        "        # Document timeline: doc_id → [ChangeEvent]",
        "        self._history: Dict[str, List[ChangeEvent]] = defaultdict(list)",
        "",
        "        # Time index: timestamp → [doc_ids changed]",
        "        self._time_index: SortedDict[datetime, Set[str]] = SortedDict()",
        "",
        "        # Co-change matrix: doc_id → {doc_id: count}",
        "        self._cochange: Dict[str, Counter] = defaultdict(Counter)",
        "",
        "        # Change frequency: doc_id → changes per period",
        "        self._frequency: Dict[str, float] = {}",
        "",
        "@dataclass",
        "class ChangeEvent:",
        "    \"\"\"Document change event.\"\"\"",
        "    timestamp: datetime",
        "    change_type: str  # 'create', 'modify', 'delete'",
        "    change_size: int  # Lines changed",
        "    commit_id: Optional[str]",
        "```",
        "",
        "**Query Types:**",
        "",
        "```python",
        "def query(self, query_text: str, top_n: int = 10, context: Optional[Dict] = None) -> ExpertResult:",
        "    \"\"\"Handle temporal queries.\"\"\"",
        "    # Parse time expressions",
        "    time_range = self._parse_time_range(query_text)",
        "",
        "    if time_range:",
        "        return self._find_in_range(time_range, top_n)",
        "    elif 'frequently' in query_text.lower():",
        "        return self._find_frequently_changed(top_n)",
        "    elif 'together' in query_text.lower() or 'related' in query_text.lower():",
        "        return self._find_cochanged(query_text, top_n)",
        "    else:",
        "        # Default: recency-weighted search",
        "        return self._recency_search(query_text, top_n)",
        "```",
        "",
        "**Capabilities:** `{'temporal', 'recency', 'cochange', 'history'}`",
        "",
        "### 3.6 Episodic Expert",
        "",
        "**Purpose:** Session-aware personalization.",
        "",
        "**Data Structures:**",
        "",
        "```python",
        "# cortical/moe/experts/episodic.py",
        "",
        "class EpisodicExpert(ExpertIndex):",
        "    \"\"\"Session-aware contextual search.\"\"\"",
        "",
        "    def __init__(self, config: EpisodicConfig):",
        "        # Query history (ring buffer)",
        "        self._query_history: Deque[QueryEvent] = deque(maxlen=config.history_size)",
        "",
        "        # Document interactions",
        "        self._clicks: Dict[str, int] = Counter()  # doc_id → click count",
        "        self._views: Dict[str, float] = {}        # doc_id → view duration",
        "",
        "        # Session context vector",
        "        self._context_terms: Counter = Counter()  # Accumulated query terms",
        "",
        "        # Continuation patterns: query → [follow-up queries]",
        "        self._continuations: Dict[str, List[str]] = defaultdict(list)",
        "",
        "@dataclass",
        "class QueryEvent:",
        "    \"\"\"Query event in session history.\"\"\"",
        "    query: str",
        "    timestamp: datetime",
        "    results_clicked: List[str]",
        "    dwell_time_ms: int",
        "```",
        "",
        "**Capabilities:** `{'episodic', 'session', 'personalization', 'continuation'}`",
        "",
        "---",
        "",
        "## 4. Gating Network Design",
        "",
        "### 4.1 Overview",
        "",
        "The gating network computes expert weights without ML dependencies.",
        "",
        "```",
        "Query → Feature Extraction → Intent Parsing → Weight Combination → Expert Weights",
        "```",
        "",
        "### 4.2 Feature Extraction",
        "",
        "```python",
        "# cortical/moe/router.py",
        "",
        "@dataclass",
        "class QueryFeatures:",
        "    \"\"\"Extracted query features.\"\"\"",
        "    length: int                    # Word count",
        "    has_quotes: bool              # Contains quoted phrase",
        "    has_identifiers: bool         # Contains code identifiers",
        "    has_question_word: bool       # Starts with who/what/where/etc",
        "    has_time_expression: bool     # Contains time references",
        "    code_pattern_score: float     # 0-1 code likelihood",
        "    semantic_density: float       # 0-1 conceptual complexity",
        "    specificity: float           # 0-1 how specific/narrow",
        "",
        "class FeatureExtractor:",
        "    \"\"\"Extract query features for routing.\"\"\"",
        "",
        "    # Patterns",
        "    IDENTIFIER_PATTERN = re.compile(r'[a-z]+[A-Z][a-zA-Z]*|[a-z]+_[a-z]+')",
        "    TIME_PATTERNS = [",
        "        r'\\b(today|yesterday|last\\s+week|recently|latest)\\b',",
        "        r'\\b\\d{4}-\\d{2}-\\d{2}\\b',",
        "        r'\\b(before|after|since)\\s+\\w+\\b',",
        "    ]",
        "    QUESTION_WORDS = {'what', 'where', 'how', 'why', 'when', 'who', 'which'}",
        "",
        "    def extract(self, query: str) -> QueryFeatures:",
        "        \"\"\"Extract features from query.\"\"\"",
        "        tokens = query.lower().split()",
        "",
        "        return QueryFeatures(",
        "            length=len(tokens),",
        "            has_quotes='\"' in query or \"'\" in query,",
        "            has_identifiers=bool(self.IDENTIFIER_PATTERN.search(query)),",
        "            has_question_word=tokens[0] in self.QUESTION_WORDS if tokens else False,",
        "            has_time_expression=any(",
        "                re.search(p, query, re.I) for p in self.TIME_PATTERNS",
        "            ),",
        "            code_pattern_score=self._compute_code_score(query),",
        "            semantic_density=self._compute_semantic_density(tokens),",
        "            specificity=self._compute_specificity(tokens),",
        "        )",
        "```",
        "",
        "### 4.3 Feature-Based Weight Computation",
        "",
        "```python",
        "class FeatureBasedGate:",
        "    \"\"\"Compute expert weights from features.\"\"\"",
        "",
        "    # Feature → Expert weight contributions",
        "    FEATURE_WEIGHTS = {",
        "        'lexical': {",
        "            'short_query': 0.3,      # length < 4",
        "            'has_quotes': 0.4,",
        "            'has_identifiers': 0.2,",
        "            'high_specificity': 0.3,",
        "        },",
        "        'semantic': {",
        "            'has_question_word': 0.4,",
        "            'long_query': 0.2,       # length >= 4",
        "            'high_semantic_density': 0.3,",
        "            'low_specificity': 0.2,",
        "        },",
        "        'structural': {",
        "            'has_identifiers': 0.4,",
        "            'code_pattern': 0.4,",
        "            'structural_keywords': 0.3,  # calls, imports, etc",
        "        },",
        "        'temporal': {",
        "            'has_time_expression': 0.6,",
        "            'temporal_keywords': 0.3,    # changed, modified, etc",
        "        },",
        "        'episodic': {",
        "            'continuation_pattern': 0.4,",
        "            'session_context_match': 0.3,",
        "        },",
        "    }",
        "",
        "    def compute_weights(self, features: QueryFeatures) -> Dict[str, float]:",
        "        \"\"\"Compute expert weights from features.\"\"\"",
        "        weights = {}",
        "",
        "        for expert, feature_weights in self.FEATURE_WEIGHTS.items():",
        "            weight = 0.0",
        "",
        "            # Short vs long query",
        "            if expert == 'lexical' and features.length < 4:",
        "                weight += feature_weights.get('short_query', 0)",
        "            if expert == 'semantic' and features.length >= 4:",
        "                weight += feature_weights.get('long_query', 0)",
        "",
        "            # Boolean features",
        "            if features.has_quotes:",
        "                weight += feature_weights.get('has_quotes', 0)",
        "            if features.has_identifiers:",
        "                weight += feature_weights.get('has_identifiers', 0)",
        "            if features.has_question_word:",
        "                weight += feature_weights.get('has_question_word', 0)",
        "            if features.has_time_expression:",
        "                weight += feature_weights.get('has_time_expression', 0)",
        "",
        "            # Continuous features",
        "            weight += features.code_pattern_score * feature_weights.get('code_pattern', 0)",
        "            weight += features.semantic_density * feature_weights.get('high_semantic_density', 0)",
        "            weight += features.specificity * feature_weights.get('high_specificity', 0)",
        "            weight += (1 - features.specificity) * feature_weights.get('low_specificity', 0)",
        "",
        "            weights[expert] = weight",
        "",
        "        return self._normalize(weights)",
        "```",
        "",
        "### 4.4 Intent-Based Routing",
        "",
        "```python",
        "class IntentBasedGate:",
        "    \"\"\"Route based on parsed query intent.\"\"\"",
        "",
        "    INTENT_ROUTING = {",
        "        'definition': {",
        "            'lexical': 0.4,",
        "            'semantic': 0.5,",
        "            'structural': 0.1,",
        "        },",
        "        'location': {",
        "            'lexical': 0.3,",
        "            'structural': 0.5,",
        "            'semantic': 0.2,",
        "        },",
        "        'implementation': {",
        "            'semantic': 0.4,",
        "            'structural': 0.4,",
        "            'lexical': 0.2,",
        "        },",
        "        'explanation': {",
        "            'semantic': 0.7,",
        "            'lexical': 0.2,",
        "            'episodic': 0.1,",
        "        },",
        "        'history': {",
        "            'temporal': 0.6,",
        "            'lexical': 0.2,",
        "            'structural': 0.2,",
        "        },",
        "        'continuation': {",
        "            'episodic': 0.5,",
        "            'semantic': 0.3,",
        "            'lexical': 0.2,",
        "        },",
        "    }",
        "",
        "    def compute_weights(self, query: str, intent_parser) -> Dict[str, float]:",
        "        \"\"\"Compute weights based on parsed intent.\"\"\"",
        "        parsed = intent_parser.parse_intent_query(query)",
        "        intent_type = parsed.get('intent', 'definition')",
        "",
        "        return self.INTENT_ROUTING.get(",
        "            intent_type,",
        "            {'semantic': 0.5, 'lexical': 0.5}  # Default",
        "        )",
        "```",
        "",
        "### 4.5 Feedback-Adaptive Routing",
        "",
        "```python",
        "class FeedbackAdaptiveGate:",
        "    \"\"\"Adapt routing based on historical success.\"\"\"",
        "",
        "    def __init__(self, decay_rate: float = 0.95):",
        "        # Pattern → Expert → (successes, total)",
        "        self._success_counts: Dict[str, Dict[str, Tuple[float, float]]] = defaultdict(",
        "            lambda: defaultdict(lambda: (1.0, 2.0))  # Laplace smoothing",
        "        )",
        "        self._decay_rate = decay_rate",
        "",
        "    def compute_weights(self, query: str) -> Dict[str, float]:",
        "        \"\"\"Compute weights from historical success rates.\"\"\"",
        "        pattern = self._query_to_pattern(query)",
        "",
        "        weights = {}",
        "        for expert in EXPERT_NAMES:",
        "            successes, total = self._success_counts[pattern][expert]",
        "            weights[expert] = successes / total",
        "",
        "        return self._normalize(weights)",
        "",
        "    def record_feedback(",
        "        self,",
        "        query: str,",
        "        expert: str,",
        "        was_helpful: bool",
        "    ) -> None:",
        "        \"\"\"Record interaction feedback.\"\"\"",
        "        pattern = self._query_to_pattern(query)",
        "",
        "        # Decay old counts",
        "        for exp in EXPERT_NAMES:",
        "            s, t = self._success_counts[pattern][exp]",
        "            self._success_counts[pattern][exp] = (",
        "                s * self._decay_rate,",
        "                t * self._decay_rate",
        "            )",
        "",
        "        # Update current",
        "        s, t = self._success_counts[pattern][expert]",
        "        self._success_counts[pattern][expert] = (",
        "            s + (1.0 if was_helpful else 0.0),",
        "            t + 1.0",
        "        )",
        "",
        "    def _query_to_pattern(self, query: str) -> str:",
        "        \"\"\"Convert query to pattern for grouping.\"\"\"",
        "        # Normalize: \"where is X\" → \"where_is_NOUN\"",
        "        tokens = query.lower().split()[:3]",
        "        pattern_tokens = []",
        "        for token in tokens:",
        "            if token in QUESTION_WORDS:",
        "                pattern_tokens.append(token)",
        "            elif self._is_identifier(token):",
        "                pattern_tokens.append('IDENT')",
        "            elif token.isdigit():",
        "                pattern_tokens.append('NUM')",
        "            else:",
        "                pattern_tokens.append('WORD')",
        "        return '_'.join(pattern_tokens)",
        "```",
        "",
        "### 4.6 Combined Gating",
        "",
        "```python",
        "class QueryRouter:",
        "    \"\"\"Combined routing using all gating strategies.\"\"\"",
        "",
        "    def __init__(self, config: RouterConfig):",
        "        self._feature_gate = FeatureBasedGate()",
        "        self._intent_gate = IntentBasedGate()",
        "        self._feedback_gate = FeedbackAdaptiveGate()",
        "",
        "        # Combination weights",
        "        self._feature_weight = config.feature_weight  # 0.4",
        "        self._intent_weight = config.intent_weight    # 0.4",
        "        self._feedback_weight = config.feedback_weight  # 0.2",
        "",
        "    def route(",
        "        self,",
        "        query: str,",
        "        top_k: int = 2,",
        "        intent_parser = None",
        "    ) -> List[Tuple[str, float]]:",
        "        \"\"\"Compute final routing weights.\"\"\"",
        "        features = self._feature_extractor.extract(query)",
        "",
        "        # Get weights from each strategy",
        "        feature_weights = self._feature_gate.compute_weights(features)",
        "        intent_weights = (",
        "            self._intent_gate.compute_weights(query, intent_parser)",
        "            if intent_parser else {}",
        "        )",
        "        feedback_weights = self._feedback_gate.compute_weights(query)",
        "",
        "        # Combine",
        "        combined = {}",
        "        for expert in EXPERT_NAMES:",
        "            combined[expert] = (",
        "                self._feature_weight * feature_weights.get(expert, 0) +",
        "                self._intent_weight * intent_weights.get(expert, 0) +",
        "                self._feedback_weight * feedback_weights.get(expert, 0)",
        "            )",
        "",
        "        # Normalize and select top-K",
        "        normalized = self._normalize(combined)",
        "        sorted_experts = sorted(normalized.items(), key=lambda x: -x[1])",
        "",
        "        return sorted_experts[:top_k]",
        "```",
        "",
        "---",
        "",
        "## 5. Result Fusion",
        "",
        "### 5.1 Score Normalization",
        "",
        "Different experts return scores on different scales. Normalize before fusion.",
        "",
        "```python",
        "# cortical/moe/fusion.py",
        "",
        "class ScoreNormalizer:",
        "    \"\"\"Normalize scores across experts.\"\"\"",
        "",
        "    @staticmethod",
        "    def min_max_normalize(scores: Dict[str, float]) -> Dict[str, float]:",
        "        \"\"\"Scale to [0, 1] range.\"\"\"",
        "        if not scores:",
        "            return {}",
        "",
        "        min_score = min(scores.values())",
        "        max_score = max(scores.values())",
        "        range_score = max_score - min_score",
        "",
        "        if range_score == 0:",
        "            return {k: 1.0 for k in scores}",
        "",
        "        return {",
        "            k: (v - min_score) / range_score",
        "            for k, v in scores.items()",
        "        }",
        "",
        "    @staticmethod",
        "    def z_score_normalize(scores: Dict[str, float]) -> Dict[str, float]:",
        "        \"\"\"Standardize to mean=0, std=1.\"\"\"",
        "        if not scores:",
        "            return {}",
        "",
        "        values = list(scores.values())",
        "        mean = sum(values) / len(values)",
        "        std = (sum((v - mean) ** 2 for v in values) / len(values)) ** 0.5",
        "",
        "        if std == 0:",
        "            return {k: 0.0 for k in scores}",
        "",
        "        return {k: (v - mean) / std for k, v in scores.items()}",
        "```",
        "",
        "### 5.2 Reciprocal Rank Fusion",
        "",
        "```python",
        "class RRFFusion:",
        "    \"\"\"Reciprocal Rank Fusion for combining ranked lists.\"\"\"",
        "",
        "    def __init__(self, k: int = 60):",
        "        self._k = k  # Smoothing constant",
        "",
        "    def fuse(",
        "        self,",
        "        expert_results: Dict[str, ExpertResult],",
        "        expert_weights: Dict[str, float]",
        "    ) -> List[Tuple[str, float]]:",
        "        \"\"\"Fuse ranked lists using weighted RRF.\"\"\"",
        "        doc_scores: Dict[str, float] = defaultdict(float)",
        "",
        "        for expert, result in expert_results.items():",
        "            weight = expert_weights.get(expert, 1.0)",
        "",
        "            for rank, doc_id in enumerate(result.documents):",
        "                # RRF score: 1 / (k + rank)",
        "                rrf_score = 1.0 / (self._k + rank + 1)",
        "                doc_scores[doc_id] += weight * rrf_score",
        "",
        "        # Sort by fused score",
        "        return sorted(doc_scores.items(), key=lambda x: -x[1])",
        "```",
        "",
        "### 5.3 Weighted Score Fusion",
        "",
        "```python",
        "class WeightedScoreFusion:",
        "    \"\"\"Combine normalized scores with weights.\"\"\"",
        "",
        "    def __init__(self, normalizer: ScoreNormalizer):",
        "        self._normalizer = normalizer",
        "",
        "    def fuse(",
        "        self,",
        "        expert_results: Dict[str, ExpertResult],",
        "        expert_weights: Dict[str, float]",
        "    ) -> List[Tuple[str, float]]:",
        "        \"\"\"Fuse using weighted score combination.\"\"\"",
        "        doc_scores: Dict[str, float] = defaultdict(float)",
        "",
        "        for expert, result in expert_results.items():",
        "            weight = expert_weights.get(expert, 1.0)",
        "            normalized = self._normalizer.min_max_normalize(result.scores)",
        "",
        "            for doc_id, score in normalized.items():",
        "                doc_scores[doc_id] += weight * score",
        "",
        "        return sorted(doc_scores.items(), key=lambda x: -x[1])",
        "```",
        "",
        "### 5.4 Result Fusioner",
        "",
        "```python",
        "class ResultFusioner:",
        "    \"\"\"Main fusion orchestrator.\"\"\"",
        "",
        "    def __init__(self, config: FusionConfig):",
        "        self._strategy = config.strategy  # 'rrf', 'weighted', 'hybrid'",
        "        self._rrf = RRFFusion(k=config.rrf_k)",
        "        self._weighted = WeightedScoreFusion(ScoreNormalizer())",
        "",
        "    def fuse(",
        "        self,",
        "        expert_results: Dict[str, ExpertResult],",
        "        expert_weights: Dict[str, float],",
        "        top_n: int = 10",
        "    ) -> MoEResult:",
        "        \"\"\"Fuse expert results into final ranking.\"\"\"",
        "",
        "        if self._strategy == 'rrf':",
        "            fused = self._rrf.fuse(expert_results, expert_weights)",
        "        elif self._strategy == 'weighted':",
        "            fused = self._weighted.fuse(expert_results, expert_weights)",
        "        else:  # hybrid",
        "            rrf_results = self._rrf.fuse(expert_results, expert_weights)",
        "            weighted_results = self._weighted.fuse(expert_results, expert_weights)",
        "            fused = self._combine_rankings(rrf_results, weighted_results)",
        "",
        "        return MoEResult(",
        "            documents=[doc for doc, _ in fused[:top_n]],",
        "            scores={doc: score for doc, score in fused[:top_n]},",
        "            expert_weights=expert_weights,",
        "            expert_contributions=self._compute_contributions(expert_results, fused[:top_n]),",
        "        )",
        "```",
        "",
        "---",
        "",
        "## 6. Cross-Index Communication",
        "",
        "### 6.1 Cross-Pollination Interface",
        "",
        "```python",
        "# cortical/moe/cross_pollination.py",
        "",
        "class CrossPollinator:",
        "    \"\"\"Enable experts to inform each other.\"\"\"",
        "",
        "    def pollinate(",
        "        self,",
        "        query: str,",
        "        partial_results: Dict[str, ExpertResult],",
        "        experts: Dict[str, ExpertIndex]",
        "    ) -> Dict[str, ExpertResult]:",
        "        \"\"\"Let experts refine each other's results.\"\"\"",
        "        refined = dict(partial_results)",
        "",
        "        # Semantic expansion can help lexical",
        "        if 'semantic' in partial_results and 'lexical' in experts:",
        "            semantic_terms = self._extract_expansion_terms(",
        "                partial_results['semantic']",
        "            )",
        "            refined['lexical'] = experts['lexical'].query(",
        "                query,",
        "                expansion_terms=semantic_terms",
        "            )",
        "",
        "        # Structural relations can boost semantic",
        "        if 'structural' in partial_results and 'semantic' in refined:",
        "            structural_docs = set(partial_results['structural'].documents[:5])",
        "            refined['semantic'] = self._boost_documents(",
        "                refined['semantic'],",
        "                structural_docs,",
        "                boost_factor=1.2",
        "            )",
        "",
        "        # Temporal recency can re-rank all",
        "        if 'temporal' in partial_results:",
        "            recency_scores = {",
        "                doc: score",
        "                for doc, score in partial_results['temporal'].scores.items()",
        "            }",
        "            for expert, result in refined.items():",
        "                if expert != 'temporal':",
        "                    refined[expert] = self._apply_recency(",
        "                        result, recency_scores, weight=0.1",
        "                    )",
        "",
        "        return refined",
        "```",
        "",
        "### 6.2 Expert Coordination Protocol",
        "",
        "```python",
        "class ExpertCoordinator:",
        "    \"\"\"Coordinate expert interactions.\"\"\"",
        "",
        "    async def query_with_coordination(",
        "        self,",
        "        query: str,",
        "        active_experts: List[Tuple[str, float]],",
        "        experts: Dict[str, ExpertIndex]",
        "    ) -> Dict[str, ExpertResult]:",
        "        \"\"\"Query experts with cross-pollination.\"\"\"",
        "",
        "        # Phase 1: Initial parallel queries",
        "        initial_results = await self._parallel_query(",
        "            query, active_experts, experts",
        "        )",
        "",
        "        # Phase 2: Cross-pollination (if enabled)",
        "        if self._config.enable_cross_pollination:",
        "            refined_results = self._cross_pollinator.pollinate(",
        "                query, initial_results, experts",
        "            )",
        "        else:",
        "            refined_results = initial_results",
        "",
        "        return refined_results",
        "```",
        "",
        "---",
        "",
        "## 7. Data Structures",
        "",
        "### 7.1 Core Types",
        "",
        "```python",
        "# cortical/moe/types.py",
        "",
        "from dataclasses import dataclass, field",
        "from typing import Dict, List, Optional, Set",
        "from enum import Enum",
        "",
        "class ExpertType(Enum):",
        "    \"\"\"Expert index types.\"\"\"",
        "    LEXICAL = 'lexical'",
        "    SEMANTIC = 'semantic'",
        "    STRUCTURAL = 'structural'",
        "    TEMPORAL = 'temporal'",
        "    EPISODIC = 'episodic'",
        "",
        "@dataclass",
        "class ExpertResult:",
        "    \"\"\"Result from a single expert query.\"\"\"",
        "    documents: List[str]",
        "    scores: Dict[str, float]",
        "    metadata: Dict[str, any] = field(default_factory=dict)",
        "    latency_ms: float = 0.0",
        "    confidence: float = 1.0",
        "",
        "@dataclass",
        "class MoEResult:",
        "    \"\"\"Combined result from MoE query.\"\"\"",
        "    documents: List[str]",
        "    scores: Dict[str, float]",
        "    expert_weights: Dict[str, float]",
        "    expert_contributions: Dict[str, Set[str]]  # expert → docs it contributed",
        "    routing_latency_ms: float = 0.0",
        "    total_latency_ms: float = 0.0",
        "",
        "    def get_explanation(self) -> str:",
        "        \"\"\"Human-readable explanation of routing.\"\"\"",
        "        lines = [\"Query routing:\"]",
        "        for expert, weight in sorted(self.expert_weights.items(), key=lambda x: -x[1]):",
        "            contributed = len(self.expert_contributions.get(expert, set()))",
        "            lines.append(f\"  {expert}: {weight:.2f} weight, {contributed} docs\")",
        "        return '\\n'.join(lines)",
        "",
        "@dataclass",
        "class QueryContext:",
        "    \"\"\"Context passed to experts.\"\"\"",
        "    session_id: Optional[str] = None",
        "    previous_queries: List[str] = field(default_factory=list)",
        "    clicked_docs: Set[str] = field(default_factory=set)",
        "    user_preferences: Dict[str, any] = field(default_factory=dict)",
        "```",
        "",
        "### 7.2 Configuration Types",
        "",
        "```python",
        "@dataclass",
        "class RouterConfig:",
        "    \"\"\"Query router configuration.\"\"\"",
        "    feature_weight: float = 0.4",
        "    intent_weight: float = 0.4",
        "    feedback_weight: float = 0.2",
        "    default_top_k: int = 2",
        "    min_expert_weight: float = 0.05  # Skip experts below this",
        "",
        "@dataclass",
        "class FusionConfig:",
        "    \"\"\"Result fusion configuration.\"\"\"",
        "    strategy: str = 'rrf'  # 'rrf', 'weighted', 'hybrid'",
        "    rrf_k: int = 60",
        "    score_normalization: str = 'min_max'  # 'min_max', 'z_score'",
        "",
        "@dataclass",
        "class MoEConfig:",
        "    \"\"\"Top-level MoE configuration.\"\"\"",
        "    router: RouterConfig = field(default_factory=RouterConfig)",
        "    fusion: FusionConfig = field(default_factory=FusionConfig)",
        "    enable_cross_pollination: bool = True",
        "    enable_feedback_learning: bool = True",
        "    expert_configs: Dict[str, Dict] = field(default_factory=dict)",
        "```",
        "",
        "---",
        "",
        "## 8. API Design",
        "",
        "### 8.1 Public API",
        "",
        "```python",
        "# cortical/moe/__init__.py",
        "",
        "class MoEIndexProcessor:",
        "    \"\"\"Mixture of Expert Index processor.\"\"\"",
        "",
        "    def __init__(",
        "        self,",
        "        config: Optional[MoEConfig] = None,",
        "        base_processor: Optional[CorticalTextProcessor] = None",
        "    ):",
        "        \"\"\"",
        "        Initialize MoE processor.",
        "",
        "        Args:",
        "            config: MoE configuration. Uses defaults if None.",
        "            base_processor: Existing processor to wrap. Creates new if None.",
        "        \"\"\"",
        "        pass",
        "",
        "    # Document Management",
        "    def add_document(self, doc_id: str, content: str, metadata: Optional[Dict] = None) -> None:",
        "        \"\"\"Add document to all expert indexes.\"\"\"",
        "        pass",
        "",
        "    def remove_document(self, doc_id: str) -> None:",
        "        \"\"\"Remove document from all expert indexes.\"\"\"",
        "        pass",
        "",
        "    def add_documents_batch(self, documents: List[Tuple[str, str, Dict]]) -> None:",
        "        \"\"\"Batch add documents.\"\"\"",
        "        pass",
        "",
        "    # Querying",
        "    def query(",
        "        self,",
        "        query_text: str,",
        "        top_n: int = 10,",
        "        context: Optional[QueryContext] = None,",
        "        force_experts: Optional[List[str]] = None,  # Override routing",
        "        explain: bool = False",
        "    ) -> MoEResult:",
        "        \"\"\"",
        "        Query with automatic expert routing.",
        "",
        "        Args:",
        "            query_text: The search query",
        "            top_n: Number of results to return",
        "            context: Optional session context",
        "            force_experts: Force specific experts (bypass routing)",
        "            explain: Include routing explanation",
        "",
        "        Returns:",
        "            MoEResult with documents, scores, and expert contributions",
        "        \"\"\"",
        "        pass",
        "",
        "    def query_expert(",
        "        self,",
        "        expert_name: str,",
        "        query_text: str,",
        "        top_n: int = 10",
        "    ) -> ExpertResult:",
        "        \"\"\"Query a specific expert directly.\"\"\"",
        "        pass",
        "",
        "    # Feedback",
        "    def record_click(self, query: str, doc_id: str, session_id: Optional[str] = None) -> None:",
        "        \"\"\"Record user click for feedback learning.\"\"\"",
        "        pass",
        "",
        "    def record_relevance(self, query: str, doc_id: str, is_relevant: bool) -> None:",
        "        \"\"\"Record explicit relevance feedback.\"\"\"",
        "        pass",
        "",
        "    # Expert Management",
        "    def get_expert(self, name: str) -> ExpertIndex:",
        "        \"\"\"Get expert by name.\"\"\"",
        "        pass",
        "",
        "    def list_experts(self) -> List[str]:",
        "        \"\"\"List available experts.\"\"\"",
        "        pass",
        "",
        "    def get_expert_stats(self, name: str) -> Dict:",
        "        \"\"\"Get expert statistics.\"\"\"",
        "        pass",
        "",
        "    # Computation",
        "    def compute_all(self) -> None:",
        "        \"\"\"Recompute all stale indexes.\"\"\"",
        "        pass",
        "",
        "    def is_stale(self) -> bool:",
        "        \"\"\"Check if any expert is stale.\"\"\"",
        "        pass",
        "",
        "    # Persistence",
        "    def save(self, path: str) -> None:",
        "        \"\"\"Save all expert indexes.\"\"\"",
        "        pass",
        "",
        "    @classmethod",
        "    def load(cls, path: str) -> 'MoEIndexProcessor':",
        "        \"\"\"Load processor from disk.\"\"\"",
        "        pass",
        "",
        "    # Metrics",
        "    def get_routing_stats(self) -> Dict:",
        "        \"\"\"Get routing statistics.\"\"\"",
        "        pass",
        "",
        "    def get_expert_utilization(self) -> Dict[str, float]:",
        "        \"\"\"Get expert utilization percentages.\"\"\"",
        "        pass",
        "```",
        "",
        "### 8.2 Backward Compatibility",
        "",
        "The `MoEIndexProcessor` maintains compatibility with `CorticalTextProcessor`:",
        "",
        "```python",
        "class MoEIndexProcessor:",
        "    \"\"\"Maintains backward compatibility.\"\"\"",
        "",
        "    def find_documents_for_query(self, query: str, top_n: int = 5) -> List[Tuple[str, float]]:",
        "        \"\"\"Backward-compatible query method.\"\"\"",
        "        result = self.query(query, top_n=top_n)",
        "        return [(doc, result.scores[doc]) for doc in result.documents]",
        "",
        "    def find_passages_for_query(self, query: str, top_n: int = 5, **kwargs) -> List[Tuple[str, str, float]]:",
        "        \"\"\"Backward-compatible passage retrieval.\"\"\"",
        "        # Delegate to semantic expert's processor",
        "        return self._semantic_expert._processor.find_passages_for_query(",
        "            query, top_n=top_n, **kwargs",
        "        )",
        "",
        "    def process_document(self, doc_id: str, content: str) -> None:",
        "        \"\"\"Backward-compatible document addition.\"\"\"",
        "        self.add_document(doc_id, content)",
        "```",
        "",
        "---",
        "",
        "## 9. Integration with Existing System",
        "",
        "### 9.1 Semantic Expert Integration",
        "",
        "The semantic expert wraps the existing `CorticalTextProcessor`:",
        "",
        "```python",
        "class SemanticExpert(ExpertIndex):",
        "    \"\"\"Wraps existing processor as an expert.\"\"\"",
        "",
        "    def __init__(self, processor: Optional[CorticalTextProcessor] = None):",
        "        if processor is None:",
        "            processor = CorticalTextProcessor()",
        "        self._processor = processor",
        "",
        "    def add_document(self, doc_id: str, content: str, metadata: Dict) -> None:",
        "        self._processor.process_document(doc_id, content)",
        "",
        "    def recompute(self) -> None:",
        "        self._processor.compute_all()",
        "",
        "    def query(self, query_text: str, top_n: int = 10, **kwargs) -> ExpertResult:",
        "        results = self._processor.find_documents_for_query(query_text, top_n=top_n)",
        "        return ExpertResult(",
        "            documents=[doc for doc, _ in results],",
        "            scores={doc: score for doc, score in results},",
        "            confidence=0.8",
        "        )",
        "```",
        "",
        "### 9.2 Shared Resources",
        "",
        "Experts share common resources to avoid duplication:",
        "",
        "```python",
        "class SharedResources:",
        "    \"\"\"Resources shared across experts.\"\"\"",
        "",
        "    def __init__(self):",
        "        self.tokenizer = Tokenizer()",
        "        self.document_store: Dict[str, str] = {}  # doc_id → content",
        "        self.document_metadata: Dict[str, Dict] = {}  # doc_id → metadata",
        "",
        "class MoEIndexProcessor:",
        "    def __init__(self, ...):",
        "        self._shared = SharedResources()",
        "",
        "        # Pass shared resources to experts",
        "        self._experts = {",
        "            'lexical': LexicalExpert(shared=self._shared),",
        "            'semantic': SemanticExpert(shared=self._shared),",
        "            # ...",
        "        }",
        "```",
        "",
        "### 9.3 Staleness Coordination",
        "",
        "```python",
        "class MoEIndexProcessor:",
        "    \"\"\"Coordinate staleness across experts.\"\"\"",
        "",
        "    def add_document(self, doc_id: str, content: str, metadata: Optional[Dict] = None):",
        "        \"\"\"Add document and mark experts stale.\"\"\"",
        "        metadata = metadata or {}",
        "",
        "        # Store in shared resources",
        "        self._shared.document_store[doc_id] = content",
        "        self._shared.document_metadata[doc_id] = metadata",
        "",
        "        # Add to each expert",
        "        for expert in self._experts.values():",
        "            expert.add_document(doc_id, content, metadata)",
        "",
        "    def compute_all(self) -> None:",
        "        \"\"\"Recompute all stale experts.\"\"\"",
        "        for name, expert in self._experts.items():",
        "            if expert.is_stale():",
        "                expert.recompute()",
        "",
        "    def is_stale(self) -> bool:",
        "        \"\"\"Check if any expert is stale.\"\"\"",
        "        return any(e.is_stale() for e in self._experts.values())",
        "```",
        "",
        "---",
        "",
        "## 10. Persistence and Synchronization",
        "",
        "### 10.1 Save/Load Strategy",
        "",
        "```python",
        "class MoEIndexProcessor:",
        "    \"\"\"Persistence methods.\"\"\"",
        "",
        "    def save(self, path: str) -> None:",
        "        \"\"\"Save all experts to directory.\"\"\"",
        "        import os",
        "        os.makedirs(path, exist_ok=True)",
        "",
        "        # Save each expert",
        "        for name, expert in self._experts.items():",
        "            expert_path = os.path.join(path, f\"{name}.pkl\")",
        "            expert.save(expert_path)",
        "",
        "        # Save shared resources",
        "        shared_path = os.path.join(path, \"shared.pkl\")",
        "        with open(shared_path, 'wb') as f:",
        "            pickle.dump(self._shared, f)",
        "",
        "        # Save router state (feedback history)",
        "        router_path = os.path.join(path, \"router.pkl\")",
        "        self._router.save(router_path)",
        "",
        "        # Save config",
        "        config_path = os.path.join(path, \"config.json\")",
        "        with open(config_path, 'w') as f:",
        "            json.dump(asdict(self._config), f)",
        "",
        "    @classmethod",
        "    def load(cls, path: str) -> 'MoEIndexProcessor':",
        "        \"\"\"Load processor from directory.\"\"\"",
        "        # Load config",
        "        config_path = os.path.join(path, \"config.json\")",
        "        with open(config_path) as f:",
        "            config = MoEConfig(**json.load(f))",
        "",
        "        processor = cls(config=config)",
        "",
        "        # Load shared resources",
        "        shared_path = os.path.join(path, \"shared.pkl\")",
        "        with open(shared_path, 'rb') as f:",
        "            processor._shared = pickle.load(f)",
        "",
        "        # Load each expert",
        "        for name in processor._experts:",
        "            expert_path = os.path.join(path, f\"{name}.pkl\")",
        "            if os.path.exists(expert_path):",
        "                processor._experts[name] = type(processor._experts[name]).load(expert_path)",
        "",
        "        # Load router state",
        "        router_path = os.path.join(path, \"router.pkl\")",
        "        if os.path.exists(router_path):",
        "            processor._router.load(router_path)",
        "",
        "        return processor",
        "```",
        "",
        "### 10.2 Incremental Updates",
        "",
        "```python",
        "class MoEIndexProcessor:",
        "    \"\"\"Support incremental updates.\"\"\"",
        "",
        "    def add_document_incremental(",
        "        self,",
        "        doc_id: str,",
        "        content: str,",
        "        metadata: Optional[Dict] = None,",
        "        recompute: str = 'minimal'  # 'none', 'minimal', 'full'",
        "    ) -> None:",
        "        \"\"\"Add document with controlled recomputation.\"\"\"",
        "        metadata = metadata or {}",
        "",
        "        # Add to shared",
        "        self._shared.document_store[doc_id] = content",
        "        self._shared.document_metadata[doc_id] = metadata",
        "",
        "        # Add to experts",
        "        for expert in self._experts.values():",
        "            expert.add_document(doc_id, content, metadata)",
        "",
        "        # Recompute based on strategy",
        "        if recompute == 'minimal':",
        "            # Only recompute fast indexes",
        "            self._experts['lexical'].recompute()",
        "        elif recompute == 'full':",
        "            self.compute_all()",
        "        # 'none' skips recomputation",
        "```",
        "",
        "---",
        "",
        "## 11. Configuration",
        "",
        "### 11.1 Default Configuration",
        "",
        "```python",
        "DEFAULT_MOE_CONFIG = MoEConfig(",
        "    router=RouterConfig(",
        "        feature_weight=0.4,",
        "        intent_weight=0.4,",
        "        feedback_weight=0.2,",
        "        default_top_k=2,",
        "        min_expert_weight=0.05,",
        "    ),",
        "    fusion=FusionConfig(",
        "        strategy='rrf',",
        "        rrf_k=60,",
        "        score_normalization='min_max',",
        "    ),",
        "    enable_cross_pollination=True,",
        "    enable_feedback_learning=True,",
        "    expert_configs={",
        "        'lexical': {",
        "            'bm25_k1': 1.2,",
        "            'bm25_b': 0.75,",
        "            'enable_autocomplete': True,",
        "        },",
        "        'semantic': {",
        "            'use_expansion': True,",
        "            'max_expansions': 10,",
        "        },",
        "        'structural': {",
        "            'max_call_depth': 3,",
        "            'include_imports': True,",
        "        },",
        "        'temporal': {",
        "            'decay_days': 30,",
        "            'cochange_threshold': 3,",
        "        },",
        "        'episodic': {",
        "            'history_size': 50,",
        "            'session_timeout_minutes': 30,",
        "        },",
        "    },",
        ")",
        "```",
        "",
        "### 11.2 Configuration File Format",
        "",
        "```yaml",
        "# moe_config.yaml",
        "router:",
        "  feature_weight: 0.4",
        "  intent_weight: 0.4",
        "  feedback_weight: 0.2",
        "  default_top_k: 2",
        "",
        "fusion:",
        "  strategy: rrf",
        "  rrf_k: 60",
        "",
        "enable_cross_pollination: true",
        "enable_feedback_learning: true",
        "",
        "experts:",
        "  lexical:",
        "    bm25_k1: 1.2",
        "    bm25_b: 0.75",
        "",
        "  semantic:",
        "    use_expansion: true",
        "    max_expansions: 10",
        "",
        "  structural:",
        "    enabled: true",
        "    max_call_depth: 3",
        "",
        "  temporal:",
        "    enabled: true",
        "    decay_days: 30",
        "",
        "  episodic:",
        "    enabled: false  # Optional",
        "```",
        "",
        "---",
        "",
        "## 12. Testing Strategy",
        "",
        "### 12.1 Unit Tests",
        "",
        "```python",
        "# tests/unit/test_moe_router.py",
        "",
        "class TestQueryRouter:",
        "    \"\"\"Test routing logic.\"\"\"",
        "",
        "    def test_short_query_routes_to_lexical(self):",
        "        router = QueryRouter(RouterConfig())",
        "        weights = router.route(\"authenticate\")",
        "        assert weights[0][0] == 'lexical'  # Highest weight",
        "",
        "    def test_question_routes_to_semantic(self):",
        "        router = QueryRouter(RouterConfig())",
        "        weights = router.route(\"how does authentication work?\")",
        "        assert 'semantic' in [w[0] for w in weights[:2]]",
        "",
        "    def test_identifier_routes_to_structural(self):",
        "        router = QueryRouter(RouterConfig())",
        "        weights = router.route(\"getUserCredentials\")",
        "        assert 'structural' in [w[0] for w in weights[:2]]",
        "",
        "# tests/unit/test_moe_fusion.py",
        "",
        "class TestResultFusion:",
        "    \"\"\"Test result fusion strategies.\"\"\"",
        "",
        "    def test_rrf_combines_rankings(self):",
        "        fusioner = RRFFusion(k=60)",
        "        results = {",
        "            'expert1': ExpertResult(documents=['a', 'b', 'c'], scores=...),",
        "            'expert2': ExpertResult(documents=['b', 'a', 'd'], scores=...),",
        "        }",
        "        fused = fusioner.fuse(results, {'expert1': 0.5, 'expert2': 0.5})",
        "        # 'b' should rank high (appears high in both)",
        "        assert fused[0][0] in ['a', 'b']",
        "```",
        "",
        "### 12.2 Integration Tests",
        "",
        "```python",
        "# tests/integration/test_moe_integration.py",
        "",
        "class TestMoEIntegration:",
        "    \"\"\"Test full MoE pipeline.\"\"\"",
        "",
        "    @pytest.fixture",
        "    def moe_processor(self, small_corpus_docs):",
        "        processor = MoEIndexProcessor()",
        "        for doc_id, content in small_corpus_docs.items():",
        "            processor.add_document(doc_id, content)",
        "        processor.compute_all()",
        "        return processor",
        "",
        "    def test_query_returns_results(self, moe_processor):",
        "        result = moe_processor.query(\"neural networks\")",
        "        assert len(result.documents) > 0",
        "        assert result.expert_weights  # Routing occurred",
        "",
        "    def test_expert_contributions_tracked(self, moe_processor):",
        "        result = moe_processor.query(\"neural networks\", explain=True)",
        "        total_contributed = sum(",
        "            len(docs) for docs in result.expert_contributions.values()",
        "        )",
        "        assert total_contributed >= len(result.documents)",
        "```",
        "",
        "### 12.3 Performance Tests",
        "",
        "```python",
        "# tests/performance/test_moe_performance.py",
        "",
        "class TestMoEPerformance:",
        "    \"\"\"Performance regression tests.\"\"\"",
        "",
        "    def test_simple_query_under_50ms(self, moe_processor):",
        "        start = time.perf_counter()",
        "        moe_processor.query(\"authenticate\", top_n=10)",
        "        elapsed_ms = (time.perf_counter() - start) * 1000",
        "        assert elapsed_ms < 50, f\"Simple query took {elapsed_ms}ms\"",
        "",
        "    def test_complex_query_under_300ms(self, moe_processor):",
        "        start = time.perf_counter()",
        "        moe_processor.query(\"how does user authentication flow work?\", top_n=10)",
        "        elapsed_ms = (time.perf_counter() - start) * 1000",
        "        assert elapsed_ms < 300, f\"Complex query took {elapsed_ms}ms\"",
        "",
        "    def test_routing_overhead_under_10ms(self, moe_processor):",
        "        # Measure routing only",
        "        start = time.perf_counter()",
        "        moe_processor._router.route(\"test query\")",
        "        elapsed_ms = (time.perf_counter() - start) * 1000",
        "        assert elapsed_ms < 10, f\"Routing took {elapsed_ms}ms\"",
        "```",
        "",
        "---",
        "",
        "## Appendix A: File-to-Component Mapping",
        "",
        "| File | Component | Lines (est.) |",
        "|------|-----------|--------------|",
        "| `moe/__init__.py` | Public exports | 50 |",
        "| `moe/types.py` | Type definitions | 100 |",
        "| `moe/router.py` | Query routing | 300 |",
        "| `moe/fusion.py` | Result fusion | 200 |",
        "| `moe/feedback.py` | Feedback tracking | 150 |",
        "| `moe/cross_pollination.py` | Expert coordination | 150 |",
        "| `moe/experts/base.py` | Base class | 150 |",
        "| `moe/experts/lexical.py` | Lexical expert | 400 |",
        "| `moe/experts/semantic.py` | Semantic expert | 200 |",
        "| `moe/experts/structural.py` | Structural expert | 500 |",
        "| `moe/experts/temporal.py` | Temporal expert | 350 |",
        "| `moe/experts/episodic.py` | Episodic expert | 250 |",
        "| **Total** | | **~2,800** |",
        "",
        "## Appendix B: Dependency Graph",
        "",
        "```mermaid",
        "graph TD",
        "    MoEIndexProcessor --> QueryRouter",
        "    MoEIndexProcessor --> ExpertRegistry",
        "    MoEIndexProcessor --> ResultFusioner",
        "    MoEIndexProcessor --> SharedResources",
        "",
        "    QueryRouter --> FeatureExtractor",
        "    QueryRouter --> IntentParser[IntentParser from query/intent.py]",
        "    QueryRouter --> FeedbackTracker",
        "",
        "    ExpertRegistry --> LexicalExpert",
        "    ExpertRegistry --> SemanticExpert",
        "    ExpertRegistry --> StructuralExpert",
        "    ExpertRegistry --> TemporalExpert",
        "    ExpertRegistry --> EpisodicExpert",
        "",
        "    SemanticExpert --> CorticalTextProcessor",
        "",
        "    ResultFusioner --> RRFFusion",
        "    ResultFusioner --> WeightedScoreFusion",
        "    ResultFusioner --> CrossPollinator",
        "```",
        "",
        "---",
        "",
        "*This design document provides the technical specification for implementing MoE indexes. See [moe-index-implementation-plan.md](moe-index-implementation-plan.md) for the phased implementation approach.*"
      ],
      "lines_removed": [],
      "context_before": [],
      "context_after": [],
      "change_type": "add"
    },
    {
      "file": "docs/moe-index-implementation-plan.md",
      "function": null,
      "start_line": 0,
      "lines_added": [
        "# Mixture of Expert Indexes: Implementation Plan",
        "",
        "**Author:** Claude (AI Assistant)",
        "**Date:** 2025-12-15",
        "**Status:** Proposed",
        "**Prerequisites:**",
        "- [moe-index-knowledge-transfer.md](moe-index-knowledge-transfer.md)",
        "- [moe-index-design.md](moe-index-design.md)",
        "",
        "---",
        "",
        "## Executive Summary",
        "",
        "This document outlines a **6-phase implementation plan** for the Mixture of Expert (MoE) index architecture. The plan prioritizes incremental value delivery, maintaining backward compatibility, and thorough testing at each phase.",
        "",
        "**Timeline:** ~6-8 weeks of focused development (no calendar estimates per project guidelines)",
        "",
        "**Total Estimated Effort:**",
        "- New code: ~2,800 lines",
        "- Test code: ~1,500 lines",
        "- Documentation: ~500 lines",
        "",
        "---",
        "",
        "## Phase Overview",
        "",
        "```",
        "Phase 1: Foundation        ████░░░░░░░░░░░░░░░░ 20%",
        "Phase 2: Lexical Expert    ████████░░░░░░░░░░░░ 40%",
        "Phase 3: Routing & Fusion  ████████████░░░░░░░░ 60%",
        "Phase 4: Additional Experts████████████████░░░░ 80%",
        "Phase 5: Cross-Pollination ██████████████████░░ 90%",
        "Phase 6: Polish & Release  ████████████████████ 100%",
        "```",
        "",
        "| Phase | Description | Dependencies | Key Deliverable |",
        "|-------|-------------|--------------|-----------------|",
        "| 1 | Foundation | None | Base types, interfaces, test fixtures |",
        "| 2 | Lexical Expert | Phase 1 | Fast exact-match search working |",
        "| 3 | Routing & Fusion | Phase 2 | Two-expert MoE system functional |",
        "| 4 | Additional Experts | Phase 3 | Structural, temporal, episodic experts |",
        "| 5 | Cross-Pollination | Phase 4 | Expert coordination enabled |",
        "| 6 | Polish & Release | Phase 5 | Production-ready with docs |",
        "",
        "---",
        "",
        "## Phase 1: Foundation",
        "",
        "**Goal:** Establish core types, interfaces, and testing infrastructure.",
        "",
        "### Tasks",
        "",
        "#### 1.1 Create Package Structure",
        "```",
        "cortical/moe/",
        "├── __init__.py           # Public exports",
        "├── types.py              # Core type definitions",
        "├── experts/",
        "│   ├── __init__.py",
        "│   └── base.py           # Abstract ExpertIndex",
        "└── config.py             # Configuration dataclasses",
        "```",
        "",
        "**Deliverables:**",
        "- [ ] Create `cortical/moe/` directory structure",
        "- [ ] Implement `ExpertResult` dataclass",
        "- [ ] Implement `MoEResult` dataclass",
        "- [ ] Implement `QueryContext` dataclass",
        "- [ ] Implement `MoEConfig` and sub-configs",
        "- [ ] Implement abstract `ExpertIndex` base class",
        "",
        "**Acceptance Criteria:**",
        "- All types are importable from `cortical.moe`",
        "- Types have proper `__slots__` for memory efficiency",
        "- Base class has `@abstractmethod` decorators",
        "- Unit tests pass for type construction",
        "",
        "#### 1.2 Test Infrastructure",
        "```",
        "tests/",
        "├── unit/",
        "│   └── moe/",
        "│       ├── __init__.py",
        "│       ├── test_types.py",
        "│       └── test_base_expert.py",
        "├── integration/",
        "│   └── moe/",
        "│       └── test_moe_integration.py",
        "└── fixtures/",
        "    └── moe_fixtures.py      # Shared test data",
        "```",
        "",
        "**Deliverables:**",
        "- [ ] Create test directory structure",
        "- [ ] Implement `moe_fixtures.py` with test documents",
        "- [ ] Implement mock expert for testing",
        "- [ ] Add MoE tests to CI pipeline",
        "",
        "**Acceptance Criteria:**",
        "- `pytest tests/unit/moe/ -v` runs successfully",
        "- Fixtures provide reproducible test data",
        "- Coverage infrastructure set up",
        "",
        "#### 1.3 Shared Resources",
        "",
        "**Deliverables:**",
        "- [ ] Implement `SharedResources` class",
        "- [ ] Integrate existing `Tokenizer`",
        "- [ ] Implement document store interface",
        "",
        "**Acceptance Criteria:**",
        "- Resources can be shared across multiple experts",
        "- Document store supports add/remove/get operations",
        "",
        "### Phase 1 Exit Criteria",
        "",
        "- [ ] All foundation types implemented and tested",
        "- [ ] Abstract `ExpertIndex` defines complete interface",
        "- [ ] Test fixtures provide adequate coverage data",
        "- [ ] `python -m pytest tests/unit/moe/ -v` passes",
        "- [ ] Code review completed",
        "",
        "---",
        "",
        "## Phase 2: Lexical Expert + Semantic Wrapper",
        "",
        "**Goal:** Implement first two experts with basic querying.",
        "",
        "### Tasks",
        "",
        "#### 2.1 Lexical Expert Implementation",
        "",
        "**Deliverables:**",
        "- [ ] Implement `Posting` dataclass (doc_id, positions, tf)",
        "- [ ] Implement `DocStats` dataclass",
        "- [ ] Implement inverted index structure",
        "- [ ] Implement `add_document()` method",
        "- [ ] Implement `remove_document()` method",
        "- [ ] Implement BM25 scoring algorithm",
        "- [ ] Implement `query()` method",
        "- [ ] Implement phrase matching (optional)",
        "- [ ] Implement persistence (`save`/`load`)",
        "",
        "**Acceptance Criteria:**",
        "- Lexical expert can index 1000 documents in <5 seconds",
        "- Simple queries return in <10ms",
        "- BM25 scores match reference implementation",
        "- Persistence round-trips correctly",
        "",
        "**Test Cases:**",
        "```python",
        "def test_lexical_exact_match():",
        "    expert = LexicalExpert()",
        "    expert.add_document(\"doc1\", \"neural networks process data\")",
        "    result = expert.query(\"neural\")",
        "    assert \"doc1\" in result.documents",
        "",
        "def test_lexical_bm25_ranking():",
        "    expert = LexicalExpert()",
        "    expert.add_document(\"doc1\", \"neural neural neural\")  # High TF",
        "    expert.add_document(\"doc2\", \"neural networks\")",
        "    result = expert.query(\"neural\")",
        "    assert result.documents[0] == \"doc1\"  # Higher TF wins",
        "",
        "def test_lexical_phrase_query():",
        "    expert = LexicalExpert()",
        "    expert.add_document(\"doc1\", \"machine learning algorithms\")",
        "    result = expert.query('\"machine learning\"')  # Phrase",
        "    assert \"doc1\" in result.documents",
        "```",
        "",
        "#### 2.2 Semantic Expert Wrapper",
        "",
        "**Deliverables:**",
        "- [ ] Implement `SemanticExpert` wrapping `CorticalTextProcessor`",
        "- [ ] Implement delegation for `add_document`",
        "- [ ] Implement delegation for `query`",
        "- [ ] Implement staleness pass-through",
        "- [ ] Implement persistence (reuse processor's)",
        "",
        "**Acceptance Criteria:**",
        "- Semantic expert produces same results as raw processor",
        "- No regression in existing functionality",
        "- Wrapper adds <5ms overhead",
        "",
        "**Test Cases:**",
        "```python",
        "def test_semantic_matches_processor():",
        "    processor = CorticalTextProcessor()",
        "    processor.process_document(\"doc1\", \"neural networks\")",
        "    processor.compute_all()",
        "",
        "    expert = SemanticExpert(processor)",
        "    result = expert.query(\"neural\")",
        "",
        "    # Should match processor output",
        "    processor_result = processor.find_documents_for_query(\"neural\")",
        "    assert result.documents == [d for d, _ in processor_result]",
        "```",
        "",
        "#### 2.3 Expert Registry",
        "",
        "**Deliverables:**",
        "- [ ] Implement `ExpertRegistry` class",
        "- [ ] Support expert registration/lookup",
        "- [ ] Support expert lifecycle management",
        "",
        "**Acceptance Criteria:**",
        "- Experts can be registered by name",
        "- Registry validates expert interface compliance",
        "- Registry supports iteration",
        "",
        "### Phase 2 Exit Criteria",
        "",
        "- [ ] Lexical expert passes all unit tests",
        "- [ ] Semantic wrapper passes all unit tests",
        "- [ ] Both experts can be queried independently",
        "- [ ] Performance benchmarks established",
        "- [ ] Code coverage >85% for new code",
        "",
        "---",
        "",
        "## Phase 3: Routing and Fusion",
        "",
        "**Goal:** Implement query routing and result fusion for two-expert system.",
        "",
        "### Tasks",
        "",
        "#### 3.1 Feature Extraction",
        "",
        "**Deliverables:**",
        "- [ ] Implement `QueryFeatures` dataclass",
        "- [ ] Implement `FeatureExtractor` class",
        "- [ ] Extract: length, quotes, identifiers, question words",
        "- [ ] Extract: time expressions, code patterns",
        "- [ ] Extract: semantic density, specificity",
        "",
        "**Test Cases:**",
        "```python",
        "def test_feature_extraction():",
        "    extractor = FeatureExtractor()",
        "",
        "    # Short exact query",
        "    f1 = extractor.extract(\"authenticate\")",
        "    assert f1.length == 1",
        "    assert not f1.has_question_word",
        "",
        "    # Question query",
        "    f2 = extractor.extract(\"how does authentication work?\")",
        "    assert f2.has_question_word",
        "",
        "    # Code query",
        "    f3 = extractor.extract(\"getUserCredentials\")",
        "    assert f3.has_identifiers",
        "```",
        "",
        "#### 3.2 Feature-Based Gating",
        "",
        "**Deliverables:**",
        "- [ ] Implement `FeatureBasedGate` class",
        "- [ ] Define feature→expert weight mappings",
        "- [ ] Implement weight computation",
        "- [ ] Implement normalization",
        "",
        "**Acceptance Criteria:**",
        "- Gate produces valid probability distribution",
        "- Short queries favor lexical expert",
        "- Question queries favor semantic expert",
        "",
        "#### 3.3 Intent-Based Gating",
        "",
        "**Deliverables:**",
        "- [ ] Implement `IntentBasedGate` class",
        "- [ ] Integrate with existing intent parser",
        "- [ ] Define intent→expert mappings",
        "- [ ] Handle unknown intents gracefully",
        "",
        "**Acceptance Criteria:**",
        "- All known intents have mappings",
        "- Unknown intents fall back to reasonable defaults",
        "",
        "#### 3.4 Query Router",
        "",
        "**Deliverables:**",
        "- [ ] Implement `QueryRouter` class",
        "- [ ] Combine feature and intent gating",
        "- [ ] Implement top-K selection",
        "- [ ] Add routing metrics collection",
        "",
        "**Test Cases:**",
        "```python",
        "def test_router_selects_topk():",
        "    router = QueryRouter(RouterConfig(default_top_k=2))",
        "    weights = router.route(\"test query\")",
        "    assert len(weights) == 2",
        "    assert all(w > 0 for _, w in weights)",
        "",
        "def test_router_normalizes():",
        "    router = QueryRouter()",
        "    weights = router.route(\"test query\")",
        "    total = sum(w for _, w in weights)",
        "    assert abs(total - 1.0) < 0.01",
        "```",
        "",
        "#### 3.5 Result Fusion",
        "",
        "**Deliverables:**",
        "- [ ] Implement `ScoreNormalizer` (min-max, z-score)",
        "- [ ] Implement `RRFFusion` class",
        "- [ ] Implement `WeightedScoreFusion` class",
        "- [ ] Implement `ResultFusioner` orchestrator",
        "",
        "**Test Cases:**",
        "```python",
        "def test_rrf_fusion():",
        "    fusioner = RRFFusion(k=60)",
        "    results = {",
        "        'lexical': ExpertResult(documents=['a', 'b', 'c'], ...),",
        "        'semantic': ExpertResult(documents=['b', 'c', 'd'], ...),",
        "    }",
        "    fused = fusioner.fuse(results, {'lexical': 0.5, 'semantic': 0.5})",
        "",
        "    # 'b' and 'c' appear in both, should rank high",
        "    top_docs = [d for d, _ in fused[:2]]",
        "    assert 'b' in top_docs or 'c' in top_docs",
        "```",
        "",
        "#### 3.6 MoEIndexProcessor (Basic)",
        "",
        "**Deliverables:**",
        "- [ ] Implement `MoEIndexProcessor` class",
        "- [ ] Wire together router, experts, fusioner",
        "- [ ] Implement `add_document()` (multi-expert)",
        "- [ ] Implement `query()` method",
        "- [ ] Implement backward-compatible methods",
        "",
        "**Test Cases:**",
        "```python",
        "def test_moe_basic_query():",
        "    processor = MoEIndexProcessor()",
        "    processor.add_document(\"doc1\", \"neural networks\")",
        "    processor.compute_all()",
        "",
        "    result = processor.query(\"neural\")",
        "    assert \"doc1\" in result.documents",
        "",
        "def test_moe_backward_compat():",
        "    processor = MoEIndexProcessor()",
        "    processor.add_document(\"doc1\", \"neural networks\")",
        "    processor.compute_all()",
        "",
        "    # Old API should still work",
        "    results = processor.find_documents_for_query(\"neural\")",
        "    assert len(results) > 0",
        "```",
        "",
        "### Phase 3 Exit Criteria",
        "",
        "- [ ] Router correctly distributes queries to experts",
        "- [ ] Fusion produces coherent rankings",
        "- [ ] Two-expert MoE system fully functional",
        "- [ ] Backward compatibility tests pass",
        "- [ ] Integration tests pass",
        "- [ ] Performance: simple query <50ms, complex <300ms",
        "",
        "---",
        "",
        "## Phase 4: Additional Experts",
        "",
        "**Goal:** Implement structural, temporal, and episodic experts.",
        "",
        "### Tasks",
        "",
        "#### 4.1 Structural Expert",
        "",
        "**Deliverables:**",
        "- [ ] Implement `SymbolDef` dataclass",
        "- [ ] Implement symbol table structure",
        "- [ ] Implement basic code parsing (regex-based)",
        "- [ ] Implement call graph construction",
        "- [ ] Implement import graph construction",
        "- [ ] Implement `query()` for symbol search",
        "- [ ] Implement `query()` for \"calls X\" patterns",
        "- [ ] Implement `query()` for \"called by X\" patterns",
        "",
        "**Acceptance Criteria:**",
        "- Correctly identifies function/class definitions",
        "- Call graph captures direct calls",
        "- Import graph captures module dependencies",
        "- Symbol queries return relevant files",
        "",
        "**Test Cases:**",
        "```python",
        "def test_structural_symbol_search():",
        "    expert = StructuralExpert()",
        "    expert.add_document(\"auth.py\", \"def authenticate(user): ...\")",
        "    result = expert.query(\"authenticate\")",
        "    assert \"auth.py\" in result.documents",
        "",
        "def test_structural_calls():",
        "    expert = StructuralExpert()",
        "    expert.add_document(\"main.py\", \"def main(): authenticate(user)\")",
        "    expert.add_document(\"auth.py\", \"def authenticate(user): ...\")",
        "    result = expert.query(\"what calls authenticate\")",
        "    assert \"main.py\" in result.documents",
        "```",
        "",
        "#### 4.2 Temporal Expert",
        "",
        "**Deliverables:**",
        "- [ ] Implement `ChangeEvent` dataclass",
        "- [ ] Implement document history tracking",
        "- [ ] Implement time-based index",
        "- [ ] Implement co-change matrix",
        "- [ ] Implement time expression parsing",
        "- [ ] Implement recency-weighted scoring",
        "- [ ] Implement \"changed recently\" queries",
        "- [ ] Implement \"changed together\" queries",
        "",
        "**Acceptance Criteria:**",
        "- Tracks document modifications over time",
        "- Correctly identifies recently changed documents",
        "- Co-change correlations are accurate",
        "",
        "**Test Cases:**",
        "```python",
        "def test_temporal_recency():",
        "    expert = TemporalExpert()",
        "    expert.add_document(\"old.py\", \"...\", timestamp=datetime(2024, 1, 1))",
        "    expert.add_document(\"new.py\", \"...\", timestamp=datetime(2025, 1, 1))",
        "    result = expert.query(\"recently changed\")",
        "    assert result.documents[0] == \"new.py\"",
        "",
        "def test_temporal_cochange():",
        "    expert = TemporalExpert()",
        "    # Simulate files changed together",
        "    expert.record_change(\"a.py\", commit=\"c1\")",
        "    expert.record_change(\"b.py\", commit=\"c1\")",
        "    expert.record_change(\"c.py\", commit=\"c2\")",
        "",
        "    result = expert.query(\"files changed with a.py\")",
        "    assert \"b.py\" in result.documents",
        "```",
        "",
        "#### 4.3 Episodic Expert",
        "",
        "**Deliverables:**",
        "- [ ] Implement `QueryEvent` dataclass",
        "- [ ] Implement query history (ring buffer)",
        "- [ ] Implement click tracking",
        "- [ ] Implement session context vector",
        "- [ ] Implement continuation pattern detection",
        "- [ ] Implement context-boosted scoring",
        "",
        "**Acceptance Criteria:**",
        "- Session history is maintained correctly",
        "- Recent queries influence results",
        "- Click patterns affect ranking",
        "",
        "**Test Cases:**",
        "```python",
        "def test_episodic_session_context():",
        "    expert = EpisodicExpert()",
        "",
        "    # Simulate session",
        "    expert.record_query(\"authentication\", results=[\"auth.py\"])",
        "    expert.record_click(\"auth.py\")",
        "",
        "    # Related query should be influenced",
        "    result = expert.query(\"security\")",
        "    # auth.py should get session boost",
        "```",
        "",
        "#### 4.4 Integration with Router",
        "",
        "**Deliverables:**",
        "- [ ] Update router for 5-expert system",
        "- [ ] Add structural routing rules",
        "- [ ] Add temporal routing rules",
        "- [ ] Add episodic routing rules",
        "- [ ] Update fusion for variable expert counts",
        "",
        "**Acceptance Criteria:**",
        "- All 5 experts can be routed to",
        "- Router handles partial expert availability",
        "- Fusion scales to 5 experts",
        "",
        "### Phase 4 Exit Criteria",
        "",
        "- [ ] All 5 experts implemented and tested",
        "- [ ] Router correctly routes to all experts",
        "- [ ] Fusion handles all combinations",
        "- [ ] Performance within targets",
        "- [ ] Code coverage >80% for all experts",
        "",
        "---",
        "",
        "## Phase 5: Cross-Pollination",
        "",
        "**Goal:** Enable experts to inform and enhance each other.",
        "",
        "### Tasks",
        "",
        "#### 5.1 Cross-Pollination Interface",
        "",
        "**Deliverables:**",
        "- [ ] Define `CrossPollinationContext` interface",
        "- [ ] Implement `CrossPollinator` class",
        "- [ ] Implement semantic→lexical expansion sharing",
        "- [ ] Implement structural→semantic boosting",
        "- [ ] Implement temporal→all recency weighting",
        "",
        "**Acceptance Criteria:**",
        "- Cross-pollination improves result quality",
        "- No significant latency increase (<20ms)",
        "- Cross-pollination can be disabled via config",
        "",
        "**Test Cases:**",
        "```python",
        "def test_cross_pollination_improves_results():",
        "    processor = MoEIndexProcessor(",
        "        config=MoEConfig(enable_cross_pollination=True)",
        "    )",
        "    # Add documents...",
        "    processor.compute_all()",
        "",
        "    # Query with cross-pollination",
        "    result_with = processor.query(\"authentication\")",
        "",
        "    # Query without",
        "    processor._config.enable_cross_pollination = False",
        "    result_without = processor.query(\"authentication\")",
        "",
        "    # Should have different rankings",
        "    assert result_with.documents != result_without.documents",
        "```",
        "",
        "#### 5.2 Feedback Learning",
        "",
        "**Deliverables:**",
        "- [ ] Implement `FeedbackTracker` class",
        "- [ ] Implement query pattern extraction",
        "- [ ] Implement success rate tracking",
        "- [ ] Implement `FeedbackAdaptiveGate`",
        "- [ ] Integrate feedback into router",
        "",
        "**Acceptance Criteria:**",
        "- Feedback is recorded correctly",
        "- Routing adapts based on feedback",
        "- Learning rate is appropriate (not too fast/slow)",
        "",
        "**Test Cases:**",
        "```python",
        "def test_feedback_learning():",
        "    router = QueryRouter(RouterConfig(feedback_weight=0.2))",
        "",
        "    # Initial routing",
        "    initial = router.route(\"test query\")",
        "",
        "    # Record positive feedback for lexical",
        "    router.record_feedback(\"test query\", \"lexical\", was_helpful=True)",
        "    router.record_feedback(\"test query\", \"lexical\", was_helpful=True)",
        "",
        "    # Routing should shift toward lexical",
        "    after = router.route(\"test query\")",
        "    lexical_initial = dict(initial).get('lexical', 0)",
        "    lexical_after = dict(after).get('lexical', 0)",
        "    assert lexical_after > lexical_initial",
        "```",
        "",
        "#### 5.3 Coordination Protocol",
        "",
        "**Deliverables:**",
        "- [ ] Implement parallel expert querying",
        "- [ ] Implement result merging protocol",
        "- [ ] Handle expert failures gracefully",
        "- [ ] Add coordination metrics",
        "",
        "**Acceptance Criteria:**",
        "- Experts can be queried in parallel",
        "- Single expert failure doesn't crash system",
        "- Coordination overhead <10ms",
        "",
        "### Phase 5 Exit Criteria",
        "",
        "- [ ] Cross-pollination implemented and tested",
        "- [ ] Feedback learning working",
        "- [ ] Coordination handles failures gracefully",
        "- [ ] Quality metrics show improvement",
        "- [ ] Performance within targets",
        "",
        "---",
        "",
        "## Phase 6: Polish and Release",
        "",
        "**Goal:** Production-ready system with documentation and optimizations.",
        "",
        "### Tasks",
        "",
        "#### 6.1 Performance Optimization",
        "",
        "**Deliverables:**",
        "- [ ] Profile query path",
        "- [ ] Optimize hot paths",
        "- [ ] Add caching where beneficial",
        "- [ ] Lazy loading for unused experts",
        "",
        "**Acceptance Criteria:**",
        "- P50 latency <100ms",
        "- P95 latency <300ms",
        "- Memory footprint <2x baseline",
        "",
        "#### 6.2 Persistence Improvements",
        "",
        "**Deliverables:**",
        "- [ ] Implement atomic multi-expert save",
        "- [ ] Implement incremental update support",
        "- [ ] Implement chunk-based expert storage",
        "- [ ] Version compatibility handling",
        "",
        "**Acceptance Criteria:**",
        "- Save/load round-trips correctly",
        "- Incremental updates work",
        "- Backward compatible with old saves",
        "",
        "#### 6.3 Observability",
        "",
        "**Deliverables:**",
        "- [ ] Add routing metrics",
        "- [ ] Add expert utilization metrics",
        "- [ ] Add latency breakdowns",
        "- [ ] Integrate with existing observability",
        "",
        "**Acceptance Criteria:**",
        "- All metrics accessible via `get_metrics()`",
        "- Metrics integrate with existing system",
        "- Can identify performance bottlenecks",
        "",
        "#### 6.4 Documentation",
        "",
        "**Deliverables:**",
        "- [ ] Update CLAUDE.md with MoE section",
        "- [ ] Write user guide in docs/",
        "- [ ] Add docstrings to all public APIs",
        "- [ ] Add examples to examples/",
        "- [ ] Update architecture.md",
        "",
        "**Acceptance Criteria:**",
        "- All public APIs documented",
        "- Examples are runnable",
        "- Documentation review completed",
        "",
        "#### 6.5 Final Testing",
        "",
        "**Deliverables:**",
        "- [ ] Comprehensive integration tests",
        "- [ ] Performance regression tests",
        "- [ ] Stress tests",
        "- [ ] Backward compatibility tests",
        "- [ ] Dog-fooding on codebase search",
        "",
        "**Acceptance Criteria:**",
        "- All tests pass",
        "- No performance regressions",
        "- Dog-fooding validates real-world usage",
        "",
        "### Phase 6 Exit Criteria",
        "",
        "- [ ] All optimizations complete",
        "- [ ] Documentation complete",
        "- [ ] All tests pass",
        "- [ ] Performance targets met",
        "- [ ] Ready for release",
        "",
        "---",
        "",
        "## Risk Mitigation",
        "",
        "### High-Priority Risks",
        "",
        "| Risk | Likelihood | Impact | Mitigation |",
        "|------|------------|--------|------------|",
        "| Router becomes bottleneck | Medium | High | Keep routing simple, cache patterns |",
        "| Expert quality diverges | Medium | Medium | Regular quality monitoring, diversity loss |",
        "| Storage explosion | Low | Medium | Share resources, lazy loading |",
        "| Integration breaks existing | Low | High | Extensive backward compat tests |",
        "",
        "### Contingency Plans",
        "",
        "1. **If router is too slow:** Fall back to simpler feature-only routing",
        "2. **If experts diverge:** Add diversity regularization or manual tuning",
        "3. **If storage too large:** Implement selective expert loading",
        "4. **If tests fail:** Prioritize backward compatibility over new features",
        "",
        "---",
        "",
        "## Success Metrics",
        "",
        "### Phase Gates",
        "",
        "| Phase | Key Metric | Target |",
        "|-------|------------|--------|",
        "| 1 | Foundation tests pass | 100% |",
        "| 2 | Lexical query latency | <10ms |",
        "| 3 | Two-expert MRR@10 | >0.5 |",
        "| 4 | All experts functional | 5/5 |",
        "| 5 | Cross-poll quality gain | >5% MRR |",
        "| 6 | Production readiness | Checklist complete |",
        "",
        "### Final Success Criteria",
        "",
        "- [ ] Simple query latency <50ms (P95)",
        "- [ ] Complex query latency <300ms (P95)",
        "- [ ] MRR@10 improvement >10% over baseline",
        "- [ ] Expert utilization balanced (20-80% each)",
        "- [ ] Zero breaking changes to public API",
        "- [ ] Code coverage >85%",
        "- [ ] Documentation complete",
        "",
        "---",
        "",
        "## Task Dependencies",
        "",
        "```mermaid",
        "graph TD",
        "    P1[Phase 1: Foundation] --> P2[Phase 2: Lexical + Semantic]",
        "    P2 --> P3[Phase 3: Routing + Fusion]",
        "    P3 --> P4A[Phase 4a: Structural Expert]",
        "    P3 --> P4B[Phase 4b: Temporal Expert]",
        "    P3 --> P4C[Phase 4c: Episodic Expert]",
        "    P4A --> P5[Phase 5: Cross-Pollination]",
        "    P4B --> P5",
        "    P4C --> P5",
        "    P5 --> P6[Phase 6: Polish + Release]",
        "```",
        "",
        "---",
        "",
        "## Quick Reference: File Creation Order",
        "",
        "```",
        "# Phase 1",
        "cortical/moe/__init__.py",
        "cortical/moe/types.py",
        "cortical/moe/config.py",
        "cortical/moe/experts/__init__.py",
        "cortical/moe/experts/base.py",
        "tests/unit/moe/__init__.py",
        "tests/unit/moe/test_types.py",
        "tests/fixtures/moe_fixtures.py",
        "",
        "# Phase 2",
        "cortical/moe/experts/lexical.py",
        "cortical/moe/experts/semantic.py",
        "cortical/moe/registry.py",
        "tests/unit/moe/test_lexical_expert.py",
        "tests/unit/moe/test_semantic_expert.py",
        "",
        "# Phase 3",
        "cortical/moe/features.py",
        "cortical/moe/router.py",
        "cortical/moe/fusion.py",
        "cortical/moe/processor.py",
        "tests/unit/moe/test_router.py",
        "tests/unit/moe/test_fusion.py",
        "tests/integration/moe/test_moe_basic.py",
        "",
        "# Phase 4",
        "cortical/moe/experts/structural.py",
        "cortical/moe/experts/temporal.py",
        "cortical/moe/experts/episodic.py",
        "tests/unit/moe/test_structural_expert.py",
        "tests/unit/moe/test_temporal_expert.py",
        "tests/unit/moe/test_episodic_expert.py",
        "",
        "# Phase 5",
        "cortical/moe/cross_pollination.py",
        "cortical/moe/feedback.py",
        "tests/unit/moe/test_cross_pollination.py",
        "tests/unit/moe/test_feedback.py",
        "tests/integration/moe/test_moe_full.py",
        "",
        "# Phase 6",
        "docs/moe-user-guide.md",
        "examples/moe_demo.py",
        "tests/performance/test_moe_performance.py",
        "```",
        "",
        "---",
        "",
        "## Appendix: Task Checklist Format",
        "",
        "For tracking during implementation, use the merge-friendly task system:",
        "",
        "```bash",
        "# Create implementation tasks",
        "python scripts/new_task.py \"MoE Phase 1: Implement core types\" --priority high --category arch",
        "python scripts/new_task.py \"MoE Phase 1: Create test infrastructure\" --priority high --category test",
        "python scripts/new_task.py \"MoE Phase 2: Implement LexicalExpert\" --priority high --category feature",
        "# ... etc",
        "```",
        "",
        "---",
        "",
        "*This implementation plan provides a structured approach to building the MoE index architecture. Each phase builds on the previous, ensuring incremental progress and continuous testing.*"
      ],
      "lines_removed": [],
      "context_before": [],
      "context_after": [],
      "change_type": "add"
    },
    {
      "file": "docs/moe-index-knowledge-transfer.md",
      "function": null,
      "start_line": 0,
      "lines_added": [
        "# Mixture of Expert Indexes: Knowledge Transfer Document",
        "",
        "**Author:** Claude (AI Assistant)",
        "**Date:** 2025-12-15",
        "**Status:** Design Proposal",
        "**Related:** [architecture.md](architecture.md), [algorithms.md](algorithms.md)",
        "",
        "---",
        "",
        "## Executive Summary",
        "",
        "This document provides comprehensive background knowledge for implementing a **Mixture of Experts (MoE) architecture** for the Cortical Text Processor's indexing system. The core idea: instead of one general-purpose index, maintain multiple specialized \"expert\" indexes, each optimized for different query types, with a learned routing mechanism that selects which experts to activate for each query.",
        "",
        "**Key insight:** Different query types have fundamentally different optimal representations. A code navigation query needs call graph awareness; a semantic similarity query needs distributional embeddings; an exact lookup needs inverted indexes. One index cannot optimize for all.",
        "",
        "---",
        "",
        "## Table of Contents",
        "",
        "1. [Background: Mixture of Experts](#1-background-mixture-of-experts)",
        "2. [Information Retrieval Foundations](#2-information-retrieval-foundations)",
        "3. [Current System Analysis](#3-current-system-analysis)",
        "4. [MoE Applied to Indexing](#4-moe-applied-to-indexing)",
        "5. [Cognitive Science Connections](#5-cognitive-science-connections)",
        "6. [Key Concepts and Terminology](#6-key-concepts-and-terminology)",
        "7. [Prior Art and Research](#7-prior-art-and-research)",
        "8. [Challenges and Considerations](#8-challenges-and-considerations)",
        "9. [Success Metrics](#9-success-metrics)",
        "",
        "---",
        "",
        "## 1. Background: Mixture of Experts",
        "",
        "### 1.1 Origins in Machine Learning",
        "",
        "Mixture of Experts (MoE) was introduced by Jacobs et al. (1991) as a method for combining multiple specialized neural networks. The key insight: rather than training one large model to handle all cases, train multiple smaller \"expert\" models, each specializing in different input regions.",
        "",
        "**Core components:**",
        "1. **Expert networks** - Specialized models for different input patterns",
        "2. **Gating network** - Learns which expert(s) to activate for each input",
        "3. **Combination function** - Merges expert outputs into final prediction",
        "",
        "### 1.2 Mathematical Foundation",
        "",
        "The standard MoE output is:",
        "",
        "```",
        "y = Σᵢ gᵢ(x) · fᵢ(x)",
        "```",
        "",
        "Where:",
        "- `x` is the input",
        "- `fᵢ(x)` is the output of expert `i`",
        "- `gᵢ(x)` is the gating weight for expert `i`",
        "- `Σᵢ gᵢ(x) = 1` (weights sum to 1)",
        "",
        "### 1.3 Sparse MoE",
        "",
        "Modern MoE systems use **sparse activation**—only a subset of experts fire for each input:",
        "",
        "```",
        "y = Σᵢ∈TopK gᵢ(x) · fᵢ(x)",
        "```",
        "",
        "**Benefits:**",
        "- Compute scales with K, not total experts",
        "- Can add experts without slowing inference",
        "- Each expert can specialize more deeply",
        "",
        "### 1.4 Key Properties",
        "",
        "| Property | Description | Relevance to Indexing |",
        "|----------|-------------|----------------------|",
        "| **Conditional computation** | Different inputs activate different experts | Different queries use different indexes |",
        "| **Specialization** | Experts develop distinct competencies | Indexes optimize for specific query types |",
        "| **Scalability** | Add capacity without proportional compute | Add new index types without slowing all queries |",
        "| **Load balancing** | Distribute work across experts | Prevent any single index from bottlenecking |",
        "| **Routing** | Learn optimal expert selection | Learn which index works best for which queries |",
        "",
        "---",
        "",
        "## 2. Information Retrieval Foundations",
        "",
        "### 2.1 The Index Diversity Problem",
        "",
        "Different IR tasks require different data structures:",
        "",
        "| Query Type | Optimal Structure | Why |",
        "|------------|-------------------|-----|",
        "| Exact match | Inverted index, hash maps | O(1) lookup |",
        "| Phrase match | Positional index | Word order matters |",
        "| Semantic similarity | Dense embeddings | Distributional semantics |",
        "| Faceted search | Bitmap indexes | Fast set operations |",
        "| Code navigation | AST, call graphs | Structural relationships |",
        "| Temporal queries | Time-series indexes | Ordered access patterns |",
        "",
        "**The problem:** A single unified index cannot optimize for all these simultaneously.",
        "",
        "### 2.2 Traditional Approaches",
        "",
        "**Single unified index:**",
        "- Pro: Simple to maintain",
        "- Con: Suboptimal for specialized queries",
        "",
        "**Multiple independent indexes:**",
        "- Pro: Each optimized for its use case",
        "- Con: No coordination, duplicate storage, complex query planning",
        "",
        "**Federated search:**",
        "- Pro: Combines multiple sources",
        "- Con: Late fusion loses cross-index insights",
        "",
        "**MoE indexing is different:** It adds intelligent routing and early fusion, allowing indexes to inform each other.",
        "",
        "### 2.3 Index Types Relevant to This System",
        "",
        "Given the Cortical Text Processor's domain (code search, documentation, semantic analysis), these index types are most relevant:",
        "",
        "#### Lexical Index",
        "- Inverted index with term positions",
        "- BM25/TF-IDF scoring",
        "- Best for: \"Find files containing `authenticate`\"",
        "",
        "#### Semantic Index",
        "- Distributional similarity",
        "- Concept clusters",
        "- Query expansion",
        "- Best for: \"Files about user verification\" (finds auth, login, session)",
        "",
        "#### Structural Index",
        "- Call graphs",
        "- Import relationships",
        "- AST-aware",
        "- Best for: \"What functions call `processDocument`?\"",
        "",
        "#### Temporal Index",
        "- Change history",
        "- Co-change patterns",
        "- Version relationships",
        "- Best for: \"What changed in the last week?\"",
        "",
        "#### Episodic Index",
        "- Session context",
        "- Recent queries",
        "- Navigation patterns",
        "- Best for: \"Similar to what I searched earlier\"",
        "",
        "---",
        "",
        "## 3. Current System Analysis",
        "",
        "### 3.1 Existing Architecture",
        "",
        "The Cortical Text Processor uses a 4-layer hierarchical architecture:",
        "",
        "```",
        "Layer 3 (DOCUMENTS)  ← Full documents",
        "    ↑↓",
        "Layer 2 (CONCEPTS)   ← Semantic clusters (Louvain)",
        "    ↑↓",
        "Layer 1 (BIGRAMS)    ← Word pairs",
        "    ↑↓",
        "Layer 0 (TOKENS)     ← Individual words",
        "```",
        "",
        "**Current strengths:**",
        "- Rich semantic relationships (PageRank, TF-IDF, clustering)",
        "- Query expansion through lateral connections",
        "- Code-aware tokenization",
        "- Intent parsing",
        "",
        "**Current limitations:**",
        "- Single monolithic index serves all query types",
        "- Simple queries pay semantic expansion overhead",
        "- No structural awareness for code queries",
        "- No temporal dimension",
        "",
        "### 3.2 Query Patterns in Current System",
        "",
        "Analyzing how the current system handles different queries:",
        "",
        "| Query Type | Current Handling | Limitation |",
        "|------------|------------------|------------|",
        "| Exact lookup | Full expansion anyway | Overhead |",
        "| Semantic search | Query expansion + TF-IDF | Good, but slow |",
        "| Code navigation | Treats code as text | Misses structure |",
        "| Definition lookup | Heuristic boosting | Not systematic |",
        "| Temporal queries | Not supported | Can't ask \"what changed?\" |",
        "",
        "### 3.3 Data Flow Analysis",
        "",
        "```",
        "Query → Tokenize → Expand → Score Documents → Rank → Return",
        "                     ↓",
        "              (always same path)",
        "```",
        "",
        "**The problem:** Every query follows the same path regardless of type. A simple exact-match query goes through full semantic expansion.",
        "",
        "### 3.4 Performance Characteristics",
        "",
        "From profiling (`scripts/profile_full_analysis.py`):",
        "",
        "| Phase | Time | Notes |",
        "|-------|------|-------|",
        "| Tokenization | ~10ms | Fast |",
        "| Query expansion | ~50-200ms | Variable, depends on connections |",
        "| Document scoring | ~100-500ms | Scales with corpus size |",
        "| Ranking | ~20ms | Fast |",
        "",
        "For simple queries, expansion and scoring dominate—often unnecessarily.",
        "",
        "---",
        "",
        "## 4. MoE Applied to Indexing",
        "",
        "### 4.1 Core Architecture",
        "",
        "```",
        "                    Query",
        "                      │",
        "                      ▼",
        "            ┌─────────────────┐",
        "            │  Query Router   │",
        "            │  (Gating)       │",
        "            └────────┬────────┘",
        "                     │",
        "     ┌───────────────┼───────────────┐",
        "     │ w₁           │ w₂           │ w₃",
        "     ▼               ▼               ▼",
        "┌─────────┐   ┌─────────┐   ┌─────────┐",
        "│ Expert  │   │ Expert  │   │ Expert  │",
        "│ Index 1 │   │ Index 2 │   │ Index 3 │",
        "└────┬────┘   └────┬────┘   └────┬────┘",
        "     │             │             │",
        "     └─────────────┼─────────────┘",
        "                   │",
        "                   ▼",
        "            ┌─────────────┐",
        "            │ Result      │",
        "            │ Fusion      │",
        "            └─────────────┘",
        "```",
        "",
        "### 4.2 Expert Index Specializations",
        "",
        "#### Expert 1: Lexical Index",
        "**Responsibility:** Fast exact and near-exact matching",
        "",
        "**Data structures:**",
        "- Inverted index (term → document list with positions)",
        "- Prefix/suffix tries for autocomplete",
        "- N-gram index for fuzzy matching",
        "",
        "**Scoring:** BM25 (lighter than full TF-IDF graph)",
        "",
        "**When activated:**",
        "- Short queries (< 4 words)",
        "- Quoted phrases",
        "- Code identifiers",
        "- File path patterns",
        "",
        "#### Expert 2: Semantic Index",
        "**Responsibility:** Meaning-based retrieval",
        "",
        "**Data structures:**",
        "- Current 4-layer hierarchy",
        "- Concept clusters",
        "- Query expansion graph",
        "- Synonym/hypernym chains",
        "",
        "**Scoring:** Expanded TF-IDF with PageRank weighting",
        "",
        "**When activated:**",
        "- Question queries (\"how do I...\", \"what is...\")",
        "- Conceptual queries (\"files about authentication\")",
        "- Multi-word descriptive queries",
        "",
        "#### Expert 3: Structural Index",
        "**Responsibility:** Code-aware navigation",
        "",
        "**Data structures:**",
        "- Function call graphs",
        "- Import/dependency DAGs",
        "- Class hierarchies",
        "- Symbol tables with scope",
        "",
        "**Scoring:** Graph distance + reference frequency",
        "",
        "**When activated:**",
        "- Queries with identifiers (camelCase, snake_case)",
        "- \"What calls X\" / \"What does X call\"",
        "- Import/dependency questions",
        "- Type hierarchy questions",
        "",
        "#### Expert 4: Temporal Index",
        "**Responsibility:** Change-aware retrieval",
        "",
        "**Data structures:**",
        "- Document version history",
        "- Change timestamp index",
        "- Co-change correlation matrix",
        "- Commit/edit frequency",
        "",
        "**Scoring:** Recency-weighted relevance",
        "",
        "**When activated:**",
        "- Time expressions (\"recently\", \"last week\")",
        "- Change queries (\"what changed\", \"history of\")",
        "- Trend queries (\"frequently modified\")",
        "",
        "#### Expert 5: Episodic Index",
        "**Responsibility:** Session-aware personalization",
        "",
        "**Data structures:**",
        "- Recent query history (ring buffer)",
        "- Click-through data",
        "- Navigation graph",
        "- User context vector",
        "",
        "**Scoring:** Contextual relevance boost",
        "",
        "**When activated:**",
        "- Continuation queries (\"more like that\")",
        "- Implicit context (recent topics boost)",
        "- Pattern detection (user frequently searches X after Y)",
        "",
        "### 4.3 Gating Mechanisms",
        "",
        "Without ML dependencies (per project philosophy), we implement gating through:",
        "",
        "#### Feature-Based Gating",
        "Extract query features and compute expert weights:",
        "",
        "```",
        "features:",
        "  - query_length (words)",
        "  - has_quotes (bool)",
        "  - has_identifiers (bool)",
        "  - has_question_word (bool)",
        "  - has_time_expression (bool)",
        "  - code_pattern_score (0-1)",
        "",
        "weights[expert] = Σ(feature_weight × feature_value)",
        "```",
        "",
        "#### Intent-Based Gating",
        "Use existing intent parser to route:",
        "",
        "```",
        "intent_to_experts = {",
        "    'definition': ['lexical', 'semantic'],",
        "    'location': ['structural', 'lexical'],",
        "    'explanation': ['semantic'],",
        "    'relationship': ['structural', 'semantic'],",
        "    'history': ['temporal', 'lexical'],",
        "}",
        "```",
        "",
        "#### Feedback-Adaptive Gating",
        "Learn from query success/failure patterns:",
        "",
        "```",
        "success_rate[query_pattern][expert] = successes / total",
        "",
        "weight[expert] = success_rate[pattern][expert] / Σ(success_rates)",
        "```",
        "",
        "### 4.4 Result Fusion Strategies",
        "",
        "#### Weighted Score Combination",
        "```",
        "final_score[doc] = Σ(expert_weight × expert_score[doc])",
        "```",
        "",
        "#### Rank Fusion (Reciprocal Rank Fusion)",
        "```",
        "RRF_score[doc] = Σ(1 / (k + rank[expert][doc]))",
        "```",
        "Where `k` is typically 60.",
        "",
        "#### Learned Combination",
        "Track which expert provided best results for similar queries and weight accordingly.",
        "",
        "### 4.5 Cross-Index Communication",
        "",
        "The real power of MoE over independent indexes: experts can inform each other.",
        "",
        "**Expansion sharing:**",
        "Semantic expert's expanded terms can refine lexical expert's query.",
        "",
        "**Structural boosting:**",
        "Structural expert's \"callers of X\" can boost documents in semantic results.",
        "",
        "**Temporal re-ranking:**",
        "Temporal expert's recency scores can re-rank semantic results.",
        "",
        "**Episodic contextualization:**",
        "Episodic expert's session context influences all other experts.",
        "",
        "---",
        "",
        "## 5. Cognitive Science Connections",
        "",
        "### 5.1 Memory Systems Analogy",
        "",
        "The MoE index architecture maps to cognitive memory systems:",
        "",
        "| Expert Index | Memory System | Function |",
        "|--------------|---------------|----------|",
        "| Lexical | Lexical memory | Word forms, spelling |",
        "| Semantic | Semantic memory | Concepts, meanings, relations |",
        "| Structural | Procedural memory | How things work, sequences |",
        "| Temporal | Episodic memory | Events, when things happened |",
        "| Episodic | Working memory | Recent context, attention |",
        "",
        "### 5.2 Attention as Routing",
        "",
        "The gating network functions like attention:",
        "- **Selective attention**: Not all memory systems are queried for every recall",
        "- **Executive function**: Deciding which systems to engage",
        "- **Inhibition**: Suppressing irrelevant systems",
        "",
        "### 5.3 Spreading Activation",
        "",
        "The current system already uses spreading activation. In MoE:",
        "- Activation can spread **within** experts (current behavior)",
        "- Activation can spread **across** experts (new capability)",
        "",
        "### 5.4 Learning and Adaptation",
        "",
        "Feedback-adaptive gating mirrors:",
        "- **Reinforcement learning**: Success strengthens pathways",
        "- **Habituation**: Repeated patterns become automatic",
        "- **Contextual learning**: Different contexts → different strategies",
        "",
        "---",
        "",
        "## 6. Key Concepts and Terminology",
        "",
        "### Core MoE Terms",
        "",
        "| Term | Definition |",
        "|------|------------|",
        "| **Expert** | A specialized index optimized for specific query types |",
        "| **Gating network** | The component that decides which experts to activate |",
        "| **Routing** | The process of directing queries to appropriate experts |",
        "| **Sparse activation** | Activating only a subset of experts per query |",
        "| **Load balancing** | Distributing queries evenly across experts |",
        "| **Expert capacity** | How many queries an expert can handle |",
        "| **Auxiliary loss** | Training signal encouraging expert specialization |",
        "",
        "### Index-Specific Terms",
        "",
        "| Term | Definition |",
        "|------|------------|",
        "| **Inverted index** | Mapping from terms to documents containing them |",
        "| **Positional index** | Inverted index with word positions for phrase queries |",
        "| **Call graph** | Directed graph of function/method calls |",
        "| **AST** | Abstract Syntax Tree representing code structure |",
        "| **Co-change** | Files that are frequently modified together |",
        "| **Session context** | State accumulated during a user's search session |",
        "",
        "### Fusion Terms",
        "",
        "| Term | Definition |",
        "|------|------------|",
        "| **Early fusion** | Combining signals before scoring |",
        "| **Late fusion** | Combining ranked result lists |",
        "| **Score fusion** | Combining expert scores via weighted sum |",
        "| **Rank fusion** | Combining expert rankings (RRF, Borda count) |",
        "| **Cross-pollination** | Using one expert's output to improve another's |",
        "",
        "### Gating Terms",
        "",
        "| Term | Definition |",
        "|------|------------|",
        "| **Hard routing** | Select exactly K experts, others get weight 0 |",
        "| **Soft routing** | All experts get some weight, even if small |",
        "| **Top-K routing** | Activate only the K highest-weighted experts |",
        "| **Load-balanced routing** | Route to maintain even expert utilization |",
        "| **Hierarchical routing** | Two-level: first coarse, then fine |",
        "",
        "---",
        "",
        "## 7. Prior Art and Research",
        "",
        "### 7.1 MoE in Large Language Models",
        "",
        "Modern LLMs use MoE for efficiency:",
        "",
        "**Switch Transformer (Google, 2021)**",
        "- Simplified routing: route to single expert",
        "- 4x efficiency gains",
        "",
        "**GShard (Google, 2020)**",
        "- Expert parallelism across devices",
        "- Load balancing via auxiliary loss",
        "",
        "**Mixtral (Mistral, 2024)**",
        "- 8 experts, 2 active per token",
        "- Matches GPT-4 at fraction of compute",
        "",
        "**Relevance:** Demonstrates sparse MoE scales efficiently.",
        "",
        "### 7.2 Federated Search and Metasearch",
        "",
        "**CORI (Collection Retrieval Inference)**",
        "- Resource selection for distributed IR",
        "- Estimates collection relevance per query",
        "",
        "**ReDDE (Relevant Document Distribution Estimation)**",
        "- Samples collections to estimate result sizes",
        "- Routes queries to likely-relevant collections",
        "",
        "**Relevance:** Establishes query-dependent source selection.",
        "",
        "### 7.3 Multi-Index Systems",
        "",
        "**Elasticsearch + Vector Search**",
        "- Hybrid BM25 + dense retrieval",
        "- Score fusion via reciprocal rank",
        "",
        "**Vespa Multi-Phase Ranking**",
        "- Fast first-phase (inverted index)",
        "- Expensive second-phase (ML ranking)",
        "",
        "**Relevance:** Production systems combining index types.",
        "",
        "### 7.4 Learning-to-Route",
        "",
        "**Adaptive Query Processing (AQP)**",
        "- Learn cost models for query operators",
        "- Route to minimize latency",
        "",
        "**Learned Index Structures (Kraska et al., 2018)**",
        "- ML models as indexes",
        "- Replace B-trees with neural networks",
        "",
        "**Relevance:** Using learning to improve index selection.",
        "",
        "### 7.5 Relevant Papers",
        "",
        "1. Jacobs et al. (1991) - \"Adaptive Mixtures of Local Experts\"",
        "2. Shazeer et al. (2017) - \"Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer\"",
        "3. Fedus et al. (2021) - \"Switch Transformers: Scaling to Trillion Parameter Models\"",
        "4. Craswell et al. (2020) - \"Overview of TREC 2020 Deep Learning Track\"",
        "5. Tonellotto et al. (2018) - \"Efficient Query Processing for Scalable Web Search\"",
        "",
        "---",
        "",
        "## 8. Challenges and Considerations",
        "",
        "### 8.1 Synchronization Complexity",
        "",
        "**Challenge:** When documents change, all relevant indexes must update consistently.",
        "",
        "**Considerations:**",
        "- Atomic updates across indexes",
        "- Eventual consistency vs. strong consistency",
        "- Version tracking per index",
        "",
        "**Mitigation:**",
        "- Transaction wrapper for multi-index updates",
        "- Staleness tracking per index (extend existing system)",
        "- Batch updates to amortize overhead",
        "",
        "### 8.2 Storage Overhead",
        "",
        "**Challenge:** Multiple indexes store overlapping information.",
        "",
        "**Estimation:**",
        "- Lexical index: ~0.3x document size",
        "- Semantic index: ~1.0x document size (current)",
        "- Structural index: ~0.2x document size (code only)",
        "- Temporal index: ~0.1x document size",
        "- Episodic index: ~0.05x document size",
        "",
        "**Total:** ~1.6-2x current storage",
        "",
        "**Mitigation:**",
        "- Share common data structures where possible",
        "- Lazy building of expensive indexes",
        "- Compression strategies per index type",
        "",
        "### 8.3 Cold Start Problem",
        "",
        "**Challenge:** Without query history, adaptive routing has no signal.",
        "",
        "**Mitigation:**",
        "- Feature-based routing as fallback",
        "- Prior distributions from intent analysis",
        "- Rapid adaptation with small learning rate",
        "",
        "### 8.4 Expert Collapse",
        "",
        "**Challenge:** All experts may converge to similar behavior.",
        "",
        "**Detection:**",
        "- Monitor result set diversity across experts",
        "- Track routing weight distributions",
        "",
        "**Mitigation:**",
        "- Diversity regularization",
        "- Negative correlation encouragement",
        "- Explicit specialization via data partitioning",
        "",
        "### 8.5 Router Complexity",
        "",
        "**Challenge:** Router becomes a bottleneck if too complex.",
        "",
        "**Target:** Router should be <10% of total query latency.",
        "",
        "**Mitigation:**",
        "- Simple feature extraction",
        "- Cached routing for repeated patterns",
        "- Hierarchical routing to reduce expert comparisons",
        "",
        "### 8.6 Evaluation Difficulty",
        "",
        "**Challenge:** How to evaluate individual experts vs. ensemble?",
        "",
        "**Approach:**",
        "- Ablation studies (remove one expert)",
        "- Expert contribution tracking",
        "- User satisfaction metrics",
        "",
        "---",
        "",
        "## 9. Success Metrics",
        "",
        "### 9.1 Latency Metrics",
        "",
        "| Metric | Target | Measurement |",
        "|--------|--------|-------------|",
        "| Router overhead | <10ms | Time from query to expert selection |",
        "| Simple query latency | <50ms | Lexical-only queries |",
        "| Complex query latency | <300ms | Multi-expert semantic queries |",
        "| P95 latency | <500ms | 95th percentile across all queries |",
        "",
        "### 9.2 Quality Metrics",
        "",
        "| Metric | Target | Measurement |",
        "|--------|--------|-------------|",
        "| MRR@10 | >0.6 | Mean reciprocal rank at 10 |",
        "| Precision@5 | >0.7 | Relevant in top 5 |",
        "| Expert utilization | 20-80% each | No expert over/underused |",
        "| Result diversity | >0.5 Jaccard | Experts return different results |",
        "",
        "### 9.3 Efficiency Metrics",
        "",
        "| Metric | Target | Measurement |",
        "|--------|--------|-------------|",
        "| Sparse activation rate | 2-3 experts/query | Average experts activated |",
        "| Storage overhead | <2x baseline | Total index size |",
        "| Index update time | <2x baseline | Time to add document |",
        "| Memory footprint | <1.5x baseline | Runtime memory |",
        "",
        "### 9.4 Operational Metrics",
        "",
        "| Metric | Target | Measurement |",
        "|--------|--------|-------------|",
        "| Routing accuracy | >80% | Expert selected matches query type |",
        "| Fallback rate | <10% | Queries requiring all experts |",
        "| Error isolation | 100% | Single expert failure doesn't crash system |",
        "",
        "---",
        "",
        "## Appendix A: Glossary Cross-Reference",
        "",
        "See [glossary.md](glossary.md) for definitions of core terms used throughout this document.",
        "",
        "## Appendix B: Related Documentation",
        "",
        "- [architecture.md](architecture.md) - Current system architecture",
        "- [algorithms.md](algorithms.md) - Core algorithm details",
        "- [moe-index-design.md](moe-index-design.md) - Technical design specification",
        "- [moe-index-implementation-plan.md](moe-index-implementation-plan.md) - Implementation phases",
        "",
        "---",
        "",
        "*This knowledge transfer document provides the conceptual foundation for the MoE index architecture. Refer to the design document for technical specifications and the implementation plan for development phases.*"
      ],
      "lines_removed": [],
      "context_before": [],
      "context_after": [],
      "change_type": "add"
    }
  ],
  "hour_of_day": 6,
  "day_of_week": "Monday",
  "seconds_since_last_commit": -27469,
  "is_merge": false,
  "is_initial": false,
  "parent_count": 1,
  "session_id": null,
  "related_chats": [],
  "ci_result": null,
  "reverted": false,
  "amended": false
}