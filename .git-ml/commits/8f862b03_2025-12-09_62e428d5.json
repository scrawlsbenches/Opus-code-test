{
  "hash": "8f862b03ab54f1dc2453a9db92567fb6047010e0",
  "message": "Persist full computed state including embeddings (Task 12)",
  "author": "Claude",
  "timestamp": "2025-12-09 19:56:02 +0000",
  "branch": "claude/multi-index-design-DvifZ",
  "files_changed": [
    "cortical/persistence.py",
    "cortical/processor.py",
    "tests/test_persistence.py"
  ],
  "insertions": 94,
  "deletions": 19,
  "hunks": [
    {
      "file": "cortical/persistence.py",
      "function": "from typing import Dict, Optional, Any",
      "start_line": 17,
      "lines_added": [
        "    embeddings: Optional[Dict[str, list]] = None,",
        "    semantic_relations: Optional[list] = None,",
        "        embeddings: Graph embeddings for terms (optional)",
        "        semantic_relations: Extracted semantic relations (optional)",
        "        'version': '2.2',",
        "        'embeddings': embeddings or {},",
        "        'semantic_relations': semantic_relations or [],",
        "",
        "",
        "",
        "        if embeddings:",
        "            print(f\"  - {len(embeddings)} embeddings\")",
        "        if semantic_relations:",
        "            print(f\"  - {len(semantic_relations)} semantic relations\")",
        "        Tuple of (layers, documents, document_metadata, embeddings, semantic_relations, metadata)",
        "    embeddings = state.get('embeddings', {})",
        "    semantic_relations = state.get('semantic_relations', [])",
        "        if embeddings:",
        "            print(f\"  - {len(embeddings)} embeddings\")",
        "        if semantic_relations:",
        "            print(f\"  - {len(semantic_relations)} semantic relations\")",
        "    return layers, documents, document_metadata, embeddings, semantic_relations, metadata"
      ],
      "lines_removed": [
        "        'version': '2.1',",
        "    ",
        "    ",
        "    ",
        "        Tuple of (layers, documents, document_metadata, metadata)",
        "    return layers, documents, document_metadata, metadata"
      ],
      "context_before": [
        "",
        "from .layers import CorticalLayer, HierarchicalLayer",
        "from .minicolumn import Minicolumn",
        "",
        "",
        "def save_processor(",
        "    filepath: str,",
        "    layers: Dict[CorticalLayer, HierarchicalLayer],",
        "    documents: Dict[str, str],",
        "    document_metadata: Optional[Dict[str, Dict[str, Any]]] = None,"
      ],
      "context_after": [
        "    metadata: Optional[Dict] = None,",
        "    verbose: bool = True",
        ") -> None:",
        "    \"\"\"",
        "    Save processor state to a file.",
        "",
        "    Args:",
        "        filepath: Path to save file",
        "        layers: Dictionary of all layers",
        "        documents: Document collection",
        "        document_metadata: Per-document metadata (source, timestamp, etc.)",
        "        metadata: Optional processor metadata (version, settings, etc.)",
        "        verbose: Print progress",
        "    \"\"\"",
        "    state = {",
        "        'layers': {},",
        "        'documents': documents,",
        "        'document_metadata': document_metadata or {},",
        "        'metadata': metadata or {}",
        "    }",
        "    # Serialize layers",
        "    for layer_enum, layer in layers.items():",
        "        state['layers'][layer_enum.value] = layer.to_dict()",
        "    with open(filepath, 'wb') as f:",
        "        pickle.dump(state, f, protocol=pickle.HIGHEST_PROTOCOL)",
        "    if verbose:",
        "        total_cols = sum(len(layer.minicolumns) for layer in layers.values())",
        "        total_conns = sum(layer.total_connections() for layer in layers.values())",
        "        print(f\"✓ Saved processor to {filepath}\")",
        "        print(f\"  - {len(documents)} documents\")",
        "        print(f\"  - {total_cols} minicolumns\")",
        "        print(f\"  - {total_conns} connections\")",
        "",
        "",
        "def load_processor(",
        "    filepath: str,",
        "    verbose: bool = True",
        ") -> tuple:",
        "    \"\"\"",
        "    Load processor state from a file.",
        "",
        "    Args:",
        "        filepath: Path to saved file",
        "        verbose: Print progress",
        "",
        "    Returns:",
        "    \"\"\"",
        "    with open(filepath, 'rb') as f:",
        "        state = pickle.load(f)",
        "",
        "    # Reconstruct layers",
        "    layers = {}",
        "    for level_value, layer_data in state.get('layers', {}).items():",
        "        layer = HierarchicalLayer.from_dict(layer_data)",
        "        layers[CorticalLayer(int(level_value))] = layer",
        "",
        "    documents = state.get('documents', {})",
        "    document_metadata = state.get('document_metadata', {})",
        "    metadata = state.get('metadata', {})",
        "",
        "    if verbose:",
        "        total_cols = sum(len(layer.minicolumns) for layer in layers.values())",
        "        total_conns = sum(layer.total_connections() for layer in layers.values())",
        "        print(f\"✓ Loaded processor from {filepath}\")",
        "        print(f\"  - {len(documents)} documents\")",
        "        print(f\"  - {total_cols} minicolumns\")",
        "        print(f\"  - {total_conns} connections\")",
        "",
        "",
        "",
        "def export_graph_json(",
        "    filepath: str,",
        "    layers: Dict[CorticalLayer, HierarchicalLayer],",
        "    layer_filter: Optional[CorticalLayer] = None,",
        "    min_weight: float = 0.0,",
        "    max_nodes: int = 500,",
        "    verbose: bool = True",
        ") -> Dict:"
      ],
      "change_type": "modify"
    },
    {
      "file": "cortical/processor.py",
      "function": "class CorticalTextProcessor:",
      "start_line": 321,
      "lines_added": [
        "        \"\"\"",
        "        Save processor state to a file.",
        "",
        "        Saves all computed state including embeddings and semantic relations,",
        "        so they don't need to be recomputed when loading.",
        "        \"\"\"",
        "            self.embeddings,",
        "            self.semantic_relations,",
        "        \"\"\"",
        "        Load processor state from a file.",
        "",
        "        Restores all computed state including embeddings and semantic relations.",
        "        \"\"\"",
        "        result = persistence.load_processor(filepath, verbose)",
        "        layers, documents, document_metadata, embeddings, semantic_relations, metadata = result",
        "        processor.embeddings = embeddings",
        "        processor.semantic_relations = semantic_relations"
      ],
      "lines_removed": [
        "        \"\"\"Save processor state to a file.\"\"\"",
        "        \"\"\"Load processor state from a file.\"\"\"",
        "        layers, documents, document_metadata, metadata = persistence.load_processor(filepath, verbose)"
      ],
      "context_before": [
        "    def get_document_signature(self, doc_id: str, n: int = 10) -> List[Tuple[str, float]]:",
        "        layer0 = self.layers[CorticalLayer.TOKENS]",
        "        terms = [(col.content, col.tfidf_per_doc.get(doc_id, col.tfidf)) ",
        "                 for col in layer0.minicolumns.values() if doc_id in col.document_ids]",
        "        return sorted(terms, key=lambda x: x[1], reverse=True)[:n]",
        "    ",
        "    def get_corpus_summary(self) -> Dict:",
        "        return persistence.get_state_summary(self.layers, self.documents)",
        "    ",
        "    def save(self, filepath: str, verbose: bool = True) -> None:"
      ],
      "context_after": [
        "        metadata = {",
        "            'has_embeddings': bool(self.embeddings),",
        "            'has_relations': bool(self.semantic_relations)",
        "        }",
        "        persistence.save_processor(",
        "            filepath,",
        "            self.layers,",
        "            self.documents,",
        "            self.document_metadata,",
        "            metadata,",
        "            verbose",
        "        )",
        "",
        "    @classmethod",
        "    def load(cls, filepath: str, verbose: bool = True) -> 'CorticalTextProcessor':",
        "        processor = cls()",
        "        processor.layers = layers",
        "        processor.documents = documents",
        "        processor.document_metadata = document_metadata",
        "        return processor",
        "    ",
        "    def export_graph(self, filepath: str, layer: Optional[CorticalLayer] = None, max_nodes: int = 500) -> Dict:",
        "        return persistence.export_graph_json(filepath, self.layers, layer, max_nodes=max_nodes)",
        "    ",
        "    def summarize_document(self, doc_id: str, num_sentences: int = 3) -> str:",
        "        if doc_id not in self.documents: return \"\"",
        "        content = self.documents[doc_id]",
        "        sentences = re.split(r'(?<=[.!?])\\s+', content)",
        "        if len(sentences) <= num_sentences: return content"
      ],
      "change_type": "modify"
    },
    {
      "file": "tests/test_persistence.py",
      "function": "class TestSaveLoad(unittest.TestCase):",
      "start_line": 25,
      "lines_added": [
        "                processor.document_metadata, processor.embeddings,",
        "                processor.semantic_relations, verbose=False",
        "            result = load_processor(filepath, verbose=False)",
        "            layers, documents, document_metadata, embeddings, semantic_relations, metadata = result",
        "                processor.document_metadata, processor.embeddings,",
        "                processor.semantic_relations, verbose=False",
        "            result = load_processor(filepath, verbose=False)",
        "            layers, documents, document_metadata, embeddings, semantic_relations, metadata = result",
        "                processor.document_metadata, processor.embeddings,",
        "                processor.semantic_relations, verbose=False",
        "            result = load_processor(filepath, verbose=False)",
        "            layers, documents, document_metadata, embeddings, semantic_relations, metadata = result",
        "                processor.document_metadata, processor.embeddings,",
        "                processor.semantic_relations, verbose=False",
        "            result = load_processor(filepath, verbose=False)",
        "            layers, documents, document_metadata, embeddings, semantic_relations, metadata = result",
        "                processor.document_metadata, processor.embeddings,",
        "                processor.semantic_relations, verbose=False",
        "            result = load_processor(filepath, verbose=False)",
        "            layers, documents, document_metadata, embeddings, semantic_relations, metadata = result",
        "    def test_save_load_preserves_embeddings(self):",
        "        \"\"\"Test that save/load preserves graph embeddings.\"\"\"",
        "        processor = CorticalTextProcessor()",
        "        processor.process_document(\"doc1\", \"Neural networks process information.\")",
        "        processor.compute_all(verbose=False)",
        "        processor.compute_graph_embeddings(dimensions=16, verbose=False)",
        "",
        "        with tempfile.TemporaryDirectory() as tmpdir:",
        "            filepath = os.path.join(tmpdir, \"test.pkl\")",
        "            processor.save(filepath, verbose=False)",
        "",
        "            loaded = CorticalTextProcessor.load(filepath, verbose=False)",
        "",
        "            self.assertEqual(len(loaded.embeddings), len(processor.embeddings))",
        "            # Check a specific embedding is preserved",
        "            for term in processor.embeddings:",
        "                self.assertIn(term, loaded.embeddings)",
        "                self.assertEqual(processor.embeddings[term], loaded.embeddings[term])",
        "",
        "    def test_save_load_preserves_semantic_relations(self):",
        "        \"\"\"Test that save/load preserves semantic relations.\"\"\"",
        "        processor = CorticalTextProcessor()",
        "        processor.process_document(\"doc1\", \"Neural networks are computational models.\")",
        "        processor.process_document(\"doc2\", \"Deep learning uses neural networks.\")",
        "        processor.compute_all(verbose=False)",
        "        processor.extract_corpus_semantics(verbose=False)",
        "",
        "        with tempfile.TemporaryDirectory() as tmpdir:",
        "            filepath = os.path.join(tmpdir, \"test.pkl\")",
        "            processor.save(filepath, verbose=False)",
        "",
        "            loaded = CorticalTextProcessor.load(filepath, verbose=False)",
        "",
        "            self.assertEqual(len(loaded.semantic_relations), len(processor.semantic_relations))",
        ""
      ],
      "lines_removed": [
        "                processor.document_metadata, verbose=False",
        "            layers, documents, document_metadata, metadata = load_processor(filepath, verbose=False)",
        "                processor.document_metadata, verbose=False",
        "            layers, documents, document_metadata, metadata = load_processor(filepath, verbose=False)",
        "                processor.document_metadata, verbose=False",
        "            layers, documents, document_metadata, metadata = load_processor(filepath, verbose=False)",
        "                processor.document_metadata, verbose=False",
        "            layers, documents, document_metadata, metadata = load_processor(filepath, verbose=False)",
        "                processor.document_metadata, verbose=False",
        "            layers, documents, document_metadata, metadata = load_processor(filepath, verbose=False)"
      ],
      "context_before": [
        "        \"\"\"Test saving and loading processor state.\"\"\"",
        "        processor = CorticalTextProcessor()",
        "        processor.process_document(\"doc1\", \"Neural networks process information.\")",
        "        processor.process_document(\"doc2\", \"Machine learning algorithms learn.\")",
        "        processor.compute_all(verbose=False)",
        "",
        "        with tempfile.TemporaryDirectory() as tmpdir:",
        "            filepath = os.path.join(tmpdir, \"test.pkl\")",
        "            save_processor(",
        "                filepath, processor.layers, processor.documents,"
      ],
      "context_after": [
        "            )",
        "",
        "",
        "            self.assertEqual(len(documents), 2)",
        "            self.assertIn(\"doc1\", documents)",
        "            self.assertIn(\"doc2\", documents)",
        "",
        "            # Check layers were restored",
        "            layer0 = layers[CorticalLayer.TOKENS]",
        "            self.assertGreater(len(layer0.minicolumns), 0)",
        "",
        "    def test_save_load_preserves_id_index(self):",
        "        \"\"\"Test that save/load preserves the ID index.\"\"\"",
        "        processor = CorticalTextProcessor()",
        "        processor.process_document(\"doc1\", \"neural networks deep learning\")",
        "        processor.compute_all(verbose=False)",
        "",
        "        with tempfile.TemporaryDirectory() as tmpdir:",
        "            filepath = os.path.join(tmpdir, \"test.pkl\")",
        "            save_processor(",
        "                filepath, processor.layers, processor.documents,",
        "            )",
        "",
        "",
        "            layer0 = layers[CorticalLayer.TOKENS]",
        "            neural = layer0.get_minicolumn(\"neural\")",
        "",
        "            # get_by_id should work after load",
        "            retrieved = layer0.get_by_id(neural.id)",
        "            self.assertEqual(retrieved.content, \"neural\")",
        "",
        "    def test_save_load_preserves_doc_occurrence_counts(self):",
        "        \"\"\"Test that save/load preserves doc_occurrence_counts.\"\"\"",
        "        processor = CorticalTextProcessor()",
        "        processor.process_document(\"doc1\", \"neural neural neural\")  # 3 times",
        "        processor.process_document(\"doc2\", \"neural\")  # 1 time",
        "        processor.compute_all(verbose=False)",
        "",
        "        with tempfile.TemporaryDirectory() as tmpdir:",
        "            filepath = os.path.join(tmpdir, \"test.pkl\")",
        "            save_processor(",
        "                filepath, processor.layers, processor.documents,",
        "            )",
        "",
        "",
        "            layer0 = layers[CorticalLayer.TOKENS]",
        "            neural = layer0.get_minicolumn(\"neural\")",
        "",
        "            self.assertEqual(neural.doc_occurrence_counts.get(\"doc1\"), 3)",
        "            self.assertEqual(neural.doc_occurrence_counts.get(\"doc2\"), 1)",
        "",
        "    def test_save_load_empty_processor(self):",
        "        \"\"\"Test saving and loading empty processor.\"\"\"",
        "        processor = CorticalTextProcessor()",
        "",
        "        with tempfile.TemporaryDirectory() as tmpdir:",
        "            filepath = os.path.join(tmpdir, \"test.pkl\")",
        "            save_processor(",
        "                filepath, processor.layers, processor.documents,",
        "            )",
        "",
        "",
        "            self.assertEqual(len(documents), 0)",
        "",
        "    def test_save_load_preserves_document_metadata(self):",
        "        \"\"\"Test that save/load preserves document metadata.\"\"\"",
        "        processor = CorticalTextProcessor()",
        "        processor.process_document(",
        "            \"doc1\", \"Neural networks process information.\",",
        "            metadata={\"source\": \"https://example.com\", \"author\": \"Test\"}",
        "        )",
        "        processor.compute_all(verbose=False)",
        "",
        "        with tempfile.TemporaryDirectory() as tmpdir:",
        "            filepath = os.path.join(tmpdir, \"test.pkl\")",
        "            save_processor(",
        "                filepath, processor.layers, processor.documents,",
        "            )",
        "",
        "",
        "            self.assertEqual(document_metadata[\"doc1\"][\"source\"], \"https://example.com\")",
        "            self.assertEqual(document_metadata[\"doc1\"][\"author\"], \"Test\")",
        "",
        "",
        "class TestExportGraphJSON(unittest.TestCase):",
        "    \"\"\"Test graph JSON export.\"\"\"",
        "",
        "    def test_export_graph_json(self):",
        "        \"\"\"Test exporting graph to JSON.\"\"\"",
        "        processor = CorticalTextProcessor()",
        "        processor.process_document(\"doc1\", \"neural networks learning\")",
        "        processor.process_document(\"doc2\", \"machine learning algorithms\")",
        "        processor.compute_all(verbose=False)"
      ],
      "change_type": "modify"
    }
  ],
  "hour_of_day": 19,
  "day_of_week": "Tuesday",
  "seconds_since_last_commit": -496126,
  "is_merge": false,
  "is_initial": false,
  "parent_count": 1,
  "session_id": null,
  "related_chats": [],
  "ci_result": null,
  "reverted": false,
  "amended": false
}