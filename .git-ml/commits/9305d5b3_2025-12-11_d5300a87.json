{
  "hash": "9305d5b3949aa4adb1bfc9f03501d698d16d0a61",
  "message": "Add 14 developer experience enhancement tasks (#67-80)",
  "author": "Claude",
  "timestamp": "2025-12-11 01:32:09 +0000",
  "branch": "claude/multi-index-design-DvifZ",
  "files_changed": [
    "TASK_LIST.md"
  ],
  "insertions": 488,
  "deletions": 2,
  "hunks": [
    {
      "file": "TASK_LIST.md",
      "function": null,
      "start_line": 1,
      "lines_added": [
        "**Last Updated:** 2025-12-11",
        "**Status:** Bug fixes complete | Developer experience enhancements planned"
      ],
      "lines_removed": [
        "**Last Updated:** 2025-12-09",
        "**Status:** Bug fixes complete | RAG enhancements planned"
      ],
      "context_before": [
        "# Task List: Bug Fixes & RAG Enhancements",
        "",
        "This document tracks bug fixes and feature enhancements for the Cortical Text Processor.",
        ""
      ],
      "context_after": [
        "",
        "---",
        "",
        "## Critical Priority",
        "",
        "### 1. Fix Per-Document TF-IDF Calculation Bug",
        "",
        "**File:** `cortical/analysis.py`",
        "**Line:** 131",
        "**Status:** [x] Completed"
      ],
      "change_type": "modify"
    },
    {
      "file": "TASK_LIST.md",
      "function": "def find_passages_for_query(..., apply_doc_boost: bool = True):",
      "start_line": 2401,
      "lines_added": [
        "",
        "---",
        "",
        "# Developer Experience Enhancements",
        "",
        "These tasks focus on making the Cortical Text Processor genuinely enjoyable to use for day-to-day development work.",
        "",
        "---",
        "",
        "## Showcase Improvements",
        "",
        "### 67. Fix O(n) Lookup in Showcase find_concept_associations",
        "",
        "**File:** `showcase.py`",
        "**Lines:** 213-218",
        "**Status:** [ ] Not Started",
        "**Priority:** Low",
        "",
        "**Problem:**",
        "The `find_concept_associations` method iterates all minicolumns to find neighbor content:",
        "```python",
        "for c in layer0.minicolumns.values():",
        "    if c.id == neighbor_id:",
        "        # found it",
        "```",
        "",
        "This is O(n) when we have O(1) `get_by_id()` available.",
        "",
        "**Solution:**",
        "```python",
        "neighbor = layer0.get_by_id(neighbor_id)",
        "if neighbor:",
        "    # use neighbor.content",
        "```",
        "",
        "---",
        "",
        "### 68. Add Code-Specific Features to Showcase",
        "",
        "**File:** `showcase.py`",
        "**Status:** [ ] Not Started",
        "**Priority:** Medium",
        "",
        "**Problem:**",
        "The showcase demonstrates general IR capabilities but not code-specific features documented in CLAUDE.md:",
        "- `expand_query_for_code()` - programming-aware query expansion",
        "- `search_by_intent()` - natural language intent queries",
        "- `get_fingerprint()` / `compare_fingerprints()` - code similarity",
        "- `is_conceptual_query()` - query type detection",
        "",
        "**Solution:**",
        "Add new demonstration sections:",
        "1. **Code Query Expansion** - show how \"fetch data\" expands to include \"get\", \"load\", \"retrieve\"",
        "2. **Intent-Based Search** - demonstrate \"where do we handle errors?\" style queries",
        "3. **Code Fingerprinting** - compare two similar functions and explain their similarity",
        "4. **Query Intent Detection** - show how system distinguishes \"what is PageRank\" vs \"compute pagerank\"",
        "",
        "---",
        "",
        "### 69. Add Passage-Level Search Demo to Showcase",
        "",
        "**File:** `showcase.py`",
        "**Status:** [ ] Not Started",
        "**Priority:** Medium",
        "",
        "**Problem:**",
        "`find_passages_for_query()` is the key RAG capability for retrieving relevant code snippets, but it's not demonstrated. This is arguably the most useful feature for LLM integration.",
        "",
        "**Solution:**",
        "Add \"RAG DEMONSTRATION\" section showing:",
        "1. Query → relevant passages with file:line references",
        "2. How passage chunking works",
        "3. Overlap handling for context preservation",
        "4. Use case: feeding context to an LLM",
        "",
        "---",
        "",
        "### 70. Add Performance Timing to Showcase",
        "",
        "**File:** `showcase.py`",
        "**Status:** [ ] Not Started",
        "**Priority:** Low",
        "",
        "**Problem:**",
        "No timing information shown. Users can't gauge performance characteristics.",
        "",
        "**Solution:**",
        "Add timing for key operations:",
        "- Document processing time",
        "- `compute_all()` time",
        "- Query expansion time",
        "- Document search time",
        "- Passage retrieval time",
        "",
        "---",
        "",
        "## Code Index Improvements",
        "",
        "### 71. Enable Code-Aware Tokenization in Index",
        "",
        "**File:** `scripts/index_codebase.py`",
        "**Status:** [ ] Not Started",
        "**Priority:** High",
        "",
        "**Problem:**",
        "The indexer uses default tokenization which doesn't split identifiers. Searching for \"user\" won't find `getUserCredentials` or `user_credentials`.",
        "",
        "**Solution:**",
        "Enable `split_identifiers=True` when creating the processor:",
        "```python",
        "processor = CorticalTextProcessor(",
        "    tokenizer_config={'split_identifiers': True}",
        ")",
        "```",
        "",
        "Or configure per-document based on file type (.py files get identifier splitting).",
        "",
        "**Impact:** Much better code search - \"auth\" would find `authenticate`, `AuthService`, `user_auth`, etc.",
        "",
        "---",
        "",
        "### 72. Use Programming Query Expansion in Search",
        "",
        "**File:** `scripts/search_codebase.py`",
        "**Status:** [ ] Not Started",
        "**Priority:** High",
        "",
        "**Problem:**",
        "Search uses `expand_query()` but not `expand_query_for_code()`. Programming synonyms aren't utilized.",
        "",
        "**Solution:**",
        "```python",
        "# In search_codebase.py",
        "if is_code_query(query):  # Detect if searching for code patterns",
        "    expanded = processor.expand_query_for_code(query)",
        "else:",
        "    expanded = processor.expand_query(query)",
        "```",
        "",
        "**Impact:** \"get data\" would expand to include \"fetch\", \"load\", \"retrieve\", \"read\" variations.",
        "",
        "---",
        "",
        "### 73. Add \"Find Similar Code\" Command",
        "",
        "**Files:** `scripts/search_codebase.py`, `cortical/processor.py`",
        "**Status:** [ ] Not Started",
        "**Priority:** Medium",
        "",
        "**Problem:**",
        "No way to find code similar to a given snippet or function. Fingerprinting exists but isn't exposed.",
        "",
        "**Solution:**",
        "Add `--similar-to` flag:",
        "```bash",
        "# Find code similar to a specific function",
        "python scripts/search_codebase.py --similar-to \"cortical/processor.py:expand_query\"",
        "",
        "# Find code similar to clipboard/stdin",
        "echo \"def process(data): return data.strip()\" | python scripts/search_codebase.py --similar-to -",
        "```",
        "",
        "**Implementation:**",
        "1. Extract fingerprint of target code",
        "2. Compare against all indexed passages",
        "3. Return passages with highest similarity scores",
        "",
        "---",
        "",
        "## Creative Developer Experience Features",
        "",
        "### 74. Add \"Explain This Code\" Command",
        "",
        "**Files:** `scripts/explain_code.py` (new)",
        "**Status:** [ ] Not Started",
        "**Priority:** Medium",
        "",
        "**Problem:**",
        "When jumping into unfamiliar code, it's hard to understand what it does and how it fits into the larger system.",
        "",
        "**Solution:**",
        "Create `explain_code.py` that uses semantic analysis to explain code:",
        "```bash",
        "python scripts/explain_code.py cortical/analysis.py:compute_pagerank",
        "",
        "# Output:",
        "# Function: compute_pagerank",
        "# Purpose: Computes importance scores for tokens using iterative graph algorithm",
        "# ",
        "# Key Concepts: pagerank, damping, convergence, graph, centrality",
        "# Related Files:",
        "#   - cortical/processor.py:789 (calls this function)",
        "#   - tests/test_analysis.py:45 (tests this function)",
        "#   - CLAUDE.md:142 (documents this feature)",
        "# ",
        "# Similar Functions:",
        "#   - compute_tfidf (same file) - also computes term importance",
        "#   - compute_importance (processor.py) - wrapper method",
        "```",
        "",
        "**Implementation:**",
        "1. Parse target location",
        "2. Get semantic fingerprint",
        "3. Find related documents (callers, tests, docs)",
        "4. Find similar code patterns",
        "5. Extract key concepts from local context",
        "",
        "---",
        "",
        "### 75. Add \"What Changed?\" Semantic Diff",
        "",
        "**Files:** `scripts/what_changed.py` (new)",
        "**Status:** [ ] Not Started",
        "**Priority:** Medium",
        "",
        "**Problem:**",
        "Git diff shows line-by-line changes but doesn't explain semantic impact. Hard to review large changes.",
        "",
        "**Solution:**",
        "Create semantic diff tool:",
        "```bash",
        "python scripts/what_changed.py HEAD~5..HEAD",
        "",
        "# Output:",
        "# Semantic Summary of Changes (5 commits)",
        "# ",
        "# New Capabilities:",
        "#   - Doc-type boosting for search results",
        "#   - Chunk-based indexing for git compatibility",
        "# ",
        "# Modified Behaviors:",
        "#   - Query expansion now considers document type",
        "#   - Passage search has new boosting parameter",
        "# ",
        "# Files Most Affected:",
        "#   - cortical/query.py (3 new functions, 2 modified)",
        "#   - scripts/search_codebase.py (new --prefer-docs flag)",
        "# ",
        "# Concepts Impacted: search, ranking, documentation, indexing",
        "```",
        "",
        "**Implementation:**",
        "1. Get changed files from git",
        "2. Re-index changed files",
        "3. Compare fingerprints before/after",
        "4. Identify new concepts, modified concepts, removed concepts",
        "5. Generate natural language summary",
        "",
        "---",
        "",
        "### 76. Add \"Suggest Related Files\" Feature",
        "",
        "**Files:** `scripts/related_files.py` (new), integration with editor",
        "**Status:** [ ] Not Started",
        "**Priority:** Medium",
        "",
        "**Problem:**",
        "When editing a file, you often need to update related files (tests, docs, callers). Easy to miss something.",
        "",
        "**Solution:**",
        "```bash",
        "python scripts/related_files.py cortical/query.py",
        "",
        "# Output:",
        "# Files related to cortical/query.py:",
        "# ",
        "# Tests (should update if changing behavior):",
        "#   - tests/test_processor.py (47 references)",
        "#   - tests/test_query.py (if exists)",
        "# ",
        "# Documentation (should update if changing API):",
        "#   - CLAUDE.md (references: expand_query, find_documents)",
        "#   - docs/usage-patterns.md (examples using query functions)",
        "# ",
        "# Callers (may be affected):",
        "#   - cortical/processor.py (imports 12 functions)",
        "#   - scripts/search_codebase.py (uses find_documents)",
        "# ",
        "# Similar Files (might need same changes):",
        "#   - cortical/analysis.py (similar structure, shared patterns)",
        "```",
        "",
        "**Implementation:**",
        "1. Find all files that import/reference target",
        "2. Find test files that test target",
        "3. Find docs that mention target functions",
        "4. Find files with similar fingerprints",
        "5. Rank by relevance",
        "",
        "---",
        "",
        "### 77. Add Interactive \"Ask the Codebase\" Mode",
        "",
        "**Files:** `scripts/ask_codebase.py` (new)",
        "**Status:** [ ] Not Started",
        "**Priority:** High",
        "",
        "**Problem:**",
        "Current search returns passages but doesn't synthesize answers. You have to read multiple results.",
        "",
        "**Solution:**",
        "Create conversational interface that uses RAG to answer questions:",
        "```bash",
        "python scripts/ask_codebase.py",
        "",
        "Ask> How does query expansion work?",
        "",
        "Based on cortical/query.py:234-298 and CLAUDE.md:156:",
        "",
        "Query expansion works by finding semantically related terms to add to a search:",
        "",
        "1. Tokenizes the query into individual terms",
        "2. For each term, finds lateral connections (co-occurring terms)",
        "3. Weights expansions by connection strength and PageRank",
        "4. Returns expanded query as term→weight dictionary",
        "",
        "Key parameters:",
        "- max_expansions: limit number of added terms (default: 10)",
        "- use_semantic: include typed semantic relations (default: True)",
        "",
        "Sources:",
        "- cortical/query.py:234 (get_expanded_query_terms)",
        "- cortical/query.py:298 (expand_query)",
        "- CLAUDE.md:156 (Quick Reference)",
        "",
        "Ask> What's different about expand_query_for_code?",
        "...",
        "```",
        "",
        "**Implementation:**",
        "1. Take natural language question",
        "2. Detect intent (conceptual vs implementation)",
        "3. Retrieve relevant passages with boosting",
        "4. Synthesize answer from passages (or format for LLM)",
        "5. Include source references",
        "",
        "---",
        "",
        "### 78. Add Code Pattern Detection",
        "",
        "**Files:** `cortical/patterns.py` (new), `scripts/find_patterns.py` (new)",
        "**Status:** [ ] Not Started",
        "**Priority:** Low",
        "",
        "**Problem:**",
        "Hard to find all instances of a pattern (e.g., \"all functions that iterate over minicolumns\").",
        "",
        "**Solution:**",
        "```bash",
        "# Find all places that iterate minicolumns (potential O(n) → O(1) optimization)",
        "python scripts/find_patterns.py \"for.*in.*minicolumns\"",
        "",
        "# Find all TF-IDF calculations",
        "python scripts/find_patterns.py --semantic \"tfidf calculation\"",
        "",
        "# Find potential bugs: linear search where O(1) exists",
        "python scripts/find_patterns.py --smell \"linear-search-with-index\"",
        "```",
        "",
        "**Implementation:**",
        "1. Regex patterns for syntactic search",
        "2. Semantic patterns using fingerprint similarity",
        "3. \"Smell\" patterns for common anti-patterns",
        "4. Report with file:line references",
        "",
        "---",
        "",
        "### 79. Add Corpus Health Dashboard",
        "",
        "**Files:** `scripts/corpus_health.py` (new)",
        "**Status:** [ ] Not Started",
        "**Priority:** Low",
        "",
        "**Problem:**",
        "No visibility into corpus quality - are docs well-connected? Any orphaned files? Coverage gaps?",
        "",
        "**Solution:**",
        "```bash",
        "python scripts/corpus_health.py",
        "",
        "# Output:",
        "# ═══════════════════════════════════════════════════",
        "#            CORPUS HEALTH REPORT",
        "# ═══════════════════════════════════════════════════",
        "# ",
        "# Overall Health: 87% (Good)",
        "# ",
        "# Coverage:",
        "#   ✓ 45/47 Python files indexed",
        "#   ✓ 8/8 documentation files indexed",
        "#   ✗ 2 files not indexed: __init__.py, __pycache__",
        "# ",
        "# Connectivity:",
        "#   ✓ Average doc connections: 12.3",
        "#   ✓ No orphaned documents",
        "#   ⚠ 3 weakly connected: test_*.py files",
        "# ",
        "# Documentation Quality:",
        "#   ✓ All public functions mentioned in docs",
        "#   ⚠ 5 functions lack docstrings",
        "#   ✗ TASK_LIST.md references deleted function",
        "# ",
        "# Index Freshness:",
        "#   ✓ Corpus updated 2 minutes ago",
        "#   ✓ All files current",
        "# ",
        "# Recommendations:",
        "#   1. Add tests for cortical/chunk_index.py (0% coverage)",
        "#   2. Document new functions in query.py:get_doc_type_boost",
        "#   3. Update TASK_LIST.md references",
        "```",
        "",
        "---",
        "",
        "### 80. Add \"Learning Mode\" for New Contributors",
        "",
        "**Files:** `scripts/learn_codebase.py` (new)",
        "**Status:** [ ] Not Started",
        "**Priority:** Low",
        "",
        "**Problem:**",
        "New contributors struggle to understand unfamiliar codebases. Where to start? What's important?",
        "",
        "**Solution:**",
        "Interactive learning mode that guides exploration:",
        "```bash",
        "python scripts/learn_codebase.py",
        "",
        "Welcome to the Cortical Text Processor codebase!",
        "",
        "This codebase implements a hierarchical text analysis system inspired by",
        "how the visual cortex processes information.",
        "",
        "Would you like to:",
        "1. Start with the architecture overview",
        "2. Explore a specific feature",
        "3. See the most important files",
        "4. Take a guided tour",
        "",
        "> 1",
        "",
        "ARCHITECTURE OVERVIEW",
        "═══════════════════════════════════════════════════",
        "",
        "The system has 4 layers, like visual cortex V1→IT:",
        "",
        "  Layer 0 (Tokens)   → Individual words",
        "  Layer 1 (Bigrams)  → Word pairs",
        "  Layer 2 (Concepts) → Semantic clusters",
        "  Layer 3 (Documents)→ Full documents",
        "",
        "Key files to understand:",
        "  1. cortical/processor.py - Main API (start here)",
        "  2. cortical/minicolumn.py - Core data structure",
        "  3. cortical/analysis.py - Graph algorithms",
        "",
        "[Press Enter to explore processor.py, or type a question]",
        "> How does PageRank work here?",
        "",
        "[Retrieves and explains relevant passages...]",
        "```",
        "",
        "---",
        "",
        "## Summary Table",
        "",
        "| # | Priority | Task | Category |",
        "|---|----------|------|----------|",
        "| 67 | Low | Fix O(n) lookup in showcase | Showcase |",
        "| 68 | Medium | Add code-specific features to showcase | Showcase |",
        "| 69 | Medium | Add passage-level search demo | Showcase |",
        "| 70 | Low | Add performance timing to showcase | Showcase |",
        "| 71 | High | Enable code-aware tokenization in index | Code Index |",
        "| 72 | High | Use programming query expansion in search | Code Index |",
        "| 73 | Medium | Add \"Find Similar Code\" command | Code Index |",
        "| 74 | Medium | Add \"Explain This Code\" command | Developer Experience |",
        "| 75 | Medium | Add \"What Changed?\" semantic diff | Developer Experience |",
        "| 76 | Medium | Add \"Suggest Related Files\" feature | Developer Experience |",
        "| 77 | High | Add interactive \"Ask the Codebase\" mode | Developer Experience |",
        "| 78 | Low | Add code pattern detection | Developer Experience |",
        "| 79 | Low | Add corpus health dashboard | Developer Experience |",
        "| 80 | Low | Add \"Learning Mode\" for new contributors | Developer Experience |",
        "",
        "---",
        "",
        "*Added 2025-12-11*"
      ],
      "lines_removed": [],
      "context_before": [
        "| 41 | Medium | Create Configuration Dataclass | [x] Completed | Code Quality |",
        "| 56 | Medium | Create Usage Patterns Documentation | [x] Completed | Documentation |",
        "| 66 | Medium | Add doc-type boost to passage search | [ ] Not Started | Search Quality |",
        "| 42 | Low | Add Simple Query Language Support | [ ] Not Started | Feature |",
        "| 44 | Low | Remove Deprecated feedforward_sources | [ ] Not Started | Code Quality |",
        "| 46 | Low | Standardize Return Types with Dataclasses | [ ] Not Started | Code Quality |",
        "",
        "---",
        "",
        "*Updated 2025-12-11*"
      ],
      "context_after": [],
      "change_type": "add"
    }
  ],
  "hour_of_day": 1,
  "day_of_week": "Thursday",
  "seconds_since_last_commit": -389559,
  "is_merge": false,
  "is_initial": false,
  "parent_count": 1,
  "session_id": null,
  "related_chats": [],
  "ci_result": null,
  "reverted": false,
  "amended": false
}